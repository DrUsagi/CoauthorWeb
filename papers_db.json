{
  "papers": {
    "1908.10345v1": {
      "title": "Artificial Intelligence Approaches",
      "authors": [
        "Yingjie Hu",
        "Wenwen Li",
        "Dawn Wright",
        "Orhun Aydin",
        "Daniel Wilson",
        "Omar Maher",
        "Mansour Raad"
      ],
      "abstract": "Artificial Intelligence (AI) has received tremendous attention from academia,\nindustry, and the general public in recent years. The integration of geography\nand AI, or GeoAI, provides novel approaches for addressing a variety of\nproblems in the natural environment and our human society. This entry briefly\nreviews the recent development of AI with a focus on machine learning and deep\nlearning approaches. We discuss the integration of AI with geography and\nparticularly geographic information science, and present a number of GeoAI\napplications and possible future directions.",
      "citation_count": 103,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fe44f4471e0e774bf173c03697e85843a886ed33",
      "published_date": "2019-08-27",
      "downloaded_date": "2025-01-31",
      "filename": "Hu-Artificial Intelligence Approaches.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1908.10345v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2001.09464v1": {
      "title": "Explainable Artificial Intelligence and Machine Learning: A reality rooted perspective",
      "authors": [
        "Frank Emmert-Streib",
        "Olli Yli-Harja",
        "Matthias Dehmer"
      ],
      "abstract": "We are used to the availability of big data generated in nearly all fields of\nscience as a consequence of technological progress. However, the analysis of\nsuch data possess vast challenges. One of these relates to the explainability\nof artificial intelligence (AI) or machine learning methods. Currently, many of\nsuch methods are non-transparent with respect to their working mechanism and\nfor this reason are called black box models, most notably deep learning\nmethods. However, it has been realized that this constitutes severe problems\nfor a number of fields including the health sciences and criminal justice and\narguments have been brought forward in favor of an explainable AI. In this\npaper, we do not assume the usual perspective presenting explainable AI as it\nshould be, but rather we provide a discussion what explainable AI can be. The\ndifference is that we do not present wishful thinking but reality grounded\nproperties in relation to a scientific theory beyond physics.",
      "citation_count": 79,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a94ce8d1d37be4c9226028c490a7820fe712ac8c",
      "published_date": "2020-01-26",
      "downloaded_date": "2025-01-31",
      "filename": "Emmert-Streib-Explainable Artificial Intelligence and Machine Learning A reality rooted perspective.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2001.09464v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2104.05314v2": {
      "title": "Machine learning and deep learning",
      "authors": [
        "Christian Janiesch",
        "Patrick Zschech",
        "Kai Heinrich"
      ],
      "abstract": "Today, intelligent systems that offer artificial intelligence capabilities\noften rely on machine learning. Machine learning describes the capacity of\nsystems to learn from problem-specific training data to automate the process of\nanalytical model building and solve associated tasks. Deep learning is a\nmachine learning concept based on artificial neural networks. For many\napplications, deep learning models outperform shallow machine learning models\nand traditional data analysis approaches. In this article, we summarize the\nfundamentals of machine learning and deep learning to generate a broader\nunderstanding of the methodical underpinning of current intelligent systems. In\nparticular, we provide a conceptual distinction between relevant terms and\nconcepts, explain the process of automated analytical model building through\nmachine learning and deep learning, and discuss the challenges that arise when\nimplementing such intelligent systems in the field of electronic markets and\nnetworked business. These naturally go beyond technological aspects and\nhighlight issues in human-machine interaction and artificial intelligence\nservitization.",
      "citation_count": 991,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a0f303b6e22ef52943355993f57d65938997066a",
      "published_date": "2021-04-12",
      "downloaded_date": "2025-01-31",
      "filename": "Janiesch-Machine learning and deep learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.05314v2",
      "categories": [
        "cs.AI"
      ]
    },
    "1708.08296v1": {
      "title": "Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models",
      "authors": [
        "Wojciech Samek",
        "Thomas Wiegand",
        "Klaus-Robert MÃ¼ller"
      ],
      "abstract": "With the availability of large databases and recent improvements in deep\nlearning methodology, the performance of AI systems is reaching or even\nexceeding the human level on an increasing number of complex tasks. Impressive\nexamples of this development can be found in domains such as image\nclassification, sentiment analysis, speech understanding or strategic game\nplaying. However, because of their nested non-linear structure, these highly\nsuccessful machine learning and artificial intelligence models are usually\napplied in a black box manner, i.e., no information is provided about what\nexactly makes them arrive at their predictions. Since this lack of transparency\ncan be a major drawback, e.g., in medical applications, the development of\nmethods for visualizing, explaining and interpreting deep learning models has\nrecently attracted increasing attention. This paper summarizes recent\ndevelopments in this field and makes a plea for more interpretability in\nartificial intelligence. Furthermore, it presents two approaches to explaining\npredictions of deep learning models, one method which computes the sensitivity\nof the prediction with respect to changes in the input and one approach which\nmeaningfully decomposes the decision in terms of the input variables. These\nmethods are evaluated on three classification tasks.",
      "citation_count": 1109,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/58e0ca33ae3068fee7005f339bf6c444fc17d55f",
      "published_date": "2017-08-28",
      "downloaded_date": "2025-01-31",
      "filename": "Samek-Explainable Artificial Intelligence Understanding Visualizing and Interpreting Deep Learning Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1708.08296v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.NE",
        "stat.ML"
      ]
    },
    "2009.13411v1": {
      "title": "Artificial Intelligence in Surgery: Neural Networks and Deep Learning",
      "authors": [
        "Deepak Alapatt",
        "Pietro Mascagni",
        "Vinkle Srivastav",
        "Nicolas Padoy"
      ],
      "abstract": "Deep neural networks power most recent successes of artificial intelligence,\nspanning from self-driving cars to computer aided diagnosis in radiology and\npathology. The high-stake data intensive process of surgery could highly\nbenefit from such computational methods. However, surgeons and computer\nscientists should partner to develop and assess deep learning applications of\nvalue to patients and healthcare systems. This chapter and the accompanying\nhands-on material were designed for surgeons willing to understand the\nintuitions behind neural networks, become familiar with deep learning concepts\nand tasks, grasp what implementing a deep learning model in surgery means, and\nfinally appreciate the specific challenges and limitations of deep neural\nnetworks in surgery. For the associated hands-on material, please see\nhttps://github.com/CAMMA-public/ai4surgery.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3456388fad60a1177a187aa39fb35fd33a02e7ab",
      "published_date": "2020-09-28",
      "downloaded_date": "2025-01-31",
      "filename": "Alapatt-Artificial Intelligence in Surgery Neural Networks and Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.13411v1",
      "categories": [
        "cs.NE"
      ]
    },
    "2007.06131v1": {
      "title": "Locality Guided Neural Networks for Explainable Artificial Intelligence",
      "authors": [
        "Randy Tan",
        "Naimul Khan",
        "Ling Guan"
      ],
      "abstract": "In current deep network architectures, deeper layers in networks tend to\ncontain hundreds of independent neurons which makes it hard for humans to\nunderstand how they interact with each other. By organizing the neurons by\ncorrelation, humans can observe how clusters of neighbouring neurons interact\nwith each other. In this paper, we propose a novel algorithm for back\npropagation, called Locality Guided Neural Network(LGNN) for training networks\nthat preserves locality between neighbouring neurons within each layer of a\ndeep network. Heavily motivated by Self-Organizing Map (SOM), the goal is to\nenforce a local topology on each layer of a deep network such that neighbouring\nneurons are highly correlated with each other. This method contributes to the\ndomain of Explainable Artificial Intelligence (XAI), which aims to alleviate\nthe black-box nature of current AI methods and make them understandable by\nhumans. Our method aims to achieve XAI in deep learning without changing the\nstructure of current models nor requiring any post processing. This paper\nfocuses on Convolutional Neural Networks (CNNs), but can theoretically be\napplied to any type of deep learning architecture. In our experiments, we train\nvarious VGG and Wide ResNet (WRN) networks for image classification on\nCIFAR100. In depth analyses presenting both qualitative and quantitative\nresults demonstrate that our method is capable of enforcing a topology on each\nlayer while achieving a small increase in classification accuracy",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/16615aa54126fc12ffd1cbfd79d78a821c398b6b",
      "published_date": "2020-07-12",
      "downloaded_date": "2025-01-31",
      "filename": "Tan-Locality Guided Neural Networks for Explainable Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.06131v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    "1901.11184v1": {
      "title": "Human-Centered Artificial Intelligence and Machine Learning",
      "authors": [
        "Mark O. Riedl"
      ],
      "abstract": "Humans are increasingly coming into contact with artificial intelligence and\nmachine learning systems. Human-centered artificial intelligence is a\nperspective on AI and ML that algorithms must be designed with awareness that\nthey are part of a larger system consisting of humans. We lay forth an argument\nthat human-centered artificial intelligence can be broken down into two\naspects: (1) AI systems that understand humans from a sociocultural\nperspective, and (2) AI systems that help humans understand them. We further\nargue that issues of social responsibility such as fairness, accountability,\ninterpretability, and transparency.",
      "citation_count": 238,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1fccba11583dc9e1030713d61bd65e9e9990e39f",
      "published_date": "2019-01-31",
      "downloaded_date": "2025-01-31",
      "filename": "Riedl-Human-Centered Artificial Intelligence and Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.11184v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1904.08796v1": {
      "title": "Artificial Intelligence for Pediatric Ophthalmology",
      "authors": [
        "Julia E. Reid",
        "Eric Eaton"
      ],
      "abstract": "PURPOSE OF REVIEW: Despite the impressive results of recent artificial\nintelligence (AI) applications to general ophthalmology, comparatively less\nprogress has been made toward solving problems in pediatric ophthalmology using\nsimilar techniques. This article discusses the unique needs of pediatric\nophthalmology patients and how AI techniques can address these challenges,\nsurveys recent applications of AI to pediatric ophthalmology, and discusses\nfuture directions in the field.\n  RECENT FINDINGS: The most significant advances involve the automated\ndetection of retinopathy of prematurity (ROP), yielding results that rival\nexperts. Machine learning (ML) has also been successfully applied to the\nclassification of pediatric cataracts, prediction of post-operative\ncomplications following cataract surgery, detection of strabismus and\nrefractive error, prediction of future high myopia, and diagnosis of reading\ndisability via eye tracking. In addition, ML techniques have been used for the\nstudy of visual development, vessel segmentation in pediatric fundus images,\nand ophthalmic image synthesis.\n  SUMMARY: AI applications could significantly benefit clinical care for\npediatric ophthalmology patients by optimizing disease detection and grading,\nbroadening access to care, furthering scientific discovery, and improving\nclinical efficiency. These methods need to match or surpass physician\nperformance in clinical trials before deployment with patients. Due to\nwidespread use of closed-access data sets and software implementations, it is\ndifficult to directly compare the performance of these approaches, and\nreproducibility is poor. Open-access data sets and software implementations\ncould alleviate these issues, and encourage further AI applications to\npediatric ophthalmology.\n  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,\ndeep learning",
      "citation_count": 56,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fcece970e90860b9ece6c09a36f33beda4ae93ea",
      "published_date": "2019-04-06",
      "downloaded_date": "2025-01-31",
      "filename": "Reid-Artificial Intelligence for Pediatric Ophthalmology.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1904.08796v1",
      "categories": [
        "physics.med-ph",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    },
    "2206.03289v1": {
      "title": "Future Artificial Intelligence tools and perspectives in medicine",
      "authors": [
        "Ahmad Chaddad",
        "Yousef Katib",
        "Lama Hassan"
      ],
      "abstract": "Purpose of review: Artificial intelligence (AI) has become popular in medical\napplications, specifically as a clinical support tool for computer-aided\ndiagnosis. These tools are typically employed on medical data (i.e., image,\nmolecular data, clinical variables, etc.) and used the statistical and machine\nlearning methods to measure the model performance. In this review, we\nsummarized and discussed the most recent radiomic pipeline used for clinical\nanalysis. Recent findings:Currently, limited management of cancers benefits\nfrom artificial intelligence, mostly related to a computer-aided diagnosis that\navoids a biopsy analysis that presents additional risks and costs. Most AI\ntools are based on imaging features, known as radiomic analysis that can be\nrefined into predictive models in non-invasively acquired imaging data. This\nreview explores the progress of AI-based radiomic tools for clinical\napplications with a brief description of necessary technical steps. Explaining\nnew radiomic approaches based on deep learning techniques will explain how the\nnew radiomic models (deep radiomic analysis) can benefit from deep\nconvolutional neural networks and be applied on limited data sets. Summary: To\nconsider the radiomic algorithms, further investigations are recommended to\ninvolve deep learning in radiomic models with additional validation steps on\nvarious cancer types.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5f36e49f7299e25413cef7c8c133303f18d91e6c",
      "published_date": "2022-06-04",
      "downloaded_date": "2025-01-31",
      "filename": "Chaddad-Future Artificial Intelligence tools and perspectives in medicine.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.03289v1",
      "categories": [
        "cs.LG",
        "eess.IV",
        "q-bio.QM"
      ]
    },
    "1910.10045v2": {
      "title": "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI",
      "authors": [
        "Alejandro Barredo Arrieta",
        "Natalia DÃ­az-RodrÃ­guez",
        "Javier Del Ser",
        "Adrien Bennetot",
        "Siham Tabik",
        "Alberto Barbado",
        "Salvador GarcÃ­a",
        "Sergio Gil-LÃ³pez",
        "Daniel Molina",
        "Richard Benjamins",
        "Raja Chatila",
        "Francisco Herrera"
      ],
      "abstract": "In the last years, Artificial Intelligence (AI) has achieved a notable\nmomentum that may deliver the best of expectations over many application\nsectors across the field. For this to occur, the entire community stands in\nfront of the barrier of explainability, an inherent problem of AI techniques\nbrought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not\npresent in the last hype of AI. Paradigms underlying this problem fall within\nthe so-called eXplainable AI (XAI) field, which is acknowledged as a crucial\nfeature for the practical deployment of AI models. This overview examines the\nexisting literature in the field of XAI, including a prospect toward what is\nyet to be reached. We summarize previous efforts to define explainability in\nMachine Learning, establishing a novel definition that covers prior conceptual\npropositions with a major focus on the audience for which explainability is\nsought. We then propose and discuss about a taxonomy of recent contributions\nrelated to the explainability of different Machine Learning models, including\nthose aimed at Deep Learning methods for which a second taxonomy is built. This\nliterature analysis serves as the background for a series of challenges faced\nby XAI, such as the crossroads between data fusion and explainability. Our\nprospects lead toward the concept of Responsible Artificial Intelligence,\nnamely, a methodology for the large-scale implementation of AI methods in real\norganizations with fairness, model explainability and accountability at its\ncore. Our ultimate goal is to provide newcomers to XAI with a reference\nmaterial in order to stimulate future research advances, but also to encourage\nexperts and professionals from other disciplines to embrace the benefits of AI\nin their activity sectors, without any prior bias for its lack of\ninterpretability.",
      "citation_count": 5480,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/530a059cb48477ad1e3d4f8f4b153274c8997332",
      "published_date": "2019-10-22",
      "downloaded_date": "2025-01-31",
      "filename": "Arrieta-Explainable Artificial Intelligence XAI Concepts Taxonomies Opportunities and Challenges toward Resp....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1910.10045v2",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2010.15581v1": {
      "title": "The De-democratization of AI: Deep Learning and the Compute Divide in Artificial Intelligence Research",
      "authors": [
        "Nur Ahmed",
        "Muntasir Wahed"
      ],
      "abstract": "Increasingly, modern Artificial Intelligence (AI) research has become more\ncomputationally intensive. However, a growing concern is that due to unequal\naccess to computing power, only certain firms and elite universities have\nadvantages in modern AI research. Using a novel dataset of 171394 papers from\n57 prestigious computer science conferences, we document that firms, in\nparticular, large technology firms and elite universities have increased\nparticipation in major AI conferences since deep learning's unanticipated rise\nin 2012. The effect is concentrated among elite universities, which are ranked\n1-50 in the QS World University Rankings. Further, we find two strategies\nthrough which firms increased their presence in AI research: first, they have\nincreased firm-only publications; and second, firms are collaborating primarily\nwith elite universities. Consequently, this increased presence of firms and\nelite universities in AI research has crowded out mid-tier (QS ranked 201-300)\nand lower-tier (QS ranked 301-500) universities. To provide causal evidence\nthat deep learning's unanticipated rise resulted in this divergence, we\nleverage the generalized synthetic control method, a data-driven counterfactual\nestimator. Using machine learning based text analysis methods, we provide\nadditional evidence that the divergence between these two groups - large firms\nand non-elite universities - is driven by access to computing power or compute,\nwhich we term as the \"compute divide\". This compute divide between large firms\nand non-elite universities increases concerns around bias and fairness within\nAI technology, and presents an obstacle towards \"democratizing\" AI. These\nresults suggest that a lack of access to specialized equipment such as compute\ncan de-democratize knowledge production.",
      "citation_count": 96,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e585f6e752fb2668b33f7d4b18c8af9bd5abc1a4",
      "published_date": "2020-10-22",
      "downloaded_date": "2025-01-31",
      "filename": "Ahmed-The De-democratization of AI Deep Learning and the Compute Divide in Artificial Intelligence Researc....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2010.15581v1",
      "categories": [
        "cs.CY",
        "cs.LG"
      ]
    },
    "2209.11234v3": {
      "title": "Artificial Intelligence in Material Engineering: A review on applications of AI in Material Engineering",
      "authors": [
        "Lipichanda Goswami",
        "Manoj Deka",
        "Mohendra Roy"
      ],
      "abstract": "The role of artificial intelligence (AI) in material science and engineering\n(MSE) is becoming increasingly important as AI technology advances. The\ndevelopment of high-performance computing has made it possible to test deep\nlearning (DL) models with significant parameters, providing an opportunity to\novercome the limitation of traditional computational methods, such as density\nfunctional theory (DFT), in property prediction. Machine learning (ML)-based\nmethods are faster and more accurate than DFT-based methods. Furthermore, the\ngenerative adversarial networks (GANs) have facilitated the generation of\nchemical compositions of inorganic materials without using crystal structure\ninformation. These developments have significantly impacted material\nengineering (ME) and research. Some of the latest developments in AI in ME\nherein are reviewed. First, the development of AI in the critical areas of ME,\nsuch as in material processing, the study of structure and material property,\nand measuring the performance of materials in various aspects, is discussed.\nThen, the significant methods of AI and their uses in MSE, such as graph neural\nnetwork, generative models, transfer of learning, etc. are discussed. The use\nof AI to analyze the results from existing analytical instruments is also\ndiscussed. Finally, AI's advantages, disadvantages, and future in ME are\ndiscussed.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-09-15",
      "downloaded_date": "2025-01-31",
      "filename": "Goswami-Artificial Intelligence in Material Engineering A review on applications of AI in Material Engineeri....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.11234v3",
      "categories": [
        "cs.LG"
      ]
    },
    "2108.10076v1": {
      "title": "Development of A Fully Data-Driven Artificial Intelligence and Deep Learning for URLLC Application in 6G Wireless Systems: A Survey",
      "authors": [
        "Adeeb Salh",
        "Lukman Audah",
        "Qazwan Abdullah",
        "Abdullah Noorsaliza",
        "Nor Shahida Mohd Shah",
        "Jameel Mukred",
        "Shipun Hamzah"
      ],
      "abstract": "The full future of the sixth generation will develop a fully data-driven that\nprovide terabit rate per second, and adopt an average of 1000+ massive number\nof connections per person in 10 years 2030 virtually instantaneously.\nData-driven for ultra-reliable and low latency communication is a new service\nparadigm provided by a new application of future sixth-generation wireless\ncommunication and network architecture, involving 100+ Gbps data rates with one\nmillisecond latency. The key constraint is the amount of computing power\navailable to spread massive data and well-designed artificial neural networks.\nArtificial Intelligence provides a new technique to design wireless networks by\napply learning, predicting, and make decisions to manage the stream of big data\ntraining individuals, which provides more the capacity to transform that expert\nlearning to develop the performance of wireless networks. We study the\ndeveloping technologies that will be the driving force are artificial\nintelligence, communication systems to guarantee low latency. This paper aims\nto discuss the efficiency of the developing network and alleviate the great\nchallenge for application scenarios and study Holographic radio, enhanced\nwireless channel coding, enormous Internet of Things integration, and haptic\ncommunication for virtual and augmented reality provide new services on the 6G\nnetwork. Furthermore, improving a multi-level architecture for ultra-reliable\nand low latency in deep Learning allows for data-driven AI and 6G networks for\ndevice intelligence, as well as allowing innovations based on effective\nlearning capabilities. These difficulties must be solved in order to meet the\nneeds of future smart networks. Furthermore, this research categorizes various\nunexplored research gaps between machine learning and the sixth generation.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/dcffbe3836bda703cd8d821a7deacffe397b00ee",
      "published_date": "2021-08-04",
      "downloaded_date": "2025-01-31",
      "filename": "Salh-Development of A Fully Data-Driven Artificial Intelligence and Deep Learning for URLLC Application i....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.10076v1",
      "categories": [
        "eess.SP",
        "cs.CC"
      ]
    },
    "2410.09105v1": {
      "title": "Artificial intelligence techniques in inherited retinal diseases: A review",
      "authors": [
        "Han Trinh",
        "Jordan Vice",
        "Jason Charng",
        "Zahra Tajbakhsh",
        "Khyber Alam",
        "Fred K. Chen",
        "Ajmal Mian"
      ],
      "abstract": "Inherited retinal diseases (IRDs) are a diverse group of genetic disorders\nthat lead to progressive vision loss and are a major cause of blindness in\nworking-age adults. The complexity and heterogeneity of IRDs pose significant\nchallenges in diagnosis, prognosis, and management. Recent advancements in\nartificial intelligence (AI) offer promising solutions to these challenges.\nHowever, the rapid development of AI techniques and their varied applications\nhave led to fragmented knowledge in this field. This review consolidates\nexisting studies, identifies gaps, and provides an overview of AI's potential\nin diagnosing and managing IRDs. It aims to structure pathways for advancing\nclinical applications by exploring AI techniques like machine learning and deep\nlearning, particularly in disease detection, progression prediction, and\npersonalized treatment planning. Special focus is placed on the effectiveness\nof convolutional neural networks in these areas. Additionally, the integration\nof explainable AI is discussed, emphasizing its importance in clinical settings\nto improve transparency and trust in AI-based systems. The review addresses the\nneed to bridge existing gaps in focused studies on AI's role in IRDs, offering\na structured analysis of current AI techniques and outlining future research\ndirections. It concludes with an overview of the challenges and opportunities\nin deploying AI for IRDs, highlighting the need for interdisciplinary\ncollaboration and the continuous development of robust, interpretable AI models\nto advance clinical applications.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/de29f0f6ef00fbe3cb1ba6fde5be94f982211154",
      "published_date": "2024-10-10",
      "downloaded_date": "2025-01-31",
      "filename": "Trinh-Artificial intelligence techniques in inherited retinal diseases A review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.09105v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    "1911.07125v1": {
      "title": "Opportunities for artificial intelligence in advancing precision medicine",
      "authors": [
        "Fabian V. Filipp"
      ],
      "abstract": "Machine learning (ML), deep learning (DL), and artificial intelligence (AI)\nare of increasing importance in biomedicine. The goal of this work is to show\nprogress in ML in digital health, to exemplify future needs and trends, and to\nidentify any essential prerequisites of AI and ML for precision health.\nHigh-throughput technologies are delivering growing volumes of biomedical data,\nsuch as large-scale genome-wide sequencing assays, libraries of medical images,\nor drug perturbation screens of healthy, developing, and diseased tissue.\nMulti-omics data in biomedicine is deep and complex, offering an opportunity\nfor data-driven insights and automated disease classification. Learning from\nthese data will open our understanding and definition of healthy baselines and\ndisease signatures. State-of-the-art applications of deep neural networks\ninclude digital image recognition, single cell clustering, and virtual drug\nscreens, demonstrating breadths and power of ML in biomedicine. Significantly,\nAI and systems biology have embraced big data challenges and may enable novel\nbiotechnology-derived therapies to facilitate the implementation of precision\nmedicine approaches.",
      "citation_count": 45,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/553f00637c18da429b7e3297109c22fde37bf263",
      "published_date": "2019-11-17",
      "downloaded_date": "2025-01-31",
      "filename": "Filipp-Opportunities for artificial intelligence in advancing precision medicine.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.07125v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.BM",
        "q-bio.GN",
        "q-bio.MN"
      ]
    },
    "2403.04130v1": {
      "title": "An Explainable AI Framework for Artificial Intelligence of Medical Things",
      "authors": [
        "Al Amin",
        "Kamrul Hasan",
        "Saleh Zein-Sabatto",
        "Deo Chimba",
        "Imtiaz Ahmed",
        "Tariqul Islam"
      ],
      "abstract": "The healthcare industry has been revolutionized by the convergence of\nArtificial Intelligence of Medical Things (AIoMT), allowing advanced\ndata-driven solutions to improve healthcare systems. With the increasing\ncomplexity of Artificial Intelligence (AI) models, the need for Explainable\nArtificial Intelligence (XAI) techniques become paramount, particularly in the\nmedical domain, where transparent and interpretable decision-making becomes\ncrucial. Therefore, in this work, we leverage a custom XAI framework,\nincorporating techniques such as Local Interpretable Model-Agnostic\nExplanations (LIME), SHapley Additive exPlanations (SHAP), and\nGradient-weighted Class Activation Mapping (Grad-Cam), explicitly designed for\nthe domain of AIoMT. The proposed framework enhances the effectiveness of\nstrategic healthcare methods and aims to instill trust and promote\nunderstanding in AI-driven medical applications. Moreover, we utilize a\nmajority voting technique that aggregates predictions from multiple\nconvolutional neural networks (CNNs) and leverages their collective\nintelligence to make robust and accurate decisions in the healthcare system.\nBuilding upon this decision-making process, we apply the XAI framework to brain\ntumor detection as a use case demonstrating accurate and transparent diagnosis.\nEvaluation results underscore the exceptional performance of the XAI framework,\nachieving high precision, recall, and F1 scores with a training accuracy of 99%\nand a validation accuracy of 98%. Combining advanced XAI techniques with\nensemble-based deep-learning (DL) methodologies allows for precise and reliable\nbrain tumor diagnoses as an application of AIoMT.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2064c2a94c093dfc32afd4751655ef4ed1741a8c",
      "published_date": "2024-03-07",
      "downloaded_date": "2025-01-31",
      "filename": "Amin-An Explainable AI Framework for Artificial Intelligence of Medical Things.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.04130v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2212.03601v2": {
      "title": "Artificial Intelligence in Governance, Risk and Compliance: Results of a study on potentials for the application of artificial intelligence (AI) in governance, risk and compliance (GRC)",
      "authors": [
        "Eva Ponick",
        "Gabriele Wieczorek"
      ],
      "abstract": "The digital transformation leads to fundamental change in organizational\nstructures. To be able to apply new technologies not only selectively,\nprocesses in companies must be revised and functional units must be viewed\nholistically, especially with regard to interfaces. Target-oriented management\ndecisions are made, among other things, on the basis of risk management and\ncompliance in combination with the internal control system as governance\nfunctions. The effectiveness and efficiency of these functions is decisive to\nfollow guidelines and regulatory requirements as well as for the evaluation of\nalternative options for acting with regard to activities of companies. GRC\n(Governance, Risk and Compliance) means an integrated governance-approach, in\nwhich the mentioned governance functions are interlinked and not separated from\neach other. Methods of artificial intelligence represents an important\ntechnology of digital transformation. This technology, which offers a broad\nrange of methods such as machine learning, artificial neural networks, natural\nlanguage processing or deep learning, offers a lot of possible applications in\nmany business areas from purchasing to production or customer service.\nArtificial intelligence is also being used in GRC, for example for processing\nand analysis of unstructured data sets. This study contains the results of a\nsurvey conducted in 2021 to identify and analyze the potential applications of\nartificial intelligence in GRC.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/963329fa99d3e98982374ba053fe4f953f4186bd",
      "published_date": "2022-12-07",
      "downloaded_date": "2025-01-31",
      "filename": "Ponick-Artificial Intelligence in Governance Risk and Compliance Results of a study on potentials for the a....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.03601v2",
      "categories": [
        "cs.CY"
      ]
    },
    "2410.22120v1": {
      "title": "Vision Paper: Designing Graph Neural Networks in Compliance with the European Artificial Intelligence Act",
      "authors": [
        "Barbara Hoffmann",
        "Jana Vatter",
        "Ruben Mayer"
      ],
      "abstract": "The European Union's Artificial Intelligence Act (AI Act) introduces\ncomprehensive guidelines for the development and oversight of Artificial\nIntelligence (AI) and Machine Learning (ML) systems, with significant\nimplications for Graph Neural Networks (GNNs). This paper addresses the unique\nchallenges posed by the AI Act for GNNs, which operate on complex\ngraph-structured data. The legislation's requirements for data management, data\ngovernance, robustness, human oversight, and privacy necessitate tailored\nstrategies for GNNs. Our study explores the impact of these requirements on GNN\ntraining and proposes methods to ensure compliance. We provide an in-depth\nanalysis of bias, robustness, explainability, and privacy in the context of\nGNNs, highlighting the need for fair sampling strategies and effective\ninterpretability techniques. Our contributions fill the research gap by\noffering specific guidance for GNNs under the new legislative framework and\nidentifying open questions and future research directions.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0d50dab4301863fc3c1d4789f5476833c3951897",
      "published_date": "2024-10-29",
      "downloaded_date": "2025-01-31",
      "filename": "Hoffmann-Vision Paper Designing Graph Neural Networks in Compliance with the European Artificial Intelligence....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.22120v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2201.01466v1": {
      "title": "Challenges of Artificial Intelligence -- From Machine Learning and Computer Vision to Emotional Intelligence",
      "authors": [
        "Matti PietikÃ¤inen",
        "Olli Silven"
      ],
      "abstract": "Artificial intelligence (AI) has become a part of everyday conversation and\nour lives. It is considered as the new electricity that is revolutionizing the\nworld. AI is heavily invested in both industry and academy. However, there is\nalso a lot of hype in the current AI debate. AI based on so-called deep\nlearning has achieved impressive results in many problems, but its limits are\nalready visible. AI has been under research since the 1940s, and the industry\nhas seen many ups and downs due to over-expectations and related\ndisappointments that have followed.\n  The purpose of this book is to give a realistic picture of AI, its history,\nits potential and limitations. We believe that AI is a helper, not a ruler of\nhumans. We begin by describing what AI is and how it has evolved over the\ndecades. After fundamentals, we explain the importance of massive data for the\ncurrent mainstream of artificial intelligence. The most common representations\nfor AI, methods, and machine learning are covered. In addition, the main\napplication areas are introduced. Computer vision has been central to the\ndevelopment of AI. The book provides a general introduction to computer vision,\nand includes an exposure to the results and applications of our own research.\nEmotions are central to human intelligence, but little use has been made in AI.\nWe present the basics of emotional intelligence and our own research on the\ntopic. We discuss super-intelligence that transcends human understanding,\nexplaining why such achievement seems impossible on the basis of present\nknowledge,and how AI could be improved. Finally, a summary is made of the\ncurrent state of AI and what to do in the future. In the appendix, we look at\nthe development of AI education, especially from the perspective of contents at\nour own university.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-01-05",
      "downloaded_date": "2025-01-31",
      "filename": "PietikÃ¤inen-Challenges of Artificial Intelligence -- From Machine Learning and Computer Vision to Emotional Inte....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2201.01466v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2409.16543v1": {
      "title": "A Review of Artificial Intelligence in Brachytherapy",
      "authors": [
        "Jingchu Chen",
        "Richard Qiu",
        "Tonghe Wang",
        "Shadab Momin",
        "Xiaofeng Yang"
      ],
      "abstract": "Artificial intelligence (AI) has the potential to revolutionize\nbrachytherapy's clinical workflow. This review comprehensively examines the\napplication of AI, focusing on machine learning and deep learning, in\nfacilitating various aspects of brachytherapy. We analyze AI's role in making\nbrachytherapy treatments more personalized, efficient, and effective. The\napplications are systematically categorized into seven categories: imaging,\npreplanning, treatment planning, applicator reconstruction, quality assurance,\noutcome prediction, and real-time monitoring. Each major category is further\nsubdivided based on cancer type or specific tasks, with detailed summaries of\nmodels, data sizes, and results presented in corresponding tables. This review\noffers insights into the current advancements, challenges, and the impact of AI\non treatment paradigms, encouraging further research to expand its clinical\nutility.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bf270c2a1238902bb77be24d37bb92769e411910",
      "published_date": "2024-09-25",
      "downloaded_date": "2025-01-31",
      "filename": "Chen-A Review of Artificial Intelligence in Brachytherapy.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.16543v1",
      "categories": [
        "physics.med-ph"
      ]
    },
    "1808.01672v3": {
      "title": "Model-Aided Wireless Artificial Intelligence: Embedding Expert Knowledge in Deep Neural Networks Towards Wireless Systems Optimization",
      "authors": [
        "Alessio Zappone",
        "Marco Di Renzo",
        "MÃ©rouane Debbah",
        "Thanh Tu Lam",
        "Xuewen Qian"
      ],
      "abstract": "Deep learning based on artificial neural networks is a powerful machine\nlearning method that, in the last few years, has been successfully used to\nrealize tasks, e.g., image classification, speech recognition, translation of\nlanguages, etc., that are usually simple to execute by human beings but\nextremely difficult to perform by machines. This is one of the reasons why deep\nlearning is considered to be one of the main enablers to realize the notion of\nartificial intelligence. In order to identify the best architecture of an\nartificial neural network that allows one to fit input-output data pairs, the\ncurrent methodology in deep learning methods consists of employing a\ndata-driven approach. Once the artificial neural network is trained, it is\ncapable of responding to never-observed inputs by providing the optimum output\nbased on past acquired knowledge. In this context, a recent trend in the deep\nlearning community is to complement pure data-driven approaches with prior\ninformation based on expert knowledge. In this work, we describe two methods\nthat implement this strategy, which aim at optimizing wireless communication\nnetworks. In addition, we illustrate numerical results in order to assess the\nperformance of the proposed approaches compared with pure data-driven\nimplementations.",
      "citation_count": 73,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f99e742711db48c11a5692edbb614597659e4b4e",
      "published_date": "2018-08-05",
      "downloaded_date": "2025-01-31",
      "filename": "Zappone-Model-Aided Wireless Artificial Intelligence Embedding Expert Knowledge in Deep Neural Networks Towa....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1808.01672v3",
      "categories": [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    },
    "060fc8cb4df1125e424f1a5e45371a271575b2c2": {
      "title": "Coupling Machine and Deep Learning with Explainable Artificial Intelligence for Improving Prediction of Groundwater Quality and Decision-Making in Arid Region, Saudi Arabia",
      "authors": [
        "Fahad Alshehri",
        "Atiqur Rahman"
      ],
      "year": 2023,
      "citations": 19,
      "abstract": "Recently, machine learning (ML) and deep learning (DL) models based on artificial intelligence (AI) have emerged as fast and reliable tools for predicting water quality index (WQI) in various regions worldwide. In this study, we propose a novel stacking framework based on DL models for WQI prediction, employing a convolutional neural network (CNN) model. Additionally, we introduce explainable AI (XAI) through XGBoost-based SHAP (SHapley Additive exPlanations) values to gain valuable insights that can enhance decision-making strategies in water management. Our findings demonstrate that the stacking model achieves the highest accuracy in WQI prediction (R2: 0.99, MAPE: 15.99%), outperforming the CNN model (R2: 0.90, MAPE: 58.97%). Although the CNN model shows a relatively high R2 value, other statistical measures indicate that it is actually the worst-performing model among the five tested. This discrepancy may be attributed to the limited training data available for the CNN model. Furthermore, the application of explainable AI (XAI) techniques, specifically XGBoost-based SHAP values, allows us to gain deep insights into the models and extract valuable information for water management purposes. The SHAP values and interaction plot reveal that elevated levels of total dissolved solids (TDS), zinc, and electrical conductivity (EC) are the primary drivers of poor water quality. These parameters exhibit a nonlinear relationship with the water quality index, implying that even minor increases in their concentrations can significantly impact water quality. Overall, this study presents a comprehensive and integrated approach to water management, emphasizing the need for collaborative efforts among all stakeholders to mitigate pollution levels and uphold water quality. By leveraging AI and XAI, our proposed framework not only provides a powerful tool for accurate WQI prediction but also offers deep insights into the models, enabling informed decision-making in water management strategies.",
      "venue": "Water",
      "filename": "01-Coupling Machine and Deep Learning with Explainable Artificial Intelligence for Improving Prediction.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "ff437a9a44dbce3faf9534454a9bbdbc12bac3c2": {
      "title": "Artificial Intelligence (AI) and Internet of Medical Things (IoMT) Assisted Biomedical Systems for Intelligent Healthcare",
      "authors": [
        "Pandiaraj Manickam",
        "Siva Ananth Mariappan",
        "S. Murugesan",
        "S. Hansda",
        "A. Kaushik",
        "Ravikumar Shinde",
        "S. P. Thipperudraswamy"
      ],
      "year": 2022,
      "citations": 246,
      "abstract": "Artificial intelligence (AI) is a modern approach based on computer science that develops programs and algorithms to make devices intelligent and efficient for performing tasks that usually require skilled human intelligence. AI involves various subsets, including machine learning (ML), deep learning (DL), conventional neural networks, fuzzy logic, and speech recognition, with unique capabilities and functionalities that can improve the performances of modern medical sciences. Such intelligent systems simplify human intervention in clinical diagnosis, medical imaging, and decision-making ability. In the same era, the Internet of Medical Things (IoMT) emerges as a next-generation bio-analytical tool that combines network-linked biomedical devices with a software application for advancing human health. In this review, we discuss the importance of AI in improving the capabilities of IoMT and point-of-care (POC) devices used in advanced healthcare sectors such as cardiac measurement, cancer diagnosis, and diabetes management. The role of AI in supporting advanced robotic surgeries developed for advanced biomedical applications is also discussed in this article. The position and importance of AI in improving the functionality, detection accuracy, decision-making ability of IoMT devices, and evaluation of associated risks assessment is discussed carefully and critically in this review. This review also encompasses the technological and engineering challenges and prospects for AI-based cloud-integrated personalized IoMT devices for designing efficient POC biomedical systems suitable for next-generation intelligent healthcare.",
      "venue": "Biosensors",
      "filename": "02-Artificial Intelligence AI and Internet of Medical Things IoMT Assisted Biomedical Systems for Intel.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "5a8d14e013173514d1c1eb1ac78f55b309465601": {
      "title": "Quantification of Deep Neural Network Prediction Uncertainties for VVUQ of Machine Learning Models",
      "authors": [
        "M. Yaseen",
        "Xu Wu"
      ],
      "year": 2022,
      "citations": 9,
      "abstract": "Abstract Recent performance breakthroughs in artificial intelligence (AI) and machine learning (ML), especially advances in deep learning, the availability of powerful and easy-to-use ML libraries (e.g., scikit-learn, TensorFlow, PyTorch), and increasing computational power, have led to unprecedented interest in AI/ML among nuclear engineers. For physics-based computational models, verification, validation, and uncertainty quantification (VVUQ) processes have been very widely investigated, and many methodologies have been developed. However, VVUQ of ML models has been relatively less studied, especially in nuclear engineering. This work focuses on uncertainty quantification (UQ) of ML models as a preliminary step of ML VVUQ, more specifically Deep Neural Networks (DNNs) because they are the most widely used supervised ML algorithm for both regression and classification tasks. This work aims at quantifying the prediction or approximation uncertainties of DNNs when they are used as surrogate models for expensive physical models. Three techniques for UQ of DNNs are compared, namely, Monte Carlo Dropout (MCD), Deep Ensembles (DE), and Bayesian Neural Networks (BNNs). Two nuclear engineering examples are used to benchmark these methods: (1) time-dependent fission gas release data using the Bison code and (2) void fraction simulation based on the Boiling Water Reactor Full-size Fine-Mesh Bundle Tests (BFBT) benchmark using the TRACE code. It is found that the three methods typically require different DNN architectures and hyperparameters to optimize their performance. The UQ results also depend on the amount of training data available and the nature of the data. Overall, all three methods can provide reasonable estimations of the approximation uncertainties. The uncertainties are generally smaller when the mean predictions are close to the test data while the BNN methods usually produce larger uncertainties than MCD and DE.",
      "venue": "Nuclear science and engineering",
      "filename": "03-Quantification of Deep Neural Network Prediction Uncertainties for VVUQ of Machine Learning Models.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "c90d9f81d69e38ac0f2ddf08a070072ec7143611": {
      "title": "Cyberattack detection in wireless sensor networks using a hybrid feature reduction technique with AI and machine learning methods",
      "authors": [
        "Mohamed H. Behiry",
        "Mohammed Aly"
      ],
      "year": 2024,
      "citations": 14,
      "abstract": null,
      "venue": "Journal of Big Data",
      "filename": "05-Cyberattack detection in wireless sensor networks using a hybrid feature reduction technique with AI.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "5af3a1e8641ac62ea02f4d115069f50f0417ae1f": {
      "title": "Artificial intelligence in orthopedics: three strategies for deep learning with orthopedic specific imaging",
      "authors": [
        "Sunho Ko",
        "Ayoosh Pareek",
        "D. Ro",
        "Yining Lu",
        "Christopher L. Camp",
        "R. K. Martin",
        "A. Krych"
      ],
      "year": 2022,
      "citations": 25,
      "abstract": null,
      "venue": "Knee Surgery, Sports Traumatology, Arthroscopy",
      "filename": "06-Artificial intelligence in orthopedics three strategies for deep learning with orthopedic specific i.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "58fe1c70fcc9a47737b1e1d803cca1762e67498c": {
      "title": "Ethical principles for the application of artificial intelligence (AI) in nuclear medicine",
      "authors": [
        "G. Currie",
        "Elizabeth Hawk",
        "Eric M. Rohren"
      ],
      "year": 2020,
      "citations": 55,
      "abstract": null,
      "venue": "European Journal of Nuclear Medicine and Molecular Imaging",
      "filename": "07-Ethical principles for the application of artificial intelligence AI in nuclear medicine.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "0ad46973c8252cf118d41f1aa7e6de73a703e196": {
      "title": "Artificial intelligence deep learning for 3D IC reliability prediction",
      "authors": [
        "Po-Ning Hsu",
        "K. Shie",
        "Kuan-Peng Chen",
        "Jing-Chen Tu",
        "Cheng-Che Wu",
        "N. Tsou",
        "Y. Lo",
        "Nan-Yow Chen",
        "Yong-Fen Hsieh",
        "Mia Wu",
        "Chih-Jung Chen",
        "K. Tu"
      ],
      "year": 2022,
      "citations": 10,
      "abstract": null,
      "venue": "Scientific Reports",
      "filename": "08-Artificial intelligence deep learning for 3D IC reliability prediction.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "cc46aa294743ecbb194fd993981750fbe5ce8415": {
      "title": "Recognizing the Differentiation Degree of Human Induced Pluripotent Stem Cell-Derived Retinal Pigment Epithelium Cells Using Machine Learning and Deep Learning-Based Approaches",
      "authors": [
        "Chung-Yueh Lien",
        "Tseng-Tse Chen",
        "En-Tung Tsai",
        "Yu-Jer Hsiao",
        "Ni Lee",
        "Chong-En Gao",
        "Yi-ping Yang",
        "Shih-Jen Chen",
        "A. Yarmishyn",
        "De-Kuang Hwang",
        "Shih-Jie Chou",
        "W-C. Chu",
        "S. Chiou",
        "Yueh Chien"
      ],
      "year": 2023,
      "citations": 12,
      "abstract": "Induced pluripotent stem cells (iPSCs) can be differentiated into mesenchymal stem cells (iPSC-MSCs), retinal ganglion cells (iPSC-RGCs), and retinal pigmental epithelium cells (iPSC-RPEs) to meet the demand of regeneration medicine. Since the production of iPSCs and iPSC-derived cell lineages generally requires massive and time-consuming laboratory work, artificial intelligence (AI)-assisted approach that can facilitate the cell classification and recognize the cell differentiation degree is of critical demand. In this study, we propose the multi-slice tensor model, a modified convolutional neural network (CNN) designed to classify iPSC-derived cells and evaluate the differentiation efficiency of iPSC-RPEs. We removed the fully connected layers and projected the features using principle component analysis (PCA), and subsequently classified iPSC-RPEs according to various differentiation degree. With the assistance of the support vector machine (SVM), this model further showed capabilities to classify iPSCs, iPSC-MSCs, iPSC-RPEs, and iPSC-RGCs with an accuracy of 97.8%. In addition, the proposed model accurately recognized the differentiation of iPSC-RPEs and showed the potential to identify the candidate cells with ideal features and simultaneously exclude cells with immature/abnormal phenotypes. This rapid screening/classification system may facilitate the translation of iPSC-based technologies into clinical uses, such as cell transplantation therapy.",
      "venue": "Cells",
      "filename": "09-Recognizing the Differentiation Degree of Human Induced Pluripotent Stem Cell-Derived Retinal Pigmen.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "7e7b96db280e7c58db4431bb74963ab18b01fc00": {
      "title": "A Deep Learning Approach for Network Intrusion Detection Using a Small Features Vector",
      "authors": [
        "Humera Ghani",
        "B. Virdee",
        "S. Salekzamankhani"
      ],
      "year": 2023,
      "citations": 6,
      "abstract": "With the growth in network usage, there has been a corresponding growth in the nefarious exploitation of this technology. A wide array of techniques is now available that can be used to deal with cyberattacks, and one of them is network intrusion detection. Artificial Intelligence (AI) and Machine Learning (ML) techniques have extensively been employed to identify network anomalies. This paper provides an effective technique to evaluate the classification performance of a deep-learning-based Feedforward Neural Network (FFNN) classifier. A small feature vector is used to detect network traffic anomalies in the UNSW-NB15 and NSL-KDD datasets. The results show that a large feature set can have redundant and unuseful features, and it requires high computation power. The proposed technique exploits a small feature vector and achieves better classification accuracy.",
      "venue": "Journal of Cybersecurity and Privacy",
      "filename": "10-A Deep Learning Approach for Network Intrusion Detection Using a Small Features Vector.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "cfb5bd06687be611ae3bd1e073dd97468259c4e3": {
      "title": "Measuring depression severity based on facial expression and body movement using deep convolutional neural network",
      "authors": [
        "Dongdong Liu",
        "Bowen Liu",
        "Tao Lin",
        "Guangya Liu",
        "Guoyu Yang",
        "Dezhen Qi",
        "Ye Qiu",
        "Yuer Lu",
        "Qinmei Yuan",
        "Stella C. Shuai",
        "Xia Li",
        "Ou Liu",
        "Xiangdong Tang",
        "Jianwei Shuai",
        "Yuping Cao",
        "Hai Lin"
      ],
      "year": 2022,
      "citations": 15,
      "abstract": "Introduction Real-time evaluations of the severity of depressive symptoms are of great significance for the diagnosis and treatment of patients with major depressive disorder (MDD). In clinical practice, the evaluation approaches are mainly based on psychological scales and doctor-patient interviews, which are time-consuming and labor-intensive. Also, the accuracy of results mainly depends on the subjective judgment of the clinician. With the development of artificial intelligence (AI) technology, more and more machine learning methods are used to diagnose depression by appearance characteristics. Most of the previous research focused on the study of single-modal data; however, in recent years, many studies have shown that multi-modal data has better prediction performance than single-modal data. This study aimed to develop a measurement of depression severity from expression and action features and to assess its validity among the patients with MDD. Methods We proposed a multi-modal deep convolutional neural network (CNN) to evaluate the severity of depressive symptoms in real-time, which was based on the detection of patientsâ facial expression and body movement from videos captured by ordinary cameras. We established behavioral depression degree (BDD) metrics, which combines expression entropy and action entropy to measure the depression severity of MDD patients. Results We found that the information extracted from different modes, when integrated in appropriate proportions, can significantly improve the accuracy of the evaluation, which has not been reported in previous studies. This method presented an over 74% Pearson similarity between BDD and self-rating depression scale (SDS), self-rating anxiety scale (SAS), and Hamilton depression scale (HAMD). In addition, we tracked and evaluated the changes of BDD in patients at different stages of a course of treatment and the results obtained were in agreement with the evaluation from the scales. Discussion The BDD can effectively measure the current state of patientsâ depression and its changing trend according to the patientâs expression and action features. Our model may provide an automatic auxiliary tool for the diagnosis and treatment of MDD.",
      "venue": "Frontiers in Psychiatry",
      "filename": "12-Measuring depression severity based on facial expression and body movement using deep convolutional .pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "f38114a872db762c1ba24806d9e3054635e18640": {
      "title": "Machine-Aided Bridge Deck Crack Condition State Assessment Using Artificial Intelligence",
      "authors": [
        "Xin Zhang",
        "Benjamin E. Wogen",
        "Xiaoyu Liu",
        "Lissette Iturburu",
        "M. Salmeron",
        "S. Dyke",
        "R. Poston",
        "J. Ramirez"
      ],
      "year": 2023,
      "citations": 6,
      "abstract": "The Federal Highway Administration (FHWA) mandates biannual bridge inspections to assess the condition of all bridges in the United States. These inspections are recorded in the National Bridge Inventory (NBI) and the respective stateâs databases to manage, study, and analyze the data. As FHWA specifications become more complex, inspections require more training and field time. Recently, element-level inspections were added, assigning a condition state to each minor element in the bridge. To address this new requirement, a machine-aided bridge inspection method was developed using artificial intelligence (AI) to assist inspectors. The proposed method focuses on the condition state assessment of cracking in reinforced concrete bridge deck elements. The deep learning-based workflow integrated with image classification and semantic segmentation methods is utilized to extract information from images and evaluate the condition state of cracks according to FHWA specifications. The new workflow uses a deep neural network to extract information required by the bridge inspection manual, enabling the determination of the condition state of cracks in the deck. The results of experimentation demonstrate the effectiveness of this workflow for this application. The method also balances the costs and risks associated with increasing levels of AI involvement, enabling inspectors to better manage their resources. This AI-based method can be implemented by asset owners, such as Departments of Transportation, to better serve communities.",
      "venue": "Italian National Conference on Sensors",
      "filename": "13-Machine-Aided Bridge Deck Crack Condition State Assessment Using Artificial Intelligence.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "c1956a796c0e47c8e71eb5e574c5c5c1a0b2cfd4": {
      "title": "Automated Facial Emotion Recognition Using the Pelican Optimization Algorithm with a Deep Convolutional Neural Network",
      "authors": [
        "Mohammed Alonazi",
        "Hala J. Alshahrani",
        "F. Alotaibi",
        "Mohammed Maray",
        "Mohammed Alghamdi",
        "Ahmed Sayed"
      ],
      "year": 2023,
      "citations": 12,
      "abstract": "Facial emotion recognition (FER) stands as a pivotal artificial intelligence (AI)-driven technology that exploits the capabilities of computer-vision techniques for decoding and comprehending emotional expressions displayed on human faces. With the use of machine-learning (ML) models, specifically deep neural networks (DNN), FER empowers the automatic detection and classification of a broad spectrum of emotions, encompassing surprise, happiness, sadness, anger, and more. Challenges in FER include handling variations in lighting, poses, and facial expressions, as well as ensuring that the model generalizes well to various emotions and populations. This study introduces an automated facial emotion recognition using the pelican optimization algorithm with a deep convolutional neural network (AFER-POADCNN) model. The primary objective of the AFER-POADCNN model lies in the automatic recognition and classification of facial emotions. To accomplish this, the AFER-POADCNN model exploits the median-filtering (MF) approach to remove the noise present in it. Furthermore, the capsule-network (CapsNet) approach can be applied to the feature-extraction process, allowing the model to capture intricate facial expressions and nuances. To optimize the CapsNet modelâs performance, hyperparameter tuning is undertaken with the aid of the pelican optimization algorithm (POA). This ensures that the model is finely tuned to detect a wide array of emotions and generalizes effectively across diverse populations and scenarios. Finally, the detection and classification of different kinds of facial emotions take place using a bidirectional long short-term memory (BiLSTM) network. The simulation analysis of the AFER-POADCNN system is tested on a benchmark FER dataset. The comparative result analysis showed the better performance of the AFER-POADCNN algorithm over existing models, with a maximum accuracy of 99.05%.",
      "venue": "Electronics",
      "filename": "14-Automated Facial Emotion Recognition Using the Pelican Optimization Algorithm with a Deep Convolutio.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "c3b10402441d2ab5b9d4fbc75964273c5c67c9d5": {
      "title": "A Deep Analysis of Brain Tumor Detection from MR Images Using Deep Learning Networks",
      "authors": [
        "Md Ishtyaq Mahmud",
        "M. Mamun",
        "A. Abdelgawad"
      ],
      "year": 2023,
      "citations": 115,
      "abstract": "Creating machines that behave and work in a way similar to humans is the objective of artificial intelligence (AI). In addition to pattern recognition, planning, and problem-solving, computer activities with artificial intelligence include other activities. A group of algorithms called âdeep learningâ is used in machine learning. With the aid of magnetic resonance imaging (MRI), deep learning is utilized to create models for the detection and categorization of brain tumors. This allows for the quick and simple identification of brain tumors. Brain disorders are mostly the result of aberrant brain cell proliferation, which can harm the structure of the brain and ultimately result in malignant brain cancer. The early identification of brain tumors and the subsequent appropriate treatment may lower the death rate. In this study, we suggest a convolutional neural network (CNN) architecture for the efficient identification of brain tumors using MR images. This paper also discusses various models such as ResNet-50, VGG16, and Inception V3 and conducts a comparison between the proposed architecture and these models. To analyze the performance of the models, we considered different metrics such as the accuracy, recall, loss, and area under the curve (AUC). As a result of analyzing different models with our proposed model using these metrics, we concluded that the proposed model performed better than the others. Using a dataset of 3264 MR images, we found that the CNN model had an accuracy of 93.3%, an AUC of 98.43%, a recall of 91.19%, and a loss of 0.25. We may infer that the proposed model is reliable for the early detection of a variety of brain tumors after comparing it to the other models.",
      "venue": "Algorithms",
      "filename": "15-A Deep Analysis of Brain Tumor Detection from MR Images Using Deep Learning Networks.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "538afbccb23034e18bcbbc6091fca62bf2dbde05": {
      "title": "Authentication System by Human Brainwaves Using Machine Learning and Artificial Intelligence",
      "authors": [
        "Zhengbing Hu",
        "V. Buriachok",
        "Mahyar TajDini",
        "V. Sokolov"
      ],
      "year": 2021,
      "citations": 14,
      "abstract": null,
      "venue": "Advances in Computer Science for Engineering and Education IV",
      "filename": "16-Authentication System by Human Brainwaves Using Machine Learning and Artificial Intelligence.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "db6ad6ded1cfa26fdc7437f27fb823ec533e96fe": {
      "title": "Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions",
      "authors": [
        "Iqbal H. Sarker"
      ],
      "year": 2021,
      "citations": 1273,
      "abstract": null,
      "venue": "SN Computer Science",
      "filename": "19-Deep Learning A Comprehensive Overview on Techniques Taxonomy Applications and Research Directions.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "739a0ce951a052246cb0a10272ca7abb9d149684": {
      "title": "Artificial Intelligence in Hypertension Management: An Ace up Your Sleeve",
      "authors": [
        "V. Visco",
        "C. Izzo",
        "C. Mancusi",
        "A. Rispoli",
        "Michele Tedeschi",
        "N. Virtuoso",
        "A. Giano",
        "R. Gioia",
        "Americo Melfi",
        "B. Serio",
        "M. Rusciano",
        "P. Di Pietro",
        "A. Bramanti",
        "G. Galasso",
        "Gianni DâAngelo",
        "A. Carrizzo",
        "C. Vecchione",
        "M. Ciccarelli"
      ],
      "year": 2023,
      "citations": 32,
      "abstract": "Arterial hypertension (AH) is a progressive issue that grows in importance with the increased average age of the world population. The potential role of artificial intelligence (AI) in its prevention and treatment is firmly recognized. Indeed, AI application allows personalized medicine and tailored treatment for each patient. Specifically, this article reviews the benefits of AI in AH management, pointing out diagnostic and therapeutic improvements without ignoring the limitations of this innovative scientific approach. Consequently, we conducted a detailed search on AI applications in AH: the articles (quantitative and qualitative) reviewed in this paper were obtained by searching journal databases such as PubMed and subject-specific professional websites, including Google Scholar. The search terms included artificial intelligence, artificial neural network, deep learning, machine learning, big data, arterial hypertension, blood pressure, blood pressure measurement, cardiovascular disease, and personalized medicine. Specifically, AI-based systems could help continuously monitor BP using wearable technologies; in particular, BP can be estimated from a photoplethysmograph (PPG) signal obtained from a smartphone or a smartwatch using DL. Furthermore, thanks to ML algorithms, it is possible to identify new hypertension genes for the early diagnosis of AH and the prevention of complications. Moreover, integrating AI with omics-based technologies will lead to the definition of the trajectory of the hypertensive patient and the use of the most appropriate drug. However, AI is not free from technical issues and biases, such as over/underfitting, the âblack-boxâ nature of many ML algorithms, and patient data privacy. In conclusion, AI-based systems will change clinical practice for AH by identifying patient trajectories for new, personalized care plans and predicting patientsâ risks and necessary therapy adjustments due to changes in disease progression and/or therapy response.",
      "venue": "Journal of Cardiovascular Development and Disease",
      "filename": "20-Artificial Intelligence in Hypertension Management An Ace up Your Sleeve.pdf",
      "downloaded_date": "2025-01-31",
      "source": "semantic_scholar"
    },
    "2411.01098v1": {
      "title": "Artificial Intelligence for Microbiology and Microbiome Research",
      "authors": [
        "Xu-Wen Wang",
        "Tong Wang",
        "Yang-Yu Liu"
      ],
      "abstract": "Advancements in artificial intelligence (AI) have transformed many scientific\nfields, with microbiology and microbiome research now experiencing significant\nbreakthroughs through machine learning and deep learning applications. This\nreview provides a comprehensive overview of AI-driven approaches tailored for\nmicrobiology and microbiome studies, emphasizing both technical advancements\nand biological insights. We begin with an introduction to foundational AI\ntechniques, including primary machine learning paradigms and various deep\nlearning architectures, and offer guidance on choosing between machine learning\nand deep learning methods based on specific research goals. The primary section\non application scenarios spans diverse research areas, from taxonomic\nprofiling, functional annotation & prediction, microbe-X interactions,\nmicrobial ecology, metabolic modeling, precision nutrition, clinical\nmicrobiology, to prevention & therapeutics. Finally, we discuss challenges\nunique to this field, including the balance between interpretability and\ncomplexity, the \"small n, large p\" problem, and the critical need for\nstandardized benchmarking datasets to validate and compare models. Together,\nthis review underscores AI's transformative role in microbiology and microbiome\nresearch, paving the way for innovative methodologies and applications that\nenhance our understanding of microbial life and its impact on our planet and\nour health.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-11-02",
      "downloaded_date": "2025-01-31",
      "filename": "Wang-Artificial Intelligence for Microbiology and Microbiome Research.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.01098v1",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2202.10336v1": {
      "title": "Artificial Intelligence for the Metaverse: A Survey",
      "authors": [
        "Thien Huynh-The",
        "Quoc-Viet Pham",
        "Xuan-Qui Pham",
        "Thanh Thi Nguyen",
        "Zhu Han",
        "Dong-Seong Kim"
      ],
      "abstract": "Along with the massive growth of the Internet from the 1990s until now,\nvarious innovative technologies have been created to bring users breathtaking\nexperiences with more virtual interactions in cyberspace. Many virtual\nenvironments with thousands of services and applications, from social networks\nto virtual gaming worlds, have been developed with immersive experience and\ndigital transformation, but most are incoherent instead of being integrated\ninto a platform. In this context, metaverse, a term formed by combining meta\nand universe, has been introduced as a shared virtual world that is fueled by\nmany emerging technologies, such as fifth-generation networks and beyond,\nvirtual reality, and artificial intelligence (AI). Among such technologies, AI\nhas shown the great importance of processing big data to enhance immersive\nexperience and enable human-like intelligence of virtual agents. In this\nsurvey, we make a beneficial effort to explore the role of AI in the foundation\nand development of the metaverse. We first deliver a preliminary of AI,\nincluding machine learning algorithms and deep learning architectures, and its\nrole in the metaverse. We then convey a comprehensive investigation of AI-based\nmethods concerning six technical aspects that have potentials for the\nmetaverse: natural language processing, machine vision, blockchain, networking,\ndigital twin, and neural interface, and being potential for the metaverse.\nSubsequently, several AI-aided applications, such as healthcare, manufacturing,\nsmart cities, and gaming, are studied to be deployed in the virtual worlds.\nFinally, we conclude the key contribution of this survey and open some future\nresearch directions in AI for the metaverse.",
      "citation_count": 346,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/96a35bb48ef7c603ffc6c1e8119bca550fa85dfa",
      "published_date": "2022-02-15",
      "downloaded_date": "2025-01-31",
      "filename": "Huynh-The-Artificial Intelligence for the Metaverse A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.10336v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ]
    },
    "1802.02172v3": {
      "title": "Augmented Artificial Intelligence: a Conceptual Framework",
      "authors": [
        "Alexander N. Gorban",
        "Bogdan Grechuk",
        "Ivan Y. Tyukin"
      ],
      "abstract": "All artificial Intelligence (AI) systems make errors. These errors are\nunexpected, and differ often from the typical human mistakes (\"non-human\"\nerrors). The AI errors should be corrected without damage of existing skills\nand, hopefully, avoiding direct human expertise. This paper presents an initial\nsummary report of project taking new and systematic approach to improving the\nintellectual effectiveness of the individual AI by communities of AIs. We\ncombine some ideas of learning in heterogeneous multiagent systems with new and\noriginal mathematical approaches for non-iterative corrections of errors of\nlegacy AI systems. The mathematical foundations of AI non-destructive\ncorrection are presented and a series of new stochastic separation theorems is\nproven. These theorems provide a new instrument for the development, analysis,\nand assessment of machine learning methods and algorithms in high dimension.\nThey demonstrate that in high dimensions and even for exponentially large\nsamples, linear classifiers in their classical Fisher's form are powerful\nenough to separate errors from correct responses with high probability and to\nprovide efficient solution to the non-destructive corrector problem. In\nparticular, we prove some hypotheses formulated in our paper `Stochastic\nSeparation Theorems' (Neural Networks, 94, 255--259, 2017), and answer one\ngeneral problem published by Donoho and Tanner in 2009.",
      "citation_count": 13,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3e51bd4f8eb7b4cc09f6d05c8ca4182138d7e18a",
      "published_date": "2018-02-06",
      "downloaded_date": "2025-01-31",
      "filename": "Gorban-Augmented Artificial Intelligence a Conceptual Framework.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1802.02172v3",
      "categories": [
        "cs.AI"
      ]
    },
    "2112.10133v3": {
      "title": "Information Field Theory and Artificial Intelligence",
      "authors": [
        "Torsten EnÃlin"
      ],
      "abstract": "Information field theory (IFT), the information theory for fields, is a\nmathematical framework for signal reconstruction and non-parametric inverse\nproblems. Artificial intelligence (AI) and machine learning (ML) aim at\ngenerating intelligent systems including such for perception, cognition, and\nlearning. This overlaps with IFT, which is designed to address perception,\nreasoning, and inference tasks. Here, the relation between concepts and tools\nin IFT and those in AI and ML research are discussed. In the context of IFT,\nfields denote physical quantities that change continuously as a function of\nspace (and time) and information theory refers to Bayesian probabilistic logic\nequipped with the associated entropic information measures. Reconstructing a\nsignal with IFT is a computational problem similar to training a generative\nneural network (GNN) in ML. In this paper, the process of inference in IFT is\nreformulated in terms of GNN training. In contrast to classical neural\nnetworks, IFT based GNNs can operate without pre-training thanks to\nincorporating expert knowledge into their architecture. Furthermore, the\ncross-fertilization of variational inference methods used in IFT and ML are\ndiscussed. These discussions suggests that IFT is well suited to address many\nproblems in AI and ML research and application.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/14e34025b5d52788636279832404f316199e569c",
      "published_date": "2021-12-19",
      "downloaded_date": "2025-01-31",
      "filename": "EnÃlin-Information Field Theory and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2112.10133v3",
      "categories": [
        "stat.ML",
        "cs.LG",
        "eess.SP"
      ]
    },
    "2501.09628v1": {
      "title": "Artificial Intelligence-Driven Clinical Decision Support Systems",
      "authors": [
        "Muhammet Alkan",
        "Idris Zakariyya",
        "Samuel Leighton",
        "Kaushik Bhargav Sivangi",
        "Christos Anagnostopoulos",
        "Fani Deligianni"
      ],
      "abstract": "As artificial intelligence (AI) becomes increasingly embedded in healthcare\ndelivery, this chapter explores the critical aspects of developing reliable and\nethical Clinical Decision Support Systems (CDSS). Beginning with the\nfundamental transition from traditional statistical models to sophisticated\nmachine learning approaches, this work examines rigorous validation strategies\nand performance assessment methods, including the crucial role of model\ncalibration and decision curve analysis. The chapter emphasizes that creating\ntrustworthy AI systems in healthcare requires more than just technical\naccuracy; it demands careful consideration of fairness, explainability, and\nprivacy. The challenge of ensuring equitable healthcare delivery through AI is\nstressed, discussing methods to identify and mitigate bias in clinical\npredictive models. The chapter then delves into explainability as a cornerstone\nof human-centered CDSS. This focus reflects the understanding that healthcare\nprofessionals must not only trust AI recommendations but also comprehend their\nunderlying reasoning. The discussion advances in an analysis of privacy\nvulnerabilities in medical AI systems, from data leakage in deep learning\nmodels to sophisticated attacks against model explanations. The text explores\nprivacy-preservation strategies such as differential privacy and federated\nlearning, while acknowledging the inherent trade-offs between privacy\nprotection and model performance. This progression, from technical validation\nto ethical considerations, reflects the multifaceted challenges of developing\nAI systems that can be seamlessly and reliably integrated into daily clinical\npractice while maintaining the highest standards of patient care and data\nprotection.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2025-01-16",
      "downloaded_date": "2025-01-31",
      "filename": "Alkan-Artificial Intelligence-Driven Clinical Decision Support Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.09628v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2206.03951v1": {
      "title": "Interpretability of artificial neural network models in artificial Intelligence vs. neuroscience",
      "authors": [
        "Kohitij Kar",
        "Simon Kornblith",
        "Evelina Fedorenko"
      ],
      "abstract": "Computationally explicit hypotheses of brain function derived from machine\nlearning (ML)-based models have recently revolutionized neuroscience. Despite\nthe unprecedented ability of these artificial neural networks (ANNs) to capture\nresponses in biological neural networks (brains), and our full access to all\ninternal model components (unlike the brain), ANNs are often referred to as\nblack-boxes with limited interpretability. Interpretability, however, is a\nmulti-faceted construct that is used differently across fields. In particular,\ninterpretability, or explainability, efforts in Artificial Intelligence (AI)\nfocus on understanding how different model components contribute to its output\n(i.e., decision making). In contrast, the neuroscientific interpretability of\nANNs requires explicit alignment between model components and neuroscientific\nconstructs (e.g., different brain areas or phenomena, like recurrence or\ntop-down feedback). Given the widespread calls to improve the interpretability\nof AI systems, we here highlight these different notions of interpretability\nand argue that the neuroscientific interpretability of ANNs can be pursued in\nparallel with, but independently from, the ongoing efforts in AI. Certain ML\ntechniques (e.g., deep dream) can be leveraged in both fields, to ask what\nstimulus optimally activates the specific model features (feature visualization\nby optimization), or how different features contribute to the model's output\n(feature attribution). However, without appropriate brain alignment, certain\nfeatures will remain uninterpretable to neuroscientists.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-06-07",
      "downloaded_date": "2025-01-31",
      "filename": "Kar-Interpretability of artificial neural network models in artificial Intelligence vs neuroscience.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.03951v1",
      "categories": [
        "q-bio.NC"
      ]
    },
    "2409.10523v1": {
      "title": "Harnessing Artificial Intelligence for Wildlife Conservation",
      "authors": [
        "Paul Fergus",
        "Carl Chalmers",
        "Steve Longmore",
        "Serge Wich"
      ],
      "abstract": "The rapid decline in global biodiversity demands innovative conservation\nstrategies. This paper examines the use of artificial intelligence (AI) in\nwildlife conservation, focusing on the Conservation AI platform. Leveraging\nmachine learning and computer vision, Conservation AI detects and classifies\nanimals, humans, and poaching-related objects using visual spectrum and thermal\ninfrared cameras. The platform processes this data with convolutional neural\nnetworks (CNNs) and Transformer architectures to monitor species, including\nthose which are critically endangered. Real-time detection provides the\nimmediate responses required for time-critical situations (e.g. poaching),\nwhile non-real-time analysis supports long-term wildlife monitoring and habitat\nhealth assessment. Case studies from Europe, North America, Africa, and\nSoutheast Asia highlight the platform's success in species identification,\nbiodiversity monitoring, and poaching prevention. The paper also discusses\nchallenges related to data quality, model accuracy, and logistical constraints,\nwhile outlining future directions involving technological advancements,\nexpansion into new geographical regions, and deeper collaboration with local\ncommunities and policymakers. Conservation AI represents a significant step\nforward in addressing the urgent challenges of wildlife conservation, offering\na scalable and adaptable solution that can be implemented globally.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-08-30",
      "downloaded_date": "2025-01-31",
      "filename": "Fergus-Harnessing Artificial Intelligence for Wildlife Conservation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.10523v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "2101.10899v1": {
      "title": "Artificial Intelligence for Satellite Communication: A Review",
      "authors": [
        "Fares Fourati",
        "Mohamed-Slim Alouini"
      ],
      "abstract": "Satellite communication offers the prospect of service continuity over\nuncovered and under-covered areas, service ubiquity, and service scalability.\nHowever, several challenges must first be addressed to realize these benefits,\nas the resource management, network control, network security, spectrum\nmanagement, and energy usage of satellite networks are more challenging than\nthat of terrestrial networks. Meanwhile, artificial intelligence (AI),\nincluding machine learning, deep learning, and reinforcement learning, has been\nsteadily growing as a research field and has shown successful results in\ndiverse applications, including wireless communication. In particular, the\napplication of AI to a wide variety of satellite communication aspects have\ndemonstrated excellent potential, including beam-hopping, anti-jamming, network\ntraffic forecasting, channel modeling, telemetry mining, ionospheric\nscintillation detecting, interference managing, remote sensing, behavior\nmodeling, space-air-ground integrating, and energy managing. This work thus\nprovides a general overview of AI, its diverse sub-fields, and its\nstate-of-the-art algorithms. Several challenges facing diverse aspects of\nsatellite communication systems are then discussed, and their proposed and\npotential AI-based solutions are presented. Finally, an outlook of field is\ndrawn, and future steps are suggested.",
      "citation_count": 90,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7ed3d41d5ba99a390ac9233e9c3d6af62358aee5",
      "published_date": "2021-01-25",
      "downloaded_date": "2025-01-31",
      "filename": "Fourati-Artificial Intelligence for Satellite Communication A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.10899v1",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    },
    "2410.01268v2": {
      "title": "Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Unveiling AI's Potential Through Tools, Techniques, and Applications",
      "authors": [
        "Pohsun Feng",
        "Ziqian Bi",
        "Yizhu Wen",
        "Xuanhe Pan",
        "Benji Peng",
        "Ming Liu",
        "Jiawei Xu",
        "Keyu Chen",
        "Junyu Liu",
        "Caitlyn Heqi Yin",
        "Sen Zhang",
        "Jinlang Wang",
        "Qian Niu",
        "Ming Li",
        "Tianyang Wang"
      ],
      "abstract": "Artificial intelligence (AI), machine learning, and deep learning have become\ntransformative forces in big data analytics and management, enabling\ngroundbreaking advancements across diverse industries. This article delves into\nthe foundational concepts and cutting-edge developments in these fields, with a\nparticular focus on large language models (LLMs) and their role in natural\nlanguage processing, multimodal reasoning, and autonomous decision-making.\nHighlighting tools such as ChatGPT, Claude, and Gemini, the discussion explores\ntheir applications in data analysis, model design, and optimization.\n  The integration of advanced algorithms like neural networks, reinforcement\nlearning, and generative models has enhanced the capabilities of AI systems to\nprocess, visualize, and interpret complex datasets. Additionally, the emergence\nof technologies like edge computing and automated machine learning (AutoML)\ndemocratizes access to AI, empowering users across skill levels to engage with\nintelligent systems. This work also underscores the importance of ethical\nconsiderations, transparency, and fairness in the deployment of AI\ntechnologies, paving the way for responsible innovation.\n  Through practical insights into hardware configurations, software\nenvironments, and real-world applications, this article serves as a\ncomprehensive resource for researchers and practitioners. By bridging\ntheoretical underpinnings with actionable strategies, it showcases the\npotential of AI and LLMs to revolutionize big data management and drive\nmeaningful advancements across domains such as healthcare, finance, and\nautonomous systems.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f0fd98df3eb493c0dbcd5160a25edd3701e5f1f7",
      "published_date": "2024-10-02",
      "downloaded_date": "2025-01-31",
      "filename": "Feng-Deep Learning and Machine Learning Advancing Big Data Analytics and Management Unveiling AIs Potenti....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.01268v2",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    "1807.09985v1": {
      "title": "Artificial Intelligent Atomic Force Microscope Enabled by Machine Learning",
      "authors": [
        "Boyuan Huang",
        "Zhenghao Li",
        "Jiangyu Li"
      ],
      "abstract": "Artificial intelligence (AI) and machine learning have promised to\nrevolutionize the way we live and work, and one of particularly promising areas\nfor AI is image analysis. Nevertheless, many current AI applications focus on\npost-processing of data, while in both materials sciences and medicines, it is\noften critical to respond to the data acquired on the fly. Here we demonstrate\nan artificial intelligent atomic force microscope (AI-AFM) that is capable of\nnot only pattern recognition and feature identification in ferroelectric\nmaterials and electrochemical systems, but can also respond to classification\nvia adaptive experimentation with additional probing at critical domain walls\nand grain boundaries, all in real time on the fly without human interference.\nWe believe such a strategy empowered by machine learning is applicable to a\nwide range of instrumentations and broader physical machineries.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/adb01374d2f7167761b7a752964c01c3a80c1b62",
      "published_date": "2018-07-26",
      "downloaded_date": "2025-01-31",
      "filename": "Huang-Artificial Intelligent Atomic Force Microscope Enabled by Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1807.09985v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.ins-det"
      ]
    },
    "2103.16910v1": {
      "title": "Trusted Artificial Intelligence: Towards Certification of Machine Learning Applications",
      "authors": [
        "Philip Matthias Winter",
        "Sebastian Eder",
        "Johannes WeissenbÃ¶ck",
        "Christoph Schwald",
        "Thomas Doms",
        "Tom Vogt",
        "Sepp Hochreiter",
        "Bernhard Nessler"
      ],
      "abstract": "Artificial Intelligence is one of the fastest growing technologies of the\n21st century and accompanies us in our daily lives when interacting with\ntechnical applications. However, reliance on such technical systems is crucial\nfor their widespread applicability and acceptance. The societal tools to\nexpress reliance are usually formalized by lawful regulations, i.e., standards,\nnorms, accreditations, and certificates. Therefore, the T\\\"UV AUSTRIA Group in\ncooperation with the Institute for Machine Learning at the Johannes Kepler\nUniversity Linz, proposes a certification process and an audit catalog for\nMachine Learning applications. We are convinced that our approach can serve as\nthe foundation for the certification of applications that use Machine Learning\nand Deep Learning, the techniques that drive the current revolution in\nArtificial Intelligence. While certain high-risk areas, such as fully\nautonomous robots in workspaces shared with humans, are still some time away\nfrom certification, we aim to cover low-risk applications with our\ncertification procedure. Our holistic approach attempts to analyze Machine\nLearning applications from multiple perspectives to evaluate and verify the\naspects of secure software development, functional requirements, data quality,\ndata protection, and ethics. Inspired by existing work, we introduce four\ncriticality levels to map the criticality of a Machine Learning application\nregarding the impact of its decisions on people, environment, and\norganizations. Currently, the audit catalog can be applied to low-risk\napplications within the scope of supervised learning as commonly encountered in\nindustry. Guided by field experience, scientific developments, and market\ndemands, the audit catalog will be extended and modified accordingly.",
      "citation_count": 23,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/86819a944dbd083caa0f968e5fdb533ac9b5dcc7",
      "published_date": "2021-03-31",
      "downloaded_date": "2025-01-31",
      "filename": "Winter-Trusted Artificial Intelligence Towards Certification of Machine Learning Applications.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.16910v1",
      "categories": [
        "stat.ML",
        "cs.CY",
        "cs.LG",
        "cs.SE"
      ]
    },
    "2101.06573v1": {
      "title": "Understanding in Artificial Intelligence",
      "authors": [
        "Stefan Maetschke",
        "David Martinez Iraola",
        "Pieter Barnard",
        "Elaheh ShafieiBavani",
        "Peter Zhong",
        "Ying Xu",
        "Antonio Jimeno Yepes"
      ],
      "abstract": "Current Artificial Intelligence (AI) methods, most based on deep learning,\nhave facilitated progress in several fields, including computer vision and\nnatural language understanding. The progress of these AI methods is measured\nusing benchmarks designed to solve challenging tasks, such as visual question\nanswering. A question remains of how much understanding is leveraged by these\nmethods and how appropriate are the current benchmarks to measure understanding\ncapabilities. To answer these questions, we have analysed existing benchmarks\nand their understanding capabilities, defined by a set of understanding\ncapabilities, and current research streams. We show how progress has been made\nin benchmark development to measure understanding capabilities of AI methods\nand we review as well how current methods develop understanding capabilities.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-01-17",
      "downloaded_date": "2025-01-31",
      "filename": "Maetschke-Understanding in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.06573v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2006.12362v1": {
      "title": "Artificial intelligence in space",
      "authors": [
        "George Anthony Gal",
        "Cristiana Santos",
        "Lucien Rapp",
        "RÃ©eka Markovich",
        "Leendert van der Torre"
      ],
      "abstract": "In the next coming years, space activities are expected to undergo a radical\ntransformation with the emergence of new satellite systems or new services\nwhich will incorporate the contributions of artificial intelligence and machine\nlearning defined as covering a wide range of innovations from autonomous\nobjects with their own decision-making power to increasingly sophisticated\nservices exploiting very large volumes of information from space. This chapter\nidentifies some of the legal and ethical challenges linked to its use. These\nlegal and ethical challenges call for solutions which the international\ntreaties in force are not sufficient to determine and implement. For this\nreason, a legal methodology must be developed that makes it possible to link\nintelligent systems and services to a system of rules applicable thereto. It\ndiscusses existing legal AI-based tools amenable for making space law\nactionable, interoperable and machine readable for future compliance tools.",
      "citation_count": 24,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/91850e845f0b5b2bf93f018875949b2dad197e55",
      "published_date": "2020-06-22",
      "downloaded_date": "2025-01-31",
      "filename": "Gal-Artificial intelligence in space.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2006.12362v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2203.09664v1": {
      "title": "Emerging Artificial Intelligence Applications in Spatial Transcriptomics Analysis",
      "authors": [
        "Yijun Li",
        "Stefan Stanojevic",
        "Lana X. Garmire"
      ],
      "abstract": "Spatial transcriptomics (ST) has advanced significantly in the last few\nyears. Such advancement comes with the urgent need for novel computational\nmethods to handle the unique challenges of ST data analysis. Many artificial\nintelligence (AI) methods have been developed to utilize various machine\nlearning and deep learning techniques for computational ST analysis. This\nreview provides a comprehensive and up-to-date survey of current AI methods for\nST analysis.",
      "citation_count": 21,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3462d7e20e3f34d6d1c9c85d6baca37ebfa9ab48",
      "published_date": "2022-03-18",
      "downloaded_date": "2025-01-31",
      "filename": "Li-Emerging Artificial Intelligence Applications in Spatial Transcriptomics Analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.09664v1",
      "categories": [
        "cs.LG",
        "q-bio.GN"
      ]
    },
    "2202.01690v1": {
      "title": "Machine Learning and Artificial Intelligence in Next-Generation Wireless Network",
      "authors": [
        "Wafeeq Iqbal",
        "Wei Wang",
        "Ting Zhu"
      ],
      "abstract": "Due to the advancement in technologies, the next-generation wireless network\nwill be very diverse, complicated, and according to the changed demands of the\nconsumers. The current network operator methodologies and approaches are\ntraditional and cannot help the next generation networks to utilize their\nresources most appropriately. The limited capability of the traditional tools\nwill not allow the network providers to fulfill the demands of the network's\nsubscribers in the future. Therefore, this paper will focus on machine\nlearning, automation, artificial intelligence, and big data analytics for\nimproving the capacity and effectiveness of next-generation wireless networks.\nThe paper will discuss the role of these new technologies in improving the\nservice and performance of the network providers in the future. The paper will\nfind out that machine learning, big data analytics, and artificial intelligence\nwill help in making the next-generation wireless network self-adaptive,\nself-aware, prescriptive, and proactive. At the end of the paper, it will be\nprovided that future wireless network operators cannot work without shifting\ntheir operational framework to AI and machine learning technologies.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2a38d6d7d275b6cc7bd6e437208290f1fc45c678",
      "published_date": "2021-12-30",
      "downloaded_date": "2025-01-31",
      "filename": "Iqbal-Machine Learning and Artificial Intelligence in Next-Generation Wireless Network.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.01690v1",
      "categories": [
        "cs.NI",
        "cs.AI"
      ]
    },
    "2012.06034v1": {
      "title": "Artificial Intelligence & Cooperation",
      "authors": [
        "Elisa Bertino",
        "Finale Doshi-Velez",
        "Maria Gini",
        "Daniel Lopresti",
        "David Parkes"
      ],
      "abstract": "The rise of Artificial Intelligence (AI) will bring with it an\never-increasing willingness to cede decision-making to machines. But rather\nthan just giving machines the power to make decisions that affect us, we need\nways to work cooperatively with AI systems. There is a vital need for research\nin \"AI and Cooperation\" that seeks to understand the ways in which systems of\nAIs and systems of AIs with people can engender cooperative behavior. Trust in\nAI is also key: trust that is intrinsic and trust that can only be earned over\ntime. Here we use the term \"AI\" in its broadest sense, as employed by the\nrecent 20-Year Community Roadmap for AI Research (Gil and Selman, 2019),\nincluding but certainly not limited to, recent advances in deep learning.\n  With success, cooperation between humans and AIs can build society just as\nhuman-human cooperation has. Whether coming from an intrinsic willingness to be\nhelpful, or driven through self-interest, human societies have grown strong and\nthe human species has found success through cooperation. We cooperate \"in the\nsmall\" -- as family units, with neighbors, with co-workers, with strangers --\nand \"in the large\" as a global community that seeks cooperative outcomes around\nquestions of commerce, climate change, and disarmament. Cooperation has evolved\nin nature also, in cells and among animals. While many cases involving\ncooperation between humans and AIs will be asymmetric, with the human\nultimately in control, AI systems are growing so complex that, even today, it\nis impossible for the human to fully comprehend their reasoning,\nrecommendations, and actions when functioning simply as passive observers.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ffef2a2dd515673d5789f416de43690620144d77",
      "published_date": "2020-12-10",
      "downloaded_date": "2025-01-31",
      "filename": "Bertino-Artificial Intelligence  Cooperation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.06034v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "1806.03982v2": {
      "title": "Quantitative Phase Imaging and Artificial Intelligence: A Review",
      "authors": [
        "YoungJu Jo",
        "Hyungjoo Cho",
        "Sang Yun Lee",
        "Gunho Choi",
        "Geon Kim",
        "Hyun-seok Min",
        "YongKeun Park"
      ],
      "abstract": "Recent advances in quantitative phase imaging (QPI) and artificial\nintelligence (AI) have opened up the possibility of an exciting frontier. The\nfast and label-free nature of QPI enables the rapid generation of large-scale\nand uniform-quality imaging data in two, three, and four dimensions.\nSubsequently, the AI-assisted interrogation of QPI data using data-driven\nmachine learning techniques results in a variety of biomedical applications.\nAlso, machine learning enhances QPI itself. Herein, we review the synergy\nbetween QPI and machine learning with a particular focus on deep learning.\nFurther, we provide practical guidelines and perspectives for further\ndevelopment.",
      "citation_count": 150,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/737a59b9f7f45885bbae959ca6f254170bd2ade3",
      "published_date": "2018-06-06",
      "downloaded_date": "2025-01-31",
      "filename": "Jo-Quantitative Phase Imaging and Artificial Intelligence A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1806.03982v2",
      "categories": [
        "cs.CV",
        "physics.data-an",
        "physics.optics"
      ]
    },
    "2410.15951v1": {
      "title": "Redefining Finance: The Influence of Artificial Intelligence (AI) and Machine Learning (ML)",
      "authors": [
        "Animesh Kumar"
      ],
      "abstract": "With rapid transformation of technologies, the fusion of Artificial\nIntelligence (AI) and Machine Learning (ML) in finance is disrupting the entire\necosystem and operations which were followed for decades. The current landscape\nis where decisions are increasingly data-driven by financial institutions with\nan appetite for automation while mitigating risks. The segments of financial\ninstitutions which are getting heavily influenced are retail banking, wealth\nmanagement, corporate banking & payment ecosystem. The solution ranges from\nonboarding the customers all the way fraud detection & prevention to enhancing\nthe customer services. Financial Institutes are leap frogging with integration\nof Artificial Intelligence and Machine Learning in mainstream applications and\nenhancing operational efficiency through advanced predictive analytics,\nextending personalized customer experiences, and automation to minimize risk\nwith fraud detection techniques. However, with Adoption of AI & ML, it is\nimperative that the financial institute also needs to address ethical and\nregulatory challenges, by putting in place robust governance frameworks and\nresponsible AI practices.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e2734f9345ed25141e8bc4def9fc9ebd5d504563",
      "published_date": "2024-10-21",
      "downloaded_date": "2025-01-31",
      "filename": "Kumar-Redefining Finance The Influence of Artificial Intelligence AI and Machine Learning ML.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.15951v1",
      "categories": [
        "cs.AI",
        "68Txx - Artificial Intelligence",
        "I.2.7"
      ]
    },
    "2410.15584v2": {
      "title": "Deep Learning and Machine Learning -- Object Detection and Semantic Segmentation: From Theory to Applications",
      "authors": [
        "Jintao Ren",
        "Ziqian Bi",
        "Qian Niu",
        "Junyu Liu",
        "Benji Peng",
        "Sen Zhang",
        "Xuanhe Pan",
        "Jinlang Wang",
        "Keyu Chen",
        "Caitlyn Heqi Yin",
        "Pohsun Feng",
        "Yizhu Wen",
        "Tianyang Wang",
        "Silin Chen",
        "Ming Li",
        "Jiawei Xu",
        "Ming Liu"
      ],
      "abstract": "An in-depth exploration of object detection and semantic segmentation is\nprovided, combining theoretical foundations with practical applications.\nState-of-the-art advancements in machine learning and deep learning are\nreviewed, focusing on convolutional neural networks (CNNs), YOLO architectures,\nand transformer-based approaches such as DETR. The integration of artificial\nintelligence (AI) techniques and large language models for enhancing object\ndetection in complex environments is examined. Additionally, a comprehensive\nanalysis of big data processing is presented, with emphasis on model\noptimization and performance evaluation metrics. By bridging the gap between\ntraditional methods and modern deep learning frameworks, valuable insights are\noffered for researchers, data scientists, and engineers aiming to apply\nAI-driven methodologies to large-scale object detection tasks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-10-21",
      "downloaded_date": "2025-01-31",
      "filename": "Ren-Deep Learning and Machine Learning -- Object Detection and Semantic Segmentation From Theory to Appl....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.15584v2",
      "categories": [
        "cs.CV",
        "cs.GR"
      ]
    },
    "2408.00208v1": {
      "title": "Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis",
      "authors": [
        "SaeedReza Motamedian",
        "Sadra Mohaghegh",
        "Elham Babadi Oregani",
        "Mahrsa Amjadi",
        "Parnian Shobeiri",
        "Negin Cheraghi",
        "Niusha Solouki",
        "Nikoo Ahmadi",
        "Hossein Mohammad-Rahimi",
        "Yassine Bouchareb",
        "Arman Rahmim"
      ],
      "abstract": "Purpose: Artificial intelligence (AI) techniques have been extensively\nutilized for diagnosing and prognosis of several diseases in recent years. This\nstudy identifies, appraises and synthesizes published studies on the use of AI\nfor the prognosis of COVID-19. Method: Electronic search was performed using\nMedline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that\nexamined machine learning or deep learning methods to determine the prognosis\nof COVID-19 using CT or chest X-ray images were included. Polled sensitivity,\nspecificity area under the curve and diagnostic odds ratio were calculated.\nResult: A total of 36 articles were included; various prognosis-related issues,\nincluding disease severity, mechanical ventilation or admission to the\nintensive care unit and mortality, were investigated. Several AI models and\narchitectures were employed, such as the Siamense model, support vector\nmachine, Random Forest , eXtreme Gradient Boosting, and convolutional neural\nnetworks. The models achieved 71%, 88% and 67% sensitivity for mortality,\nseverity assessment and need for ventilation, respectively. The specificity of\n69%, 89% and 89% were reported for the aforementioned variables. Conclusion:\nBased on the included articles, machine learning and deep learning methods used\nfor the prognosis of COVID-19 patients using radiomic features from CT or CXR\nimages can help clinicians manage patients and allocate resources more\neffectively. These studies also demonstrate that combining patient demographic,\nclinical data, laboratory tests and radiomic features improves model\nperformances.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b87986ff1151333ebde361d5b882581385e2f801",
      "published_date": "2024-08-01",
      "downloaded_date": "2025-01-31",
      "filename": "Motamedian-Prognosis of COVID-19 using Artificial Intelligence A Systematic Review and Meta-analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.00208v1",
      "categories": [
        "physics.med-ph",
        "cs.LG"
      ]
    },
    "2109.11320v1": {
      "title": "Nine Challenges in Artificial Intelligence and Wireless Communications for 6G",
      "authors": [
        "Wen Tong",
        "Geoffrey Ye Li"
      ],
      "abstract": "In recent years, techniques developed in artificial intelligence (AI),\nespecially those in machine learning (ML), have been successfully applied in\nvarious areas, leading to a widespread belief that AI will collectively play an\nimportant role in future wireless communications. To accomplish the aspiration,\nwe present nine challenges to be addressed by the interdisciplinary areas of\nAI/ML and wireless communications, with particular focus towards the sixth\ngeneration (6G) wireless networks. Specifically, this article classifies the\nnine challenges into computation in AI, distributed neural networks and\nlearning, and ML enabled semantic communications.",
      "citation_count": 90,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3c7096c6e53568274a489064380bbf58bcd9f3ca",
      "published_date": "2021-09-23",
      "downloaded_date": "2025-01-31",
      "filename": "Tong-Nine Challenges in Artificial Intelligence and Wireless Communications for 6G.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2109.11320v1",
      "categories": [
        "cs.IT",
        "math.IT"
      ]
    },
    "2407.10239v1": {
      "title": "What is Reproducibility in Artificial Intelligence and Machine Learning Research?",
      "authors": [
        "Abhyuday Desai",
        "Mohamed Abdelhamid",
        "Nakul R. Padalkar"
      ],
      "abstract": "In the rapidly evolving fields of Artificial Intelligence (AI) and Machine\nLearning (ML), the reproducibility crisis underscores the urgent need for clear\nvalidation methodologies to maintain scientific integrity and encourage\nadvancement. The crisis is compounded by the prevalent confusion over\nvalidation terminology. Responding to this challenge, we introduce a validation\nframework that clarifies the roles and definitions of key validation efforts:\nrepeatability, dependent and independent reproducibility, and direct and\nconceptual replicability. This structured framework aims to provide AI/ML\nresearchers with the necessary clarity on these essential concepts,\nfacilitating the appropriate design, conduct, and interpretation of validation\nstudies. By articulating the nuances and specific roles of each type of\nvalidation study, we hope to contribute to a more informed and methodical\napproach to addressing the challenges of reproducibility, thereby supporting\nthe community's efforts to enhance the reliability and trustworthiness of its\nresearch findings.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/843c9e5811a76a294f009463a1c44e1b84312e33",
      "published_date": "2024-04-29",
      "downloaded_date": "2025-01-31",
      "filename": "Desai-What is Reproducibility in Artificial Intelligence and Machine Learning Research.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.10239v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "I.2.m"
      ]
    },
    "2201.07935v2": {
      "title": "Towards deep observation: A systematic survey on artificial intelligence techniques to monitor fetus via Ultrasound Images",
      "authors": [
        "Mahmood Alzubaidi",
        "Marco Agus",
        "Khalid Alyafei",
        "Khaled A Althelaya",
        "Uzair Shah",
        "Alaa Abd-Alrazaq",
        "Mohammed Anbar",
        "Michel Makhlouf",
        "Mowafa Househ"
      ],
      "abstract": "Developing innovative informatics approaches aimed to enhance fetal\nmonitoring is a burgeoning field of study in reproductive medicine. Several\nreviews have been conducted regarding Artificial intelligence (AI) techniques\nto improve pregnancy outcomes. They are limited by focusing on specific data\nsuch as mother's care during pregnancy. This systematic survey aims to explore\nhow artificial intelligence (AI) can assist with fetal growth monitoring via\nUltrasound (US) image. We used eight medical and computer science bibliographic\ndatabases, including PubMed, Embase, PsycINFO, ScienceDirect, IEEE explore, ACM\nLibrary, Google Scholar, and the Web of Science. We retrieved studies published\nbetween 2010 to 2021. Data extracted from studies were synthesized using a\nnarrative approach. Out of 1269 retrieved studies, we included 107 distinct\nstudies from queries that were relevant to the topic in the survey. We found\nthat 2D ultrasound images were more popular (n=88) than 3D and 4D ultrasound\nimages (n=19). Classification is the most used method (n=42), followed by\nsegmentation (n=31), classification integrated with segmentation (n=16) and\nother miscellaneous such as object-detection, regression and reinforcement\nlearning (n=18). The most common areas within the pregnancy domain were the\nfetus head (n=43), then fetus body (n=31), fetus heart (n=13), fetus abdomen\n(n=10), and lastly the fetus face (n=10). In the most recent studies, deep\nlearning techniques were primarily used (n=81), followed by machine learning\n(n=16), artificial neural network (n=7), and reinforcement learning (n=2). AI\ntechniques played a crucial role in predicting fetal diseases and identifying\nfetus anatomy structures during pregnancy. More research is required to\nvalidate this technology from a physician's perspective, such as pilot studies\nand randomized controlled trials on AI and its applications in a hospital\nsetting.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-01-17",
      "downloaded_date": "2025-01-31",
      "filename": "Alzubaidi-Towards deep observation A systematic survey on artificial intelligence techniques to monitor fetus ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2201.07935v2",
      "categories": [
        "cs.LG",
        "cs.CV",
        "cs.CY",
        "eess.IV"
      ]
    },
    "1909.11637v1": {
      "title": "Comparison of Artificial Intelligence Techniques for Project Conceptual Cost Prediction",
      "authors": [
        "Haytham H. Elmousalami"
      ],
      "abstract": "Developing a reliable parametric cost model at the conceptual stage of the\nproject is crucial for projects managers and decision-makers. Existing methods,\nsuch as probabilistic and statistical algorithms have been developed for\nproject cost prediction. However, these methods are unable to produce accurate\nresults for conceptual cost prediction due to small and unstable data samples.\nArtificial intelligence (AI) and machine learning (ML) algorithms include\nnumerous models and algorithms for supervised regression applications.\nTherefore, a comparison analysis for AI models is required to guide\npractitioners to the appropriate model. The study focuses on investigating\ntwenty artificial intelligence (AI) techniques which are conducted for cost\nmodeling such as fuzzy logic (FL) model, artificial neural networks (ANNs),\nmultiple regression analysis (MRA), case-based reasoning (CBR), hybrid models,\nand ensemble methods such as scalable boosting trees (XGBoost). Field canals\nimprovement projects (FCIPs) are used as an actual case study to analyze the\nperformance of the applied ML models. Out of 20 AI techniques, the results\nshowed that the most accurate and suitable method is XGBoost with 9.091% and\n0.929 based on Mean Absolute Percentage Error (MAPE) and adjusted R2. Nonlinear\nadaptability, handling missing values and outliers, model interpretation and\nuncertainty have been discussed for the twenty developed AI models. Keywords:\nArtificial intelligence, Machine learning, ensemble methods, XGBoost,\nevolutionary fuzzy rules generation, Conceptual cost, and parametric cost\nmodel.",
      "citation_count": 62,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a3882e0e2ecac2a11e594175c4459542c6c2b2af",
      "published_date": "2019-08-08",
      "downloaded_date": "2025-01-31",
      "filename": "Elmousalami-Comparison of Artificial Intelligence Techniques for Project Conceptual Cost Prediction.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1909.11637v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1709.02779v1": {
      "title": "Machine learning \\& artificial intelligence in the quantum domain",
      "authors": [
        "Vedran Dunjko",
        "Hans J. Briegel"
      ],
      "abstract": "Quantum information technologies, and intelligent learning systems, are both\nemergent technologies that will likely have a transforming impact on our\nsociety. The respective underlying fields of research -- quantum information\n(QI) versus machine learning (ML) and artificial intelligence (AI) -- have\ntheir own specific challenges, which have hitherto been investigated largely\nindependently. However, in a growing body of recent work, researchers have been\nprobing the question to what extent these fields can learn and benefit from\neach other. QML explores the interaction between quantum computing and ML,\ninvestigating how results and techniques from one field can be used to solve\nthe problems of the other. Recently, we have witnessed breakthroughs in both\ndirections of influence. For instance, quantum computing is finding a vital\napplication in providing speed-ups in ML, critical in our \"big data\" world.\nConversely, ML already permeates cutting-edge technologies, and may become\ninstrumental in advanced quantum technologies. Aside from quantum speed-up in\ndata analysis, or classical ML optimization used in quantum experiments,\nquantum enhancements have also been demonstrated for interactive learning,\nhighlighting the potential of quantum-enhanced learning agents. Finally, works\nexploring the use of AI for the very design of quantum experiments, and for\nperforming parts of genuine research autonomously, have reported their first\nsuccesses. Beyond the topics of mutual enhancement, researchers have also\nbroached the fundamental issue of quantum generalizations of ML/AI concepts.\nThis deals with questions of the very meaning of learning and intelligence in a\nworld that is described by quantum mechanics. In this review, we describe the\nmain ideas, recent developments, and progress in a broad spectrum of research\ninvestigating machine learning and artificial intelligence in the quantum\ndomain.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-09-08",
      "downloaded_date": "2025-01-31",
      "filename": "Dunjko-Machine learning  artificial intelligence in the quantum domain.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1709.02779v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CV"
      ]
    },
    "1804.01396v1": {
      "title": "Artificial Intelligence and its Role in Near Future",
      "authors": [
        "Jahanzaib Shabbir",
        "Tarique Anwer"
      ],
      "abstract": "AI technology has a long history which is actively and constantly changing\nand growing. It focuses on intelligent agents, which contain devices that\nperceive the environment and based on which takes actions in order to maximize\ngoal success chances. In this paper, we will explain the modern AI basics and\nvarious representative applications of AI. In the context of the modern\ndigitalized world, AI is the property of machines, computer programs, and\nsystems to perform the intellectual and creative functions of a person,\nindependently find ways to solve problems, be able to draw conclusions and make\ndecisions. Most artificial intelligence systems have the ability to learn,\nwhich allows people to improve their performance over time. The recent research\non AI tools, including machine learning, deep learning and predictive analysis\nintended toward increasing the planning, learning, reasoning, thinking and\naction taking ability. Based on which, the proposed research intends towards\nexploring on how the human intelligence differs from the artificial\nintelligence. Moreover, we critically analyze what AI of today is capable of\ndoing, why it still cannot reach human intelligence and what are the open\nchallenges existing in front of AI to reach and outperform human level of\nintelligence. Furthermore, it will explore the future predictions for\nartificial intelligence and based on which potential solution will be\nrecommended to solve it within next decades.",
      "citation_count": 128,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b93d9995f9ce3b15f4c4855ae62f0bf6f9bc041f",
      "published_date": "2018-04-01",
      "downloaded_date": "2025-01-31",
      "filename": "Shabbir-Artificial Intelligence and its Role in Near Future.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1804.01396v1",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    "2402.09975v1": {
      "title": "Current and future roles of artificial intelligence in retinopathy of prematurity",
      "authors": [
        "Ali Jafarizadeh",
        "Shadi Farabi Maleki",
        "Parnia Pouya",
        "Navid Sobhi",
        "Mirsaeed Abdollahi",
        "Siamak Pedrammehr",
        "Chee Peng Lim",
        "Houshyar Asadi",
        "Roohallah Alizadehsani",
        "Ru-San Tan",
        "Sheikh Mohammad Shariful Islam",
        "U. Rajendra Acharya"
      ],
      "abstract": "Retinopathy of prematurity (ROP) is a severe condition affecting premature\ninfants, leading to abnormal retinal blood vessel growth, retinal detachment,\nand potential blindness. While semi-automated systems have been used in the\npast to diagnose ROP-related plus disease by quantifying retinal vessel\nfeatures, traditional machine learning (ML) models face challenges like\naccuracy and overfitting. Recent advancements in deep learning (DL), especially\nconvolutional neural networks (CNNs), have significantly improved ROP detection\nand classification. The i-ROP deep learning (i-ROP-DL) system also shows\npromise in detecting plus disease, offering reliable ROP diagnosis potential.\nThis research comprehensively examines the contemporary progress and challenges\nassociated with using retinal imaging and artificial intelligence (AI) to\ndetect ROP, offering valuable insights that can guide further investigation in\nthis domain. Based on 89 original studies in this field (out of 1487 studies\nthat were comprehensively reviewed), we concluded that traditional methods for\nROP diagnosis suffer from subjectivity and manual analysis, leading to\ninconsistent clinical decisions. AI holds great promise for improving ROP\nmanagement. This review explores AI's potential in ROP detection,\nclassification, diagnosis, and prognosis.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cf951c0af9689ef303d5d584aab8a51c881133c0",
      "published_date": "2024-02-15",
      "downloaded_date": "2025-01-31",
      "filename": "Jafarizadeh-Current and future roles of artificial intelligence in retinopathy of prematurity.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.09975v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "J.3.2; J.3.3"
      ]
    },
    "2209.15424v1": {
      "title": "Accurate Long-term Air Temperature Prediction with a Fusion of Artificial Intelligence and Data Reduction Techniques",
      "authors": [
        "DuÅ¡an Fister",
        "Jorge PÃ©rez-Aracil",
        "CÃ©sar PelÃ¡ez-RodrÃ­guez",
        "Javier Del Ser",
        "Sancho Salcedo-Sanz"
      ],
      "abstract": "In this paper three customised Artificial Intelligence (AI) frameworks,\nconsidering Deep Learning (convolutional neural networks), Machine Learning\nalgorithms and data reduction techniques are proposed, for a problem of\nlong-term summer air temperature prediction. Specifically, the prediction of\naverage air temperature in the first and second August fortnights, using input\ndata from previous months, at two different locations, Paris (France) and\nC\\'ordoba (Spain), is considered. The target variable, mainly in the first\nAugust fortnight, can contain signals of extreme events such as heatwaves, like\nthe mega-heatwave of 2003, which affected France and the Iberian Peninsula.\nThus, an accurate prediction of long-term air temperature may be valuable also\nfor different problems related to climate change, such as attribution of\nextreme events, and in other problems related to renewable energy. The analysis\ncarried out this work is based on Reanalysis data, which are first processed by\na correlation analysis among different prediction variables and the target\n(average air temperature in August first and second fortnights). An area with\nthe largest correlation is located, and the variables within, after a feature\nselection process, are the input of different deep learning and ML algorithms.\nThe experiments carried out show a very good prediction skill in the three\nproposed AI frameworks, both in Paris and C\\'ordoba regions.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/49ce29c515544d104608a9c318edbbeffbae99d6",
      "published_date": "2022-09-29",
      "downloaded_date": "2025-01-31",
      "filename": "Fister-Accurate Long-term Air Temperature Prediction with a Fusion of Artificial Intelligence and Data Redu....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.15424v1",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG",
        "68T07, 62P12, 68T01, 68T05"
      ]
    },
    "1901.05406v1": {
      "title": "Artificial Intelligence for Social Good",
      "authors": [
        "Gregory D. Hager",
        "Ann Drobnis",
        "Fei Fang",
        "Rayid Ghani",
        "Amy Greenwald",
        "Terah Lyons",
        "David C. Parkes",
        "Jason Schultz",
        "Suchi Saria",
        "Stephen F. Smith",
        "Milind Tambe"
      ],
      "abstract": "The Computing Community Consortium (CCC), along with the White House Office\nof Science and Technology Policy (OSTP), and the Association for the\nAdvancement of Artificial Intelligence (AAAI), co-sponsored a public workshop\non Artificial Intelligence for Social Good on June 7th, 2016 in Washington, DC.\nThis was one of five workshops that OSTP co-sponsored and held around the\ncountry to spur public dialogue on artificial intelligence, machine learning,\nand to identify challenges and opportunities related to AI. In the AI for\nSocial Good workshop, the successful deployments and the potential use of AI in\nvarious topics that are essential for social good were discussed, including but\nnot limited to urban computing, health, environmental sustainability, and\npublic welfare. This report highlights each of these as well as a number of\ncrosscutting issues.",
      "citation_count": 44,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c26fc9a1ccc05d8e1a025a8866a14f29ef595b8c",
      "published_date": "2019-01-16",
      "downloaded_date": "2025-01-31",
      "filename": "Hager-Artificial Intelligence for Social Good.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.05406v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2109.09844v2": {
      "title": "Assessing clinical utility of Machine Learning and Artificial Intelligence approaches to analyze speech recordings in Multiple Sclerosis: A Pilot Study",
      "authors": [
        "Emil Svoboda",
        "TomÃ¡Å¡ BoÅil",
        "Jan Rusz",
        "Tereza TykalovÃ¡",
        "Dana HorÃ¡kovÃ¡",
        "Charles R. G. Guttman",
        "Krastan B. Blagoev",
        "Hiroto Hatabu",
        "Vlad I. Valtchinov"
      ],
      "abstract": "Background: An early diagnosis together with an accurate disease progression\nmonitoring of multiple sclerosis is an important component of successful\ndisease management. Prior studies have established that multiple sclerosis is\ncorrelated with speech discrepancies. Early research using objective acoustic\nmeasurements has discovered measurable dysarthria.\n  Objective: To determine the potential clinical utility of machine learning\nand deep learning/AI approaches for the aiding of diagnosis, biomarker\nextraction and progression monitoring of multiple sclerosis using speech\nrecordings.\n  Methods: A corpus of 65 MS-positive and 66 healthy individuals reading the\nsame text aloud was used for targeted acoustic feature extraction utilizing\nautomatic phoneme segmentation. A series of binary classification models was\ntrained, tuned, and evaluated regarding their Accuracy and area-under-curve.\n  Results: The Random Forest model performed best, achieving an Accuracy of\n0.82 on the validation dataset and an area-under-curve of 0.76 across 5 k-fold\ncycles on the training dataset. 5 out of 7 acoustic features were statistically\nsignificant.\n  Conclusion: Machine learning and artificial intelligence in automatic\nanalyses of voice recordings for aiding MS diagnosis and progression tracking\nseems promising. Further clinical validation of these methods and their mapping\nonto multiple sclerosis progression is needed, as well as a validating utility\nfor English-speaking populations.",
      "citation_count": 16,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a23a8de9a16d62f9fd783db90d3fc2a9040eefff",
      "published_date": "2021-09-20",
      "downloaded_date": "2025-01-31",
      "filename": "Svoboda-Assessing clinical utility of Machine Learning and Artificial Intelligence approaches to analyze spe....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2109.09844v2",
      "categories": [
        "eess.AS",
        "cs.AI",
        "q-bio.NC"
      ]
    },
    "2410.19849v1": {
      "title": "Deep Learning and Machine Learning -- Python Data Structures and Mathematics Fundamental: From Theory to Practice",
      "authors": [
        "Silin Chen",
        "Ziqian Bi",
        "Junyu Liu",
        "Benji Peng",
        "Sen Zhang",
        "Xuanhe Pan",
        "Jiawei Xu",
        "Jinlang Wang",
        "Keyu Chen",
        "Caitlyn Heqi Yin",
        "Pohsun Feng",
        "Yizhu Wen",
        "Tianyang Wang",
        "Ming Li",
        "Jintao Ren",
        "Qian Niu",
        "Ming Liu"
      ],
      "abstract": "This book provides a comprehensive introduction to the foundational concepts\nof machine learning (ML) and deep learning (DL). It bridges the gap between\ntheoretical mathematics and practical application, focusing on Python as the\nprimary programming language for implementing key algorithms and data\nstructures. The book covers a wide range of topics, including basic and\nadvanced Python programming, fundamental mathematical operations, matrix\noperations, linear algebra, and optimization techniques crucial for training ML\nand DL models. Advanced subjects like neural networks, optimization algorithms,\nand frequency domain methods are also explored, along with real-world\napplications of large language models (LLMs) and artificial intelligence (AI)\nin big data management. Designed for both beginners and advanced learners, the\nbook emphasizes the critical role of mathematical principles in developing\nscalable AI solutions. Practical examples and Python code are provided\nthroughout, ensuring readers gain hands-on experience in applying theoretical\nknowledge to solve complex problems in ML, DL, and big data analytics.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-10-22",
      "downloaded_date": "2025-01-31",
      "filename": "Chen-Deep Learning and Machine Learning -- Python Data Structures and Mathematics Fundamental From Theory....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.19849v1",
      "categories": [
        "cs.LG",
        "cs.DS",
        "cs.PL"
      ]
    },
    "2404.02348v3": {
      "title": "COVID-19 Detection Based on Blood Test Parameters using Various Artificial Intelligence Methods",
      "authors": [
        "Kavian Khanjani",
        "Seyed Rasoul Hosseini",
        "Hamid Taheri",
        "Shahrzad Shashaani",
        "Mohammad Teshnehlab"
      ],
      "abstract": "In 2019, the world faced a new challenge: a COVID-19 disease caused by the\nnovel coronavirus, SARS-CoV-2. The virus rapidly spread across the globe,\nleading to a high rate of mortality, which prompted health organizations to\ntake measures to control its transmission. Early disease detection is crucial\nin the treatment process, and computer-based automatic detection systems have\nbeen developed to aid in this effort. These systems often rely on artificial\nintelligence (AI) approaches such as machine learning, neural networks, fuzzy\nsystems, and deep learning to classify diseases. This study aimed to\ndifferentiate COVID-19 patients from others using self-categorizing classifiers\nand employing various AI methods. This study used two datasets: the blood test\nsamples and radiography images. The best results for the blood test samples\nobtained from San Raphael Hospital, which include two classes of individuals,\nthose with COVID-19 and those with non-COVID diseases, were achieved through\nthe use of the Ensemble method (a combination of a neural network and two\nmachines learning methods). The results showed that this approach for COVID-19\ndiagnosis is cost-effective and provides results in a shorter amount of time\nthan other methods. The proposed model achieved an accuracy of 94.09% on the\ndataset used. Secondly, the radiographic images were divided into four classes:\nnormal, viral pneumonia, ground glass opacity, and COVID-19 infection. These\nwere used for segmentation and classification. The lung lobes were extracted\nfrom the images and then categorized into specific classes. We achieved an\naccuracy of 91.1% on the image dataset. Generally, this study highlights the\npotential of AI in detecting and managing COVID-19 and underscores the\nimportance of continued research and development in this field.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e212fe640b400595822afed7ed97277ee111d7bf",
      "published_date": "2024-04-02",
      "downloaded_date": "2025-01-31",
      "filename": "Khanjani-COVID-19 Detection Based on Blood Test Parameters using Various Artificial Intelligence Methods.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.02348v3",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "2409.17120v1": {
      "title": "Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Handy Appetizer",
      "authors": [
        "Benji Peng",
        "Xuanhe Pan",
        "Yizhu Wen",
        "Ziqian Bi",
        "Keyu Chen",
        "Ming Li",
        "Ming Liu",
        "Qian Niu",
        "Junyu Liu",
        "Jinlang Wang",
        "Sen Zhang",
        "Jiawei Xu",
        "Pohsun Feng"
      ],
      "abstract": "This book explores the role of Artificial Intelligence (AI), Machine Learning\n(ML), and Deep Learning (DL) in driving the progress of big data analytics and\nmanagement. The book focuses on simplifying the complex mathematical concepts\nbehind deep learning, offering intuitive visualizations and practical case\nstudies to help readers understand how neural networks and technologies like\nConvolutional Neural Networks (CNNs) work. It introduces several classic models\nand technologies such as Transformers, GPT, ResNet, BERT, and YOLO,\nhighlighting their applications in fields like natural language processing,\nimage recognition, and autonomous driving. The book also emphasizes the\nimportance of pre-trained models and how they can enhance model performance and\naccuracy, with instructions on how to apply these models in various real-world\nscenarios. Additionally, it provides an overview of key big data management\ntechnologies like SQL and NoSQL databases, as well as distributed computing\nframeworks such as Apache Hadoop and Spark, explaining their importance in\nmanaging and processing vast amounts of data. Ultimately, the book underscores\nthe value of mastering deep learning and big data management skills as critical\ntools for the future workforce, making it an essential resource for both\nbeginners and experienced professionals.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cce9362ef2012f288a3d8b54079696fbca0a2b8e",
      "published_date": "2024-09-25",
      "downloaded_date": "2025-01-31",
      "filename": "Peng-Deep Learning and Machine Learning Advancing Big Data Analytics and Management Handy Appetizer.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.17120v1",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    "2006.11371v2": {
      "title": "Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey",
      "authors": [
        "Arun Das",
        "Paul Rad"
      ],
      "abstract": "Nowadays, deep neural networks are widely used in mission critical systems\nsuch as healthcare, self-driving vehicles, and military which have direct\nimpact on human lives. However, the black-box nature of deep neural networks\nchallenges its use in mission critical applications, raising ethical and\njudicial concerns inducing lack of trust. Explainable Artificial Intelligence\n(XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools,\ntechniques, and algorithms that can generate high-quality interpretable,\nintuitive, human-understandable explanations of AI decisions. In addition to\nproviding a holistic view of the current XAI landscape in deep learning, this\npaper provides mathematical summaries of seminal work. We start by proposing a\ntaxonomy and categorizing the XAI techniques based on their scope of\nexplanations, methodology behind the algorithms, and explanation level or usage\nwhich helps build trustworthy, interpretable, and self-explanatory deep\nlearning models. We then describe the main principles used in XAI research and\npresent the historical timeline for landmark studies in XAI from 2007 to 2020.\nAfter explaining each category of algorithms and approaches in detail, we then\nevaluate the explanation maps generated by eight XAI algorithms on image data,\ndiscuss the limitations of this approach, and provide potential future\ndirections to improve XAI evaluation.",
      "citation_count": 526,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c483beec0afae8d08f011182460095049025b8d1",
      "published_date": "2020-06-16",
      "downloaded_date": "2025-01-31",
      "filename": "Das-Opportunities and Challenges in Explainable Artificial Intelligence XAI A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2006.11371v2",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2202.07276v3": {
      "title": "Explaining reaction coordinates of alanine dipeptide isomerization obtained from deep neural networks using Explainable Artificial Intelligence (XAI)",
      "authors": [
        "Takuma Kikutsuji",
        "Yusuke Mori",
        "Kei-ichi Okazaki",
        "Toshifumi Mori",
        "Kang Kim",
        "Nobuyuki Matubayasi"
      ],
      "abstract": "A method for obtaining appropriate reaction coordinates is required to\nidentify transition states distinguishing product and reactant in complex\nmolecular systems. Recently, abundant research has been devoted to obtaining\nreaction coordinates using artificial neural networks from deep learning\nliterature, where many collective variables are typically utilized in the input\nlayer. However, it is difficult to explain the details of which collective\nvariables contribute to the predicted reaction coordinates owing to the\ncomplexity of the nonlinear functions in deep neural networks. To overcome this\nlimitation, we used Explainable Artificial Intelligence (XAI) methods of the\nLocal Interpretable Model-agnostic Explanation (LIME) and the game theory-based\nframework known as Shapley Additive exPlanations (SHAP). We demonstrated that\nXAI enables us to obtain the degree of contribution of each collective variable\nto reaction coordinates that is determined by nonlinear regressions with deep\nlearning for the committor of the alanine dipeptide isomerization in vacuum. In\nparticular, both LIME and SHAP provide important features to the predicted\nreaction coordinates, which are characterized by appropriate dihedral angles\nconsistent with those previously reported from the committor test analysis. The\npresent study offers an AI-aided framework to explain the appropriate reaction\ncoordinates, which acquires considerable significance when the number of\ndegrees of freedom increases.",
      "citation_count": 25,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a077798a65ab902d84a43acf333da897b69ae4c9",
      "published_date": "2022-02-15",
      "downloaded_date": "2025-01-31",
      "filename": "Kikutsuji-Explaining reaction coordinates of alanine dipeptide isomerization obtained from deep neural network....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.07276v3",
      "categories": [
        "physics.chem-ph",
        "cond-mat.soft"
      ]
    },
    "2202.02283v1": {
      "title": "Choosing an Appropriate Platform and Workflow for Processing Camera Trap Data using Artificial Intelligence",
      "authors": [
        "Juliana VÃ©lez",
        "Paula J. Castiblanco-Camacho",
        "Michael A. Tabak",
        "Carl Chalmers",
        "Paul Fergus",
        "John Fieberg"
      ],
      "abstract": "Camera traps have transformed how ecologists study wildlife species\ndistributions, activity patterns, and interspecific interactions. Although\ncamera traps provide a cost-effective method for monitoring species, the time\nrequired for data processing can limit survey efficiency. Thus, the potential\nof Artificial Intelligence (AI), specifically Deep Learning (DL), to process\ncamera-trap data has gained considerable attention. Using DL for these\napplications involves training algorithms, such as Convolutional Neural\nNetworks (CNNs), to automatically detect objects and classify species. To\novercome technical challenges associated with training CNNs, several research\ncommunities have recently developed platforms that incorporate DL in\neasy-to-use interfaces. We review key characteristics of four AI-powered\nplatforms -- Wildlife Insights (WI), MegaDetector (MD), Machine Learning for\nWildlife Image Classification (MLWIC2), and Conservation AI -- including data\nmanagement tools and AI features. We also provide R code in an open-source\nGitBook, to demonstrate how users can evaluate model performance, and\nincorporate AI output in semi-automated workflows. We found that species\nclassifications from WI and MLWIC2 generally had low recall values (animals\nthat were present in the images often were not classified to the correct\nspecies). Yet, the precision of WI and MLWIC2 classifications for some species\nwas high (i.e., when classifications were made, they were generally accurate).\nMD, which classifies images using broader categories (e.g., \"blank\" or\n\"animal\"), also performed well. Thus, we conclude that, although species\nclassifiers were not accurate enough to automate image processing, DL could be\nused to improve efficiencies by accepting classifications with high confidence\nvalues for certain species or by filtering images containing blanks.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3b3b649cdc7c8ae251ee354b681ffc431559d402",
      "published_date": "2022-02-04",
      "downloaded_date": "2025-01-31",
      "filename": "VÃ©lez-Choosing an Appropriate Platform and Workflow for Processing Camera Trap Data using Artificial Intel....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.02283v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2205.14828v2": {
      "title": "Lepton Flavour Violation Identification in Tau Decay ($Ï^{-} \\rightarrow Î¼^{-}Î¼^{-}Î¼^{+}$) Using Artificial Intelligence",
      "authors": [
        "Reymond Mesuga"
      ],
      "abstract": "The discovery of neutrino oscillation, proving that neutrinos do have masses,\nreveals the misfits of particles in the current Standard Model (SM) theory. In\ntheory, neutrinos having masses could result in lepton flavour not being a\nsymmetry called Lepton Flavour Violation (LFV). While SM theory extensions\nallowed LFV processes, their branching fractions are too small, making them\nunobservable even with the strongest equipment up-to-date. With that,\nscientists in recent years have generated LFV-like processes from the combined\nLHCb and Monte-Carlo-Simulated data in an attempt to identify LFV using\nArtificial Intelligence (AI), specifically Machine Learning (ML) and Deep\nLearning (DL). In this paper, the performance of several algorithms in AI has\nbeen presented, such as XGBoost, LightGBM, custom 1-D Dense Block Neural\nNetworks (DBNNs), and custom 1-D Convolutional Neural Networks (CNNs) in\nidentifying LFV signals, specifically $\\tau^{-} \\rightarrow\n\\mu^{-}\\mu^{-}\\mu^{+}$ decay from the combined LHCb and Monte-Carlo-Simulated\ndata that imitates the signatures of the said decay. Kolmogorov-Smirnov (KS)\nand Cramer-von Mises (CvM) tests were also conducted to verify the validity of\npredictions for each of the trained algorithms. The result shows decent\nperformances among algorithms, except for the LightGBM, for failing the CvM\ntest, and a 20-layered CNN for having recorded a considerably low AUC.\nMeanwhile, XGBoost and a 10-layered DBNN recorded the highest AUC of 0.88. The\nmain contribution of this paper is the extensive experiment involving custom\nDBNN and CNN algorithms in different layers, all of which have been rarely used\nin the past years in identifying LFV-like signatures, unlike GBMs and\ntree-based algorithms, which have been more popular in the said task.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-05-30",
      "downloaded_date": "2025-01-31",
      "filename": "Mesuga-Lepton Flavour Violation Identification in Tau Decay Ï- rightarrow Î¼-Î¼-Î¼ Using Artificial Intelligen....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.14828v2",
      "categories": [
        "hep-ph",
        "cs.LG"
      ]
    },
    "2007.12391v6": {
      "title": "Artificial Intelligence in the Creative Industries: A Review",
      "authors": [
        "Nantheera Anantrasirichai",
        "David Bull"
      ],
      "abstract": "This paper reviews the current state of the art in Artificial Intelligence\n(AI) technologies and applications in the context of the creative industries. A\nbrief background of AI, and specifically Machine Learning (ML) algorithms, is\nprovided including Convolutional Neural Network (CNNs), Generative Adversarial\nNetworks (GANs), Recurrent Neural Networks (RNNs) and Deep Reinforcement\nLearning (DRL). We categorise creative applications into five groups related to\nhow AI technologies are used: i) content creation, ii) information analysis,\niii) content enhancement and post production workflows, iv) information\nextraction and enhancement, and v) data compression. We critically examine the\nsuccesses and limitations of this rapidly advancing technology in each of these\nareas. We further differentiate between the use of AI as a creative tool and\nits potential as a creator in its own right. We foresee that, in the near\nfuture, machine learning-based AI will be adopted widely as a tool or\ncollaborative assistant for creativity. In contrast, we observe that the\nsuccesses of machine learning in domains with fewer constraints, where AI is\nthe `creator', remain modest. The potential of AI (or its developers) to win\nawards for its original creations in competition with human creatives is also\nlimited, based on contemporary technologies. We therefore conclude that, in the\ncontext of creative industries, maximum benefit from AI will be derived where\nits focus is human centric -- where it is designed to augment, rather than\nreplace, human creativity.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-07-24",
      "downloaded_date": "2025-01-31",
      "filename": "Anantrasirichai-Artificial Intelligence in the Creative Industries A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.12391v6",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2201.09130v2": {
      "title": "Artificial Intelligence for Suicide Assessment using Audiovisual Cues: A Review",
      "authors": [
        "Sahraoui Dhelim",
        "Liming Chen",
        "Huansheng Ning",
        "Chris Nugent"
      ],
      "abstract": "Death by suicide is the seventh leading death cause worldwide. The recent\nadvancement in Artificial Intelligence (AI), specifically AI applications in\nimage and voice processing, has created a promising opportunity to\nrevolutionize suicide risk assessment. Subsequently, we have witnessed\nfast-growing literature of research that applies AI to extract audiovisual\nnon-verbal cues for mental illness assessment. However, the majority of the\nrecent works focus on depression, despite the evident difference between\ndepression symptoms and suicidal behavior and non-verbal cues. This paper\nreviews recent works that study suicide ideation and suicide behavior detection\nthrough audiovisual feature analysis, mainly suicidal voice/speech acoustic\nfeatures analysis and suicidal visual cues. Automatic suicide assessment is a\npromising research direction that is still in the early stages. Accordingly,\nthere is a lack of large datasets that can be used to train machine learning\nand deep learning models proven to be effective in other, similar tasks.",
      "citation_count": 18,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bc453bad32137ce9079c4afa8192ea565860a41e",
      "published_date": "2022-01-22",
      "downloaded_date": "2025-01-31",
      "filename": "Dhelim-Artificial Intelligence for Suicide Assessment using Audiovisual Cues A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2201.09130v2",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "cs.HC",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ]
    },
    "1704.01407v3": {
      "title": "Embodied Artificial Intelligence through Distributed Adaptive Control: An Integrated Framework",
      "authors": [
        "ClÃ©ment Moulin-Frier",
        "Jordi-Ysard PuigbÃ²",
        "Xerxes D. Arsiwalla",
        "MartÃ¬ Sanchez-Fibla",
        "Paul F. M. J. Verschure"
      ],
      "abstract": "In this paper, we argue that the future of Artificial Intelligence research\nresides in two keywords: integration and embodiment. We support this claim by\nanalyzing the recent advances of the field. Regarding integration, we note that\nthe most impactful recent contributions have been made possible through the\nintegration of recent Machine Learning methods (based in particular on Deep\nLearning and Recurrent Neural Networks) with more traditional ones (e.g.\nMonte-Carlo tree search, goal babbling exploration or addressable memory\nsystems). Regarding embodiment, we note that the traditional benchmark tasks\n(e.g. visual classification or board games) are becoming obsolete as\nstate-of-the-art learning algorithms approach or even surpass human performance\nin most of them, having recently encouraged the development of first-person 3D\ngame platforms embedding realistic physics. Building upon this analysis, we\nfirst propose an embodied cognitive architecture integrating heterogenous\nsub-fields of Artificial Intelligence into a unified framework. We demonstrate\nthe utility of our approach by showing how major contributions of the field can\nbe expressed within the proposed framework. We then claim that benchmarking\nenvironments need to reproduce ecologically-valid conditions for bootstrapping\nthe acquisition of increasingly complex cognitive skills through the concept of\na cognitive arms race between embodied agents.",
      "citation_count": 24,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/78ffa1f5a3089953005b2293a84e30afdf772d8a",
      "published_date": "2017-04-05",
      "downloaded_date": "2025-01-31",
      "filename": "Moulin-Frier-Embodied Artificial Intelligence through Distributed Adaptive Control An Integrated Framework.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1704.01407v3",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    },
    "2209.10298v1": {
      "title": "Artificial Intelligence-Based Image Reconstruction in Cardiac Magnetic Resonance",
      "authors": [
        "Chen Qin",
        "Daniel Rueckert"
      ],
      "abstract": "Artificial intelligence (AI) and Machine Learning (ML) have shown great\npotential in improving the medical imaging workflow, from image acquisition and\nreconstruction to disease diagnosis and treatment. Particularly, in recent\nyears, there has been a significant growth in the use of AI and ML algorithms,\nespecially Deep Learning (DL) based methods, for medical image reconstruction.\nDL techniques have shown to be competitive and often superior over conventional\nreconstruction methods in terms of both reconstruction quality and\ncomputational efficiency. The use of DL-based image reconstruction also\nprovides promising opportunities to transform the way cardiac images are\nacquired and reconstructed. In this chapter, we will review recent advances in\nDL-based reconstruction techniques for cardiac imaging, with emphasis on\ncardiac magnetic resonance (CMR) image reconstruction. We mainly focus on\nsupervised DL methods for the application, including image post-processing\ntechniques, model-driven approaches and k-space based methods. Current\nlimitations, challenges and future opportunities of DL for cardiac image\nreconstruction are also discussed.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e15343e2a699887e0e813524e1e3c1532efd6559",
      "published_date": "2022-09-21",
      "downloaded_date": "2025-01-31",
      "filename": "Qin-Artificial Intelligence-Based Image Reconstruction in Cardiac Magnetic Resonance.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.10298v1",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "2206.12770v1": {
      "title": "Malware Detection and Prevention using Artificial Intelligence Techniques",
      "authors": [
        "Md Jobair Hossain Faruk",
        "Hossain Shahriar",
        "Maria Valero",
        "Farhat Lamia Barsha",
        "Shahriar Sobhan",
        "Md Abdullah Khan",
        "Michael Whitman",
        "Alfredo Cuzzocreak",
        "Dan Lo",
        "Akond Rahman",
        "Fan Wu"
      ],
      "abstract": "With the rapid technological advancement, security has become a major issue\ndue to the increase in malware activity that poses a serious threat to the\nsecurity and safety of both computer systems and stakeholders. To maintain\nstakeholders, particularly, end users security, protecting the data from\nfraudulent efforts is one of the most pressing concerns. A set of malicious\nprogramming code, scripts, active content, or intrusive software that is\ndesigned to destroy intended computer systems and programs or mobile and web\napplications is referred to as malware. According to a study, naive users are\nunable to distinguish between malicious and benign applications. Thus, computer\nsystems and mobile applications should be designed to detect malicious\nactivities towards protecting the stakeholders. A number of algorithms are\navailable to detect malware activities by utilizing novel concepts including\nArtificial Intelligence, Machine Learning, and Deep Learning. In this study, we\nemphasize Artificial Intelligence (AI) based techniques for detecting and\npreventing malware activity. We present a detailed review of current malware\ndetection technologies, their shortcomings, and ways to improve efficiency. Our\nstudy shows that adopting futuristic approaches for the development of malware\ndetection applications shall provide significant advantages. The comprehension\nof this synthesis shall help researchers for further research on malware\ndetection and prevention using AI.",
      "citation_count": 49,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/da1b7b655fcad95daadb331417375756d36b5abc",
      "published_date": "2022-06-26",
      "downloaded_date": "2025-01-31",
      "filename": "Faruk-Malware Detection and Prevention using Artificial Intelligence Techniques.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.12770v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2412.12668v1": {
      "title": "Artificial Intelligence for Central Dogma-Centric Multi-Omics: Challenges and Breakthroughs",
      "authors": [
        "Lei Xin",
        "Caiyun Huang",
        "Hao Li",
        "Shihong Huang",
        "Yuling Feng",
        "Zhenglun Kong",
        "Zicheng Liu",
        "Siyuan Li",
        "Chang Yu",
        "Fei Shen",
        "Hao Tang"
      ],
      "abstract": "With the rapid development of high-throughput sequencing platforms, an\nincreasing number of omics technologies, such as genomics, metabolomics, and\ntranscriptomics, are being applied to disease genetics research. However,\nbiological data often exhibit high dimensionality and significant noise, making\nit challenging to effectively distinguish disease subtypes using a single-omics\napproach. To address these challenges and better capture the interactions among\nDNA, RNA, and proteins described by the central dogma, numerous studies have\nleveraged artificial intelligence to develop multi-omics models for disease\nresearch. These AI-driven models have improved the accuracy of disease\nprediction and facilitated the identification of genetic loci associated with\ndiseases, thus advancing precision medicine. This paper reviews the\nmathematical definitions of multi-omics, strategies for integrating multi-omics\ndata, applications of artificial intelligence and deep learning in multi-omics,\nthe establishment of foundational models, and breakthroughs in multi-omics\ntechnologies, drawing insights from over 130 related articles. It aims to\nprovide practical guidance for computational biologists to better understand\nand effectively utilize AI-based multi-omics machine learning algorithms in the\ncontext of central dogma.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1d9dc21cbdf927a1a4c7fc6af4816249fd35f912",
      "published_date": "2024-12-17",
      "downloaded_date": "2025-01-31",
      "filename": "Xin-Artificial Intelligence for Central Dogma-Centric Multi-Omics Challenges and Breakthroughs.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.12668v1",
      "categories": [
        "q-bio.GN"
      ]
    },
    "2101.04255v6": {
      "title": "Quantum Mathematics in Artificial Intelligence",
      "authors": [
        "Dominic Widdows",
        "Kirsty Kitto",
        "Trevor Cohen"
      ],
      "abstract": "In the decade since 2010, successes in artificial intelligence have been at\nthe forefront of computer science and technology, and vector space models have\nsolidified a position at the forefront of artificial intelligence. At the same\ntime, quantum computers have become much more powerful, and announcements of\nmajor advances are frequently in the news.\n  The mathematical techniques underlying both these areas have more in common\nthan is sometimes realized. Vector spaces took a position at the axiomatic\nheart of quantum mechanics in the 1930s, and this adoption was a key motivation\nfor the derivation of logic and probability from the linear geometry of vector\nspaces. Quantum interactions between particles are modelled using the tensor\nproduct, which is also used to express objects and operations in artificial\nneural networks.\n  This paper describes some of these common mathematical areas, including\nexamples of how they are used in artificial intelligence (AI), particularly in\nautomated reasoning and natural language processing (NLP). Techniques discussed\ninclude vector spaces, scalar products, subspaces and implication, orthogonal\nprojection and negation, dual vectors, density matrices, positive operators,\nand tensor products. Application areas include information retrieval,\ncategorization and implication, modelling word-senses and disambiguation,\ninference in knowledge bases, and semantic composition.\n  Some of these approaches can potentially be implemented on quantum hardware.\nMany of the practical steps in this implementation are in early stages, and\nsome are already realized. Explaining some of the common mathematical tools can\nhelp researchers in both AI and quantum computing further exploit these\noverlaps, recognizing and exploring new directions along the way.",
      "citation_count": 15,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6181243b00fb7fc91083c2a7d56ad5c21e76419e",
      "published_date": "2021-01-12",
      "downloaded_date": "2025-01-31",
      "filename": "Widdows-Quantum Mathematics in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.04255v6",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    },
    "2303.06455v2": {
      "title": "Graph Neural Network contextual embedding for Deep Learning on Tabular Data",
      "authors": [
        "Mario VillaizÃ¡n-Vallelado",
        "Matteo Salvatori",
        "BelÃ©n Carro Martinez",
        "Antonio Javier Sanchez Esguevillas"
      ],
      "abstract": "All industries are trying to leverage Artificial Intelligence (AI) based on\ntheir existing big data which is available in so called tabular form, where\neach record is composed of a number of heterogeneous continuous and categorical\ncolumns also known as features. Deep Learning (DL) has constituted a major\nbreakthrough for AI in fields related to human skills like natural language\nprocessing, but its applicability to tabular data has been more challenging.\nMore classical Machine Learning (ML) models like tree-based ensemble ones\nusually perform better. This paper presents a novel DL model using Graph Neural\nNetwork (GNN) more specifically Interaction Network (IN), for contextual\nembedding and modelling interactions among tabular features. Its results\noutperform those of a recently published survey with DL benchmark based on five\npublic datasets, also achieving competitive results when compared to\nboosted-tree solutions.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2c9f340202b8a6ab3482c997a772c011171d5755",
      "published_date": "2023-03-11",
      "downloaded_date": "2025-01-31",
      "filename": "VillaizÃ¡n-Vallelado-Graph Neural Network contextual embedding for Deep Learning on Tabular Data.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.06455v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1810.01989v1": {
      "title": "Verification for Machine Learning, Autonomy, and Neural Networks Survey",
      "authors": [
        "Weiming Xiang",
        "Patrick Musau",
        "Ayana A. Wild",
        "Diego Manzanas Lopez",
        "Nathaniel Hamilton",
        "Xiaodong Yang",
        "Joel Rosenfeld",
        "Taylor T. Johnson"
      ],
      "abstract": "This survey presents an overview of verification techniques for autonomous\nsystems, with a focus on safety-critical autonomous cyber-physical systems\n(CPS) and subcomponents thereof. Autonomy in CPS is enabling by recent advances\nin artificial intelligence (AI) and machine learning (ML) through approaches\nsuch as deep neural networks (DNNs), embedded in so-called learning enabled\ncomponents (LECs) that accomplish tasks from classification to control.\nRecently, the formal methods and formal verification community has developed\nmethods to characterize behaviors in these LECs with eventual goals of formally\nverifying specifications for LECs, and this article presents a survey of many\nof these recent approaches.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-10-03",
      "downloaded_date": "2025-01-31",
      "filename": "Xiang-Verification for Machine Learning Autonomy and Neural Networks Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1810.01989v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "1810.11709v3": {
      "title": "Intelligent Nanophotonics: Merging Photonics and Artificial Intelligence at the Nanoscale",
      "authors": [
        "Kan Yao",
        "Rohit Unni",
        "Yuebing Zheng"
      ],
      "abstract": "Nanophotonics has been an active research field over the past two decades,\ntriggered by the rising interests in exploring new physics and technologies\nwith light at the nanoscale. As the demands of performance and integration\nlevel keep increasing, the design and optimization of nanophotonic devices\nbecome computationally expensive and time-inefficient. Advanced computational\nmethods and artificial intelligence, especially its subfield of machine\nlearning, have led to revolutionary development in many applications, such as\nweb searches, computer vision, and speech/image recognition. The complex models\nand algorithms help to exploit the enormous parameter space in a highly\nefficient way. In this review, we summarize the recent advances on the emerging\nfield where nanophotonics and machine learning blend. We provide an overview of\ndifferent computational methods, with the focus on deep learning, for the\nnanophotonic inverse design. The implementation of deep neural networks with\nphotonic platforms is also discussed. This review aims at sketching an\nillustration of the nanophotonic design with machine learning and giving a\nperspective on the future tasks.",
      "citation_count": 253,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bb82053d4229357925b28ffe647377f56d93b06e",
      "published_date": "2018-10-27",
      "downloaded_date": "2025-01-31",
      "filename": "Yao-Intelligent Nanophotonics Merging Photonics and Artificial Intelligence at the Nanoscale.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1810.11709v3",
      "categories": [
        "physics.optics"
      ]
    },
    "2104.00093v2": {
      "title": "Imagine All the People: Citizen Science, Artificial Intelligence, and Computational Research",
      "authors": [
        "Lea A. Shanley",
        "Lucy Fortson",
        "Tanya Berger-Wolf",
        "Kevin Crowston",
        "Pietro Michelucci"
      ],
      "abstract": "Machine learning, artificial intelligence, and deep learning have advanced\nsignificantly over the past decade. Nonetheless, humans possess unique\nabilities such as creativity, intuition, context and abstraction, analytic\nproblem solving, and detecting unusual events. To successfully tackle pressing\nscientific and societal challenges, we need the complementary capabilities of\nboth humans and machines. The Federal Government could accelerate its\npriorities on multiple fronts through judicious integration of citizen science\nand crowdsourcing with artificial intelligence (AI), Internet of Things (IoT),\nand cloud strategies.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/dd26d1e730203aff6906bd800afa344cfd1d2e09",
      "published_date": "2021-03-31",
      "downloaded_date": "2025-01-31",
      "filename": "Shanley-Imagine All the People Citizen Science Artificial Intelligence and Computational Research.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.00093v2",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2501.10465v1": {
      "title": "The Mathematics of Artificial Intelligence",
      "authors": [
        "Gabriel PeyrÃ©"
      ],
      "abstract": "This overview article highlights the critical role of mathematics in\nartificial intelligence (AI), emphasizing that mathematics provides tools to\nbetter understand and enhance AI systems. Conversely, AI raises new problems\nand drives the development of new mathematics at the intersection of various\nfields. This article focuses on the application of analytical and probabilistic\ntools to model neural network architectures and better understand their\noptimization. Statistical questions (particularly the generalization capacity\nof these networks) are intentionally set aside, though they are of crucial\nimportance. We also shed light on the evolution of ideas that have enabled\nsignificant advances in AI through architectures tailored to specific tasks,\neach echoing distinct mathematical techniques. The goal is to encourage more\nmathematicians to take an interest in and contribute to this exciting field.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3b04a0a1d60ca6116edbaeaf0b4f9faf0539738f",
      "published_date": "2025-01-15",
      "downloaded_date": "2025-01-31",
      "filename": "PeyrÃ©-The Mathematics of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.10465v1",
      "categories": [
        "math.OC",
        "cs.AI"
      ]
    },
    "2111.12444v1": {
      "title": "Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications",
      "authors": [
        "Khaled B. Letaief",
        "Yuanming Shi",
        "Jianmin Lu",
        "Jianhua Lu"
      ],
      "abstract": "The thriving of artificial intelligence (AI) applications is driving the\nfurther evolution of wireless networks. It has been envisioned that 6G will be\ntransformative and will revolutionize the evolution of wireless from \"connected\nthings\" to \"connected intelligence\". However, state-of-the-art deep learning\nand big data analytics based AI systems require tremendous computation and\ncommunication resources, causing significant latency, energy consumption,\nnetwork congestion, and privacy leakage in both of the training and inference\nprocesses. By embedding model training and inference capabilities into the\nnetwork edge, edge AI stands out as a disruptive technology for 6G to\nseamlessly integrate sensing, communication, computation, and intelligence,\nthereby improving the efficiency, effectiveness, privacy, and security of 6G\nnetworks. In this paper, we shall provide our vision for scalable and\ntrustworthy edge AI systems with integrated design of wireless communication\nstrategies and decentralized machine learning models. New design principles of\nwireless networks, service-driven resource allocation optimization methods, as\nwell as a holistic end-to-end system architecture to support edge AI will be\ndescribed. Standardization, software and hardware platforms, and application\nscenarios are also discussed to facilitate the industrialization and\ncommercialization of edge AI systems.",
      "citation_count": 356,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/be0bbf06977c4dadbf702287733187884a531b8a",
      "published_date": "2021-11-24",
      "downloaded_date": "2025-01-31",
      "filename": "Letaief-Edge Artificial Intelligence for 6G Vision Enabling Technologies and Applications.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.12444v1",
      "categories": [
        "cs.IT",
        "cs.LG",
        "cs.NI",
        "eess.SP",
        "math.IT"
      ]
    },
    "2206.14615v1": {
      "title": "Quantification of Deep Neural Network Prediction Uncertainties for VVUQ of Machine Learning Models",
      "authors": [
        "Mahmoud Yaseen",
        "Xu Wu"
      ],
      "abstract": "Recent performance breakthroughs in Artificial intelligence (AI) and Machine\nlearning (ML), especially advances in Deep learning (DL), the availability of\npowerful, easy-to-use ML libraries (e.g., scikit-learn, TensorFlow, PyTorch.),\nand increasing computational power have led to unprecedented interest in AI/ML\namong nuclear engineers. For physics-based computational models, Verification,\nValidation and Uncertainty Quantification (VVUQ) have been very widely\ninvestigated and a lot of methodologies have been developed. However, VVUQ of\nML models has been relatively less studied, especially in nuclear engineering.\nIn this work, we focus on UQ of ML models as a preliminary step of ML VVUQ,\nmore specifically, Deep Neural Networks (DNNs) because they are the most widely\nused supervised ML algorithm for both regression and classification tasks. This\nwork aims at quantifying the prediction, or approximation uncertainties of DNNs\nwhen they are used as surrogate models for expensive physical models. Three\ntechniques for UQ of DNNs are compared, namely Monte Carlo Dropout (MCD), Deep\nEnsembles (DE) and Bayesian Neural Networks (BNNs). Two nuclear engineering\nexamples are used to benchmark these methods, (1) time-dependent fission gas\nrelease data using the Bison code, and (2) void fraction simulation based on\nthe BFBT benchmark using the TRACE code. It was found that the three methods\ntypically require different DNN architectures and hyperparameters to optimize\ntheir performance. The UQ results also depend on the amount of training data\navailable and the nature of the data. Overall, all these three methods can\nprovide reasonable estimations of the approximation uncertainties. The\nuncertainties are generally smaller when the mean predictions are close to the\ntest data, while the BNN methods usually produce larger uncertainties than MCD\nand DE.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5a8d14e013173514d1c1eb1ac78f55b309465601",
      "published_date": "2022-06-27",
      "downloaded_date": "2025-01-31",
      "filename": "Yaseen-Quantification of Deep Neural Network Prediction Uncertainties for VVUQ of Machine Learning Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.14615v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2305.16346v1": {
      "title": "Artificial Intelligence-Based Methods for Precision Medicine: Diabetes Risk Prediction",
      "authors": [
        "Farida Mohsen",
        "Hamada R. H. Al-Absi",
        "Noha A. Yousri",
        "Nady El Hajj",
        "Zubair Shah"
      ],
      "abstract": "The rising prevalence of type 2 diabetes mellitus (T2DM) necessitates the\ndevelopment of predictive models for T2DM risk assessment. Artificial\nintelligence (AI) models are being extensively used for this purpose, but a\ncomprehensive review of their advancements and challenges is lacking. This\nscoping review analyzes existing literature on AI-based models for T2DM risk\nprediction. Forty studies were included, mainly published in the past four\nyears. Traditional machine learning models were more prevalent than deep\nlearning models. Electronic health records were the most commonly used data\nsource. Unimodal AI models relying on EHR data were prominent, while only a few\nutilized multimodal models. Both unimodal and multimodal models showed\npromising performance, with the latter outperforming the former. Internal\nvalidation was common, while external validation was limited. Interpretability\nmethods were reported in half of the studies. Few studies reported novel\nbiomarkers, and open-source code availability was limited. This review provides\ninsights into the current state and limitations of AI-based T2DM risk\nprediction models and highlights challenges for their development and clinical\nimplementation.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a115939b116ebd79edb1f8611ac551dbcc44ea0d",
      "published_date": "2023-05-24",
      "downloaded_date": "2025-01-31",
      "filename": "Mohsen-Artificial Intelligence-Based Methods for Precision Medicine Diabetes Risk Prediction.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.16346v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2312.07003v1": {
      "title": "RACER: Rational Artificial Intelligence Car-following-model Enhanced by Reality",
      "authors": [
        "Tianyi Li",
        "Alexander Halatsis",
        "Raphael Stern"
      ],
      "abstract": "This paper introduces RACER, the Rational Artificial Intelligence\nCar-following model Enhanced by Reality, a cutting-edge deep learning\ncar-following model, that satisfies partial derivative constraints, designed to\npredict Adaptive Cruise Control (ACC) driving behavior while staying\ntheoretically feasible. Unlike conventional models, RACER effectively\nintegrates Rational Driving Constraints (RDCs), crucial tenets of actual\ndriving, resulting in strikingly accurate and realistic predictions. Against\nestablished models like the Optimal Velocity Relative Velocity (OVRV), a\ncar-following Neural Network (NN), and a car-following Physics-Informed Neural\nNetwork (PINN), RACER excels across key metrics, such as acceleration,\nvelocity, and spacing. Notably, it displays a perfect adherence to the RDCs,\nregistering zero violations, in stark contrast to other models. This study\nhighlights the immense value of incorporating physical constraints within AI\nmodels, especially for augmenting safety measures in transportation. It also\npaves the way for future research to test these models against human driving\ndata, with the potential to guide safer and more rational driving behavior. The\nversatility of the proposed model, including its potential to incorporate\nadditional derivative constraints and broader architectural applications,\nenhances its appeal and broadens its impact within the scientific community.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/de9559ff219fc9d99efe41b9084116a3059dbc2b",
      "published_date": "2023-12-12",
      "downloaded_date": "2025-01-31",
      "filename": "Li-RACER Rational Artificial Intelligence Car-following-model Enhanced by Reality.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.07003v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    "2212.11279v2": {
      "title": "Annotated History of Modern AI and Deep Learning",
      "authors": [
        "Juergen Schmidhuber"
      ],
      "abstract": "Machine learning is the science of credit assignment: finding patterns in\nobservations that predict the consequences of actions and help to improve\nfuture performance. Credit assignment is also required for human understanding\nof how the world works, not only for individuals navigating daily life, but\nalso for academic professionals like historians who interpret the present in\nlight of past events. Here I focus on the history of modern artificial\nintelligence (AI) which is dominated by artificial neural networks (NNs) and\ndeep learning, both conceptually closer to the old field of cybernetics than to\nwhat's been called AI since 1956 (e.g., expert systems and logic programming).\nA modern history of AI will emphasize breakthroughs outside of the focus of\ntraditional AI text books, in particular, mathematical foundations of today's\nNNs such as the chain rule (1676), the first NNs (linear regression, circa\n1800), and the first working deep learners (1965-). From the perspective of\n2022, I provide a timeline of the -- in hindsight -- most important relevant\nevents in the history of NNs, deep learning, AI, computer science, and\nmathematics in general, crediting those who laid foundations of the field. The\ntext contains numerous hyperlinks to relevant overview sites from my AI Blog.\nIt supplements my previous deep learning survey (2015) which provides hundreds\nof additional references. Finally, to round it off, I'll put things in a\nbroader historic context spanning the time since the Big Bang until when the\nuniverse will be many times older than it is now.",
      "citation_count": 18,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8a195693047aa27b58924241d2da706cf41d62a3",
      "published_date": "2022-12-21",
      "downloaded_date": "2025-01-31",
      "filename": "Schmidhuber-Annotated History of Modern AI and Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.11279v2",
      "categories": [
        "cs.NE"
      ]
    },
    "2310.13006v1": {
      "title": "Software Metadata Classification based on Generative Artificial Intelligence",
      "authors": [
        "Seetharam Killivalavan",
        "Durairaj Thenmozhi"
      ],
      "abstract": "This paper presents a novel approach to enhance the performance of binary\ncode comment quality classification models through the application of\nGenerative Artificial Intelligence (AI). By leveraging the OpenAI API, a\ndataset comprising 1239 newly generated code-comment pairs, extracted from\nvarious GitHub repositories and open-source projects, has been labelled as\n\"Useful\" or \"Not Useful\", and integrated into the existing corpus of 9048 pairs\nin the C programming language. Employing a cutting-edge Large Language Model\nArchitecture, the generated dataset demonstrates notable improvements in model\naccuracy. Specifically, when incorporated into the Support Vector Machine (SVM)\nmodel, a 6% increase in precision is observed, rising from 0.79 to 0.85.\nAdditionally, the Artificial Neural Network (ANN) model exhibits a 1.5%\nincrease in recall, climbing from 0.731 to 0.746. This paper sheds light on the\npotential of Generative AI in augmenting code comment quality classification\nmodels. The results affirm the effectiveness of this methodology, indicating\nits applicability in broader contexts within software development and quality\nassurance domains. The findings underscore the significance of integrating\ngenerative techniques to advance the accuracy and efficacy of machine learning\nmodels in practical software engineering scenarios.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ebd67c4f8ab4f3037f0eabedb44c3520c9c73850",
      "published_date": "2023-10-14",
      "downloaded_date": "2025-01-31",
      "filename": "Killivalavan-Software Metadata Classification based on Generative Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.13006v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ]
    },
    "2305.14948v1": {
      "title": "Music Representing Corpus Virtual: An Open Sourced Library for Explorative Music Generation, Sound Design, and Instrument Creation with Artificial Intelligence and Machine Learning",
      "authors": [
        "Christopher Johann Clarke"
      ],
      "abstract": "Music Representing Corpus Virtual (MRCV) is an open source software suite\ndesigned to explore the capabilities of Artificial Intelligence (AI) and\nMachine Learning (ML) in Music Generation, Sound Design, and Virtual Instrument\nCreation (MGSDIC). The software is accessible to users of varying levels of\nexperience, with an emphasis on providing an explorative approach to MGSDIC.\nThe main aim of MRCV is to facilitate creativity, allowing users to customize\ninput datasets for training the neural networks, and offering a range of\noptions for each neural network (thoroughly documented in the Github Wiki). The\nsoftware suite is designed to be accessible to musicians, audio professionals,\nsound designers, and composers, regardless of their prior experience in AI or\nML. The documentation is prepared in such a way as to abstract technical\ndetails, thereby making it easy to understand. The software is open source,\nmeaning users can contribute to its development, and the community can\ncollectively benefit from the insights and experience of other users.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3a6c71230fd09193bd7f5395f0f5e578069124e5",
      "published_date": "2023-05-24",
      "downloaded_date": "2025-01-31",
      "filename": "Clarke-Music Representing Corpus Virtual An Open Sourced Library for Explorative Music Generation Sound Des....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.14948v1",
      "categories": [
        "eess.AS",
        "cs.AI"
      ]
    },
    "1907.01521v1": {
      "title": "Artificial Intelligence Enhances the Performance of Chaos-based Wireless Communication",
      "authors": [
        "Hai-Peng Ren",
        "Hong-Er Zhao",
        "Chao Bai",
        "Hui-Ping Yin",
        "Celso Grebogi"
      ],
      "abstract": "Some new findings for chaos-based wireless communication systems have been\nidentified recently. First, chaos has proven to be the optimal communication\nwaveform because chaotic signals can achieve the maximum signal to noise ratio\nat receiver with the simplest matched filter. Second, the information\ntransmitted in chaotic signals is not modified by the multipath wireless\nchannel. Third, chaos properties can be used to relief inter-symbol\ninterference (ISI) caused by multipath propagation. Although recent work has\nreported the method of obtaining the optimal threshold to eliminate the ISI in\nchaos-based wireless communication, its practical implementation is still a\nchallenge. By knowing the channel parameters and all symbols, especially the\nfuture symbol to be transmitted in advance, it is almost an impossible task in\nthe practical communication systems. Owning to Artificial intelligence (AI)\nrecent developments, Convolutional Neural Network (CNN) with deep learning\nstructure is being proposed to predict future symbols based on the received\nsignal, so as to further reduce ISI and obtain better bit error rate (BER)\nperformance as compared to that used the existing sub-optimal threshold. The\nfeature of the method involves predicting the future symbol and obtaining a\nbetter threshold suitable for time variant channel. Numerical simulation and\nexperimental results validate our theory and the superiority of the proposed\nmethod.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-06-27",
      "downloaded_date": "2025-01-31",
      "filename": "Ren-Artificial Intelligence Enhances the Performance of Chaos-based Wireless Communication.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.01521v1",
      "categories": [
        "eess.SP"
      ]
    },
    "2004.04479v1": {
      "title": "On Adversarial Examples and Stealth Attacks in Artificial Intelligence Systems",
      "authors": [
        "Ivan Y. Tyukin",
        "Desmond J. Higham",
        "Alexander N. Gorban"
      ],
      "abstract": "In this work we present a formal theoretical framework for assessing and\nanalyzing two classes of malevolent action towards generic Artificial\nIntelligence (AI) systems. Our results apply to general multi-class classifiers\nthat map from an input space into a decision space, including artificial neural\nnetworks used in deep learning applications. Two classes of attacks are\nconsidered. The first class involves adversarial examples and concerns the\nintroduction of small perturbations of the input data that cause\nmisclassification. The second class, introduced here for the first time and\nnamed stealth attacks, involves small perturbations to the AI system itself.\nHere the perturbed system produces whatever output is desired by the attacker\non a specific small data set, perhaps even a single input, but performs as\nnormal on a validation set (which is unknown to the attacker). We show that in\nboth cases, i.e., in the case of an attack based on adversarial examples and in\nthe case of a stealth attack, the dimensionality of the AI's decision-making\nspace is a major contributor to the AI's susceptibility. For attacks based on\nadversarial examples, a second crucial parameter is the absence of local\nconcentrations in the data probability distribution, a property known as\nSmeared Absolute Continuity. According to our findings, robustness to\nadversarial examples requires either (a) the data distributions in the AI's\nfeature space to have concentrated probability density functions or (b) the\ndimensionality of the AI's decision variables to be sufficiently small. We also\nshow how to construct stealth attacks on high-dimensional AI systems that are\nhard to spot unless the validation set is made exponentially large.",
      "citation_count": 38,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1aae9eb27f5e4634ee9ba2a368303bdf6228b8dc",
      "published_date": "2020-04-09",
      "downloaded_date": "2025-01-31",
      "filename": "Tyukin-On Adversarial Examples and Stealth Attacks in Artificial Intelligence Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.04479v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05, 68T10, 90C31"
      ]
    },
    "2206.10604v1": {
      "title": "Artificial intelligence system based on multi-value classification of fully connected neural network for construction management",
      "authors": [
        "Tetyana Honcharenko",
        "Roman Akselrod",
        "Andrii Shpakov",
        "Oleksandr Khomenko"
      ],
      "abstract": "This study is devoted to solving the problem to determine the professional\nadaptive capabilities of construction management staff using artificial\nintelligence systems.It is proposed Fully Connected Feed-Forward Neural Network\narchitecture and performed empirical modeling to create a Data Set. Model of\nartificial intelligence system allows evaluating the processes in an Fully\nConnected Feed-Forward Neural Network during the execution of multi-value\nclassification of professional areas. A method has been developed for the\ntraining process of a machine learning model, which reflects the internal\nconnections between the components of an artificial intelligence system that\nallow it to learn from training data. To train the neural network, a data set\nof 35 input parameters and 29 output parameters was used; the amount of data in\nthe set is 936 data lines. Neural network training occurred in the proportion\nof 10% and 90%, respectively. Results of this study research can be used to\nfurther improve the knowledge and skills necessary for successful professional\nrealization.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/01b5ed3ff257639aadbf048e02837963b40dad8d",
      "published_date": "2022-06-19",
      "downloaded_date": "2025-01-31",
      "filename": "Honcharenko-Artificial intelligence system based on multi-value classification of fully connected neural network....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.10604v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2110.14910v1": {
      "title": "Diagnosis of COVID-19 Using Machine Learning and Deep Learning: A review",
      "authors": [
        "M. Rubaiyat Hossain Mondal",
        "Subrato Bharati",
        "Prajoy Podder"
      ],
      "abstract": "Background: This paper provides a systematic review of the application of\nArtificial Intelligence (AI) in the form of Machine Learning (ML) and Deep\nLearning (DL) techniques in fighting against the effects of novel coronavirus\ndisease (COVID-19). Objective & Methods: The objective is to perform a scoping\nreview on AI for COVID-19 using preferred reporting items of systematic reviews\nand meta-analysis (PRISMA) guidelines. A literature search was performed for\nrelevant studies published from 1 January 2020 till 27 March 2021. Out of 4050\nresearch papers available in reputed publishers, a full-text review of 440\narticles was done based on the keywords of AI, COVID-19, ML, forecasting, DL,\nX-ray, and Computed Tomography (CT). Finally, 52 articles were included in the\nresult synthesis of this paper. As part of the review, different ML regression\nmethods were reviewed first in predicting the number of confirmed and death\ncases. Secondly, a comprehensive survey was carried out on the use of ML in\nclassifying COVID-19 patients. Thirdly, different datasets on medical imaging\nwere compared in terms of the number of images, number of positive samples and\nnumber of classes in the datasets. The different stages of the diagnosis,\nincluding preprocessing, segmentation and feature extraction were also\nreviewed. Fourthly, the performance results of different research papers were\ncompared to evaluate the effectiveness of DL methods on different datasets.\nResults: Results show that residual neural network (ResNet-18) and densely\nconnected convolutional network (DenseNet 169) exhibit excellent classification\naccuracy for X-ray images, while DenseNet-201 has the maximum accuracy in\nclassifying CT scan images. This indicates that ML and DL are useful tools in\nassisting researchers and medical professionals in predicting, screening and\ndetecting COVID-19.",
      "citation_count": 54,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/662d2de60c05e7f37fc3c2aa8741c3c2fe103d25",
      "published_date": "2021-10-28",
      "downloaded_date": "2025-01-31",
      "filename": "Mondal-Diagnosis of COVID-19 Using Machine Learning and Deep Learning A review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.14910v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ]
    },
    "2012.05410v1": {
      "title": "Artificial Intelligence at the Edge",
      "authors": [
        "Elisa Bertino",
        "Sujata Banerjee"
      ],
      "abstract": "The Internet of Things (IoT) and edge computing applications aim to support a\nvariety of societal needs, including the global pandemic situation that the\nentire world is currently experiencing and responses to natural disasters.\n  The need for real-time interactive applications such as immersive video\nconferencing, augmented/virtual reality, and autonomous vehicles, in education,\nhealthcare, disaster recovery and other domains, has never been higher. At the\nsame time, there have been recent technological breakthroughs in highly\nrelevant fields such as artificial intelligence (AI)/machine learning (ML),\nadvanced communication systems (5G and beyond), privacy-preserving\ncomputations, and hardware accelerators. 5G mobile communication networks\nincrease communication capacity, reduce transmission latency and error, and\nsave energy -- capabilities that are essential for new applications. The\nenvisioned future 6G technology will integrate many more technologies,\nincluding for example visible light communication, to support groundbreaking\napplications, such as holographic communications and high precision\nmanufacturing. Many of these applications require computations and analytics\nclose to application end-points: that is, at the edge of the network, rather\nthan in a centralized cloud. AI techniques applied at the edge have tremendous\npotential both to power new applications and to need more efficient operation\nof edge infrastructure. However, it is critical to understand where to deploy\nAI systems within complex ecosystems consisting of advanced applications and\nthe specific real-time requirements towards AI systems.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/edf57bbeea2d13b987792cff9878f25e1e8bcc5c",
      "published_date": "2020-12-10",
      "downloaded_date": "2025-01-31",
      "filename": "Bertino-Artificial Intelligence at the Edge.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.05410v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "1912.02934v1": {
      "title": "Surveying the reach and maturity of machine learning and artificial intelligence in astronomy",
      "authors": [
        "Christopher J. Fluke",
        "Colin Jacobs"
      ],
      "abstract": "Machine learning (automated processes that learn by example in order to\nclassify, predict, discover or generate new data) and artificial intelligence\n(methods by which a computer makes decisions or discoveries that would usually\nrequire human intelligence) are now firmly established in astronomy. Every\nweek, new applications of machine learning and artificial intelligence are\nadded to a growing corpus of work. Random forests, support vector machines, and\nneural networks (artificial, deep, and convolutional) are now having a genuine\nimpact for applications as diverse as discovering extrasolar planets, transient\nobjects, quasars, and gravitationally-lensed systems, forecasting solar\nactivity, and distinguishing between signals and instrumental effects in\ngravitational wave astronomy. This review surveys contemporary, published\nliterature on machine learning and artificial intelligence in astronomy and\nastrophysics. Applications span seven main categories of activity:\nclassification, regression, clustering, forecasting, generation, discovery, and\nthe development of new scientific insight. These categories form the basis of a\nhierarchy of maturity, as the use of machine learning and artificial\nintelligence emerges, progresses or becomes established.",
      "citation_count": 83,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c97a189dae51cb015cb649d6dbbf5a82966806e7",
      "published_date": "2019-12-06",
      "downloaded_date": "2025-01-31",
      "filename": "Fluke-Surveying the reach and maturity of machine learning and artificial intelligence in astronomy.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1912.02934v1",
      "categories": [
        "astro-ph.IM"
      ]
    },
    "2403.08425v3": {
      "title": "Specification Overfitting in Artificial Intelligence",
      "authors": [
        "Benjamin Roth",
        "Pedro Henrique Luz de Araujo",
        "Yuxi Xia",
        "Saskia Kaltenbrunner",
        "Christoph Korab"
      ],
      "abstract": "Machine learning (ML) and artificial intelligence (AI) approaches are often\ncriticized for their inherent bias and for their lack of control,\naccountability, and transparency. Consequently, regulatory bodies struggle with\ncontaining this technology's potential negative side effects. High-level\nrequirements such as fairness and robustness need to be formalized into\nconcrete specification metrics, imperfect proxies that capture isolated aspects\nof the underlying requirements. Given possible trade-offs between different\nmetrics and their vulnerability to over-optimization, integrating specification\nmetrics in system development processes is not trivial. This paper defines\nspecification overfitting, a scenario where systems focus excessively on\nspecified metrics to the detriment of high-level requirements and task\nperformance. We present an extensive literature survey to categorize how\nresearchers propose, measure, and optimize specification metrics in several AI\nfields (e.g., natural language processing, computer vision, reinforcement\nlearning). Using a keyword-based search on papers from major AI conferences and\njournals between 2018 and mid-2023, we identify and analyze 74 papers that\npropose or optimize specification metrics. We find that although most papers\nimplicitly address specification overfitting (e.g., by reporting more than one\nspecification metric), they rarely discuss which role specification metrics\nshould play in system development or explicitly define the scope and\nassumptions behind metric formulations.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c210cc23009b7b9f15ef0a2f4a337a624c3e736b",
      "published_date": "2024-03-13",
      "downloaded_date": "2025-01-31",
      "filename": "Roth-Specification Overfitting in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.08425v3",
      "categories": [
        "cs.AI"
      ]
    },
    "1807.07987v2": {
      "title": "Deep Learning",
      "authors": [
        "Nicholas G. Polson",
        "Vadim O. Sokolov"
      ],
      "abstract": "Deep learning (DL) is a high dimensional data reduction technique for\nconstructing high-dimensional predictors in input-output models. DL is a form\nof machine learning that uses hierarchical layers of latent features. In this\narticle, we review the state-of-the-art of deep learning from a modeling and\nalgorithmic perspective. We provide a list of successful areas of applications\nin Artificial Intelligence (AI), Image Processing, Robotics and Automation.\nDeep learning is predictive in its nature rather then inferential and can be\nviewed as a black-box methodology for high-dimensional function estimation.",
      "citation_count": 38631,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3c8a456509e6c0805354bd40a35e3f2dbf8069b1",
      "published_date": "2018-07-20",
      "downloaded_date": "2025-01-31",
      "filename": "Polson-Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1807.07987v2",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    "1904.06376v1": {
      "title": "Leveraging the bfloat16 Artificial Intelligence Datatype For Higher-Precision Computations",
      "authors": [
        "Greg Henry",
        "Ping Tak Peter Tang",
        "Alexander Heinecke"
      ],
      "abstract": "In recent years fused-multiply-add (FMA) units with lower-precision\nmultiplications and higher-precision accumulation have proven useful in machine\nlearning/artificial intelligence applications, most notably in training deep\nneural networks due to their extreme computational intensity. Compared to\nclassical IEEE-754 32 bit (FP32) and 64 bit (FP64) arithmetic, these reduced\nprecision arithmetic can naturally be sped up disproportional to their\nshortened width. The common strategy of all major hardware vendors is to\naggressively further enhance their performance disproportionately. One\nparticular FMA operation that multiplies two BF16 numbers while accumulating in\nFP32 has been found useful in deep learning, where BF16 is the 16-bit floating\npoint datatype with IEEE FP32 numerical range but 8 significant bits of\nprecision. In this paper, we examine the use this FMA unit to implement\nhigher-precision matrix routines in terms of potential performance gain and\nimplications on accuracy. We demonstrate how a decomposition into multiple\nsmaller datatypes can be used to assemble a high-precision result, leveraging\nthe higher precision accumulation of the FMA unit. We first demonstrate that\ncomputations of vector inner products and by natural extension, matrix-matrix\nproducts can be achieved by decomposing FP32 numbers in several BF16 numbers\nfollowed by appropriate computations that can accommodate the dynamic range and\npreserve accuracy compared to standard FP32 computations, while projecting up\nto 5.2x speed-up. Furthermore, we examine solution of linear equations\nformulated in the residual form that allows for iterative refinement. We\ndemonstrate that the solution obtained to be comparable to those offered by\nFP64 under a large range of linear system condition numbers.",
      "citation_count": 48,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3f33390e951699ba44c29029a7344fc47766f2b6",
      "published_date": "2019-04-12",
      "downloaded_date": "2025-01-31",
      "filename": "Henry-Leveraging the bfloat16 Artificial Intelligence Datatype For Higher-Precision Computations.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1904.06376v1",
      "categories": [
        "cs.MS",
        "cs.NA"
      ]
    },
    "1702.02461v1": {
      "title": "Who Will Win Practical Artificial Intelligence? AI Engineerings in China",
      "authors": [
        "Huai-Yu Wu",
        "Feiyue Wang",
        "Chunhong Pan"
      ],
      "abstract": "Currently, Artificial Intelligence (AI) has won unprecedented attention and\nis becoming the increasingly popular focus in China. This change can be judged\nby the impressive record of academic publications, the amount of state-level\ninvestment and the presence of nation-wide participation and devotion. In this\npaper, we place emphasis on discussing the progress of artificial intelligence\nengineerings in China. We first introduce the focus on AI in Chinese academia,\nincluding the supercomputing brain system, Cambrian Period supercomputer of\nneural networks, and biometric systems. Then, the development of AI in\nindustrial circles and the latest layout of AI products in companies, such as\nBaidu, Tencent, and Alibaba, are introduced. Last, we bring in the opinions and\narguments of the main intelligentsia of China about the future development of\nAI, including how to examine the relationship between humanity on one side and\nscience and technology on the other.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/342b38a793e4c3ed17899106e78d92db7e490aee",
      "published_date": "2017-02-06",
      "downloaded_date": "2025-01-31",
      "filename": "Wu-Who Will Win Practical Artificial Intelligence AI Engineerings in China.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1702.02461v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2005.13635v3": {
      "title": "Towards AI Forensics: Did the Artificial Intelligence System Do It?",
      "authors": [
        "Johannes Schneider",
        "Frank Breitinger"
      ],
      "abstract": "Artificial intelligence (AI) makes decisions impacting our daily lives in an\nincreasingly autonomous manner. Their actions might cause accidents, harm, or,\nmore generally, violate regulations. Determining whether an AI caused a\nspecific event and, if so, what triggered the AI's action, are key forensic\nquestions. We provide a conceptualization of the problems and strategies for\nforensic investigation. We focus on AI that is potentially ``malicious by\ndesign'' and grey box analysis. Our evaluation using convolutional neural\nnetworks illustrates challenges and ideas for identifying malicious AI.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/44a8ffd1d36114d9530fa38e20916df70073f34d",
      "published_date": "2020-05-27",
      "downloaded_date": "2025-01-31",
      "filename": "Schneider-Towards AI Forensics Did the Artificial Intelligence System Do It.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.13635v3",
      "categories": [
        "cs.AI",
        "cs.CR"
      ]
    },
    "2412.02187v1": {
      "title": "Deep Learning, Machine Learning, Advancing Big Data Analytics and Management",
      "authors": [
        "Weiche Hsieh",
        "Ziqian Bi",
        "Keyu Chen",
        "Benji Peng",
        "Sen Zhang",
        "Jiawei Xu",
        "Jinlang Wang",
        "Caitlyn Heqi Yin",
        "Yichao Zhang",
        "Pohsun Feng",
        "Yizhu Wen",
        "Tianyang Wang",
        "Ming Li",
        "Chia Xin Liang",
        "Jintao Ren",
        "Qian Niu",
        "Silin Chen",
        "Lawrence K. Q. Yan",
        "Han Xu",
        "Hong-Ming Tseng",
        "Xinyuan Song",
        "Bowen Jing",
        "Junjie Yang",
        "Junhao Song",
        "Junyu Liu",
        "Ming Liu"
      ],
      "abstract": "Advancements in artificial intelligence, machine learning, and deep learning\nhave catalyzed the transformation of big data analytics and management into\npivotal domains for research and application. This work explores the\ntheoretical foundations, methodological advancements, and practical\nimplementations of these technologies, emphasizing their role in uncovering\nactionable insights from massive, high-dimensional datasets. The study presents\na systematic overview of data preprocessing techniques, including data\ncleaning, normalization, integration, and dimensionality reduction, to prepare\nraw data for analysis. Core analytics methodologies such as classification,\nclustering, regression, and anomaly detection are examined, with a focus on\nalgorithmic innovation and scalability. Furthermore, the text delves into\nstate-of-the-art frameworks for data mining and predictive modeling,\nhighlighting the role of neural networks, support vector machines, and ensemble\nmethods in tackling complex analytical challenges. Special emphasis is placed\non the convergence of big data with distributed computing paradigms, including\ncloud and edge computing, to address challenges in storage, computation, and\nreal-time analytics. The integration of ethical considerations, including data\nprivacy and compliance with global standards, ensures a holistic perspective on\ndata management. Practical applications across healthcare, finance, marketing,\nand policy-making illustrate the real-world impact of these technologies.\nThrough comprehensive case studies and Python-based implementations, this work\nequips researchers, practitioners, and data enthusiasts with the tools to\nnavigate the complexities of modern data analytics. It bridges the gap between\ntheory and practice, fostering the development of innovative solutions for\nmanaging and leveraging data in the era of artificial intelligence.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7f0a33157d315c9bbcab70caa48779bb3cc7d932",
      "published_date": "2024-12-03",
      "downloaded_date": "2025-01-31",
      "filename": "Hsieh-Deep Learning Machine Learning Advancing Big Data Analytics and Management.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.02187v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2108.02618v1": {
      "title": "Using a Collated Cybersecurity Dataset for Machine Learning and Artificial Intelligence",
      "authors": [
        "Erik Hemberg",
        "Una-May O'Reilly"
      ],
      "abstract": "Artificial Intelligence (AI) and Machine Learning (ML) algorithms can support\nthe span of indicator-level, e.g. anomaly detection, to behavioral level cyber\nsecurity modeling and inference. This contribution is based on a dataset named\nBRON which is amalgamated from public threat and vulnerability behavioral\nsources. We demonstrate how BRON can support prediction of related threat\ntechniques and attack patterns. We also discuss other AI and ML uses of BRON to\nexploit its behavioral knowledge.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-08-05",
      "downloaded_date": "2025-01-31",
      "filename": "Hemberg-Using a Collated Cybersecurity Dataset for Machine Learning and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.02618v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    "0811.1711v1": {
      "title": "Artificial Intelligence Techniques for Steam Generator Modelling",
      "authors": [
        "Sarah Wright",
        "Tshilidzi Marwala"
      ],
      "abstract": "This paper investigates the use of different Artificial Intelligence methods\nto predict the values of several continuous variables from a Steam Generator.\nThe objective was to determine how the different artificial intelligence\nmethods performed in making predictions on the given dataset. The artificial\nintelligence methods evaluated were Neural Networks, Support Vector Machines,\nand Adaptive Neuro-Fuzzy Inference Systems. The types of neural networks\ninvestigated were Multi-Layer Perceptions, and Radial Basis Function. Bayesian\nand committee techniques were applied to these neural networks. Each of the AI\nmethods considered was simulated in Matlab. The results of the simulations\nshowed that all the AI methods were capable of predicting the Steam Generator\ndata reasonably accurately. However, the Adaptive Neuro-Fuzzy Inference system\nout performed the other methods in terms of accuracy and ease of\nimplementation, while still achieving a fast execution time as well as a\nreasonable training time.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/afcb0398dc21bb084e4feae1efadd29a6490f6d3",
      "published_date": "2008-11-11",
      "downloaded_date": "2025-01-31",
      "filename": "Wright-Artificial Intelligence Techniques for Steam Generator Modelling.pdf",
      "arxiv_url": "http://arxiv.org/pdf/0811.1711v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2308.13035v1": {
      "title": "The intersection of video capsule endoscopy and artificial intelligence: addressing unique challenges using machine learning",
      "authors": [
        "Shan Guleria",
        "Benjamin Schwartz",
        "Yash Sharma",
        "Philip Fernandes",
        "James Jablonski",
        "Sodiq Adewole",
        "Sanjana Srivastava",
        "Fisher Rhoads",
        "Michael Porter",
        "Michelle Yeghyayan",
        "Dylan Hyatt",
        "Andrew Copland",
        "Lubaina Ehsan",
        "Donald Brown",
        "Sana Syed"
      ],
      "abstract": "Introduction: Technical burdens and time-intensive review processes limit the\npractical utility of video capsule endoscopy (VCE). Artificial intelligence\n(AI) is poised to address these limitations, but the intersection of AI and VCE\nreveals challenges that must first be overcome. We identified five challenges\nto address. Challenge #1: VCE data are stochastic and contains significant\nartifact. Challenge #2: VCE interpretation is cost-intensive. Challenge #3: VCE\ndata are inherently imbalanced. Challenge #4: Existing VCE AIMLT are\ncomputationally cumbersome. Challenge #5: Clinicians are hesitant to accept\nAIMLT that cannot explain their process.\n  Methods: An anatomic landmark detection model was used to test the\napplication of convolutional neural networks (CNNs) to the task of classifying\nVCE data. We also created a tool that assists in expert annotation of VCE data.\nWe then created more elaborate models using different approaches including a\nmulti-frame approach, a CNN based on graph representation, and a few-shot\napproach based on meta-learning.\n  Results: When used on full-length VCE footage, CNNs accurately identified\nanatomic landmarks (99.1%), with gradient weighted-class activation mapping\nshowing the parts of each frame that the CNN used to make its decision. The\ngraph CNN with weakly supervised learning (accuracy 89.9%, sensitivity of\n91.1%), the few-shot model (accuracy 90.8%, precision 91.4%, sensitivity\n90.9%), and the multi-frame model (accuracy 97.5%, precision 91.5%, sensitivity\n94.8%) performed well. Discussion: Each of these five challenges is addressed,\nin part, by one of our AI-based models. Our goal of producing high performance\nusing lightweight models that aim to improve clinician confidence was achieved.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b488a9e015dc981d589a8a3e51cac571e114fcee",
      "published_date": "2023-08-24",
      "downloaded_date": "2025-01-31",
      "filename": "Guleria-The intersection of video capsule endoscopy and artificial intelligence addressing unique challenges....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.13035v1",
      "categories": [
        "q-bio.QM",
        "cs.LG"
      ]
    },
    "2411.18656v1": {
      "title": "The Return of Pseudosciences in Artificial Intelligence: Have Machine Learning and Deep Learning Forgotten Lessons from Statistics and History?",
      "authors": [
        "JÃ©rÃ©mie Sublime"
      ],
      "abstract": "In today's world, AI programs powered by Machine Learning are ubiquitous, and\nhave achieved seemingly exceptional performance across a broad range of tasks,\nfrom medical diagnosis and credit rating in banking, to theft detection via\nvideo analysis, and even predicting political or sexual orientation from facial\nimages. These predominantly deep learning methods excel due to their\nextraordinary capacity to process vast amounts of complex data to extract\ncomplex correlations and relationship from different levels of features.\n  In this paper, we contend that the designers and final users of these ML\nmethods have forgotten a fundamental lesson from statistics: correlation does\nnot imply causation. Not only do most state-of-the-art methods neglect this\ncrucial principle, but by doing so they often produce nonsensical or flawed\ncausal models, akin to social astrology or physiognomy. Consequently, we argue\nthat current efforts to make AI models more ethical by merely reducing biases\nin the training data are insufficient. Through examples, we will demonstrate\nthat the potential for harm posed by these methods can only be mitigated by a\ncomplete rethinking of their core models, improved quality assessment metrics\nand policies, and by maintaining humans oversight throughout the process.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b42848affe7be9eecf67d31eb623f2b259362ef5",
      "published_date": "2024-11-27",
      "downloaded_date": "2025-01-31",
      "filename": "Sublime-The Return of Pseudosciences in Artificial Intelligence Have Machine Learning and Deep Learning Forg....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.18656v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2401.07020v1": {
      "title": "Empowering Medical Imaging with Artificial Intelligence: A Review of Machine Learning Approaches for the Detection, and Segmentation of COVID-19 Using Radiographic and Tomographic Images",
      "authors": [
        "Sayed Amir Mousavi Mobarakeh",
        "Kamran Kazemi",
        "Ardalan Aarabi",
        "Habibollah Danyal"
      ],
      "abstract": "Since 2019, the global dissemination of the Coronavirus and its novel strains\nhas resulted in a surge of new infections. The use of X-ray and computed\ntomography (CT) imaging techniques is critical in diagnosing and managing\nCOVID-19. Incorporating artificial intelligence (AI) into the field of medical\nimaging is a powerful combination that can provide valuable support to\nhealthcare professionals.This paper focuses on the methodological approach of\nusing machine learning (ML) to enhance medical imaging for COVID-19\ndiagnosis.For example, deep learning can accurately distinguish lesions from\nother parts of the lung without human intervention in a matter of\nminutes.Moreover, ML can enhance performance efficiency by assisting\nradiologists in making more precise clinical decisions, such as detecting and\ndistinguishing Covid-19 from different respiratory infections and segmenting\ninfections in CT and X-ray images, even when the lesions have varying sizes and\nshapes.This article critically assesses machine learning methodologies utilized\nfor the segmentation, classification, and detection of Covid-19 within CT and\nX-ray images, which are commonly employed tools in clinical and hospital\nsettings to represent the lung in various aspects and extensive detail.There is\na widespread expectation that this technology will continue to hold a central\nposition within the healthcare sector, driving further progress in the\nmanagement of the pandemic.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-01-13",
      "downloaded_date": "2025-01-31",
      "filename": "Mobarakeh-Empowering Medical Imaging with Artificial Intelligence A Review of Machine Learning Approaches for ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.07020v1",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "1701.07103v1": {
      "title": "Artificial Intelligence Approaches To UCAV Autonomy",
      "authors": [
        "Amir Husain",
        "Bruce Porter"
      ],
      "abstract": "This paper covers a number of approaches that leverage Artificial\nIntelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle\n(UCAV) autonomy. An analysis of current approaches to autonomous control is\nprovided followed by an exploration of how these techniques can be extended and\nenriched with AI techniques including Artificial Neural Networks (ANN),\nEnsembling and Reinforcement Learning (RL) to evolve control strategies for\nUCAVs.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e238fb4cdddb822e4a9b0ea93d1a10c65aaa37c6",
      "published_date": "2017-01-24",
      "downloaded_date": "2025-01-31",
      "filename": "Husain-Artificial Intelligence Approaches To UCAV Autonomy.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1701.07103v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    "2101.09163v6": {
      "title": "The Next Decade of Telecommunications Artificial Intelligence",
      "authors": [
        "Ye Ouyang",
        "Lilei Wang",
        "Aidong Yang",
        "Maulik Shah",
        "David Belanger",
        "Tongqing Gao",
        "Leping Wei",
        "Yaqin Zhang"
      ],
      "abstract": "It has been an exciting journey since the mobile communications and\nartificial intelligence were conceived 37 years and 64 years ago. While both\nfields evolved independently and profoundly changed communications and\ncomputing industries, the rapid convergence of 5G and deep learning is\nbeginning to significantly transform the core communication infrastructure,\nnetwork management and vertical applications. The paper first outlines the\nindividual roadmaps of mobile communications and artificial intelligence in the\nearly stage, with a concentration to review the era from 3G to 5G when AI and\nmobile communications started to converge. With regard to telecommunications\nartificial intelligence, the paper further introduces in detail the progress of\nartificial intelligence in the ecosystem of mobile communications. The paper\nthen summarizes the classifications of AI in telecom ecosystems along with its\nevolution paths specified by various international telecommunications\nstandardization bodies. Towards the next decade, the paper forecasts the\nprospective roadmap of telecommunications artificial intelligence. In line with\n3GPP and ITU-R timeline of 5G & 6G, the paper further explores the network\nintelligence following 3GPP and ORAN routes respectively, experience and\nintention driven network management and operation, network AI signalling\nsystem, intelligent middle-office based BSS, intelligent customer experience\nmanagement and policy control driven by BSS and OSS convergence, evolution from\nSLA to ELA, and intelligent private network for verticals. The paper is\nconcluded with the vision that AI will reshape the future B5G or 6G landscape\nand we need pivot our R&D, standardizations, and ecosystem to fully take the\nunprecedented opportunities.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9a8acb976683395e1dc3748aec0700a04045fe6c",
      "published_date": "2021-01-19",
      "downloaded_date": "2025-01-31",
      "filename": "Ouyang-The Next Decade of Telecommunications Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.09163v6",
      "categories": [
        "cs.NI",
        "cs.AI"
      ]
    },
    "2311.15728v1": {
      "title": "Adinkra Symbol Recognition using Classical Machine Learning and Deep Learning",
      "authors": [
        "Michael Adjeisah",
        "Kwame Omono Asamoah",
        "Martha Asamoah Yeboah",
        "Raji Rafiu King",
        "Godwin Ferguson Achaab",
        "Kingsley Adjei"
      ],
      "abstract": "Artificial intelligence (AI) has emerged as a transformative influence,\nengendering paradigm shifts in global societies, spanning academia and\nindustry. However, in light of these rapid advances, addressing the\nunderrepresentation of black communities and African countries in AI is\ncrucial. Boosting enthusiasm for AI can be effectively accomplished by\nshowcasing straightforward applications around tasks like identifying and\ncategorizing traditional symbols, such as Adinkra symbols, or familiar objects\nwithin the community. In this research endeavor, we dived into classical\nmachine learning and harnessed the power of deep learning models to tackle the\nintricate task of classifying and recognizing Adinkra symbols. The idea led to\na newly constructed ADINKRA dataset comprising 174,338 images meticulously\norganized into 62 distinct classes, each representing a singular and emblematic\nsymbol. We constructed a CNN model for classification and recognition using six\nconvolutional layers, three fully connected (FC) layers, and optional dropout\nregularization. The model is a simpler and smaller version of VGG, with fewer\nlayers, smaller channel sizes, and a fixed kernel size. Additionally, we tap\ninto the transfer learning capabilities provided by pre-trained models like VGG\nand ResNet. These models assist us in both classifying images and extracting\nfeatures that can be used with classical machine learning models. We assess the\nmodel's performance by measuring its accuracy and convergence rate and\nvisualizing the areas that significantly influence its predictions. These\nevaluations serve as a foundational benchmark for future assessments of the\nADINKRA dataset. We hope this application exemplar inspires ideas on the\nvarious uses of AI in organizing our traditional and modern lives.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/325a4148e25980265f555bee5bbb93f6004410b0",
      "published_date": "2023-11-27",
      "downloaded_date": "2025-01-31",
      "filename": "Adjeisah-Adinkra Symbol Recognition using Classical Machine Learning and Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.15728v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2112.01275v1": {
      "title": "Advancing Artificial Intelligence and Machine Learning in the U.S. Government Through Improved Public Competitions",
      "authors": [
        "Ezekiel J. Maier"
      ],
      "abstract": "In the last two years, the U.S. government has emphasized the importance of\naccelerating artificial intelligence (AI) and machine learning (ML) within the\ngovernment and across the nation. In particular, the National Artificial\nIntelligence Initiative Act of 2020, which became law on January 1, 2021,\nprovides for a coordinated program across the entire federal government to\naccelerate AI research and application. The U.S. government can benefit from\npublic artificial intelligence and machine learning challenges through the\ndevelopment of novel algorithms and participation in experiential training.\nAlthough the public, private, and non-profit sectors have a history of\nleveraging crowdsourcing initiatives to generate novel solutions to difficult\nproblems and engage stakeholders, interest in public competitions has waned in\nrecent years as a result of at least three major factors: (1) a lack of\nhigh-quality, high-impact data; (2) a narrow engagement focus on specialized\ngroups; and (3) insufficient operationalization of challenge results. Herein we\nidentify common issues and recommend approaches to increase the effectiveness\nof challenges. To address these barriers, enabling the use of public\ncompetitions for accelerating AI and ML practice, the U.S. government must\nleverage methods that protect sensitive data while enabling modelling, enable\neasier participation, empower deployment of validated models, and incentivize\nengagement from broad sections of the population.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-11-29",
      "downloaded_date": "2025-01-31",
      "filename": "Maier-Advancing Artificial Intelligence and Machine Learning in the US Government Through Improved Public ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2112.01275v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2009.11190v1": {
      "title": "Enterprise AI Canvas -- Integrating Artificial Intelligence into Business",
      "authors": [
        "U. Kerzel"
      ],
      "abstract": "Artificial Intelligence (AI) and Machine Learning have enormous potential to\ntransform businesses and disrupt entire industry sectors. However, companies\nwishing to integrate algorithmic decisions into their face multiple challenges:\nThey have to identify use-cases in which artificial intelligence can create\nvalue, as well as decisions that can be supported or executed automatically.\nFurthermore, the organization will need to be transformed to be able to\nintegrate AI based systems into their human work-force. Furthermore, the more\ntechnical aspects of the underlying machine learning model have to be discussed\nin terms of how they impact the various units of a business: Where do the\nrelevant data come from, which constraints have to be considered, how is the\nquality of the data and the prediction evaluated?\n  The Enterprise AI canvas is designed to bring Data Scientist and business\nexpert together to discuss and define all relevant aspects which need to be\nclarified in order to integrate AI based systems into a digital enterprise. It\nconsists of two parts where part one focuses on the business view and\norganizational aspects, whereas part two focuses on the underlying machine\nlearning model and the data it uses.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-09-18",
      "downloaded_date": "2025-01-31",
      "filename": "Kerzel-Enterprise AI Canvas -- Integrating Artificial Intelligence into Business.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.11190v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2407.09563v1": {
      "title": "Psychology of Artificial Intelligence: Epistemological Markers of the Cognitive Analysis of Neural Networks",
      "authors": [
        "Michael Pichat"
      ],
      "abstract": "What is the \"nature\" of the cognitive processes and contents of an artificial\nneural network? In other words, how does an artificial intelligence\nfundamentally \"think,\" and in what form does its knowledge reside? The\npsychology of artificial intelligence, as predicted by Asimov (1950), aims to\nstudy this AI probing and explainability-sensitive matter. This study requires\na neuronal level of cognitive granularity, so as not to be limited solely to\nthe secondary macro-cognitive results (such as cognitive and cultural biases)\nof synthetic neural cognition. A prerequisite for examining the latter is to\nclarify some epistemological milestones regarding the cognitive status we can\nattribute to its phenomenology.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a268248ef02a2e00eb04a1c928650cfcb4aa1756",
      "published_date": "2024-07-04",
      "downloaded_date": "2025-01-31",
      "filename": "Pichat-Psychology of Artificial Intelligence Epistemological Markers of the Cognitive Analysis of Neural Ne....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.09563v1",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ]
    },
    "1810.10862v4": {
      "title": "Multiparty Dynamics and Failure Modes for Machine Learning and Artificial Intelligence",
      "authors": [
        "David Manheim"
      ],
      "abstract": "An important challenge for safety in machine learning and artificial\nintelligence systems is a~set of related failures involving specification\ngaming, reward hacking, fragility to distributional shifts, and Goodhart's or\nCampbell's law. This paper presents additional failure modes for interactions\nwithin multi-agent systems that are closely related. These multi-agent failure\nmodes are more complex, more problematic, and less well understood than the\nsingle-agent case, and are also already occurring, largely unnoticed. After\nmotivating the discussion with examples from poker-playing artificial\nintelligence (AI), the paper explains why these failure modes are in some\nsenses unavoidable. Following this, the paper categorizes failure modes,\nprovides definitions, and cites examples for each of the modes: accidental\nsteering, coordination failures, adversarial misalignment, input spoofing and\nfiltering, and goal co-option or direct hacking. The paper then discusses how\nextant literature on multi-agent AI fails to address these failure modes, and\nidentifies work which may be useful for the mitigation of these failure modes.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-10-16",
      "downloaded_date": "2025-01-31",
      "filename": "Manheim-Multiparty Dynamics and Failure Modes for Machine Learning and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1810.10862v4",
      "categories": [
        "cs.MA",
        "cs.AI",
        "91E45, 91A06"
      ]
    },
    "2105.15103v1": {
      "title": "Applications of Artificial Intelligence, Machine Learning and related techniques for Computer Networking Systems",
      "authors": [
        "Krishna M. Sivalingam"
      ],
      "abstract": "This article presents a primer/overview of applications of Artificial\nIntelligence and Machine Learning (AI/ML) techniques to address problems in the\ndomain of computer networking. In particular, the techniques have been used to\nsupport efficient and accurate traffic prediction, traffic classification,\nanomaly detection, network management, network security, network resource\nallocation and optimization, network scheduling algorithms, fault diagnosis and\nmany more such applications. The article first summarizes some of the key\nnetworking concepts and a few representative machine learning techniques and\nalgorithms. The article then presents details regarding the availability of\ndata sets for networking applications and machine learning software and\ntoolkits for processing these data sets. Highlights of some of the standards\nactivities, pursued by ITU-T and ETSI, which are related to AI/ML for\nnetworking, are also presented. Finally, the article discusses a small set of\nrepresentative networking problems where AI/ML techniques have been\nsuccessfully applied.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-04-21",
      "downloaded_date": "2025-01-31",
      "filename": "Sivalingam-Applications of Artificial Intelligence Machine Learning and related techniques for Computer Network....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.15103v1",
      "categories": [
        "cs.NI",
        "cs.LG"
      ]
    },
    "2301.10231v1": {
      "title": "Proactive and Reactive Engagement of Artificial Intelligence Methods for Education: A Review",
      "authors": [
        "Sruti Mallik",
        "Ahana Gangopadhyay"
      ],
      "abstract": "Quality education, one of the seventeen sustainable development goals (SDGs)\nidentified by the United Nations General Assembly, stands to benefit enormously\nfrom the adoption of artificial intelligence (AI) driven tools and\ntechnologies. The concurrent boom of necessary infrastructure, digitized data\nand general social awareness has propelled massive research and development\nefforts in the artificial intelligence for education (AIEd) sector. In this\nreview article, we investigate how artificial intelligence, machine learning\nand deep learning methods are being utilized to support students, educators and\nadministrative staff. We do this through the lens of a novel categorization\napproach. We consider the involvement of AI-driven methods in the education\nprocess in its entirety - from students admissions, course scheduling etc. in\nthe proactive planning phase to knowledge delivery, performance assessment etc.\nin the reactive execution phase. We outline and analyze the major research\ndirections under proactive and reactive engagement of AI in education using a\nrepresentative group of 194 original research articles published in the past\ntwo decades i.e., 2003 - 2022. We discuss the paradigm shifts in the solution\napproaches proposed, i.e., in the choice of data and algorithms used over this\ntime. We further dive into how the COVID-19 pandemic challenged and reshaped\nthe education landscape at the fag end of this time period. Finally, we\npinpoint existing limitations in adopting artificial intelligence for education\nand reflect on the path forward.",
      "citation_count": 24,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/00a36102c009698878c4285f66f84e827efc4803",
      "published_date": "2023-01-23",
      "downloaded_date": "2025-01-31",
      "filename": "Mallik-Proactive and Reactive Engagement of Artificial Intelligence Methods for Education A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2301.10231v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2008.05607v1": {
      "title": "A clarification of misconceptions, myths and desired status of artificial intelligence",
      "authors": [
        "Frank Emmert-Streib",
        "Olli Yli-Harja",
        "Matthias Dehmer"
      ],
      "abstract": "The field artificial intelligence (AI) has been founded over 65 years ago.\nStarting with great hopes and ambitious goals the field progressed though\nvarious stages of popularity and received recently a revival in the form of\ndeep neural networks. Some problems of AI are that so far neither\n'intelligence' nor the goals of AI are formally defined causing confusion when\ncomparing AI to other fields. In this paper, we present a perspective on the\ndesired and current status of AI in relation to machine learning and statistics\nand clarify common misconceptions and myths. Our discussion is intended to\nuncurtain the veil of vagueness surrounding AI to see its true countenance.",
      "citation_count": 24,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3f22551231aeee84d5a82257a9709a2af53269e3",
      "published_date": "2020-08-03",
      "downloaded_date": "2025-01-31",
      "filename": "Emmert-Streib-A clarification of misconceptions myths and desired status of artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.05607v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2003.00260v1": {
      "title": "On Safety Assessment of Artificial Intelligence",
      "authors": [
        "Jens Braband",
        "Hendrik SchÃ¤be"
      ],
      "abstract": "In this paper we discuss how systems with Artificial Intelligence (AI) can\nundergo safety assessment. This is relevant, if AI is used in safety related\napplications. Taking a deeper look into AI models, we show, that many models of\nartificial intelligence, in particular machine learning, are statistical\nmodels. Safety assessment would then have t o concentrate on the model that is\nused in AI, besides the normal assessment procedure. Part of the budget of\ndangerous random failures for the relevant safety integrity level needs to be\nused for the probabilistic faulty behavior of the AI system. We demonstrate our\nthoughts with a simple example and propose a research challenge that may be\ndecisive for the use of AI in safety related systems.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/99cadaf09e78f298ebd920bdb8a6ae39025523e4",
      "published_date": "2020-02-29",
      "downloaded_date": "2025-01-31",
      "filename": "Braband-On Safety Assessment of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2003.00260v1",
      "categories": [
        "cs.AI",
        "stat.ML"
      ]
    },
    "2402.03806v1": {
      "title": "Explainable Automated Machine Learning for Credit Decisions: Enhancing Human Artificial Intelligence Collaboration in Financial Engineering",
      "authors": [
        "Marc Schmitt"
      ],
      "abstract": "This paper explores the integration of Explainable Automated Machine Learning\n(AutoML) in the realm of financial engineering, specifically focusing on its\napplication in credit decision-making. The rapid evolution of Artificial\nIntelligence (AI) in finance has necessitated a balance between sophisticated\nalgorithmic decision-making and the need for transparency in these systems. The\nfocus is on how AutoML can streamline the development of robust machine\nlearning models for credit scoring, while Explainable AI (XAI) methods,\nparticularly SHapley Additive exPlanations (SHAP), provide insights into the\nmodels' decision-making processes. This study demonstrates how the combination\nof AutoML and XAI not only enhances the efficiency and accuracy of credit\ndecisions but also fosters trust and collaboration between humans and AI\nsystems. The findings underscore the potential of explainable AutoML in\nimproving the transparency and accountability of AI-driven financial decisions,\naligning with regulatory requirements and ethical considerations.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/57dce5a7088f84f4ffd936d9c251d7426762ecf3",
      "published_date": "2024-02-06",
      "downloaded_date": "2025-01-31",
      "filename": "Schmitt-Explainable Automated Machine Learning for Credit Decisions Enhancing Human Artificial Intelligence ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.03806v1",
      "categories": [
        "q-fin.RM",
        "cs.LG",
        "q-fin.CP"
      ]
    },
    "2302.00225v2": {
      "title": "The Past, Current, and Future of Neonatal Intensive Care Units with Artificial Intelligence",
      "authors": [
        "Elif Keles",
        "Ulas Bagci"
      ],
      "abstract": "Machine learning and deep learning are two subsets of artificial intelligence\nthat involve teaching computers to learn and make decisions from any sort of\ndata. Most recent developments in artificial intelligence are coming from deep\nlearning, which has proven revolutionary in almost all fields, from computer\nvision to health sciences. The effects of deep learning in medicine have\nchanged the conventional ways of clinical application significantly. Although\nsome sub-fields of medicine, such as pediatrics, have been relatively slow in\nreceiving the critical benefits of deep learning, related research in\npediatrics has started to accumulate to a significant level, too. Hence, in\nthis paper, we review recently developed machine learning and deep\nlearning-based solutions for neonatology applications. We systematically\nevaluate the roles of both classical machine learning and deep learning in\nneonatology applications, define the methodologies, including algorithmic\ndevelopments, and describe the remaining challenges in the assessment of\nneonatal diseases by using PRISMA 2020 guidelines. To date, the primary areas\nof focus in neonatology regarding AI applications have included survival\nanalysis, neuroimaging, analysis of vital parameters and biosignals, and\nretinopathy of prematurity diagnosis. We have categorically summarized 106\nresearch articles from 1996 to 2022 and discussed their pros and cons,\nrespectively. In this systematic review, we aimed to further enhance the\ncomprehensiveness of the study. We also discuss possible directions for new AI\nmodels and the future of neonatology with the rising power of AI, suggesting\nroadmaps for the integration of AI into neonatal intensive care units.",
      "citation_count": 15,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ed400104a7e1f376cae9917ccb477e39e078bb70",
      "published_date": "2023-02-01",
      "downloaded_date": "2025-01-31",
      "filename": "Keles-The Past Current and Future of Neonatal Intensive Care Units with Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.00225v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "1705.00594v2": {
      "title": "A System for Accessible Artificial Intelligence",
      "authors": [
        "Randal S. Olson",
        "Moshe Sipper",
        "William La Cava",
        "Sharon Tartarone",
        "Steven Vitale",
        "Weixuan Fu",
        "Patryk Orzechowski",
        "Ryan J. Urbanowicz",
        "John H. Holmes",
        "Jason H. Moore"
      ],
      "abstract": "While artificial intelligence (AI) has become widespread, many commercial AI\nsystems are not yet accessible to individual researchers nor the general public\ndue to the deep knowledge of the systems required to use them. We believe that\nAI has matured to the point where it should be an accessible technology for\neveryone. We present an ongoing project whose ultimate goal is to deliver an\nopen source, user-friendly AI system that is specialized for machine learning\nanalysis of complex data in the biomedical and health care domains. We discuss\nhow genetic programming can aid in this endeavor, and highlight specific\nexamples where genetic programming has automated machine learning analyses in\nprevious projects.",
      "citation_count": 31,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9c83221ea08ec1ea54cb017f4cc45d7548236176",
      "published_date": "2017-05-01",
      "downloaded_date": "2025-01-31",
      "filename": "Olson-A System for Accessible Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1705.00594v2",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.NE"
      ]
    },
    "2011.08001v3": {
      "title": "Deep-LIBRA: Artificial intelligence method for robust quantification of breast density with independent validation in breast cancer risk assessment",
      "authors": [
        "Omid Haji Maghsoudi",
        "Aimilia Gastounioti",
        "Christopher Scott",
        "Lauren Pantalone",
        "Fang-Fang Wu",
        "Eric A. Cohen",
        "Stacey Winham",
        "Emily F. Conant",
        "Celine Vachon",
        "Despina Kontos"
      ],
      "abstract": "Breast density is an important risk factor for breast cancer that also\naffects the specificity and sensitivity of screening mammography. Current\nfederal legislation mandates reporting of breast density for all women\nundergoing breast screening. Clinically, breast density is assessed visually\nusing the American College of Radiology Breast Imaging Reporting And Data\nSystem (BI-RADS) scale. Here, we introduce an artificial intelligence (AI)\nmethod to estimate breast percentage density (PD) from digital mammograms. Our\nmethod leverages deep learning (DL) using two convolutional neural network\narchitectures to accurately segment the breast area. A machine-learning\nalgorithm combining superpixel generation, texture feature analysis, and\nsupport vector machine is then applied to differentiate dense from non-dense\ntissue regions, from which PD is estimated. Our method has been trained and\nvalidated on a multi-ethnic, multi-institutional dataset of 15,661 images\n(4,437 women), and then tested on an independent dataset of 6,368 digital\nmammograms (1,702 women; cases=414) for both PD estimation and discrimination\nof breast cancer. On the independent dataset, PD estimates from Deep-LIBRA and\nan expert reader were strongly correlated (Spearman correlation coefficient =\n0.90). Moreover, Deep-LIBRA yielded a higher breast cancer discrimination\nperformance (area under the ROC curve, AUC = 0.611 [95% confidence interval\n(CI): 0.583, 0.639]) compared to four other widely-used research and commercial\nPD assessment methods (AUCs = 0.528 to 0.588). Our results suggest a strong\nagreement of PD estimates between Deep-LIBRA and gold-standard assessment by an\nexpert reader, as well as improved performance in breast cancer risk assessment\nover state-of-the-art open-source and commercial methods.",
      "citation_count": 39,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1975071bc8535d63c6c6ea7ff5728c603c15d9a9",
      "published_date": "2020-11-13",
      "downloaded_date": "2025-01-31",
      "filename": "Maghsoudi-Deep-LIBRA Artificial intelligence method for robust quantification of breast density with independe....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2011.08001v3",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2008.13547v2": {
      "title": "Machine learning for metal additive manufacturing: Predicting temperature and melt pool fluid dynamics using physics-informed neural networks",
      "authors": [
        "Qiming Zhu",
        "Zeliang Liu",
        "Jinhui Yan"
      ],
      "abstract": "The recent explosion of machine learning (ML) and artificial intelligence\n(AI) shows great potential in the breakthrough of metal additive manufacturing\n(AM) process modeling. However, the success of conventional machine learning\ntools in data science is primarily attributed to the unprecedented large amount\nof labeled data-sets (big data), which can be either obtained by experiments or\nfirst-principle simulations. Unfortunately, these labeled data-sets are\nexpensive to obtain in AM due to the high expense of the AM experiments and\nprohibitive computational cost of high-fidelity simulations.\n  We propose a physics-informed neural network (PINN) framework that fuses both\ndata and first physical principles, including conservation laws of momentum,\nmass, and energy, into the neural network to inform the learning processes. To\nthe best knowledge of the authors, this is the first application of PINN to\nthree dimensional AM processes modeling. Besides, we propose a hard-type\napproach for Dirichlet boundary conditions (BCs) based on a Heaviside function,\nwhich can not only enforce the BCs but also accelerate the learning process.\nThe PINN framework is applied to two representative metal manufacturing\nproblems, including the 2018 NIST AM-Benchmark test series. We carefully assess\nthe performance of the PINN model by comparing the predictions with available\nexperimental data and high-fidelity simulation results. The investigations show\nthat the PINN, owed to the additional physical knowledge, can accurately\npredict the temperature and melt pool dynamics during metal AM processes with\nonly a moderate amount of labeled data-sets. The foray of PINN to metal AM\nshows the great potential of physics-informed deep learning for broader\napplications to advanced manufacturing.",
      "citation_count": 267,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/68f691a444ddf3914f785f03765790f95cce7ab0",
      "published_date": "2020-07-28",
      "downloaded_date": "2025-01-31",
      "filename": "Zhu-Machine learning for metal additive manufacturing Predicting temperature and melt pool fluid dynamic....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.13547v2",
      "categories": [
        "cs.CE",
        "cs.LG",
        "physics.app-ph",
        "physics.flu-dyn"
      ]
    },
    "2209.00083v1": {
      "title": "Feynman on Artificial Intelligence and Machine Learning, with Updates",
      "authors": [
        "Eric Mjolsness"
      ],
      "abstract": "I present my recollections of Richard Feynman's mid-1980s interest in\nartificial intelligence and neural networks, set in the technical context of\nthe physics-related approaches to neural networks of that time. I attempt to\nevaluate his ideas in the light of the substantial advances in the field since\nthen, and vice versa. There are aspects of Feynman's interests that I think\nhave been largely achieved and others that remain excitingly open, notably in\ncomputational science, and potentially including the revival of symbolic\nmethods therein.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3b5e3f645f48e2cf01c5ec662ac4cd410715f6fc",
      "published_date": "2022-08-31",
      "downloaded_date": "2025-01-31",
      "filename": "Mjolsness-Feynman on Artificial Intelligence and Machine Learning with Updates.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.00083v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2204.05023v3": {
      "title": "Machine Learning and Deep Learning -- A review for Ecologists",
      "authors": [
        "Maximilian Pichler",
        "Florian Hartig"
      ],
      "abstract": "1. The popularity of Machine learning (ML), Deep learning (DL), and\nArtificial intelligence (AI) has risen sharply in recent years. Despite this\nspike in popularity, the inner workings of ML and DL algorithms are often\nperceived as opaque, and their relationship to classical data analysis tools\nremains debated. 2. Although it is often assumed that ML and DL excel primarily\nat making predictions, ML and DL can also be used for analytical tasks\ntraditionally addressed with statistical models. Moreover, most recent\ndiscussions and reviews on ML focus mainly on DL, missing out on synthesizing\nthe wealth of ML algorithms with different advantages and general principles.\n3. Here, we provide a comprehensive overview of the field of ML and DL,\nstarting by summarizing its historical developments, existing algorithm\nfamilies, differences to traditional statistical tools, and universal ML\nprinciples. We then discuss why and when ML and DL models excel at prediction\ntasks and where they could offer alternatives to traditional statistical\nmethods for inference, highlighting current and emerging applications for\necological problems. Finally, we summarize emerging trends such as scientific\nand causal ML, explainable AI, and responsible AI that may significantly impact\necological data analysis in the future. 4. We conclude that ML and DL are\npowerful new tools for predictive modeling and data analysis. The superior\nperformance of ML and DL algorithms compared to statistical models can be\nexplained by their higher flexibility and automatic data-dependent complexity\noptimization. However, their use for causal inference is still disputed as the\nfocus of ML and DL methods on predictions creates challenges for the\ninterpretation of these models. Nevertheless, we expect ML and DL to become an\nindispensable tool in E&E, comparable to other traditional statistical tools.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-04-11",
      "downloaded_date": "2025-01-31",
      "filename": "Pichler-Machine Learning and Deep Learning -- A review for Ecologists.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2204.05023v3",
      "categories": [
        "q-bio.QM",
        "stat.ML"
      ]
    },
    "2009.13250v1": {
      "title": "Advancing the Research and Development of Assured Artificial Intelligence and Machine Learning Capabilities",
      "authors": [
        "Tyler J. Shipp",
        "Daniel J. Clouse",
        "Michael J. De Lucia",
        "Metin B. Ahiskali",
        "Kai Steverson",
        "Jonathan M. Mullin",
        "Nathaniel D. Bastian"
      ],
      "abstract": "Artificial intelligence (AI) and machine learning (ML) have become\nincreasingly vital in the development of novel defense and intelligence\ncapabilities across all domains of warfare. An adversarial AI (A2I) and\nadversarial ML (AML) attack seeks to deceive and manipulate AI/ML models. It is\nimperative that AI/ML models can defend against these attacks. A2I/AML defenses\nwill help provide the necessary assurance of these advanced capabilities that\nuse AI/ML models. The A2I Working Group (A2IWG) seeks to advance the research\nand development of assured AI/ML capabilities via new A2I/AML defenses by\nfostering a collaborative environment across the U.S. Department of Defense and\nU.S. Intelligence Community. The A2IWG aims to identify specific challenges\nthat it can help solve or address more directly, with initial focus on three\ntopics: AI Trusted Robustness, AI System Security, and AI/ML Architecture\nVulnerabilities.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6bab367818e2bec4d21dec2c0a78fa03d514bb94",
      "published_date": "2020-09-24",
      "downloaded_date": "2025-01-31",
      "filename": "Shipp-Advancing the Research and Development of Assured Artificial Intelligence and Machine Learning Capab....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.13250v1",
      "categories": [
        "cs.LG",
        "cs.CR",
        "cs.CY",
        "cs.SE"
      ]
    },
    "1912.11945v1": {
      "title": "On the Morality of Artificial Intelligence",
      "authors": [
        "Alexandra Luccioni",
        "Yoshua Bengio"
      ],
      "abstract": "Much of the existing research on the social and ethical impact of Artificial\nIntelligence has been focused on defining ethical principles and guidelines\nsurrounding Machine Learning (ML) and other Artificial Intelligence (AI)\nalgorithms [IEEE, 2017, Jobin et al., 2019]. While this is extremely useful for\nhelping define the appropriate social norms of AI, we believe that it is\nequally important to discuss both the potential and risks of ML and to inspire\nthe community to use ML for beneficial objectives. In the present article,\nwhich is specifically aimed at ML practitioners, we thus focus more on the\nlatter, carrying out an overview of existing high-level ethical frameworks and\nguidelines, but above all proposing both conceptual and practical principles\nand guidelines for ML research and deployment, insisting on concrete actions\nthat can be taken by practitioners to pursue a more ethical and moral practice\nof ML aimed at using AI for social good.",
      "citation_count": 22,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/04575c2be68dab227b6c3d89cc58cd9d99f40a99",
      "published_date": "2019-12-26",
      "downloaded_date": "2025-01-31",
      "filename": "Luccioni-On the Morality of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1912.11945v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2011.00111v2": {
      "title": "Photonics for artificial intelligence and neuromorphic computing",
      "authors": [
        "Bhavin J. Shastri",
        "Alexander N. Tait",
        "Thomas Ferreira de Lima",
        "Wolfram H. P. Pernice",
        "Harish Bhaskaran",
        "C. David Wright",
        "Paul R. Prucnal"
      ],
      "abstract": "Research in photonic computing has flourished due to the proliferation of\noptoelectronic components on photonic integration platforms. Photonic\nintegrated circuits have enabled ultrafast artificial neural networks,\nproviding a framework for a new class of information processing machines.\nAlgorithms running on such hardware have the potential to address the growing\ndemand for machine learning and artificial intelligence, in areas such as\nmedical diagnosis, telecommunications, and high-performance and scientific\ncomputing. In parallel, the development of neuromorphic electronics has\nhighlighted challenges in that domain, in particular, related to processor\nlatency. Neuromorphic photonics offers sub-nanosecond latencies, providing a\ncomplementary opportunity to extend the domain of artificial intelligence.\nHere, we review recent advances in integrated photonic neuromorphic systems,\ndiscuss current and future challenges, and outline the advances in science and\ntechnology needed to meet those challenges.",
      "citation_count": 1056,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5e7a7fb69ef7447c2cb8966589e49a5acbee416e",
      "published_date": "2020-10-30",
      "downloaded_date": "2025-01-31",
      "filename": "Shastri-Photonics for artificial intelligence and neuromorphic computing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2011.00111v2",
      "categories": [
        "physics.optics",
        "cs.NE",
        "physics.app-ph"
      ]
    },
    "2112.04573v1": {
      "title": "Application of Artificial Intelligence and Machine Learning in Libraries: A Systematic Review",
      "authors": [
        "Rajesh Kumar Das",
        "Mohammad Sharif Ul Islam"
      ],
      "abstract": "As the concept and implementation of cutting-edge technologies like\nartificial intelligence and machine learning has become relevant, academics,\nresearchers and information professionals involve research in this area. The\nobjective of this systematic literature review is to provide a synthesis of\nempirical studies exploring application of artificial intelligence and machine\nlearning in libraries. To achieve the objectives of the study, a systematic\nliterature review was conducted based on the original guidelines proposed by\nKitchenham et al. (2009). Data was collected from Web of Science, Scopus, LISA\nand LISTA databases. Following the rigorous/ established selection process, a\ntotal of thirty-two articles were finally selected, reviewed and analyzed to\nsummarize on the application of AI and ML domain and techniques which are most\noften used in libraries. Findings show that the current state of the AI and ML\nresearch that is relevant with the LIS domain mainly focuses on theoretical\nworks. However, some researchers also emphasized on implementation projects or\ncase studies. This study will provide a panoramic view of AI and ML in\nlibraries for researchers, practitioners and educators for furthering the more\ntechnology-oriented approaches, and anticipating future innovation pathways.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0fa420a8dc7aaba6177419fc220a5edf03729c18",
      "published_date": "2021-12-06",
      "downloaded_date": "2025-01-31",
      "filename": "Das-Application of Artificial Intelligence and Machine Learning in Libraries A Systematic Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2112.04573v1",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2304.11880v2": {
      "title": "The State of the Art in transformer fault diagnosis with artificial intelligence and Dissolved Gas Analysis: A Review of the Literature",
      "authors": [
        "Yuyan Li"
      ],
      "abstract": "Transformer fault diagnosis (TFD) is a critical aspect of power system\nmaintenance and management. This review paper provides a comprehensive overview\nof the current state of the art in TFD using artificial intelligence (AI) and\ndissolved gas analysis (DGA). The paper presents an analysis of recent\nadvancements in this field, including the use of deep learning algorithms and\nadvanced data analytics techniques, and their potential impact on TFD and the\npower industry as a whole. The review also highlights the benefits and\nlimitations of different approaches to transformer fault diagnosis, including\nrule-based systems, expert systems, neural networks, and machine learning\nalgorithms. Overall, this review aims to provide valuable insights into the\nimportance of TFD and the role of AI in ensuring the reliable operation of\npower systems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-04-24",
      "downloaded_date": "2025-01-31",
      "filename": "Li-The State of the Art in transformer fault diagnosis with artificial intelligence and Dissolved Gas A....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.11880v2",
      "categories": [
        "eess.SY",
        "cs.LG",
        "cs.SY"
      ]
    },
    "2307.03681v1": {
      "title": "Guideline for Trustworthy Artificial Intelligence -- AI Assessment Catalog",
      "authors": [
        "Maximilian Poretschkin",
        "Anna Schmitz",
        "Maram Akila",
        "Linara Adilova",
        "Daniel Becker",
        "Armin B. Cremers",
        "Dirk Hecker",
        "Sebastian Houben",
        "Michael Mock",
        "Julia Rosenzweig",
        "Joachim Sicking",
        "Elena Schulz",
        "Angelika Voss",
        "Stefan Wrobel"
      ],
      "abstract": "Artificial Intelligence (AI) has made impressive progress in recent years and\nrepresents a key technology that has a crucial impact on the economy and\nsociety. However, it is clear that AI and business models based on it can only\nreach their full potential if AI applications are developed according to high\nquality standards and are effectively protected against new AI risks. For\ninstance, AI bears the risk of unfair treatment of individuals when processing\npersonal data e.g., to support credit lending or staff recruitment decisions.\nThe emergence of these new risks is closely linked to the fact that the\nbehavior of AI applications, particularly those based on Machine Learning (ML),\nis essentially learned from large volumes of data and is not predetermined by\nfixed programmed rules.\n  Thus, the issue of the trustworthiness of AI applications is crucial and is\nthe subject of numerous major publications by stakeholders in politics,\nbusiness and society. In addition, there is mutual agreement that the\nrequirements for trustworthy AI, which are often described in an abstract way,\nmust now be made clear and tangible. One challenge to overcome here relates to\nthe fact that the specific quality criteria for an AI application depend\nheavily on the application context and possible measures to fulfill them in\nturn depend heavily on the AI technology used. Lastly, practical assessment\nprocedures are needed to evaluate whether specific AI applications have been\ndeveloped according to adequate quality standards. This AI assessment catalog\naddresses exactly this point and is intended for two target groups: Firstly, it\nprovides developers with a guideline for systematically making their AI\napplications trustworthy. Secondly, it guides assessors and auditors on how to\nexamine AI applications for trustworthiness in a structured way.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1fc231b7a4b5eae6ca6b9bc7617559c16520139c",
      "published_date": "2023-06-20",
      "downloaded_date": "2025-01-31",
      "filename": "Poretschkin-Guideline for Trustworthy Artificial Intelligence -- AI Assessment Catalog.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.03681v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2208.12120v1": {
      "title": "Towards Benchmarking Explainable Artificial Intelligence Methods",
      "authors": [
        "Lars Holmberg"
      ],
      "abstract": "The currently dominating artificial intelligence and machine learning\ntechnology, neural networks, builds on inductive statistical learning. Neural\nnetworks of today are information processing systems void of understanding and\nreasoning capabilities, consequently, they cannot explain promoted decisions in\na humanly valid form. In this work, we revisit and use fundamental philosophy\nof science theories as an analytical lens with the goal of revealing, what can\nbe expected, and more importantly, not expected, from methods that aim to\nexplain decisions promoted by a neural network. By conducting a case study we\ninvestigate a selection of explainability method's performance over two mundane\ndomains, animals and headgear. Through our study, we lay bare that the\nusefulness of these methods relies on human domain knowledge and our ability to\nunderstand, generalise and reason. The explainability methods can be useful\nwhen the goal is to gain further insights into a trained neural network's\nstrengths and weaknesses. If our aim instead is to use these explainability\nmethods to promote actionable decisions or build trust in ML-models they need\nto be less ambiguous than they are today. In this work, we conclude from our\nstudy, that benchmarking explainability methods, is a central quest towards\ntrustworthy artificial intelligence and machine learning.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1990c9301dc96334a03b455df38c757ac0b19256",
      "published_date": "2022-08-25",
      "downloaded_date": "2025-01-31",
      "filename": "Holmberg-Towards Benchmarking Explainable Artificial Intelligence Methods.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2208.12120v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.4"
      ]
    },
    "2006.00093v4": {
      "title": "Explainable Artificial Intelligence: a Systematic Review",
      "authors": [
        "Giulia Vilone",
        "Luca Longo"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) has experienced a significant\ngrowth over the last few years. This is due to the widespread application of\nmachine learning, particularly deep learning, that has led to the development\nof highly accurate models but lack explainability and interpretability. A\nplethora of methods to tackle this problem have been proposed, developed and\ntested. This systematic review contributes to the body of knowledge by\nclustering these methods with a hierarchical classification system with four\nmain clusters: review articles, theories and notions, methods and their\nevaluation. It also summarises the state-of-the-art in XAI and recommends\nfuture research directions.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-05-29",
      "downloaded_date": "2025-01-31",
      "filename": "Vilone-Explainable Artificial Intelligence a Systematic Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2006.00093v4",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.0; I.2.6; I.2.m"
      ]
    },
    "1906.05270v1": {
      "title": "Artificial Intelligence Enabled Material Behavior Prediction",
      "authors": [
        "Timothy Hanlon",
        "Johan Reimann",
        "Monica A. Soare",
        "Anjali Singhal",
        "James Grande",
        "Marc Edgar",
        "Kareem S. Aggour",
        "Joseph Vinciquerra"
      ],
      "abstract": "Artificial Intelligence and Machine Learning algorithms have considerable\npotential to influence the prediction of material properties. Additive\nmaterials have a unique property prediction challenge in the form of surface\nroughness effects on fatigue behavior of structural components. Traditional\napproaches using finite element methods to calculate stress risers associated\nwith additively built surfaces have been challenging due to the computational\nresources required, often taking over a day to calculate a single sample\nprediction. To address this performance challenge, Deep Learning has been\nemployed to enable low cycle fatigue life prediction in additive materials in a\nmatter of seconds.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/42caefaccd27dd8eaab076accc0da9871f18cd39",
      "published_date": "2019-06-12",
      "downloaded_date": "2025-01-31",
      "filename": "Hanlon-Artificial Intelligence Enabled Material Behavior Prediction.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1906.05270v1",
      "categories": [
        "cs.LG",
        "physics.app-ph"
      ]
    },
    "2401.01342v1": {
      "title": "Securing the Digital World: Protecting smart infrastructures and digital industries with Artificial Intelligence (AI)-enabled malware and intrusion detection",
      "authors": [
        "Marc Schmitt"
      ],
      "abstract": "The last decades have been characterized by unprecedented technological\nadvances, many of them powered by modern technologies such as Artificial\nIntelligence (AI) and Machine Learning (ML). The world has become more\ndigitally connected than ever, but we face major challenges. One of the most\nsignificant is cybercrime, which has emerged as a global threat to governments,\nbusinesses, and civil societies. The pervasiveness of digital technologies\ncombined with a constantly shifting technological foundation has created a\ncomplex and powerful playground for cybercriminals, which triggered a surge in\ndemand for intelligent threat detection systems based on machine and deep\nlearning. This paper investigates AI-based cyber threat detection to protect\nour modern digital ecosystems. The primary focus is on evaluating ML-based\nclassifiers and ensembles for anomaly-based malware detection and network\nintrusion detection and how to integrate those models in the context of network\nsecurity, mobile security, and IoT security. The discussion highlights the\nchallenges when deploying and integrating AI-enabled cybersecurity solutions\ninto existing enterprise systems and IT infrastructures, including options to\novercome those challenges. Finally, the paper provides future research\ndirections to further increase the security and resilience of our modern\ndigital industries, infrastructures, and ecosystems.",
      "citation_count": 53,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/986ee54849ba6e3297bcb560e4ec57e0979c002c",
      "published_date": "2023-10-15",
      "downloaded_date": "2025-01-31",
      "filename": "Schmitt-Securing the Digital World Protecting smart infrastructures and digital industries with Artificial I....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.01342v1",
      "categories": [
        "cs.CR",
        "cs.LG"
      ]
    },
    "2107.01031v1": {
      "title": "Effectiveness of Artificial Intelligence in Stock Market Prediction based on Machine Learning",
      "authors": [
        "Sohrab Mokhtari",
        "Kang K. Yen",
        "Jin Liu"
      ],
      "abstract": "This paper tries to address the problem of stock market prediction leveraging\nartificial intelligence (AI) strategies. The stock market prediction can be\nmodeled based on two principal analyses called technical and fundamental. In\nthe technical analysis approach, the regression machine learning (ML)\nalgorithms are employed to predict the stock price trend at the end of a\nbusiness day based on the historical price data. In contrast, in the\nfundamental analysis, the classification ML algorithms are applied to classify\nthe public sentiment based on news and social media. In the technical analysis,\nthe historical price data is exploited from Yahoo Finance, and in fundamental\nanalysis, public tweets on Twitter associated with the stock market are\ninvestigated to assess the impact of sentiments on the stock market's forecast.\nThe results show a median performance, implying that with the current\ntechnology of AI, it is too soon to claim AI can beat the stock markets.",
      "citation_count": 36,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1119547a3a1c248a42d0d32cb9dfa26107c29fde",
      "published_date": "2021-06-30",
      "downloaded_date": "2025-01-31",
      "filename": "Mokhtari-Effectiveness of Artificial Intelligence in Stock Market Prediction based on Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.01031v1",
      "categories": [
        "q-fin.ST"
      ]
    },
    "2402.06775v2": {
      "title": "Twenty Constructionist Things to Do with Artificial Intelligence and Machine Learning",
      "authors": [
        "Yasmin Kafai",
        "Luis Morales-Navarro"
      ],
      "abstract": "In this paper, we build on the 1971 memo \"Twenty Things to Do With a\nComputer\" by Seymour Papert and Cynthia Solomon and propose twenty\nconstructionist things to do with artificial intelligence and machine learning.\nSeveral proposals build on ideas developed in the original memo while others\nare new and address topics in science, mathematics, and the arts. In reviewing\nthe big themes, we notice a renewed interest in children's engagement not just\nfor technical proficiency but also to cultivate a deeper understanding of their\nown cognitive processes. Furthermore, the ideas stress the importance of\ndesigning personally relevant AI/ML applications, moving beyond isolated models\nand off-the-shelf datasets disconnected from their interests. We also\nacknowledge the social aspects of data production involved in making AI/ML\napplications. Finally, we highlight the critical dimensions necessary to\naddress potential harmful algorithmic biases and consequences of AI/ML\napplications.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bfd390fa1786d1a9c601d46c13fb0bf83e193b4c",
      "published_date": "2024-02-09",
      "downloaded_date": "2025-01-31",
      "filename": "Kafai-Twenty Constructionist Things to Do with Artificial Intelligence and Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.06775v2",
      "categories": [
        "cs.CY",
        "K.3.2"
      ]
    },
    "1709.01547v2": {
      "title": "Knowledge Transfer Between Artificial Intelligence Systems",
      "authors": [
        "Ivan Y. Tyukin",
        "Alexander N. Gorban",
        "Konstantin Sofeikov",
        "Ilya Romanenko"
      ],
      "abstract": "We consider the fundamental question: how a legacy \"student\" Artificial\nIntelligent (AI) system could learn from a legacy \"teacher\" AI system or a\nhuman expert without complete re-training and, most importantly, without\nrequiring significant computational resources. Here \"learning\" is understood as\nan ability of one system to mimic responses of the other and vice-versa. We\ncall such learning an Artificial Intelligence knowledge transfer. We show that\nif internal variables of the \"student\" Artificial Intelligent system have the\nstructure of an $n$-dimensional topological vector space and $n$ is\nsufficiently high then, with probability close to one, the required knowledge\ntransfer can be implemented by simple cascades of linear functionals. In\nparticular, for $n$ sufficiently large, with probability close to one, the\n\"student\" system can successfully and non-iteratively learn $k\\ll n$ new\nexamples from the \"teacher\" (or correct the same number of mistakes) at the\ncost of two additional inner products. The concept is illustrated with an\nexample of knowledge transfer from a pre-trained convolutional neural network\nto a simple linear classifier with HOG features.",
      "citation_count": 29,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0f246c88598b57062fee80b97589fa72ad9e96cf",
      "published_date": "2017-09-05",
      "downloaded_date": "2025-01-31",
      "filename": "Tyukin-Knowledge Transfer Between Artificial Intelligence Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1709.01547v2",
      "categories": [
        "cs.AI",
        "68T05, 68T30"
      ]
    },
    "2003.09415v2": {
      "title": "Comments on Sejnowski's \"The unreasonable effectiveness of deep learning in artificial intelligence\" [arXiv:2002.04806]",
      "authors": [
        "Leslie S. Smith"
      ],
      "abstract": "Terry Sejnowski's 2020 paper [arXiv:2002.04806] is entitled \"The unreasonable\neffectiveness of deep learning in artificial intelligence\". However, the paper\ndoesn't attempt to answer the implied question of why Deep Convolutional Neural\nNetworks (DCNNs) can approximate so many of the mappings that they have been\ntrained to model. While there are detailed mathematical analyses, this short\npaper attempts to look at the issue differently, considering the way that these\nnetworks are used, the subset of these functions that can be achieved by\ntraining (starting from some location in the original function space), as well\nas the functions to which these networks will actually be applied.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-03-20",
      "downloaded_date": "2025-01-31",
      "filename": "Smith-Comments on Sejnowskis The unreasonable effectiveness of deep learning in artificial intelligence ar....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2003.09415v2",
      "categories": [
        "cs.NE",
        "I1.2"
      ]
    },
    "2107.06179v2": {
      "title": "Application of artificial intelligence techniques for automated detection of myocardial infarction: A review",
      "authors": [
        "Javad Hassannataj Joloudari",
        "Sanaz Mojrian",
        "Issa Nodehi",
        "Amir Mashmool",
        "Zeynab Kiani Zadegan",
        "Sahar Khanjani Shirkharkolaie",
        "Roohallah Alizadehsani",
        "Tahereh Tamadon",
        "Samiyeh Khosravi",
        "Mitra Akbari Kohnehshari",
        "Edris Hassannatajjeloudari",
        "Danial Sharifrazi",
        "Amir Mosavi",
        "Hui Wen Loh",
        "Ru-San Tan",
        "U Rajendra Acharya"
      ],
      "abstract": "Myocardial infarction (MI) results in heart muscle injury due to receiving\ninsufficient blood flow. MI is the most common cause of mortality in\nmiddle-aged and elderly individuals around the world. To diagnose MI,\nclinicians need to interpret electrocardiography (ECG) signals, which requires\nexpertise and is subject to observer bias. Artificial intelligence-based\nmethods can be utilized to screen for or diagnose MI automatically using ECG\nsignals. In this work, we conducted a comprehensive assessment of artificial\nintelligence-based approaches for MI detection based on ECG as well as other\nbiophysical signals, including machine learning (ML) and deep learning (DL)\nmodels. The performance of traditional ML methods relies on handcrafted\nfeatures and manual selection of ECG signals, whereas DL models can automate\nthese tasks. The review observed that deep convolutional neural networks\n(DCNNs) yielded excellent classification performance for MI diagnosis, which\nexplains why they have become prevalent in recent years. To our knowledge, this\nis the first comprehensive survey of artificial intelligence techniques\nemployed for MI diagnosis using ECG and other biophysical signals.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-07-05",
      "downloaded_date": "2025-01-31",
      "filename": "Joloudari-Application of artificial intelligence techniques for automated detection of myocardial infarction A....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.06179v2",
      "categories": [
        "eess.SP",
        "cs.CV"
      ]
    },
    "2303.06049v1": {
      "title": "Affordable Artificial Intelligence -- Augmenting Farmer Knowledge with AI",
      "authors": [
        "Peeyush Kumar",
        "Andrew Nelson",
        "Zerina Kapetanovic",
        "Ranveer Chandra"
      ],
      "abstract": "Farms produce hundreds of thousands of data points on the ground daily.\nFarming technique which combines farming practices with the insights uncovered\nin these data points using AI technology is called precision farming. Precision\nfarming technology augments and extends farmers' deep knowledge about their\nland, making production more sustainable and profitable. As part of the larger\neffort at Microsoft for empowering agricultural labor force to be more\nproductive and sustainable, this paper presents the AI technology for\npredicting micro-climate conditions on the farm.\n  This article is a chapter in publication by Food and Agriculture Organization\nof the United Nations and International Telecommunication Union Bangkok, 2021.\nThis publication on artificial intelligence (AI) for agriculture is the fifth\nin the E-agriculture in Action series, launched in 2016 and jointly produced by\nFAO and ITU. It aims to raise awareness about existing AI applications in\nagriculture and to inspire stakeholders to develop and replicate the new ones.\nImprovement of capacity and tools for capturing and processing data and\nsubstantial advances in the field of machine learning open new horizons for\ndata-driven solutions that can support decision-making, facilitate supervision\nand monitoring, improve the timeliness and effectiveness of safety measures\n(e.g. use of pesticides), and support automation of many resource-consuming\ntasks in agriculture. This publication presents the reader with a collection of\ninformative applications highlighting various ways AI is used in agriculture\nand offering valuable insights on the implementation process, success factors,\nand lessons learnt.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-03-04",
      "downloaded_date": "2025-01-31",
      "filename": "Kumar-Affordable Artificial Intelligence -- Augmenting Farmer Knowledge with AI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.06049v1",
      "categories": [
        "eess.SP",
        "cs.AI"
      ]
    },
    "2412.11911v2": {
      "title": "What Can Youth Learn About Artificial Intelligence and Machine Learning in One Hour? Examining How Hour of Code Activities Address the Five Big Ideas of AI",
      "authors": [
        "Luis Morales-Navarro",
        "Yasmin B. Kafai",
        "Eric Yang",
        "Asep Suryana"
      ],
      "abstract": "The prominence of artificial intelligence and machine learning in everyday\nlife has led to efforts to foster AI literacy for all K-12 students. In this\npaper, we review how Hour of Code activities engage with the five big ideas of\nAI, in particular with machine learning and societal impact. We found that a\nlarge majority of activities focus on perception and machine learning, with\nlittle attention paid to representation and other topics. A surprising finding\nwas the increased attention paid to critical aspects of computing. However, we\nalso observed a limited engagement with hands-on activities. In the discussion,\nwe address how future introductory activities could be designed to offer a\nbroader array of topics, including the development of tools to introduce\nnovices to artificial intelligence and machine learning and the design of more\nunplugged and collaborative activities.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cc5bcaeef811f2fc7c73652c767e879aa6e0d8d9",
      "published_date": "2024-12-16",
      "downloaded_date": "2025-01-31",
      "filename": "Morales-Navarro-What Can Youth Learn About Artificial Intelligence and Machine Learning in One Hour Examining How Ho....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.11911v2",
      "categories": [
        "cs.CY"
      ]
    },
    "1902.04245v2": {
      "title": "VERIFAI: A Toolkit for the Design and Analysis of Artificial Intelligence-Based Systems",
      "authors": [
        "Tommaso Dreossi",
        "Daniel J. Fremont",
        "Shromona Ghosh",
        "Edward Kim",
        "Hadi Ravanbakhsh",
        "Marcell Vazquez-Chanlatte",
        "Sanjit A. Seshia"
      ],
      "abstract": "We present VERIFAI, a software toolkit for the formal design and analysis of\nsystems that include artificial intelligence (AI) and machine learning (ML)\ncomponents. VERIFAI particularly seeks to address challenges with applying\nformal methods to perception and ML components, including those based on neural\nnetworks, and to model and analyze system behavior in the presence of\nenvironment uncertainty. We describe the initial version of VERIFAI which\ncenters on simulation guided by formal models and specifications. Several use\ncases are illustrated with examples, including temporal-logic falsification,\nmodel-based systematic fuzz testing, parameter synthesis, counterexample\nanalysis, and data set augmentation.",
      "citation_count": 27,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6749f800bc8f51c322639eb8fd7abce080ad1836",
      "published_date": "2019-02-12",
      "downloaded_date": "2025-01-31",
      "filename": "Dreossi-VERIFAI A Toolkit for the Design and Analysis of Artificial Intelligence-Based Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1902.04245v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2211.00147v2": {
      "title": "A Machine Learning Tutorial for Operational Meteorology, Part II: Neural Networks and Deep Learning",
      "authors": [
        "Randy J. Chase",
        "David R. Harrison",
        "Gary Lackmann",
        "Amy McGovern"
      ],
      "abstract": "Over the past decade the use of machine learning in meteorology has grown\nrapidly. Specifically neural networks and deep learning have been used at an\nunprecedented rate. In order to fill the dearth of resources covering neural\nnetworks with a meteorological lens, this paper discusses machine learning\nmethods in a plain language format that is targeted for the operational\nmeteorological community. This is the second paper in a pair that aim to serve\nas a machine learning resource for meteorologists. While the first paper\nfocused on traditional machine learning methods (e.g., random forest), here a\nbroad spectrum of neural networks and deep learning methods are discussed.\nSpecifically this paper covers perceptrons, artificial neural networks,\nconvolutional neural networks and U-networks. Like the part 1 paper, this\nmanuscript discusses the terms associated with neural networks and their\ntraining. Then the manuscript provides some intuition behind every method and\nconcludes by showing each method used in a meteorological example of diagnosing\nthunderstorms from satellite images (e.g., lightning flashes). This paper is\naccompanied with an open-source code repository to allow readers to explore\nneural networks using either the dataset provided (which is used in the paper)\nor as a template for alternate datasets.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-10-31",
      "downloaded_date": "2025-01-31",
      "filename": "Chase-A Machine Learning Tutorial for Operational Meteorology Part II Neural Networks and Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.00147v2",
      "categories": [
        "cs.LG",
        "cs.CV",
        "physics.ao-ph"
      ]
    },
    "2304.13815v2": {
      "title": "Recent advances in describing and driving crystal nucleation using machine learning and artificial intelligence",
      "authors": [
        "Eric R. Beyerle",
        "Ziyue Zou",
        "Pratyush Tiwary"
      ],
      "abstract": "With the advent of faster computer processors and especially graphics\nprocessing units (GPUs) over the last few decades, the use of data-intensive\nmachine learning (ML) and artificial intelligence (AI) has increased greatly,\nand the study of crystal nucleation has been one of the beneficiaries. In this\nreview, we outline how ML and AI have been applied to address four outstanding\ndifficulties of crystal nucleation: how to discover better reaction coordinates\n(RCs) for describing accurately non-classical nucleation situations; the\ndevelopment of more accurate force fields for describing the nucleation of\nmultiple polymorphs or phases for a single system; more robust identification\nmethods for determining crystal phases and structures; and as a method to yield\nimproved course-grained models for studying nucleation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-04-26",
      "downloaded_date": "2025-01-31",
      "filename": "Beyerle-Recent advances in describing and driving crystal nucleation using machine learning and artificial i....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.13815v2",
      "categories": [
        "cond-mat.stat-mech"
      ]
    },
    "2010.14376v1": {
      "title": "The DigitalTwin from an Artificial Intelligence Perspective",
      "authors": [
        "Oliver Niggemann",
        "Alexander Diedrich",
        "Christian Kuehnert",
        "Erik Pfannstiel",
        "Joshua Schraven"
      ],
      "abstract": "Services for Cyber-Physical Systems based on Artificial Intelligence and\nMachine Learning require a virtual representation of the physical. To reduce\nmodeling efforts and to synchronize results, for each system, a common and\nunique virtual representation used by all services during the whole system\nlife-cycle is needed, i.e. a DigitalTwin. In this paper such a DigitalTwin,\nnamely the AI reference model AITwin, is defined. This reference model is\nverified by using a running example from process industry and by analyzing the\nwork done in recent projects.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-10-27",
      "downloaded_date": "2025-01-31",
      "filename": "Niggemann-The DigitalTwin from an Artificial Intelligence Perspective.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2010.14376v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2312.11507v1": {
      "title": "Explain To Decide: A Human-Centric Review on the Role of Explainable Artificial Intelligence in AI-assisted Decision Making",
      "authors": [
        "Milad Rogha"
      ],
      "abstract": "The unprecedented performance of machine learning models in recent years,\nparticularly Deep Learning and transformer models, has resulted in their\napplication in various domains such as finance, healthcare, and education.\nHowever, the models are error-prone and cannot be used autonomously, especially\nin decision-making scenarios where, technically or ethically, the cost of error\nis high. Moreover, because of the black-box nature of these models, it is\nfrequently difficult for the end user to comprehend the models' outcomes and\nunderlying processes to trust and use the model outcome to make a decision.\nExplainable Artificial Intelligence (XAI) aids end-user understanding of the\nmodel by utilizing approaches, including visualization techniques, to explain\nand interpret the inner workings of the model and how it arrives at a result.\nAlthough numerous research studies have been conducted recently focusing on the\nperformance of models and the XAI approaches, less work has been done on the\nimpact of explanations on human-AI team performance. This paper surveyed the\nrecent empirical studies on XAI's impact on human-AI decision-making,\nidentified the challenges, and proposed future research directions.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c20f9066606dd92c00b4fce8e87a1a869c040466",
      "published_date": "2023-12-11",
      "downloaded_date": "2025-01-31",
      "filename": "Rogha-Explain To Decide A Human-Centric Review on the Role of Explainable Artificial Intelligence in AI-as....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.11507v1",
      "categories": [
        "cs.HC",
        "cs.LG"
      ]
    },
    "2002.04803v2": {
      "title": "Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence",
      "authors": [
        "Sebastian Raschka",
        "Joshua Patterson",
        "Corey Nolet"
      ],
      "abstract": "Smarter applications are making better use of the insights gleaned from data,\nhaving an impact on every industry and research discipline. At the core of this\nrevolution lies the tools and the methods that are driving it, from processing\nthe massive piles of data generated each day to learning from and taking useful\naction. Deep neural networks, along with advancements in classical ML and\nscalable general-purpose GPU computing, have become critical components of\nartificial intelligence, enabling many of these astounding breakthroughs and\nlowering the barrier to adoption. Python continues to be the most preferred\nlanguage for scientific computing, data science, and machine learning, boosting\nboth performance and productivity by enabling the use of low-level libraries\nand clean high-level APIs. This survey offers insight into the field of machine\nlearning with Python, taking a tour through important topics to identify some\nof the core hardware and software paradigms that have enabled it. We cover\nwidely-used libraries and concepts, collected together for holistic comparison,\nwith the goal of educating the reader and driving the field of Python machine\nlearning forward.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-02-12",
      "downloaded_date": "2025-01-31",
      "filename": "Raschka-Machine Learning in Python Main developments and technology trends in data science machine learning ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2002.04803v2",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2411.05861v2": {
      "title": "Rethinking Deep Learning: Non-backpropagation and Non-optimization Machine Learning Approach Using Hebbian Neural Networks",
      "authors": [
        "Kei Itoh"
      ],
      "abstract": "Developing strong AI could provide a powerful tool for addressing social and\nscientific challenges. Neural networks (NNs), inspired by biological systems,\nhave the potential to achieve this. However, weight optimization techniques\nusing error backpropagation are not observed in biological systems, raising\ndoubts about current NNs approaches. In this context, Itoh (2024) solved the\nMNIST classification problem without using objective functions or\nbackpropagation. However, weight updates were not used, so it does not qualify\nas machine learning AI. In this study, I develop a machine learning method that\nmimics biological neural systems by implementing Hebbian learning in NNs\nwithout backpropagation and optimization method to solve the MNIST\nclassification problem and analyze its output. Development proceeded in three\nstages. In the first stage, I applied the Hebbian learning rule to the MNIST\ncharacter recognition algorithm by Itoh (2024), resulting in lower accuracy\nthan non-Hebbian NNs, highlighting the limitations of conventional training\nprocedures for Hebbian learning. In the second stage, I examined the properties\nof individually trained NNs using norm-based cognition, showing that NNs\ntrained on a specific label respond powerfully to that label. In the third\nstage, I created an MNIST character recognition program using vector norm\nmagnitude as the criterion, achieving an accuracy of approximately 75%. This\ndemonstrates that the Hebbian learning NNs can recognize handwritten characters\nwithout objective functions, backpropagation, optimization processes, and large\ndata set. Based on these results, developing a mechanism based on norm-based\ncognition as a fundamental unit and then increasing complexity to achieve\nindirect similarity cognition should help mimic biological neural systems and\ncontribute to realizing strong AI.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fc88e360f8c23d7944b2c7ea38f78bf057a312a6",
      "published_date": "2024-11-07",
      "downloaded_date": "2025-01-31",
      "filename": "Itoh-Rethinking Deep Learning Non-backpropagation and Non-optimization Machine Learning Approach Using He....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.05861v2",
      "categories": [
        "cs.NE",
        "cs.LG"
      ]
    },
    "2005.06540v1": {
      "title": "Deep Learning for Political Science",
      "authors": [
        "Kakia Chatsiou",
        "Slava Jankin Mikhaylov"
      ],
      "abstract": "Political science, and social science in general, have traditionally been\nusing computational methods to study areas such as voting behavior, policy\nmaking, international conflict, and international development. More recently,\nincreasingly available quantities of data are being combined with improved\nalgorithms and affordable computational resources to predict, learn, and\ndiscover new insights from data that is large in volume and variety. New\ndevelopments in the areas of machine learning, deep learning, natural language\nprocessing (NLP), and, more generally, artificial intelligence (AI) are opening\nup new opportunities for testing theories and evaluating the impact of\ninterventions and programs in a more dynamic and effective way. Applications\nusing large volumes of structured and unstructured data are becoming common in\ngovernment and industry, and increasingly also in social science research. This\nchapter offers an introduction to such methods drawing examples from political\nscience. Focusing on the areas where the strengths of the methods coincide with\nchallenges in these fields, the chapter first presents an introduction to AI\nand its core technology - machine learning, with its rapidly developing\nsubfield of deep learning. The discussion of deep neural networks is\nillustrated with the NLP tasks that are relevant to political science. The\nlatest advances in deep learning methods for NLP are also reviewed, together\nwith their potential for improving information extraction and pattern\nrecognition from political science texts.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/acff518b945f15b1a687ac313b25048c50fed044",
      "published_date": "2020-05-13",
      "downloaded_date": "2025-01-31",
      "filename": "Chatsiou-Deep Learning for Political Science.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.06540v1",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    "2404.11597v2": {
      "title": "Explainable Artificial Intelligence Techniques for Accurate Fault Detection and Diagnosis: A Review",
      "authors": [
        "Ahmed Maged",
        "Salah Haridy",
        "Herman Shen"
      ],
      "abstract": "As the manufacturing industry advances with sensor integration and\nautomation, the opaque nature of deep learning models in machine learning poses\na significant challenge for fault detection and diagnosis. And despite the\nrelated predictive insights Artificial Intelligence (AI) can deliver, advanced\nmachine learning engines often remain a black box. This paper reviews the\neXplainable AI (XAI) tools and techniques in this context. We explore various\nXAI methodologies, focusing on their role in making AI decision-making\ntransparent, particularly in critical scenarios where humans are involved. We\nalso discuss current limitations and potential future research that aims to\nbalance explainability with model performance while improving trustworthiness\nin the context of AI applications for critical industrial use cases.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/30b4b3847070492d90e32bc0fed63a542279be9f",
      "published_date": "2024-04-17",
      "downloaded_date": "2025-01-31",
      "filename": "Maged-Explainable Artificial Intelligence Techniques for Accurate Fault Detection and Diagnosis A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.11597v2",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "1912.06796v1": {
      "title": "Artificial Intelligence Techniques for Security Vulnerability Prevention",
      "authors": [
        "Steve Kommrusch"
      ],
      "abstract": "Computer security has been a concern for decades and artificial intelligence\ntechniques have been applied to the area for nearly as long. Most of the\ntechniques are being applied to the detection of attacks to running systems,\nbut recent improvements in machine learning (for example, in natural language\nprocessing) have enabled the opportunity to process software and specifications\nto detect vulnerabilities in a system before it is deployed. This paper\npresents a survey of artificial intelligence techniques (including machine\nlearning) to detect or repair security vulnerabilities before product\nintroduction. In the surveyed papers, techniques are presented for using NLP to\nanalyze requirements documents for security standard completeness, performing\nneural fuzz testing of software, generating exploits to detect risk, and more.\nWe categorize current techniques into 3 groups: vulnerability detection,\nvulnerability repair, and specification analysis. Generally, while AI\ntechniques have become quite useful in this area, we show that AI techniques\nstill tend to be limited in scope, providing a collection of tools which can\naugment but not replace careful system development to reduce vulnerability\nrisks.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/777103e233f93f2adb19b26c4cff3a775bfaef1e",
      "published_date": "2019-12-14",
      "downloaded_date": "2025-01-31",
      "filename": "Kommrusch-Artificial Intelligence Techniques for Security Vulnerability Prevention.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1912.06796v1",
      "categories": [
        "cs.CR"
      ]
    },
    "2407.09013v1": {
      "title": "Procedural Content Generation via Generative Artificial Intelligence",
      "authors": [
        "Xinyu Mao",
        "Wanli Yu",
        "Kazunori D Yamada",
        "Michael R. Zielewski"
      ],
      "abstract": "The attempt to utilize machine learning in PCG has been made in the past. In\nthis survey paper, we investigate how generative artificial intelligence (AI),\nwhich saw a significant increase in interest in the mid-2010s, is being used\nfor PCG. We review applications of generative AI for the creation of various\ntypes of content, including terrains, items, and even storylines. While\ngenerative AI is effective for PCG, one significant issues it faces is that\nbuilding high-performance generative AI requires vast amounts of training data.\nBecause content generally highly customized, domain-specific training data is\nscarce, and straightforward approaches to generative AI models may not work\nwell. For PCG research to advance further, issues related to limited training\ndata must be overcome. Thus, we also give special consideration to research\nthat addresses the challenges posed by limited training data.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/941283fee75f4e765f4eba9134e8e359039c2b36",
      "published_date": "2024-07-12",
      "downloaded_date": "2025-01-31",
      "filename": "Mao-Procedural Content Generation via Generative Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.09013v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2201.08789v1": {
      "title": "AiTLAS: Artificial Intelligence Toolbox for Earth Observation",
      "authors": [
        "Ivica Dimitrovski",
        "Ivan Kitanovski",
        "PanÄe Panov",
        "Nikola Simidjievski",
        "Dragi Kocev"
      ],
      "abstract": "The AiTLAS toolbox (Artificial Intelligence Toolbox for Earth Observation)\nincludes state-of-the-art machine learning methods for exploratory and\npredictive analysis of satellite imagery as well as repository of AI-ready\nEarth Observation (EO) datasets. It can be easily applied for a variety of\nEarth Observation tasks, such as land use and cover classification, crop type\nprediction, localization of specific objects (semantic segmentation), etc. The\nmain goal of AiTLAS is to facilitate better usability and adoption of novel AI\nmethods (and models) by EO experts, while offering easy access and standardized\nformat of EO datasets to AI experts which further allows benchmarking of\nvarious existing and novel AI methods tailored for EO data.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9911ece7ee5d1c65c1f2e5bc61aa4452c5c500ad",
      "published_date": "2022-01-21",
      "downloaded_date": "2025-01-31",
      "filename": "Dimitrovski-AiTLAS Artificial Intelligence Toolbox for Earth Observation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2201.08789v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2409.02693v1": {
      "title": "The Role of Artificial Intelligence and Machine Learning in Software Testing",
      "authors": [
        "Ahmed Ramadan",
        "Husam Yasin",
        "Burhan Pektas"
      ],
      "abstract": "Artificial Intelligence (AI) and Machine Learning (ML) have significantly\nimpacted various industries, including software development. Software testing,\na crucial part of the software development lifecycle (SDLC), ensures the\nquality and reliability of software products. Traditionally, software testing\nhas been a labor-intensive process requiring significant manual effort.\nHowever, the advent of AI and ML has transformed this landscape by introducing\nautomation and intelligent decision-making capabilities. AI and ML technologies\nenhance the efficiency and effectiveness of software testing by automating\ncomplex tasks such as test case generation, test execution, and result\nanalysis. These technologies reduce the time required for testing and improve\nthe accuracy of defect detection, ultimately leading to higher quality\nsoftware. AI can predict potential areas of failure by analyzing historical\ndata and identifying patterns, which allows for more targeted and efficient\ntesting. This paper explores the role of AI and ML in software testing by\nreviewing existing literature, analyzing current tools and techniques, and\npresenting case studies that demonstrate the practical benefits of these\ntechnologies. The literature review provides a comprehensive overview of the\nadvancements in AI and ML applications in software testing, highlighting key\nmethodologies and findings from various studies. The analysis of current tools\nshowcases the capabilities of popular AI-driven testing tools such as Eggplant\nAI, Test.ai, Selenium, Appvance, Applitools Eyes, Katalon Studio, and Tricentis\nTosca, each offering unique features and advantages. Case studies included in\nthis paper illustrate real-world applications of AI and ML in software testing,\nshowing significant improvements in testing efficiency, accuracy, and overall\nsoftware quality.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/de44518a86df9297529dcb6860a6560df263bbff",
      "published_date": "2024-09-04",
      "downloaded_date": "2025-01-31",
      "filename": "Ramadan-The Role of Artificial Intelligence and Machine Learning in Software Testing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.02693v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    "2405.10883v2": {
      "title": "Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: A Systematic Scoping Review",
      "authors": [
        "Hongyi Yang",
        "Fangyuan Chang",
        "Dian Zhu",
        "Muroi Fumie",
        "Zhao Liu"
      ],
      "abstract": "This systematic review assessed the current state and future prospects of\nartificial intelligence (AI) in schizophrenia rehabilitation management. We\nreviewed 61 studies on AI-related data types, feature engineering methods,\nalgorithmic models, and evaluation metrics published from 2012-2024. The review\ncategorizes AI applications into the following key application areas: symptom\nmonitoring, medication management, risk management, functional training, and\npsychosocial support. Findings indicate that supervised machine learning\ntechniques, particularly for symptom monitoring and relapse risk management,\nremain the predominant approaches, effectively leveraging structured data while\nincorporating interpretable algorithms. This study underscores the potential of\nAI in transforming long-term management strategies for schizophrenia, offering\nvaluable insights into improving the quality of life of patients. Future\nresearch should focus on expanding data sources through multimodal data\nintegration, exploring deep learning models, and integrating AI-driven\ninterventions into training tasks to fully capitalize on AI's potential in\nschizophrenia rehabilitation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-05-17",
      "downloaded_date": "2025-01-31",
      "filename": "Yang-Application of Artificial Intelligence in Schizophrenia Rehabilitation Management A Systematic Scopi....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.10883v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2008.12629v1": {
      "title": "Optical oxygen sensing with artificial intelligence",
      "authors": [
        "Umberto Michelucci",
        "Michael Baumgartner",
        "Francesca Venturini"
      ],
      "abstract": "Luminescence-based sensors for measuring oxygen concentration are widely used\nboth in industry and research due to the practical advantages and sensitivity\nof this type of sensing. The measuring principle is the luminescence quenching\nby oxygen molecules, which results in a change of the luminescence decay time\nand intensity. In the classical approach, this change is related to an oxygen\nconcentration using the Stern-Volmer equation. This equation, which in most of\nthe cases is non-linear, is parametrized through device-specific constants.\nTherefore, to determine these parameters every sensor needs to be precisely\ncalibrated at one or more known concentrations. This work explores an entirely\nnew artificial intelligence approach and demonstrates the feasibility of oxygen\nsensing through machine learning. The specifically developed neural network\nlearns very efficiently to relate the input quantities to the oxygen\nconcentration. The results show a mean deviation of the predicted from the\nmeasured concentration of 0.5 percent air, comparable to many commercial and\nlow-cost sensors. Since the network was trained using synthetically generated\ndata, the accuracy of the model predictions is limited by the ability of the\ngenerated data to describe the measured data, opening up future possibilities\nfor significant improvement by using a large number of experimental\nmeasurements for training. The approach described in this work demonstrates the\napplicability of artificial intelligence to sensing of sensors.",
      "citation_count": 20,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/80785870fbf1388464f121101658fee2a69e0f78",
      "published_date": "2020-07-27",
      "downloaded_date": "2025-01-31",
      "filename": "Michelucci-Optical oxygen sensing with artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.12629v1",
      "categories": [
        "eess.SP",
        "cs.LG"
      ]
    },
    "2402.04557v1": {
      "title": "An Artificial Intelligence (AI) workflow for catalyst design and optimization",
      "authors": [
        "Nung Siong Lai",
        "Yi Shen Tew",
        "Xialin Zhong",
        "Jun Yin",
        "Jiali Li",
        "Binhang Yan",
        "Xiaonan Wang"
      ],
      "abstract": "In the pursuit of novel catalyst development to address pressing\nenvironmental concerns and energy demand, conventional design and optimization\nmethods often fall short due to the complexity and vastness of the catalyst\nparameter space. The advent of Machine Learning (ML) has ushered in a new era\nin the field of catalyst optimization, offering potential solutions to the\nshortcomings of traditional techniques. However, existing methods fail to\neffectively harness the wealth of information contained within the burgeoning\nbody of scientific literature on catalyst synthesis. To address this gap, this\nstudy proposes an innovative Artificial Intelligence (AI) workflow that\nintegrates Large Language Models (LLMs), Bayesian optimization, and an active\nlearning loop to expedite and enhance catalyst optimization. Our methodology\ncombines advanced language understanding with robust optimization strategies,\neffectively translating knowledge extracted from diverse literature into\nactionable parameters for practical experimentation and optimization. In this\narticle, we demonstrate the application of this AI workflow in the optimization\nof catalyst synthesis for ammonia production. The results underscore the\nworkflow's ability to streamline the catalyst development process, offering a\nswift, resource-efficient, and high-precision alternative to conventional\nmethods.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d6ad64455802d2088ddbae50f48ded06021e3c28",
      "published_date": "2024-02-07",
      "downloaded_date": "2025-01-31",
      "filename": "Lai-An Artificial Intelligence AI workflow for catalyst design and optimization.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.04557v1",
      "categories": [
        "physics.chem-ph",
        "cs.LG"
      ]
    },
    "1902.04704v2": {
      "title": "Neural network models and deep learning - a primer for biologists",
      "authors": [
        "Nikolaus Kriegeskorte",
        "Tal Golan"
      ],
      "abstract": "Originally inspired by neurobiology, deep neural network models have become a\npowerful tool of machine learning and artificial intelligence, where they are\nused to approximate functions and dynamics by learning from examples. Here we\ngive a brief introduction to neural network models and deep learning for\nbiologists. We introduce feedforward and recurrent networks and explain the\nexpressive power of this modeling framework and the backpropagation algorithm\nfor setting the parameters. Finally, we consider how deep neural networks might\nhelp us understand the brain's computations.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-02-13",
      "downloaded_date": "2025-01-31",
      "filename": "Kriegeskorte-Neural network models and deep learning - a primer for biologists.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1902.04704v2",
      "categories": [
        "q-bio.NC",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2501.17894v1": {
      "title": "Progress in Artificial Intelligence and its Determinants",
      "authors": [
        "Michael R. Douglas",
        "Sergiy Verstyuk"
      ],
      "abstract": "We study long-run progress in artificial intelligence in a quantitative way.\nMany measures, including traditional ones such as patents and publications,\nmachine learning benchmarks, and a new Aggregate State of the Art in ML (or\nASOTA) Index we have constructed from these, show exponential growth at roughly\nconstant rates over long periods. Production of patents and publications\ndoubles every ten years, by contrast with the growth of computing resources\ndriven by Moore's Law, roughly a doubling every two years. We argue that the\ninput of AI researchers is also crucial and its contribution can be objectively\nestimated. Consequently, we give a simple argument that explains the 5:1\nrelation between these two rates. We then discuss the application of this\nargument to different output measures and compare our analyses with predictions\nbased on machine learning scaling laws proposed in existing literature. Our\nquantitative framework facilitates understanding, predicting, and modulating\nthe development of these important technologies.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2025-01-29",
      "downloaded_date": "2025-01-31",
      "filename": "Douglas-Progress in Artificial Intelligence and its Determinants.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.17894v1",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "physics.soc-ph",
        "q-fin.EC"
      ]
    },
    "1710.10967v3": {
      "title": "Artificial Intelligence as Structural Estimation: Economic Interpretations of Deep Blue, Bonanza, and AlphaGo",
      "authors": [
        "Mitsuru Igami"
      ],
      "abstract": "Artificial intelligence (AI) has achieved superhuman performance in a growing\nnumber of tasks, but understanding and explaining AI remain challenging. This\npaper clarifies the connections between machine-learning algorithms to develop\nAIs and the econometrics of dynamic structural models through the case studies\nof three famous game AIs. Chess-playing Deep Blue is a calibrated value\nfunction, whereas shogi-playing Bonanza is an estimated value function via\nRust's (1987) nested fixed-point method. AlphaGo's \"supervised-learning policy\nnetwork\" is a deep neural network implementation of Hotz and Miller's (1993)\nconditional choice probability estimation; its \"reinforcement-learning value\nnetwork\" is equivalent to Hotz, Miller, Sanders, and Smith's (1994) conditional\nchoice simulation method. Relaxing these AIs' implicit econometric assumptions\nwould improve their structural interpretability.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-10-30",
      "downloaded_date": "2025-01-31",
      "filename": "Igami-Artificial Intelligence as Structural Estimation Economic Interpretations of Deep Blue Bonanza and A....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1710.10967v3",
      "categories": [
        "econ.EM",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2101.03613v1": {
      "title": "Explainable Artificial Intelligence (XAI): An Engineering Perspective",
      "authors": [
        "F. Hussain",
        "R. Hussain",
        "E. Hossain"
      ],
      "abstract": "The remarkable advancements in Deep Learning (DL) algorithms have fueled\nenthusiasm for using Artificial Intelligence (AI) technologies in almost every\ndomain; however, the opaqueness of these algorithms put a question mark on\ntheir applications in safety-critical systems. In this regard, the\n`explainability' dimension is not only essential to both explain the inner\nworkings of black-box algorithms, but it also adds accountability and\ntransparency dimensions that are of prime importance for regulators, consumers,\nand service providers. eXplainable Artificial Intelligence (XAI) is the set of\ntechniques and methods to convert the so-called black-box AI algorithms to\nwhite-box algorithms, where the results achieved by these algorithms and the\nvariables, parameters, and steps taken by the algorithm to reach the obtained\nresults, are transparent and explainable. To complement the existing literature\non XAI, in this paper, we take an `engineering' approach to illustrate the\nconcepts of XAI. We discuss the stakeholders in XAI and describe the\nmathematical contours of XAI from engineering perspective. Then we take the\nautonomous car as a use-case and discuss the applications of XAI for its\ndifferent components such as object detection, perception, control, action\ndecision, and so on. This work is an exploratory study to identify new avenues\nof research in the field of XAI.",
      "citation_count": 24,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1f0d09386ee7685c4a8953aed81adbd4055763c1",
      "published_date": "2021-01-10",
      "downloaded_date": "2025-01-31",
      "filename": "Hussain-Explainable Artificial Intelligence XAI An Engineering Perspective.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.03613v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2008.07341v1": {
      "title": "Data, Power and Bias in Artificial Intelligence",
      "authors": [
        "Susan Leavy",
        "Barry O'Sullivan",
        "Eugenia Siapera"
      ],
      "abstract": "Artificial Intelligence has the potential to exacerbate societal bias and set\nback decades of advances in equal rights and civil liberty. Data used to train\nmachine learning algorithms may capture social injustices, inequality or\ndiscriminatory attitudes that may be learned and perpetuated in society.\nAttempts to address this issue are rapidly emerging from different perspectives\ninvolving technical solutions, social justice and data governance measures.\nWhile each of these approaches are essential to the development of a\ncomprehensive solution, often discourse associated with each seems disparate.\nThis paper reviews ongoing work to ensure data justice, fairness and bias\nmitigation in AI systems from different domains exploring the interrelated\ndynamics of each and examining whether the inevitability of bias in AI training\ndata may in fact be used for social good. We highlight the complexity\nassociated with defining policies for dealing with bias. We also consider\ntechnical challenges in addressing issues of societal bias.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-07-28",
      "downloaded_date": "2025-01-31",
      "filename": "Leavy-Data Power and Bias in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.07341v1",
      "categories": [
        "cs.CY"
      ]
    },
    "1809.05889v1": {
      "title": "Comparison of Deep Learning and the Classical Machine Learning Algorithm for the Malware Detection",
      "authors": [
        "Mohit Sewak",
        "Sanjay K. Sahay",
        "Hemant Rathore"
      ],
      "abstract": "Recently, Deep Learning has been showing promising results in various\nArtificial Intelligence applications like image recognition, natural language\nprocessing, language modeling, neural machine translation, etc. Although, in\ngeneral, it is computationally more expensive as compared to classical machine\nlearning techniques, their results are found to be more effective in some\ncases. Therefore, in this paper, we investigated and compared one of the Deep\nLearning Architecture called Deep Neural Network (DNN) with the classical\nRandom Forest (RF) machine learning algorithm for the malware classification.\nWe studied the performance of the classical RF and DNN with 2, 4 & 7 layers\narchitectures with the four different feature sets, and found that irrespective\nof the features inputs, the classical RF accuracy outperforms the DNN.",
      "citation_count": 66,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0a78afe0ed6967ac8bb69191c35b06c1f4220523",
      "published_date": "2018-09-16",
      "downloaded_date": "2025-01-31",
      "filename": "Sewak-Comparison of Deep Learning and the Classical Machine Learning Algorithm for the Malware Detection.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1809.05889v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2011.03751v1": {
      "title": "Software engineering for artificial intelligence and machine learning software: A systematic literature review",
      "authors": [
        "Elizamary Nascimento",
        "Anh Nguyen-Duc",
        "Ingrid SundbÃ¸",
        "Tayana Conte"
      ],
      "abstract": "Artificial Intelligence (AI) or Machine Learning (ML) systems have been\nwidely adopted as value propositions by companies in all industries in order to\ncreate or extend the services and products they offer. However, developing\nAI/ML systems has presented several engineering problems that are different\nfrom those that arise in, non-AI/ML software development. This study aims to\ninvestigate how software engineering (SE) has been applied in the development\nof AI/ML systems and identify challenges and practices that are applicable and\ndetermine whether they meet the needs of professionals. Also, we assessed\nwhether these SE practices apply to different contexts, and in which areas they\nmay be applicable. We conducted a systematic review of literature from 1990 to\n2019 to (i) understand and summarize the current state of the art in this field\nand (ii) analyze its limitations and open challenges that will drive future\nresearch. Our results show these systems are developed on a lab context or a\nlarge company and followed a research-driven development process. The main\nchallenges faced by professionals are in areas of testing, AI software quality,\nand data management. The contribution types of most of the proposed SE\npractices are guidelines, lessons learned, and tools.",
      "citation_count": 37,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/11d11794b4b48e8842602dbb2737aa68f2ddf6cf",
      "published_date": "2020-11-07",
      "downloaded_date": "2025-01-31",
      "filename": "Nascimento-Software engineering for artificial intelligence and machine learning software A systematic literatu....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2011.03751v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    "2007.04490v1": {
      "title": "Artificial Intelligence and Machine Learning in 5G Network Security: Opportunities, advantages, and future research trends",
      "authors": [
        "Noman Haider",
        "Muhammad Zeeshan Baig",
        "Muhammad Imran"
      ],
      "abstract": "Recent technological and architectural advancements in 5G networks have\nproven their worth as the deployment has started over the world. Key\nperformance elevating factor from access to core network are softwareization,\ncloudification and virtualization of key enabling network functions. Along with\nthe rapid evolution comes the risks, threats and vulnerabilities in the system\nfor those who plan to exploit it. Therefore, ensuring fool proof end-to-end\n(E2E) security becomes a vital concern. Artificial intelligence (AI) and\nmachine learning (ML) can play vital role in design, modelling and automation\nof efficient security protocols against diverse and wide range of threats. AI\nand ML has already proven their effectiveness in different fields for\nclassification, identification and automation with higher accuracy. As 5G\nnetworks' primary selling point has been higher data rates and speed, it will\nbe difficult to tackle wide range of threats from different points using\ntypical/traditional protective measures. Therefore, AI and ML can play central\nrole in protecting highly data-driven softwareized and virtualized network\ncomponents. This article presents AI and ML driven applications for 5G network\nsecurity, their implications and possible research directions. Also, an\noverview of key data collection points in 5G architecture for threat\nclassification and anomaly detection are discussed.",
      "citation_count": 31,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/00cb7feb3fed6d9116f9f4b26af8ce66968bc27d",
      "published_date": "2020-07-09",
      "downloaded_date": "2025-01-31",
      "filename": "Haider-Artificial Intelligence and Machine Learning in 5G Network Security Opportunities advantages and fut....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.04490v1",
      "categories": [
        "cs.CR",
        "cs.LG"
      ]
    },
    "2105.02117v1": {
      "title": "Ethics and Governance of Artificial Intelligence: Evidence from a Survey of Machine Learning Researchers",
      "authors": [
        "Baobao Zhang",
        "Markus Anderljung",
        "Lauren Kahn",
        "Noemi Dreksler",
        "Michael C. Horowitz",
        "Allan Dafoe"
      ],
      "abstract": "Machine learning (ML) and artificial intelligence (AI) researchers play an\nimportant role in the ethics and governance of AI, including taking action\nagainst what they perceive to be unethical uses of AI (Belfield, 2020; Van\nNoorden, 2020). Nevertheless, this influential group's attitudes are not well\nunderstood, which undermines our ability to discern consensuses or\ndisagreements between AI/ML researchers. To examine these researchers' views,\nwe conducted a survey of those who published in the top AI/ML conferences (N =\n524). We compare these results with those from a 2016 survey of AI/ML\nresearchers (Grace, Salvatier, Dafoe, Zhang, & Evans, 2018) and a 2018 survey\nof the US public (Zhang & Dafoe, 2020). We find that AI/ML researchers place\nhigh levels of trust in international organizations and scientific\norganizations to shape the development and use of AI in the public interest;\nmoderate trust in most Western tech companies; and low trust in national\nmilitaries, Chinese tech companies, and Facebook. While the respondents were\noverwhelmingly opposed to AI/ML researchers working on lethal autonomous\nweapons, they are less opposed to researchers working on other military\napplications of AI, particularly logistics algorithms. A strong majority of\nrespondents think that AI safety research should be prioritized and that ML\ninstitutions should conduct pre-publication review to assess potential harms.\nBeing closer to the technology itself, AI/ML re-searchers are well placed to\nhighlight new risks and develop technical solutions, so this novel attempt to\nmeasure their attitudes has broad relevance. The findings should help to\nimprove how researchers, private sector executives, and policymakers think\nabout regulations, governance frameworks, guiding principles, and national and\ninternational governance strategies for AI.",
      "citation_count": 50,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cd2b2bbb13f37b2bff8826a5a7614b1f897e2db2",
      "published_date": "2021-05-05",
      "downloaded_date": "2025-01-31",
      "filename": "Zhang-Ethics and Governance of Artificial Intelligence Evidence from a Survey of Machine Learning Research....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.02117v1",
      "categories": [
        "cs.CY",
        "K.7.4"
      ]
    },
    "1803.11261v1": {
      "title": "How an Electrical Engineer Became an Artificial Intelligence Researcher, a Multiphase Active Contours Analysis",
      "authors": [
        "Kush R. Varshney"
      ],
      "abstract": "This essay examines how what is considered to be artificial intelligence (AI)\nhas changed over time and come to intersect with the expertise of the author.\nInitially, AI developed on a separate trajectory, both topically and\ninstitutionally, from pattern recognition, neural information processing,\ndecision and control systems, and allied topics by focusing on symbolic systems\nwithin computer science departments rather than on continuous systems in\nelectrical engineering departments. The separate evolutions continued\nthroughout the author's lifetime, with some crossover in reinforcement learning\nand graphical models, but were shocked into converging by the virality of deep\nlearning, thus making an electrical engineer into an AI researcher. Now that\nthis convergence has happened, opportunity exists to pursue an agenda that\ncombines learning and reasoning bridged by interpretable machine learning\nmodels.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cfd15f34dbecbd17bfb62adfaeeba4eab0c692ae",
      "published_date": "2018-03-29",
      "downloaded_date": "2025-01-31",
      "filename": "Varshney-How an Electrical Engineer Became an Artificial Intelligence Researcher a Multiphase Active Contours....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1803.11261v1",
      "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ]
    },
    "1905.04224v1": {
      "title": "Supervised machine learning based multi-task artificial intelligence classification of retinopathies",
      "authors": [
        "Minhaj Alam",
        "David Le",
        "Jennifer I. Lim",
        "R. V. P. Chan",
        "Xincheng Yao"
      ],
      "abstract": "Artificial intelligence (AI) classification holds promise as a novel and\naffordable screening tool for clinical management of ocular diseases. Rural and\nunderserved areas, which suffer from lack of access to experienced\nophthalmologists may particularly benefit from this technology. Quantitative\noptical coherence tomography angiography (OCTA) imaging provides excellent\ncapability to identify subtle vascular distortions, which are useful for\nclassifying retinovascular diseases. However, application of AI for\ndifferentiation and classification of multiple eye diseases is not yet\nestablished. In this study, we demonstrate supervised machine learning based\nmulti-task OCTA classification. We sought 1) to differentiate normal from\ndiseased ocular conditions, 2) to differentiate different ocular disease\nconditions from each other, and 3) to stage the severity of each ocular\ncondition. Quantitative OCTA features, including blood vessel tortuosity (BVT),\nblood vascular caliber (BVC), vessel perimeter index (VPI), blood vessel\ndensity (BVD), foveal avascular zone (FAZ) area (FAZ-A), and FAZ contour\nirregularity (FAZ-CI) were fully automatically extracted from the OCTA images.\nA stepwise backward elimination approach was employed to identify sensitive\nOCTA features and optimal-feature-combinations for the multi-task\nclassification. For proof-of-concept demonstration, diabetic retinopathy (DR)\nand sickle cell retinopathy (SCR) were used to validate the supervised machine\nleaning classifier. The presented AI classification methodology is applicable\nand can be readily extended to other ocular diseases, holding promise to enable\na mass-screening platform for clinical deployment and telemedicine.",
      "citation_count": 62,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a4dd064cf7418b8a12c49243e4d3182a3eddedb1",
      "published_date": "2019-05-10",
      "downloaded_date": "2025-01-31",
      "filename": "Alam-Supervised machine learning based multi-task artificial intelligence classification of retinopathies.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1905.04224v1",
      "categories": [
        "q-bio.QM",
        "eess.IV",
        "q-bio.TO"
      ]
    },
    "2205.01042v1": {
      "title": "Machine Learning and Artificial Intelligence in Circular Economy: A Bibliometric Analysis and Systematic Literature Review",
      "authors": [
        "Abdulla All noman",
        "Umma Habiba Akter",
        "Tahmid Hasan Pranto",
        "AKM Bahalul Haque"
      ],
      "abstract": "With unorganized, unplanned and improper use of limited raw materials, an\nabundant amount of waste is being produced, which is harmful to our environment\nand ecosystem. While traditional linear production lines fail to address\nfar-reaching issues like waste production and a shorter product life cycle, a\nprospective concept, namely circular economy (CE), has shown promising\nprospects to be adopted at industrial and governmental levels. CE aims to\ncomplete the product life cycle loop by bringing out the highest values from\nraw materials in the design phase and later on by reusing, recycling, and\nremanufacturing. Innovative technologies like artificial intelligence (AI) and\nmachine learning(ML) provide vital assistance in effectively adopting and\nimplementing CE in real-world practices. This study explores the adoption and\nintegration of applied AI techniques in CE. First, we conducted bibliometric\nanalysis on a collection of 104 SCOPUS indexed documents exploring the critical\nresearch criteria in AI and CE. Forty papers were picked to conduct a\nsystematic literature review from these documents. The selected documents were\nfurther divided into six categories: sustainable development, reverse\nlogistics, waste management, supply chain management, recycle & reuse, and\nmanufacturing development. Comprehensive research insights and trends have been\nextracted and delineated. Finally, the research gap needing further attention\nhas been identified and the future research directions have also been\ndiscussed.",
      "citation_count": 33,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4bbfad3cf017a8b8979432c41bce806ce1082fed",
      "published_date": "2022-04-01",
      "downloaded_date": "2025-01-31",
      "filename": "noman-Machine Learning and Artificial Intelligence in Circular Economy A Bibliometric Analysis and Systema....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.01042v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2106.02498v1": {
      "title": "Towards Fairness Certification in Artificial Intelligence",
      "authors": [
        "Tatiana Tommasi",
        "Silvia Bucci",
        "Barbara Caputo",
        "Pietro Asinari"
      ],
      "abstract": "Thanks to the great progress of machine learning in the last years, several\nArtificial Intelligence (AI) techniques have been increasingly moving from the\ncontrolled research laboratory settings to our everyday life. AI is clearly\nsupportive in many decision-making scenarios, but when it comes to sensitive\nareas such as health care, hiring policies, education, banking or justice, with\nmajor impact on individuals and society, it becomes crucial to establish\nguidelines on how to design, develop, deploy and monitor this technology.\nIndeed the decision rules elaborated by machine learning models are data-driven\nand there are multiple ways in which discriminatory biases can seep into data.\nAlgorithms trained on those data incur the risk of amplifying prejudices and\nsocietal stereotypes by over associating protected attributes such as gender,\nethnicity or disabilities with the prediction task. Starting from the extensive\nexperience of the National Metrology Institute on measurement standards and\ncertification roadmaps, and of Politecnico di Torino on machine learning as\nwell as methods for domain bias evaluation and mastering, we propose a first\njoint effort to define the operational steps needed for AI fairness\ncertification. Specifically we will overview the criteria that should be met by\nan AI system before coming into official service and the conformity assessment\nprocedures useful to monitor its functioning for fair decisions.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/157246efaa0a667383cd78da0599231687368e0e",
      "published_date": "2021-06-04",
      "downloaded_date": "2025-01-31",
      "filename": "Tommasi-Towards Fairness Certification in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2106.02498v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1810.05593v2": {
      "title": "Fast Construction of Correcting Ensembles for Legacy Artificial Intelligence Systems: Algorithms and a Case Study",
      "authors": [
        "Ivan Y. Tyukin",
        "Alexander N. Gorban",
        "Stephen Green",
        "Danil Prokhorov"
      ],
      "abstract": "This paper presents a technology for simple and computationally efficient\nimprovements of a generic Artificial Intelligence (AI) system, including\nMultilayer and Deep Learning neural networks. The improvements are, in essence,\nsmall network ensembles constructed on top of the existing AI architectures.\nTheoretical foundations of the technology are based on Stochastic Separation\nTheorems and the ideas of the concentration of measure. We show that, subject\nto mild technical assumptions on statistical properties of internal signals in\nthe original AI system, the technology enables instantaneous and\ncomputationally efficient removal of spurious and systematic errors with\nprobability close to one on the datasets which are exponentially large in\ndimension. The method is illustrated with numerical examples and a case study\nof ten digits recognition from American Sign Language.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/50110fdefe8b38c99258c671c373345cce195673",
      "published_date": "2018-10-12",
      "downloaded_date": "2025-01-31",
      "filename": "Tyukin-Fast Construction of Correcting Ensembles for Legacy Artificial Intelligence Systems Algorithms and ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1810.05593v2",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2406.00532v1": {
      "title": "Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques",
      "authors": [
        "Samita Bai",
        "Sidra Nasir",
        "Rizwan Ahmed Khan",
        "Sheeraz Arif",
        "Alexandre Meyer",
        "Hubert Konik"
      ],
      "abstract": "Breast cancer (BC) stands as one of the most common malignancies affecting\nwomen worldwide, necessitating advancements in diagnostic methodologies for\nbetter clinical outcomes. This article provides a comprehensive exploration of\nthe application of Explainable Artificial Intelligence (XAI) techniques in the\ndetection and diagnosis of breast cancer. As Artificial Intelligence (AI)\ntechnologies continue to permeate the healthcare sector, particularly in\noncology, the need for transparent and interpretable models becomes imperative\nto enhance clinical decision-making and patient care. This review discusses the\nintegration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and\nothers, with machine learning and deep learning models utilized in breast\ncancer detection and classification. By investigating the modalities of breast\ncancer datasets, including mammograms, ultrasounds and their processing with\nAI, the paper highlights how XAI can lead to more accurate diagnoses and\npersonalized treatment plans. It also examines the challenges in implementing\nthese techniques and the importance of developing standardized metrics for\nevaluating XAI's effectiveness in clinical settings. Through detailed analysis\nand discussion, this article aims to highlight the potential of XAI in bridging\nthe gap between complex AI models and practical healthcare applications,\nthereby fostering trust and understanding among medical professionals and\nimproving patient outcomes.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1943a5ed302536d88b93c8a7a593bd60775bb6bf",
      "published_date": "2024-06-01",
      "downloaded_date": "2025-01-31",
      "filename": "Bai-Breast Cancer Diagnosis A Comprehensive Exploration of Explainable Artificial Intelligence XAI Techn....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.00532v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "1901.04595v1": {
      "title": "Artificial Intelligence Assists Discovery of Reaction Coordinates and Mechanisms from Molecular Dynamics Simulations",
      "authors": [
        "Hendrik Jung",
        "Roberto Covino",
        "Gerhard Hummer"
      ],
      "abstract": "Exascale computing holds great opportunities for molecular dynamics (MD)\nsimulations. However, to take full advantage of the new possibilities, we must\nlearn how to focus computational power on the discovery of complex molecular\nmechanisms, and how to extract them from enormous amounts of data. Both aspects\nstill rely heavily on human experts, which becomes a serious bottleneck when a\nlarge number of parallel simulations have to be orchestrated to take full\nadvantage of the available computing power. Here, we use artificial\nintelligence (AI) both to guide the sampling and to extract the relevant\nmechanistic information. We combine advanced sampling schemes with statistical\ninference, artificial neural networks, and deep learning to discover molecular\nmechanisms from MD simulations. Our framework adaptively and autonomously\ninitializes simulations and learns the sampled mechanism, and is thus suitable\nfor massively parallel computing architectures. We propose practical solutions\nto make the neural networks interpretable, as illustrated in applications to\nmolecular systems.",
      "citation_count": 41,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/23318a709145ebf46b23c348293580fadd339f75",
      "published_date": "2019-01-14",
      "downloaded_date": "2025-01-31",
      "filename": "Jung-Artificial Intelligence Assists Discovery of Reaction Coordinates and Mechanisms from Molecular Dyna....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.04595v1",
      "categories": [
        "physics.chem-ph",
        "cond-mat.stat-mech",
        "physics.comp-ph"
      ]
    },
    "2102.06125v2": {
      "title": "Artificial Intelligence Advances for De Novo Molecular Structure Modeling in Cryo-EM",
      "authors": [
        "Dong Si",
        "Andrew Nakamura",
        "Runbang Tang",
        "Haowen Guan",
        "Jie Hou",
        "Ammaar Firozi",
        "Renzhi Cao",
        "Kyle Hippe",
        "Minglei Zhao"
      ],
      "abstract": "Cryo-electron microscopy (cryo-EM) has become a major experimental technique\nto determine the structures of large protein complexes and molecular\nassemblies, as evidenced by the 2017 Nobel Prize. Although cryo-EM has been\ndrastically improved to generate high-resolution three-dimensional (3D) maps\nthat contain detailed structural information about macromolecules, the\ncomputational methods for using the data to automatically build structure\nmodels are lagging far behind. The traditional cryo-EM model building approach\nis template-based homology modeling. Manual de novo modeling is very\ntime-consuming when no template model is found in the database. In recent\nyears, de novo cryo-EM modeling using machine learning (ML) and deep learning\n(DL) has ranked among the top-performing methods in macromolecular structure\nmodeling. Deep-learning-based de novo cryo-EM modeling is an important\napplication of artificial intelligence, with impressive results and great\npotential for the next generation of molecular biomedicine. Accordingly, we\nsystematically review the representative ML/DL-based de novo cryo-EM modeling\nmethods. And their significances are discussed from both practical and\nmethodological viewpoints. We also briefly describe the background of cryo-EM\ndata processing workflow. Overall, this review provides an introductory guide\nto modern research on artificial intelligence (AI) for de novo molecular\nstructure modeling and future directions in this emerging field.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/40f7050a39bed4512f76e8c3453515d521cba1e9",
      "published_date": "2021-02-11",
      "downloaded_date": "2025-01-31",
      "filename": "Si-Artificial Intelligence Advances for De Novo Molecular Structure Modeling in Cryo-EM.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.06125v2",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "physics.bio-ph",
        "physics.comp-ph"
      ]
    },
    "2401.03093v4": {
      "title": "XXAI: Towards eXplicitly eXplainable Artificial Intelligence",
      "authors": [
        "V. L. Kalmykov",
        "L. V. Kalmykov"
      ],
      "abstract": "There are concerns about the reliability and safety of artificial\nintelligence (AI) based on sub-symbolic neural networks because its decisions\ncannot be explained explicitly. This is the black box problem of modern AI. At\nthe same time, symbolic AI has the nature of a white box and is able to ensure\nthe reliability and safety of its decisions. However, several problems prevent\nthe widespread use of symbolic AI: the opacity of mathematical models and\nnatural language terms, the lack of a unified ontology, and the combinatorial\nexplosion of search capabilities. To solve the black-box problem of AI, we\npropose eXplicitly eXplainable AI (XXAI) - a fully transparent white-box AI\nbased on deterministic logical cellular automata whose rules are derived from\nthe first principles of the general theory of the relevant domain. In this\ncase, the general theory of the domain plays the role of a knowledge base for\nderiving the inferences of the cellular automata. A cellular automaton\nimplements parallel multi-level logical inference at all levels of organization\n- from local interactions of the element base to the system as a whole. Our\nverification of several ecological hypotheses sets a precedent for the\nsuccessful implementation of the proposed solution. XXAI is able to\nautomatically verify the reliability, security and ethics of sub-symbolic\nneural network solutions in both the final and training phases. In this\narticle, we present precedents for the successful implementation of XXAI, the\ntheoretical and methodological foundations for its further development, and\ndiscuss prospects for the future.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b59069068c1e77e8c3d9e535c4780796279c5433",
      "published_date": "2024-01-05",
      "downloaded_date": "2025-01-31",
      "filename": "Kalmykov-XXAI Towards eXplicitly eXplainable Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.03093v4",
      "categories": [
        "cs.AI",
        "q-bio.PE"
      ]
    },
    "2403.06910v1": {
      "title": "Responsible Artificial Intelligence: A Structured Literature Review",
      "authors": [
        "Sabrina Goellner",
        "Marina Tropmann-Frick",
        "Bostjan Brumen"
      ],
      "abstract": "Our research endeavors to advance the concept of responsible artificial\nintelligence (AI), a topic of increasing importance within EU policy\ndiscussions. The EU has recently issued several publications emphasizing the\nnecessity of trust in AI, underscoring the dual nature of AI as both a\nbeneficial tool and a potential weapon. This dichotomy highlights the urgent\nneed for international regulation. Concurrently, there is a need for frameworks\nthat guide companies in AI development, ensuring compliance with such\nregulations. Our research aims to assist lawmakers and machine learning\npractitioners in navigating the evolving landscape of AI regulation,\nidentifying focal areas for future attention. This paper introduces a\ncomprehensive and, to our knowledge, the first unified definition of\nresponsible AI. Through a structured literature review, we elucidate the\ncurrent understanding of responsible AI. Drawing from this analysis, we propose\nan approach for developing a future framework centered around this concept. Our\nfindings advocate for a human-centric approach to Responsible AI. This approach\nencompasses the implementation of AI methods with a strong emphasis on ethics,\nmodel explainability, and the pillars of privacy, security, and trust.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9110ca60bd6f8cc44741c82d628990e7c6f9438f",
      "published_date": "2024-03-11",
      "downloaded_date": "2025-01-31",
      "filename": "Goellner-Responsible Artificial Intelligence A Structured Literature Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.06910v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    "2109.01658v1": {
      "title": "Artificial Intelligence in Dry Eye Disease",
      "authors": [
        "Andrea M. StorÃ¥s",
        "Inga StrÃ¼mke",
        "Michael A. Riegler",
        "Jakob Grauslund",
        "Hugo L. Hammer",
        "Anis Yazidi",
        "PÃ¥l Halvorsen",
        "Kjell G. Gundersen",
        "Tor P. Utheim",
        "Catherine Jackson"
      ],
      "abstract": "Dry eye disease (DED) has a prevalence of between 5 and 50\\%, depending on\nthe diagnostic criteria used and population under study. However, it remains\none of the most underdiagnosed and undertreated conditions in ophthalmology.\nMany tests used in the diagnosis of DED rely on an experienced observer for\nimage interpretation, which may be considered subjective and result in\nvariation in diagnosis. Since artificial intelligence (AI) systems are capable\nof advanced problem solving, use of such techniques could lead to more\nobjective diagnosis. Although the term `AI' is commonly used, recent success in\nits applications to medicine is mainly due to advancements in the sub-field of\nmachine learning, which has been used to automatically classify images and\npredict medical outcomes. Powerful machine learning techniques have been\nharnessed to understand nuances in patient data and medical images, aiming for\nconsistent diagnosis and stratification of disease severity. This is the first\nliterature review on the use of AI in DED. We provide a brief introduction to\nAI, report its current use in DED research and its potential for application in\nthe clinic. Our review found that AI has been employed in a wide range of DED\nclinical tests and research applications, primarily for interpretation of\ninterferometry, slit-lamp and meibography images. While initial results are\npromising, much work is still needed on model development, clinical testing and\nstandardisation.",
      "citation_count": 34,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a104faa61f69639bca248f5ffccc9acacacf98ab",
      "published_date": "2021-09-02",
      "downloaded_date": "2025-01-31",
      "filename": "StorÃ¥s-Artificial Intelligence in Dry Eye Disease.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2109.01658v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV"
      ]
    },
    "2303.12702v3": {
      "title": "Automatic Identification of Crystal Structures and Interfaces via Artificial-Intelligence-based Electron Microscopy",
      "authors": [
        "Andreas Leitherer",
        "Byung Chul Yeo",
        "Christian H. Liebscher",
        "Luca M. Ghiringhelli"
      ],
      "abstract": "Characterizing crystal structures and interfaces down to the atomic level is\nan important step for designing advanced materials. Modern electron microscopy\nroutinely achieves atomic resolution and is capable to resolve complex\narrangements of atoms with picometer precision. Here, we present AI-STEM, an\nautomatic, artificial-intelligence based method, for accurately identifying key\ncharacteristics from atomic-resolution scanning transmission electron\nmicroscopy (STEM) images of polycrystalline materials. The method is based on a\nBayesian convolutional neural network (BNN) that is trained only on simulated\nimages. AI-STEM automatically and accurately identifies crystal structure,\nlattice orientation, and location of interface regions in synthetic and\nexperimental images. The model is trained on cubic and hexagonal crystal\nstructures, yielding classifications and uncertainty estimates, while no\nexplicit information on structural patterns at the interfaces is included\nduring training. This work combines principles from probabilistic modeling,\ndeep learning, and information theory, enabling automatic analysis of\nexperimental, atomic-resolution images.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/47d9fb80366d495108a14907be871ae7950cb323",
      "published_date": "2023-03-22",
      "downloaded_date": "2025-01-31",
      "filename": "Leitherer-Automatic Identification of Crystal Structures and Interfaces via Artificial-Intelligence-based Elec....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.12702v3",
      "categories": [
        "cond-mat.mtrl-sci"
      ]
    },
    "2311.10744v1": {
      "title": "Advancing a Model of Students' Intentional Persistence in Machine Learning and Artificial Intelligence",
      "authors": [
        "Sharon Ferguson",
        "Katherine Mao",
        "James Magarian",
        "Alison Olechowski"
      ],
      "abstract": "Machine Learning (ML) and Artificial Intelligence (AI) are powering the\napplications we use, the decisions we make, and the decisions made about us. We\nhave seen numerous examples of non-equitable outcomes, from facial recognition\nalgorithms to recidivism algorithms, when they are designed without diversity\nin mind. Thus, we must take action to promote diversity among those in this\nfield. A critical step in this work is understanding why some students who\nchoose to study ML/AI later leave the field. While the persistence of diverse\npopulations has been studied in engineering, there is a lack of research\ninvestigating factors that influence persistence in ML/AI. In this work, we\npresent the advancement of a model of intentional persistence in ML/AI by\nsurveying students in ML/AI courses. We examine persistence across demographic\ngroups, such as gender, international student status, student loan status, and\nvisible minority status. We investigate independent variables that distinguish\nML/AI from other STEM fields, such as the varying emphasis on non-technical\nskills, the ambiguous ethical implications of the work, and the highly\ncompetitive and lucrative nature of the field. Our findings suggest that\nshort-term intentional persistence is associated with academic enrollment\nfactors such as major and level of study. Long-term intentional persistence is\ncorrelated with measures of professional role confidence. Unique to our study,\nwe show that wanting your work to have a positive social benefit is a negative\npredictor of long-term intentional persistence, and women generally care more\nabout this. We provide recommendations to educators to meaningfully discuss\nML/AI ethics in classes and encourage the development of interpersonal skills\nto help increase diversity in the field.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b1ae8e4c61d54bde963604470b0f20464ddf7cac",
      "published_date": "2023-10-30",
      "downloaded_date": "2025-01-31",
      "filename": "Ferguson-Advancing a Model of Students Intentional Persistence in Machine Learning and Artificial Intelligenc....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.10744v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2303.02819v1": {
      "title": "Artificial Intelligence: 70 Years Down the Road",
      "authors": [
        "Lin Zhang"
      ],
      "abstract": "Artificial intelligence (AI) has a history of nearly a century from its\ninception to the present day. We have summarized the development trends and\ndiscovered universal rules, including both success and failure. We have\nanalyzed the reasons from both technical and philosophical perspectives to help\nunderstand the reasons behind the past failures and current successes of AI,\nand to provide a basis for thinking and exploring future development.\nSpecifically, we have found that the development of AI in different fields,\nincluding computer vision, natural language processing, and machine learning,\nfollows a pattern from rules to statistics to data-driven methods. In the face\nof past failures and current successes, we need to think systematically about\nthe reasons behind them. Given the unity of AI between natural and social\nsciences, it is necessary to incorporate philosophical thinking to understand\nand solve AI problems, and we believe that starting from the dialectical method\nof Marx is a feasible path. We have concluded that the sustainable development\ndirection of AI should be human-machine collaboration and a technology path\ncentered on computing power. Finally, we have summarized the impact of AI on\nsociety from this trend.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-03-06",
      "downloaded_date": "2025-01-31",
      "filename": "Zhang-Artificial Intelligence 70 Years Down the Road.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.02819v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "2303.10158v3": {
      "title": "Data-centric Artificial Intelligence: A Survey",
      "authors": [
        "Daochen Zha",
        "Zaid Pervaiz Bhat",
        "Kwei-Herng Lai",
        "Fan Yang",
        "Zhimeng Jiang",
        "Shaochen Zhong",
        "Xia Hu"
      ],
      "abstract": "Artificial Intelligence (AI) is making a profound impact in almost every\ndomain. A vital enabler of its great success is the availability of abundant\nand high-quality data for building machine learning models. Recently, the role\nof data in AI has been significantly magnified, giving rise to the emerging\nconcept of data-centric AI. The attention of researchers and practitioners has\ngradually shifted from advancing model design to enhancing the quality and\nquantity of the data. In this survey, we discuss the necessity of data-centric\nAI, followed by a holistic view of three general data-centric goals (training\ndata development, inference data development, and data maintenance) and the\nrepresentative methods. We also organize the existing literature from\nautomation and collaboration perspectives, discuss the challenges, and tabulate\nthe benchmarks for various tasks. We believe this is the first comprehensive\nsurvey that provides a global view of a spectrum of tasks across various stages\nof the data lifecycle. We hope it can help the readers efficiently grasp a\nbroad picture of this field, and equip them with the techniques and further\nresearch ideas to systematically engineer data for building AI systems. A\ncompanion list of data-centric AI resources will be regularly updated on\nhttps://github.com/daochenzha/data-centric-AI",
      "citation_count": 150,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/12c6be503e4e5b7c9cb1810152d4364f26628a8d",
      "published_date": "2023-03-17",
      "downloaded_date": "2025-01-31",
      "filename": "Zha-Data-centric Artificial Intelligence A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.10158v3",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ]
    },
    "1710.02913v2": {
      "title": "Artificial Neural Networks-Based Machine Learning for Wireless Networks: A Tutorial",
      "authors": [
        "Mingzhe Chen",
        "Ursula Challita",
        "Walid Saad",
        "Changchuan Yin",
        "MÃ©rouane Debbah"
      ],
      "abstract": "Next-generation wireless networks must support ultra-reliable, low-latency\ncommunication and intelligently manage a massive number of Internet of Things\n(IoT) devices in real-time, within a highly dynamic environment. This need for\nstringent communication quality-of-service (QoS) requirements as well as mobile\nedge and core intelligence can only be realized by integrating fundamental\nnotions of artificial intelligence (AI) and machine learning across the\nwireless infrastructure and end-user devices. In this context, this paper\nprovides a comprehensive tutorial that introduces the main concepts of machine\nlearning, in general, and artificial neural networks (ANNs), in particular, and\ntheir potential applications in wireless communications. For this purpose, we\npresent a comprehensive overview on a number of key types of neural networks\nthat include feed-forward, recurrent, spiking, and deep neural networks. For\neach type of neural network, we present the basic architecture and training\nprocedure, as well as the associated challenges and opportunities. Then, we\nprovide an in-depth overview on the variety of wireless communication problems\nthat can be addressed using ANNs, ranging from communication using unmanned\naerial vehicles to virtual reality and edge caching.For each individual\napplication, we present the main motivation for using ANNs along with the\nassociated challenges while also providing a detailed example for a use case\nscenario and outlining future works that can be addressed using ANNs. In a\nnutshell, this article constitutes one of the first holistic tutorials on the\ndevelopment of machine learning techniques tailored to the needs of future\nwireless networks.",
      "citation_count": 712,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b9bf865c3cad373caa48a8328596394dad1ac0e4",
      "published_date": "2017-10-09",
      "downloaded_date": "2025-01-31",
      "filename": "Chen-Artificial Neural Networks-Based Machine Learning for Wireless Networks A Tutorial.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1710.02913v2",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ]
    },
    "1905.00547v1": {
      "title": "The relationship between Biological and Artificial Intelligence",
      "authors": [
        "George Cevora"
      ],
      "abstract": "Intelligence can be defined as a predominantly human ability to accomplish\ntasks that are generally hard for computers and animals. Artificial\nIntelligence [AI] is a field attempting to accomplish such tasks with\ncomputers. AI is becoming increasingly widespread, as are claims of its\nrelationship with Biological Intelligence. Often these claims are made to imply\nhigher chances of a given technology succeeding, working on the assumption that\nAI systems which mimic the mechanisms of Biological Intelligence should be more\nsuccessful.\n  In this article I will discuss the similarities and differences between AI\nand the extent of our knowledge about the mechanisms of intelligence in\nbiology, especially within humans. I will also explore the validity of the\nassumption that biomimicry in AI systems aids their advancement, and I will\nargue that existing similarity to biological systems in the way Artificial\nNeural Networks [ANNs] tackle tasks is due to design decisions, rather than\ninherent similarity of underlying mechanisms. This article is aimed at people\nwho understand the basics of AI (especially ANNs), and would like to be better\nable to evaluate the often wild claims about the value of biomimicry in AI.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ed9826c7560b62a87a0dc9c32ed48098dae19453",
      "published_date": "2019-05-01",
      "downloaded_date": "2025-01-31",
      "filename": "Cevora-The relationship between Biological and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1905.00547v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2312.00030v1": {
      "title": "Artificial Intelligence in Sustainable Vertical Farming",
      "authors": [
        "Hribhu Chowdhury",
        "Debo Brata Paul Argha",
        "Md Ashik Ahmed"
      ],
      "abstract": "As global challenges of population growth, climate change, and resource\nscarcity intensify, the agricultural landscape is at a critical juncture.\nSustainable vertical farming emerges as a transformative solution to address\nthese challenges by maximizing crop yields in controlled environments. This\nparadigm shift necessitates the integration of cutting-edge technologies, with\nArtificial Intelligence (AI) at the forefront. The paper provides a\ncomprehensive exploration of the role of AI in sustainable vertical farming,\ninvestigating its potential, challenges, and opportunities. The review\nsynthesizes the current state of AI applications, encompassing machine\nlearning, computer vision, the Internet of Things (IoT), and robotics, in\noptimizing resource usage, automating tasks, and enhancing decision-making. It\nidentifies gaps in research, emphasizing the need for optimized AI models,\ninterdisciplinary collaboration, and the development of explainable AI in\nagriculture. The implications extend beyond efficiency gains, considering\neconomic viability, reduced environmental impact, and increased food security.\nThe paper concludes by offering insights for stakeholders and suggesting\navenues for future research, aiming to guide the integration of AI technologies\nin sustainable vertical farming for a resilient and sustainable future in\nagriculture.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/963904c6340901ee8c9320322050bc37667d8dcb",
      "published_date": "2023-11-17",
      "downloaded_date": "2025-01-31",
      "filename": "Chowdhury-Artificial Intelligence in Sustainable Vertical Farming.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.00030v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2404.19598v1": {
      "title": "Artificial Intelligence in Bone Metastasis Analysis: Current Advancements, Opportunities and Challenges",
      "authors": [
        "Marwa Afnouch",
        "Fares Bougourzi",
        "Olfa Gaddour",
        "Fadi Dornaika",
        "Abdelmalik Taleb-Ahmed"
      ],
      "abstract": "In recent years, Artificial Intelligence (AI) has been widely used in\nmedicine, particularly in the analysis of medical imaging, which has been\ndriven by advances in computer vision and deep learning methods. This is\nparticularly important in overcoming the challenges posed by diseases such as\nBone Metastases (BM), a common and complex malignancy of the bones. Indeed,\nthere have been an increasing interest in developing Machine Learning (ML)\ntechniques into oncologic imaging for BM analysis. In order to provide a\ncomprehensive overview of the current state-of-the-art and advancements for BM\nanalysis using artificial intelligence, this review is conducted with the\naccordance with PRISMA guidelines. Firstly, this review highlights the clinical\nand oncologic perspectives of BM and the used medical imaging modalities, with\ndiscussing their advantages and limitations. Then the review focuses on modern\napproaches with considering the main BM analysis tasks, which includes:\nclassification, detection and segmentation. The results analysis show that ML\ntechnologies can achieve promising performance for BM analysis and have\nsignificant potential to improve clinician efficiency and cope with time and\ncost limitations. Furthermore, there are requirements for further research to\nvalidate the clinical performance of ML tools and facilitate their integration\ninto routine clinical practice.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/edbbc7f87d465129dfa6b9f470b618171c7a48b4",
      "published_date": "2024-04-30",
      "downloaded_date": "2025-01-31",
      "filename": "Afnouch-Artificial Intelligence in Bone Metastasis Analysis Current Advancements Opportunities and Challenge....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.19598v1",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "2010.01217v1": {
      "title": "Artificial Intelligence Enabled Traffic Monitoring System",
      "authors": [
        "Vishal Mandal",
        "Abdul Rashid Mussah",
        "Peng Jin",
        "Yaw Adu-Gyamfi"
      ],
      "abstract": "Manual traffic surveillance can be a daunting task as Traffic Management\nCenters operate a myriad of cameras installed over a network. Injecting some\nlevel of automation could help lighten the workload of human operators\nperforming manual surveillance and facilitate making proactive decisions which\nwould reduce the impact of incidents and recurring congestion on roadways. This\narticle presents a novel approach to automatically monitor real time traffic\nfootage using deep convolutional neural networks and a stand-alone graphical\nuser interface. The authors describe the results of research received in the\nprocess of developing models that serve as an integrated framework for an\nartificial intelligence enabled traffic monitoring system. The proposed system\ndeploys several state-of-the-art deep learning algorithms to automate different\ntraffic monitoring needs. Taking advantage of a large database of annotated\nvideo surveillance data, deep learning-based models are trained to detect\nqueues, track stationary vehicles, and tabulate vehicle counts. A pixel-level\nsegmentation approach is applied to detect traffic queues and predict severity.\nReal-time object detection algorithms coupled with different tracking systems\nare deployed to automatically detect stranded vehicles as well as perform\nvehicular counts. At each stages of development, interesting experimental\nresults are presented to demonstrate the effectiveness of the proposed system.\nOverall, the results demonstrate that the proposed framework performs\nsatisfactorily under varied conditions without being immensely impacted by\nenvironmental hazards such as blurry camera views, low illumination, rain, or\nsnow.",
      "citation_count": 45,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a9763f4c43748d6135168bf94f0af8b791d916aa",
      "published_date": "2020-10-02",
      "downloaded_date": "2025-01-31",
      "filename": "Mandal-Artificial Intelligence Enabled Traffic Monitoring System.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2010.01217v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2007.11621v2": {
      "title": "Privacy-preserving Artificial Intelligence Techniques in Biomedicine",
      "authors": [
        "Reihaneh Torkzadehmahani",
        "Reza Nasirigerdeh",
        "David B. Blumenthal",
        "Tim Kacprowski",
        "Markus List",
        "Julian Matschinske",
        "Julian SpÃ¤th",
        "Nina Kerstin Wenke",
        "BÃ©la Bihari",
        "Tobias Frisch",
        "Anne Hartebrodt",
        "Anne-Christin Hausschild",
        "Dominik Heider",
        "Andreas Holzinger",
        "Walter HÃ¶tzendorfer",
        "Markus Kastelitz",
        "Rudolf Mayer",
        "Cristian Nogales",
        "Anastasia Pustozerova",
        "Richard RÃ¶ttger",
        "Harald H. H. W. Schmidt",
        "Ameli Schwalber",
        "Christof Tschohl",
        "Andrea Wohner",
        "Jan Baumbach"
      ],
      "abstract": "Artificial intelligence (AI) has been successfully applied in numerous\nscientific domains. In biomedicine, AI has already shown tremendous potential,\ne.g. in the interpretation of next-generation sequencing data and in the design\nof clinical decision support systems. However, training an AI model on\nsensitive data raises concerns about the privacy of individual participants.\nFor example, summary statistics of a genome-wide association study can be used\nto determine the presence or absence of an individual in a given dataset. This\nconsiderable privacy risk has led to restrictions in accessing genomic and\nother biomedical data, which is detrimental for collaborative research and\nimpedes scientific progress. Hence, there has been a substantial effort to\ndevelop AI methods that can learn from sensitive data while protecting\nindividuals' privacy. This paper provides a structured overview of recent\nadvances in privacy-preserving AI techniques in biomedicine. It places the most\nimportant state-of-the-art approaches within a unified taxonomy and discusses\ntheir strengths, limitations, and open problems. As the most promising\ndirection, we suggest combining federated machine learning as a more scalable\napproach with other additional privacy preserving techniques. This would allow\nto merge the advantages to provide privacy guarantees in a distributed way for\nbiomedical applications. Nonetheless, more research is necessary as hybrid\napproaches pose new challenges such as additional network or computation\noverhead.",
      "citation_count": 47,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8f694a82fe075a630a7cc0b8b6b91be103b5c103",
      "published_date": "2020-07-22",
      "downloaded_date": "2025-01-31",
      "filename": "Torkzadehmahani-Privacy-preserving Artificial Intelligence Techniques in Biomedicine.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.11621v2",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    "2312.02796v1": {
      "title": "Materials Expert-Artificial Intelligence for Materials Discovery",
      "authors": [
        "Yanjun Liu",
        "Milena Jovanovic",
        "Krishnanand Mallayya",
        "Wesley J. Maddox",
        "Andrew Gordon Wilson",
        "Sebastian Klemenz",
        "Leslie M. Schoop",
        "Eun-Ah Kim"
      ],
      "abstract": "The advent of material databases provides an unprecedented opportunity to\nuncover predictive descriptors for emergent material properties from vast data\nspace. However, common reliance on high-throughput ab initio data necessarily\ninherits limitations of such data: mismatch with experiments. On the other\nhand, experimental decisions are often guided by an expert's intuition honed\nfrom experiences that are rarely articulated. We propose using machine learning\nto \"bottle\" such operational intuition into quantifiable descriptors using\nexpertly curated measurement-based data. We introduce \"Materials\nExpert-Artificial Intelligence\" (ME-AI) to encapsulate and articulate this\nhuman intuition. As a first step towards such a program, we focus on the\ntopological semimetal (TSM) among square-net materials as the property inspired\nby the expert-identified descriptor based on structural information: the\ntolerance factor. We start by curating a dataset encompassing 12 primary\nfeatures of 879 square-net materials, using experimental data whenever\npossible. We then use Dirichlet-based Gaussian process regression using a\nspecialized kernel to reveal composite descriptors for square-net topological\nsemimetals. The ME-AI learned descriptors independently reproduce expert\nintuition and expand upon it. Specifically, new descriptors point to\nhypervalency as a critical chemical feature predicting TSM within square-net\ncompounds. Our success with a carefully defined problem points to the \"machine\nbottling human insight\" approach as promising for machine learning-aided\nmaterial discovery.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d147071f1bec13101c67b1dd63837fae4ae1d9a5",
      "published_date": "2023-12-05",
      "downloaded_date": "2025-01-31",
      "filename": "Liu-Materials Expert-Artificial Intelligence for Materials Discovery.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.02796v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el",
        "cs.LG",
        "physics.data-an"
      ]
    },
    "1903.12069v1": {
      "title": "The Virtual Doctor: An Interactive Artificial Intelligence based on Deep Learning for Non-Invasive Prediction of Diabetes",
      "authors": [
        "Sebastian SpÃ¤nig",
        "Agnes Emberger-Klein",
        "Jan-Peter Sowa",
        "Ali Canbay",
        "Klaus Menrad",
        "Dominik Heider"
      ],
      "abstract": "Artificial intelligence (AI) will pave the way to a new era in medicine.\nHowever, currently available AI systems do not interact with a patient, e.g.,\nfor anamnesis, and thus are only used by the physicians for predictions in\ndiagnosis or prognosis. However, these systems are widely used, e.g., in\ndiabetes or cancer prediction. In the current study, we developed an AI that is\nable to interact with a patient (virtual doctor) by using a speech recognition\nand speech synthesis system and thus can autonomously interact with the\npatient, which is particularly important for, e.g., rural areas, where the\navailability of primary medical care is strongly limited by low population\ndensities. As a proof-of-concept, the system is able to predict type 2 diabetes\nmellitus (T2DM) based on non-invasive sensors and deep neural networks.\nMoreover, the system provides an easy-to-interpret probability estimation for\nT2DM for a given patient. Besides the development of the AI, we further\nanalyzed the acceptance of young people for AI in healthcare to estimate the\nimpact of such system in the future.",
      "citation_count": 68,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5d2999447bf54b40f2e1b5e07f280b04fd066643",
      "published_date": "2019-03-09",
      "downloaded_date": "2025-01-31",
      "filename": "SpÃ¤nig-The Virtual Doctor An Interactive Artificial Intelligence based on Deep Learning for Non-Invasive Pr....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1903.12069v1",
      "categories": [
        "cs.CY",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2110.12773v1": {
      "title": "Scientific Machine Learning Benchmarks",
      "authors": [
        "Jeyan Thiyagalingam",
        "Mallikarjun Shankar",
        "Geoffrey Fox",
        "Tony Hey"
      ],
      "abstract": "The breakthrough in Deep Learning neural networks has transformed the use of\nAI and machine learning technologies for the analysis of very large\nexperimental datasets. These datasets are typically generated by large-scale\nexperimental facilities at national laboratories. In the context of science,\nscientific machine learning focuses on training machines to identify patterns,\ntrends, and anomalies to extract meaningful scientific insights from such\ndatasets. With a new generation of experimental facilities, the rate of data\ngeneration and the scale of data volumes will increasingly require the use of\nmore automated data analysis. At present, identifying the most appropriate\nmachine learning algorithm for the analysis of any given scientific dataset is\nstill a challenge for scientists. This is due to many different machine\nlearning frameworks, computer architectures, and machine learning models.\nHistorically, for modelling and simulation on HPC systems such problems have\nbeen addressed through benchmarking computer applications, algorithms, and\narchitectures. Extending such a benchmarking approach and identifying metrics\nfor the application of machine learning methods to scientific datasets is a new\nchallenge for both scientists and computer scientists. In this paper, we\ndescribe our approach to the development of scientific machine learning\nbenchmarks and review other approaches to benchmarking scientific machine\nlearning.",
      "citation_count": 92,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/babe0882cfde20cde8a7d8f3e9e4b4213724fd20",
      "published_date": "2021-10-25",
      "downloaded_date": "2025-01-31",
      "filename": "Thiyagalingam-Scientific Machine Learning Benchmarks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.12773v1",
      "categories": [
        "cs.LG",
        "physics.comp-ph",
        "I.2"
      ]
    },
    "2202.01916v1": {
      "title": "Artificial Intelligence Powered Material Search Engine",
      "authors": [
        "Mohendra Roy"
      ],
      "abstract": "Many data-driven applications in material science have been made possible\nbecause of recent breakthroughs in artificial intelligence(AI). The use of AI\nin material engineering is becoming more viable as the number of material data\nsuch as X-Ray diffraction, various spectroscopy, and microscope data grows. In\nthis work, we have reported a material search engine that uses the interatomic\nspace (d value) from X-ray diffraction to provide material information. We have\ninvestigated various techniques for predicting prospective material using X-ray\ndiffraction data. We used the Random Forest, Naive Bayes (Gaussian), and Neural\nNetwork algorithms to achieve this. These algorithms have an average accuracy\nof 88.50\\%, 100.0\\%, and 88.89\\%, respectively. Finally, we combined all these\ntechniques into an ensemble approach to make the prediction more generic. This\nensemble method has a ~100\\% accuracy rate. Furthermore, we are designing a\ngraph neural network (GNN)-based architecture to improve interpretability and\naccuracy. Thus, we want to solve the computational and time complexity of\ntraditional dictionary-based and metadata-based material search engines and to\nprovide a more generic prediction.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/efc3b51effdefb014a5695563ee3290678018cc5",
      "published_date": "2022-01-19",
      "downloaded_date": "2025-01-31",
      "filename": "Roy-Artificial Intelligence Powered Material Search Engine.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.01916v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.LG"
      ]
    },
    "2410.15820v1": {
      "title": "MAC Revivo: Artificial Intelligence Paves the Way",
      "authors": [
        "Jinzhe Pan",
        "Jingqing Wang",
        "Zelin Yun",
        "Zhiyong Xiao",
        "Yuehui Ouyang",
        "Wenchi Cheng",
        "Wei Zhang"
      ],
      "abstract": "The vast adoption of Wi-Fi and/or Bluetooth capabilities in Internet of\nThings (IoT) devices, along with the rapid growth of deployed smart devices,\nhas caused significant interference and congestion in the industrial,\nscientific, and medical (ISM) bands. Traditional Wi-Fi Medium Access Control\n(MAC) design faces significant challenges in managing increasingly complex\nwireless environments while ensuring network Quality of Service (QoS)\nperformance. This paper explores the potential integration of advanced\nArtificial Intelligence (AI) methods into the design of Wi-Fi MAC protocols. We\npropose AI-MAC, an innovative approach that employs machine learning algorithms\nto dynamically adapt to changing network conditions, optimize channel access,\nmitigate interference, and ensure deterministic latency. By intelligently\npredicting and managing interference, AI-MAC aims to provide a robust solution\nfor next generation of Wi-Fi networks, enabling seamless connectivity and\nenhanced QoS. Our experimental results demonstrate that AI-MAC significantly\nreduces both interference and latency, paving the way for more reliable and\nefficient wireless communications in the increasingly crowded ISM band.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fc9a445781759ea26b57b929c16b65442114ab36",
      "published_date": "2024-10-21",
      "downloaded_date": "2025-01-31",
      "filename": "Pan-MAC Revivo Artificial Intelligence Paves the Way.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.15820v1",
      "categories": [
        "cs.NI",
        "cs.AI"
      ]
    },
    "2411.05943v1": {
      "title": "Quantifying artificial intelligence through algebraic generalization",
      "authors": [
        "Takuya Ito",
        "Murray Campbell",
        "Lior Horesh",
        "Tim Klinger",
        "Parikshit Ram"
      ],
      "abstract": "The rapid development of modern artificial intelligence (AI) systems has\ncreated an urgent need for their scientific quantification. While their fluency\nacross a variety of domains is impressive, modern AI systems fall short on\ntests requiring symbolic processing and abstraction - a glaring limitation\ngiven the necessity for interpretable and reliable technology. Despite a surge\nof reasoning benchmarks emerging from the academic community, no comprehensive\nand theoretically-motivated framework exists to quantify reasoning (and more\ngenerally, symbolic ability) in AI systems. Here, we adopt a framework from\ncomputational complexity theory to explicitly quantify symbolic generalization:\nalgebraic circuit complexity. Many symbolic reasoning problems can be recast as\nalgebraic expressions. Thus, algebraic circuit complexity theory - the study of\nalgebraic expressions as circuit models (i.e., directed acyclic graphs) - is a\nnatural framework to study the complexity of symbolic computation. The tools of\nalgebraic circuit complexity enable the study of generalization by defining\nbenchmarks in terms of their complexity-theoretic properties (i.e., the\ndifficulty of a problem). Moreover, algebraic circuits are generic mathematical\nobjects; for a given algebraic circuit, an arbitrarily large number of samples\ncan be generated for a specific circuit, making it an optimal testbed for the\ndata-hungry machine learning algorithms that are used today. Here, we adopt\ntools from algebraic circuit complexity theory, apply it to formalize a science\nof symbolic generalization, and address key theoretical and empirical\nchallenges for its successful application to AI science and its impact on the\nbroader community.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/dba51fda27c0db2d32c297a18fc69cefb62dbe1f",
      "published_date": "2024-11-08",
      "downloaded_date": "2025-01-31",
      "filename": "Ito-Quantifying artificial intelligence through algebraic generalization.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.05943v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.LO"
      ]
    },
    "2008.05959v1": {
      "title": "Creativity in the era of artificial intelligence",
      "authors": [
        "Philippe Esling",
        "Ninon Devis"
      ],
      "abstract": "Creativity is a deeply debated topic, as this concept is arguably\nquintessential to our humanity. Across different epochs, it has been infused\nwith an extensive variety of meanings relevant to that era. Along these, the\nevolution of technology have provided a plurality of novel tools for creative\npurposes. Recently, the advent of Artificial Intelligence (AI), through deep\nlearning approaches, have seen proficient successes across various\napplications. The use of such technologies for creativity appear in a natural\ncontinuity to the artistic trend of this century. However, the aura of a\ntechnological artefact labeled as intelligent has unleashed passionate and\nsomewhat unhinged debates on its implication for creative endeavors. In this\npaper, we aim to provide a new perspective on the question of creativity at the\nera of AI, by blurring the frontier between social and computational sciences.\nTo do so, we rely on reflections from social science studies of creativity to\nview how current AI would be considered through this lens. As creativity is a\nhighly context-prone concept, we underline the limits and deficiencies of\ncurrent AI, requiring to move towards artificial creativity. We argue that the\nobjective of trying to purely mimic human creative traits towards a\nself-contained ex-nihilo generative machine would be highly counterproductive,\nputting us at risk of not harnessing the almost unlimited possibilities offered\nby the sheer computational power of artificial agents.",
      "citation_count": 16,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9808b23447904614379e81651d377211e1828d1a",
      "published_date": "2020-08-13",
      "downloaded_date": "2025-01-31",
      "filename": "Esling-Creativity in the era of artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.05959v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    "1911.08448v4": {
      "title": "Artificial intelligence approach to momentum risk-taking",
      "authors": [
        "Ivan Cherednik"
      ],
      "abstract": "We propose a mathematical model of momentum risk-taking, which is essentially\nreal-time risk management focused on short-term volatility of stock markets.\nIts implementation, our fully automated momentum equity trading system\npresented systematically, proved to be successful in extensive historical and\nreal-time experiments. Momentum risk-taking is one of the key components of\ngeneral decision-making, a challenge for artificial intelligence and machine\nlearning with deep roots in cognitive science; its variants beyond stock\nmarkets are discussed. We begin with a new algebraic-type theory of news impact\non share-prices, which describes well their power growth, periodicity, and the\nmarket phenomena like price targets and profit-taking. This theory generally\nrequires Bessel and hypergeometric functions. Its discretization results in\nsome tables of bids, which are basically expected returns for main investment\nhorizons, the key in our trading system. The ML procedures we use are similar\nto those in neural networking. A preimage of our approach is the new contract\ncard game provided at the end, a combination of bridge and poker. Relations to\nrandom processes and the fractional Brownian motion are outlined.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9225c4ab424f426229b50149aa3b2e1807c8b0ff",
      "published_date": "2019-11-19",
      "downloaded_date": "2025-01-31",
      "filename": "Cherednik-Artificial intelligence approach to momentum risk-taking.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.08448v4",
      "categories": [
        "q-fin.RM",
        "33C90, 33C10, 60K37, 68R01, 90B50, 91A35, 91A80, 92C30, 93E35,\n  33D90, 91E10, 91E45, 68T27, 68T37"
      ]
    },
    "2403.09762v1": {
      "title": "Emotional Intelligence Through Artificial Intelligence : NLP and Deep Learning in the Analysis of Healthcare Texts",
      "authors": [
        "Prashant Kumar Nag",
        "Amit Bhagat",
        "R. Vishnu Priya",
        "Deepak kumar Khare"
      ],
      "abstract": "This manuscript presents a methodical examination of the utilization of\nArtificial Intelligence in the assessment of emotions in texts related to\nhealthcare, with a particular focus on the incorporation of Natural Language\nProcessing and deep learning technologies. We scrutinize numerous research\nstudies that employ AI to augment sentiment analysis, categorize emotions, and\nforecast patient outcomes based on textual information derived from clinical\nnarratives, patient feedback on medications, and online health discussions. The\nreview demonstrates noteworthy progress in the precision of algorithms used for\nsentiment classification, the prognostic capabilities of AI models for\nneurodegenerative diseases, and the creation of AI-powered systems that offer\nsupport in clinical decision-making. Remarkably, the utilization of AI\napplications has exhibited an enhancement in personalized therapy plans by\nintegrating patient sentiment and contributing to the early identification of\nmental health disorders. There persist challenges, which encompass ensuring the\nethical application of AI, safeguarding patient confidentiality, and addressing\npotential biases in algorithmic procedures. Nevertheless, the potential of AI\nto revolutionize healthcare practices is unmistakable, offering a future where\nhealthcare is not only more knowledgeable and efficient but also more\nempathetic and centered around the needs of patients. This investigation\nunderscores the transformative influence of AI on healthcare, delivering a\ncomprehensive comprehension of its role in examining emotional content in\nhealthcare texts and highlighting the trajectory towards a more compassionate\napproach to patient care. The findings advocate for a harmonious synergy\nbetween AI's analytical capabilities and the human aspects of healthcare.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-03-14",
      "downloaded_date": "2025-01-31",
      "filename": "Nag-Emotional Intelligence Through Artificial Intelligence  NLP and Deep Learning in the Analysis of Hea....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.09762v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2111.00601v1": {
      "title": "Explainable Artificial Intelligence for Smart City Application: A Secure and Trusted Platform",
      "authors": [
        "M. Humayn Kabir",
        "Khondokar Fida Hasan",
        "Mohammad Kamrul Hasan",
        "Keyvan Ansari"
      ],
      "abstract": "Artificial Intelligence (AI) is one of the disruptive technologies that is\nshaping the future. It has growing applications for data-driven decisions in\nmajor smart city solutions, including transportation, education, healthcare,\npublic governance, and power systems. At the same time, it is gaining\npopularity in protecting critical cyber infrastructure from cyber threats,\nattacks, damages, or unauthorized access. However, one of the significant\nissues of those traditional AI technologies (e.g., deep learning) is that the\nrapid progress in complexity and sophistication propelled and turned out to be\nuninterpretable black boxes. On many occasions, it is very challenging to\nunderstand the decision and bias to control and trust systems' unexpected or\nseemingly unpredictable outputs. It is acknowledged that the loss of control\nover interpretability of decision-making becomes a critical issue for many\ndata-driven automated applications. But how may it affect the system's security\nand trustworthiness? This chapter conducts a comprehensive study of machine\nlearning applications in cybersecurity to indicate the need for explainability\nto address this question. While doing that, this chapter first discusses the\nblack-box problems of AI technologies for Cybersecurity applications in smart\ncity-based solutions. Later, considering the new technological paradigm,\nExplainable Artificial Intelligence (XAI), this chapter discusses the\ntransition from black-box to white-box. This chapter also discusses the\ntransition requirements concerning the interpretability, transparency,\nunderstandability, and Explainability of AI-based technologies in applying\ndifferent autonomous systems in smart cities. Finally, it has presented some\ncommercial XAI platforms that offer explainability over traditional AI\ntechnologies before presenting future challenges and opportunities.",
      "citation_count": 20,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4b03870cc029c2121963742c3604b5e27b281c36",
      "published_date": "2021-10-31",
      "downloaded_date": "2025-01-31",
      "filename": "Kabir-Explainable Artificial Intelligence for Smart City Application A Secure and Trusted Platform.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.00601v1",
      "categories": [
        "cs.LG",
        "cs.CR",
        "cs.NI"
      ]
    },
    "2108.01591v1": {
      "title": "The application of artificial intelligence in software engineering: a review challenging conventional wisdom",
      "authors": [
        "Feras A. Batarseh",
        "Rasika Mohod",
        "Abhinav Kumar",
        "Justin Bui"
      ],
      "abstract": "The field of artificial intelligence (AI) is witnessing a recent upsurge in\nresearch, tools development, and deployment of applications. Multiple software\ncompanies are shifting their focus to developing intelligent systems; and many\nothers are deploying AI paradigms to their existing processes. In parallel, the\nacademic research community is injecting AI paradigms to provide solutions to\ntraditional engineering problems. Similarly, AI has evidently been proved\nuseful to software engineering (SE). When one observes the SE phases\n(requirements, design, development, testing, release, and maintenance), it\nbecomes clear that multiple AI paradigms (such as neural networks, machine\nlearning, knowledge-based systems, natural language processing) could be\napplied to improve the process and eliminate many of the major challenges that\nthe SE field has been facing. This survey chapter is a review of the most\ncommonplace methods of AI applied to SE. The review covers methods between\nyears 1975-2017, for the requirements phase, 46 major AI-driven methods are\nfound, 19 for design, 15 for development, 68 for testing, and 15 for release\nand maintenance. Furthermore, the purpose of this chapter is threefold;\nfirstly, to answer the following questions: is there sufficient intelligence in\nthe SE lifecycle? What does applying AI to SE entail? Secondly, to measure,\nformulize, and evaluate the overlap of SE phases and AI disciplines. Lastly,\nthis chapter aims to provide serious questions to challenging the current\nconventional wisdom (i.e., status quo) of the state-of-the-art, craft a call\nfor action, and to redefine the path forward.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d6f96888d28a259fcb16d861c0ad8f5e77a618ff",
      "published_date": "2021-08-03",
      "downloaded_date": "2025-01-31",
      "filename": "Batarseh-The application of artificial intelligence in software engineering a review challenging conventional....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.01591v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    "2104.09445v2": {
      "title": "Artificial Intelligence in Open Radio Access Network",
      "authors": [
        "Paul H. Masur",
        "Jeffrey H. Reed"
      ],
      "abstract": "This tutorial seeks to outline the proposed Open Radio Access Network (O-RAN)\ndeployment for Fifth generation (5G) wireless networks. O-RAN seeks to supplant\nhardware-specific Radio Access Network (RAN) components (e.g., the mobility\nmanagement entity (MME) or base station (gNB)) with generic hardware,\nspecialized software, and open signaling interfaces. The virtualization and\nnetwork slicing features of 5G allow for software to replace previously\nhardware specific functions. Software further provides faster analytics, thus\nsupporting 5Gs latency requirements and advanced usage scenarios (i.e.,\nenhanced mobile broadband (eMBB), massive machine type communications (mMTC),\nand ultra-reliable low latency communications (uRLLC)). Furthermore, as\nsoftware annexes control of the RAN, there is freedom to integrate Artificial\nIntelligence/Machine Learning (AI/ML) algorithms into RAN management\n(particularly at the user plane). This integration is one of the goals of\nO-RAN. Lastly, relying on generic hardware and specialized, open-source\nsoftware eliminates reliance upon specific device manufacturers. This paper\nwill provide questions regarding the future of O-RAN, with a focus on 5G\nnetwork device security.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-04-19",
      "downloaded_date": "2025-01-31",
      "filename": "Masur-Artificial Intelligence in Open Radio Access Network.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.09445v2",
      "categories": [
        "cs.NI"
      ]
    },
    "2305.04887v1": {
      "title": "Hardware Acceleration of Explainable Artificial Intelligence",
      "authors": [
        "Zhixin Pan",
        "Prabhat Mishra"
      ],
      "abstract": "Machine learning (ML) is successful in achieving human-level artificial\nintelligence in various fields. However, it lacks the ability to explain an\noutcome due to its black-box nature. While recent efforts on explainable AI\n(XAI) has received significant attention, most of the existing solutions are\nnot applicable in real-time systems since they map interpretability as an\noptimization problem, which leads to numerous iterations of time-consuming\ncomplex computations. Although there are existing hardware-based acceleration\nframework for XAI, they are implemented through FPGA and designed for specific\ntasks, leading to expensive cost and lack of flexibility. In this paper, we\npropose a simple yet efficient framework to accelerate various XAI algorithms\nwith existing hardware accelerators. Specifically, this paper makes three\nimportant contributions. (1) The proposed method is the first attempt in\nexploring the effectiveness of Tensor Processing Unit (TPU) to accelerate XAI.\n(2) Our proposed solution explores the close relationship between several\nexisting XAI algorithms with matrix computations, and exploits the synergy\nbetween convolution and Fourier transform, which takes full advantage of TPU's\ninherent ability in accelerating matrix computations. (3) Our proposed approach\ncan lead to real-time outcome interpretation. Extensive experimental evaluation\ndemonstrates that proposed approach deployed on TPU can provide drastic\nimprovement in interpretation time (39x on average) as well as energy\nefficiency (69x on average) compared to existing acceleration techniques.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/90079f4a07d3d78146fcc72822060f102186b1c0",
      "published_date": "2023-05-04",
      "downloaded_date": "2025-01-31",
      "filename": "Pan-Hardware Acceleration of Explainable Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.04887v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2308.00705v1": {
      "title": "A Bibliographic Study on Artificial Intelligence Research: Global Panorama and Indian Appearance",
      "authors": [
        "Amit Tiwari",
        "Susmita Bardhan",
        "Vikas Kumar"
      ],
      "abstract": "The present study identifies and assesses the bibliographic trend in\nArtificial Intelligence (AI) research for the years 2015-2020 using the science\nmapping method of bibliometric study. The required data has been collected from\nthe Scopus database. To make the collected data analysis-ready, essential data\ntransformation was performed manually and with the help of a tool viz.\nOpenRefine. For determining the trend and performing the mapping techniques,\ntop five open access and commercial journals of AI have been chosen based on\ntheir citescore driven ranking. The work includes 6880 articles published in\nthe specified period for analysis. The trend is based on Country-wise\npublications, year-wise publications, topical terms in AI, top-cited articles,\nprominent authors, major institutions, involvement of industries in AI and\nIndian appearance. The results show that compared to open access journals;\ncommercial journals have a higher citescore and number of articles published\nover the years. Additionally, IEEE is the prominent publisher which publishes\n84% of the top-cited publications. Further, China and the United States are the\nmajor contributors to literature in the AI domain. The study reveals that\nneural networks and deep learning are the major topics included in top AI\nresearch publications. Recently, not only public institutions but also private\nbodies are investing their resources in AI research. The study also\ninvestigates the relative position of Indian researchers in terms of AI\nresearch. Present work helps in understanding the initial development, current\nstand and future direction of AI.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ddcb8ac38242a42d83505a5ca5784a4a45434027",
      "published_date": "2023-07-04",
      "downloaded_date": "2025-01-31",
      "filename": "Tiwari-A Bibliographic Study on Artificial Intelligence Research Global Panorama and Indian Appearance.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.00705v1",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2008.01916v1": {
      "title": "More Than Privacy: Applying Differential Privacy in Key Areas of Artificial Intelligence",
      "authors": [
        "Tianqing Zhu",
        "Dayong Ye",
        "Wei Wang",
        "Wanlei Zhou",
        "Philip S. Yu"
      ],
      "abstract": "Artificial Intelligence (AI) has attracted a great deal of attention in\nrecent years. However, alongside all its advancements, problems have also\nemerged, such as privacy violations, security issues and model fairness.\nDifferential privacy, as a promising mathematical model, has several attractive\nproperties that can help solve these problems, making it quite a valuable tool.\nFor this reason, differential privacy has been broadly applied in AI but to\ndate, no study has documented which differential privacy mechanisms can or have\nbeen leveraged to overcome its issues or the properties that make this\npossible. In this paper, we show that differential privacy can do more than\njust privacy preservation. It can also be used to improve security, stabilize\nlearning, build fair models, and impose composition in selected areas of AI.\nWith a focus on regular machine learning, distributed machine learning, deep\nlearning, and multi-agent systems, the purpose of this article is to deliver a\nnew view on many possibilities for improving AI performance with differential\nprivacy techniques.",
      "citation_count": 115,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7d5b94f9d2cee5823757352155d0234454f09a0e",
      "published_date": "2020-08-05",
      "downloaded_date": "2025-01-31",
      "filename": "Zhu-More Than Privacy Applying Differential Privacy in Key Areas of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.01916v1",
      "categories": [
        "cs.CR",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2202.03407v2": {
      "title": "Investigating the fidelity of explainable artificial intelligence methods for applications of convolutional neural networks in geoscience",
      "authors": [
        "Antonios Mamalakis",
        "Elizabeth A. Barnes",
        "Imme Ebert-Uphoff"
      ],
      "abstract": "Convolutional neural networks (CNNs) have recently attracted great attention\nin geoscience due to their ability to capture non-linear system behavior and\nextract predictive spatiotemporal patterns. Given their black-box nature\nhowever, and the importance of prediction explainability, methods of\nexplainable artificial intelligence (XAI) are gaining popularity as a means to\nexplain the CNN decision-making strategy. Here, we establish an intercomparison\nof some of the most popular XAI methods and investigate their fidelity in\nexplaining CNN decisions for geoscientific applications. Our goal is to raise\nawareness of the theoretical limitations of these methods and gain insight into\nthe relative strengths and weaknesses to help guide best practices. The\nconsidered XAI methods are first applied to an idealized attribution benchmark,\nwhere the ground truth of explanation of the network is known a priori, to help\nobjectively assess their performance. Secondly, we apply XAI to a\nclimate-related prediction setting, namely to explain a CNN that is trained to\npredict the number of atmospheric rivers in daily snapshots of climate\nsimulations. Our results highlight several important issues of XAI methods\n(e.g., gradient shattering, inability to distinguish the sign of attribution,\nignorance to zero input) that have previously been overlooked in our field and,\nif not considered cautiously, may lead to a distorted picture of the CNN\ndecision-making strategy. We envision that our analysis will motivate further\ninvestigation into XAI fidelity and will help towards a cautious implementation\nof XAI in geoscience, which can lead to further exploitation of CNNs and deep\nlearning for prediction problems.",
      "citation_count": 64,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/15e794037c5025f8d57b9e92e6ee0dee296e7403",
      "published_date": "2022-02-07",
      "downloaded_date": "2025-01-31",
      "filename": "Mamalakis-Investigating the fidelity of explainable artificial intelligence methods for applications of convol....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.03407v2",
      "categories": [
        "physics.geo-ph",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2411.05026v2": {
      "title": "Deep Learning and Machine Learning -- Natural Language Processing: From Theory to Application",
      "authors": [
        "Keyu Chen",
        "Cheng Fei",
        "Ziqian Bi",
        "Junyu Liu",
        "Benji Peng",
        "Sen Zhang",
        "Xuanhe Pan",
        "Jiawei Xu",
        "Jinlang Wang",
        "Caitlyn Heqi Yin",
        "Yichao Zhang",
        "Pohsun Feng",
        "Yizhu Wen",
        "Tianyang Wang",
        "Ming Li",
        "Jintao Ren",
        "Qian Niu",
        "Silin Chen",
        "Weiche Hsieh",
        "Lawrence K. Q. Yan",
        "Chia Xin Liang",
        "Han Xu",
        "Hong-Ming Tseng",
        "Xinyuan Song",
        "Ming Liu"
      ],
      "abstract": "With a focus on natural language processing (NLP) and the role of large\nlanguage models (LLMs), we explore the intersection of machine learning, deep\nlearning, and artificial intelligence. As artificial intelligence continues to\nrevolutionize fields from healthcare to finance, NLP techniques such as\ntokenization, text classification, and entity recognition are essential for\nprocessing and understanding human language. This paper discusses advanced data\npreprocessing techniques and the use of frameworks like Hugging Face for\nimplementing transformer-based models. Additionally, it highlights challenges\nsuch as handling multilingual data, reducing bias, and ensuring model\nrobustness. By addressing key aspects of data processing and model fine-tuning,\nthis work aims to provide insights into deploying effective and ethically sound\nAI solutions.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-10-30",
      "downloaded_date": "2025-01-31",
      "filename": "Chen-Deep Learning and Machine Learning -- Natural Language Processing From Theory to Application.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.05026v2",
      "categories": [
        "cs.CL",
        "cs.HC"
      ]
    },
    "2107.10715v1": {
      "title": "Philosophical Specification of Empathetic Ethical Artificial Intelligence",
      "authors": [
        "Michael Timothy Bennett",
        "Yoshihiro Maruyama"
      ],
      "abstract": "In order to construct an ethical artificial intelligence (AI) two complex\nproblems must be overcome. Firstly, humans do not consistently agree on what is\nor is not ethical. Second, contemporary AI and machine learning methods tend to\nbe blunt instruments which either search for solutions within the bounds of\npredefined rules, or mimic behaviour. An ethical AI must be capable of\ninferring unspoken rules, interpreting nuance and context, possess and be able\nto infer intent, and explain not just its actions but its intent. Using\nenactivism, semiotics, perceptual symbol systems and symbol emergence, we\nspecify an agent that learns not just arbitrary relations between signs but\ntheir meaning in terms of the perceptual states of its sensorimotor system.\nSubsequently it can learn what is meant by a sentence and infer the intent of\nothers in terms of its own experiences. It has malleable intent because the\nmeaning of symbols changes as it learns, and its intent is represented\nsymbolically as a goal. As such it may learn a concept of what is most likely\nto be considered ethical by the majority within a population of humans, which\nmay then be used as a goal. The meaning of abstract symbols is expressed using\nperceptual symbols of raw sensorimotor stimuli as the weakest (consistent with\nOckham's Razor) necessary and sufficient concept, an intensional definition\nlearned from an ostensive definition, from which the extensional definition or\ncategory of all ethical decisions may be obtained. Because these abstract\nsymbols are the same for both situation and response, the same symbol is used\nwhen either performing or observing an action. This is akin to mirror neurons\nin the human brain. Mirror symbols may allow the agent to empathise, because\nits own experiences are associated with the symbol, which is also associated\nwith the observation of another agent experiencing something that symbol\nrepresents.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d874d9f80b862d44ab841e1c87bc774fb7282907",
      "published_date": "2021-07-22",
      "downloaded_date": "2025-01-31",
      "filename": "Bennett-Philosophical Specification of Empathetic Ethical Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.10715v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2412.14056v1": {
      "title": "A Review of Multimodal Explainable Artificial Intelligence: Past, Present and Future",
      "authors": [
        "Shilin Sun",
        "Wenbin An",
        "Feng Tian",
        "Fang Nan",
        "Qidong Liu",
        "Jun Liu",
        "Nazaraf Shah",
        "Ping Chen"
      ],
      "abstract": "Artificial intelligence (AI) has rapidly developed through advancements in\ncomputational power and the growth of massive datasets. However, this progress\nhas also heightened challenges in interpreting the \"black-box\" nature of AI\nmodels. To address these concerns, eXplainable AI (XAI) has emerged with a\nfocus on transparency and interpretability to enhance human understanding and\ntrust in AI decision-making processes. In the context of multimodal data fusion\nand complex reasoning scenarios, the proposal of Multimodal eXplainable AI\n(MXAI) integrates multiple modalities for prediction and explanation tasks.\nMeanwhile, the advent of Large Language Models (LLMs) has led to remarkable\nbreakthroughs in natural language processing, yet their complexity has further\nexacerbated the issue of MXAI. To gain key insights into the development of\nMXAI methods and provide crucial guidance for building more transparent, fair,\nand trustworthy AI systems, we review the MXAI methods from a historical\nperspective and categorize them across four eras: traditional machine learning,\ndeep learning, discriminative foundation models, and generative LLMs. We also\nreview evaluation metrics and datasets used in MXAI research, concluding with a\ndiscussion of future challenges and directions. A project related to this\nreview has been created at https://github.com/ShilinSun/mxai_review.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6c6ee9986b06cad886ef8e534336a19a21fc6b2c",
      "published_date": "2024-12-18",
      "downloaded_date": "2025-01-31",
      "filename": "Sun-A Review of Multimodal Explainable Artificial Intelligence Past Present and Future.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.14056v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ]
    },
    "2312.03555v2": {
      "title": "Enabling Edge Artificial Intelligence via Goal-oriented Deep Neural Network Splitting",
      "authors": [
        "Francesco Binucci",
        "Mattia Merluzzi",
        "Paolo Banelli",
        "Emilio Calvanese Strinati",
        "Paolo Di Lorenzo"
      ],
      "abstract": "Deep Neural Network (DNN) splitting is one of the key enablers of edge\nArtificial Intelligence (AI), as it allows end users to pre-process data and\noffload part of the computational burden to nearby Edge Cloud Servers (ECSs).\nThis opens new opportunities and degrees of freedom in balancing energy\nconsumption, delay, accuracy, privacy, and other trustworthiness metrics. In\nthis work, we explore the opportunity of DNN splitting at the edge of 6G\nwireless networks to enable low energy cooperative inference with target delay\nand accuracy with a goal-oriented perspective. Going beyond the current\nliterature, we explore new trade-offs that take into account the accuracy\ndegradation as a function of the Splitting Point (SP) selection and wireless\nchannel conditions. Then, we propose an algorithm that dynamically controls SP\nselection, local computing resources, uplink transmit power and bandwidth\nallocation, in a goal-oriented fashion, to meet a target goal-effectiveness. To\nthe best of our knowledge, this is the first work proposing adaptive SP\nselection on the basis of all learning performance (i.e., energy, delay,\naccuracy), with the aim of guaranteeing the accomplishment of a goal (e.g.,\nminimize the energy consumption under latency and accuracy constraints).\nNumerical results show the advantages of the proposed SP selection and resource\nallocation, to enable energy frugal and effective edge AI.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/273cce033f4a6bee3be05324f5f107cd6aeb26b6",
      "published_date": "2023-12-06",
      "downloaded_date": "2025-01-31",
      "filename": "Binucci-Enabling Edge Artificial Intelligence via Goal-oriented Deep Neural Network Splitting.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.03555v2",
      "categories": [
        "eess.SP"
      ]
    },
    "2104.01375v2": {
      "title": "Evaluating explainable artificial intelligence methods for multi-label deep learning classification tasks in remote sensing",
      "authors": [
        "Ioannis Kakogeorgiou",
        "Konstantinos Karantzalos"
      ],
      "abstract": "Although deep neural networks hold the state-of-the-art in several remote\nsensing tasks, their black-box operation hinders the understanding of their\ndecisions, concealing any bias and other shortcomings in datasets and model\nperformance. To this end, we have applied explainable artificial intelligence\n(XAI) methods in remote sensing multi-label classification tasks towards\nproducing human-interpretable explanations and improve transparency. In\nparticular, we utilized and trained deep learning models with state-of-the-art\nperformance in the benchmark BigEarthNet and SEN12MS datasets. Ten XAI methods\nwere employed towards understanding and interpreting models' predictions, along\nwith quantitative metrics to assess and compare their performance. Numerous\nexperiments were performed to assess the overall performance of XAI methods for\nstraightforward prediction cases, competing multiple labels, as well as\nmisclassification cases. According to our findings, Occlusion, Grad-CAM and\nLime were the most interpretable and reliable XAI methods. However, none\ndelivers high-resolution outputs, while apart from Grad-CAM, both Lime and\nOcclusion are computationally expensive. We also highlight different aspects of\nXAI performance and elaborate with insights on black-box decisions in order to\nimprove transparency, understand their behavior and reveal, as well, datasets'\nparticularities.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-04-03",
      "downloaded_date": "2025-01-31",
      "filename": "Kakogeorgiou-Evaluating explainable artificial intelligence methods for multi-label deep learning classification ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.01375v2",
      "categories": [
        "cs.LG",
        "cs.CV"
      ]
    },
    "2312.07901v1": {
      "title": "Artificial Intelligence Studies in Cartography: A Review and Synthesis of Methods, Applications, and Ethics",
      "authors": [
        "Yuhao Kang",
        "Song Gao",
        "Robert E. Roth"
      ],
      "abstract": "The past decade has witnessed the rapid development of geospatial artificial\nintelligence (GeoAI) primarily due to the ground-breaking achievements in deep\nlearning and machine learning. A growing number of scholars from cartography\nhave demonstrated successfully that GeoAI can accelerate previously complex\ncartographic design tasks and even enable cartographic creativity in new ways.\nDespite the promise of GeoAI, researchers and practitioners have growing\nconcerns about the ethical issues of GeoAI for cartography. In this paper, we\nconducted a systematic content analysis and narrative synthesis of research\nstudies integrating GeoAI and cartography to summarize current research and\ndevelopment trends regarding the usage of GeoAI for cartographic design. Based\non this review and synthesis, we first identify dimensions of GeoAI methods for\ncartography such as data sources, data formats, map evaluations, and six\ncontemporary GeoAI models, each of which serves a variety of cartographic\ntasks. These models include decision trees, knowledge graph and semantic web\ntechnologies, deep convolutional neural networks, generative adversarial\nnetworks, graph neural networks, and reinforcement learning. Further, we\nsummarize seven cartographic design applications where GeoAI have been\neffectively employed: generalization, symbolization, typography, map reading,\nmap interpretation, map analysis, and map production. We also raise five\npotential ethical challenges that need to be addressed in the integration of\nGeoAI for cartography: commodification, responsibility, privacy, bias, and\n(together) transparency, explainability, and provenance. We conclude by\nidentifying four potential research directions for future cartographic research\nwith GeoAI: GeoAI-enabled active cartographic symbolism, human-in-the-loop\nGeoAI for cartography, GeoAI-based mapping-as-a-service, and generative GeoAI\nfor cartography.",
      "citation_count": 15,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7327f152502e8d7a80989772deace698410afaf0",
      "published_date": "2023-12-13",
      "downloaded_date": "2025-01-31",
      "filename": "Kang-Artificial Intelligence Studies in Cartography A Review and Synthesis of Methods Applications and Et....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.07901v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.GR"
      ]
    },
    "2305.14370v1": {
      "title": "A Survey on the Role of Artificial Intelligence in the Prediction and Diagnosis of Schizophrenia",
      "authors": [
        "Narges Ramesh",
        "Yasmin Ghodsi",
        "Hamidreza Bolhasani"
      ],
      "abstract": "Machine learning is employed in healthcare to draw approximate conclusions\nregarding human diseases and mental health problems. Compared to older\ntraditional methods, it can help to analyze data more efficiently and produce\nbetter and more dependable results. Millions of people are affected by\nschizophrenia, which is a chronic mental disorder that can significantly impact\ntheir lives. Many machine learning algorithms have been developed to predict\nand prevent this disease, and they can potentially be implemented in the\ndiagnosis of individuals who have it. This survey aims to review papers that\nhave focused on the use of deep learning to detect and predict schizophrenia\nusing EEG signals, functional magnetic resonance imaging (fMRI), and diffusion\nmagnetic resonance imaging (dMRI). With our chosen search strategy, we assessed\nten publications from 2019 to 2022. All studies achieved successful predictions\nof more than 80%. This review provides summaries of the studies and compares\ntheir notable aspects. In the field of artificial intelligence (AI) and machine\nlearning (ML) for schizophrenia, significant advances have been made due to the\navailability of ML tools, and we are optimistic that this field will continue\nto grow.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/34c625f3d76a5a1849d692f6365fd11a5f8472e4",
      "published_date": "2023-05-19",
      "downloaded_date": "2025-01-31",
      "filename": "Ramesh-A Survey on the Role of Artificial Intelligence in the Prediction and Diagnosis of Schizophrenia.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.14370v1",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2405.04189v1": {
      "title": "Artificial Intelligence-powered fossil shark tooth identification: Unleashing the potential of Convolutional Neural Networks",
      "authors": [
        "Andrea Barucci",
        "Giulia Ciacci",
        "Pietro LiÃ²",
        "Tiago Azevedo",
        "Andrea Di Cencio",
        "Marco Merella",
        "Giovanni Bianucci",
        "Giulia Bosio",
        "Simone Casati",
        "Alberto Collareta"
      ],
      "abstract": "All fields of knowledge are being impacted by Artificial Intelligence. In\nparticular, the Deep Learning paradigm enables the development of data analysis\ntools that support subject matter experts in a variety of sectors, from physics\nup to the recognition of ancient languages. Palaeontology is now observing this\ntrend as well. This study explores the capability of Convolutional Neural\nNetworks (CNNs), a particular class of Deep Learning algorithms specifically\ncrafted for computer vision tasks, to classify images of isolated fossil shark\nteeth gathered from online datasets as well as from the authors$'$ experience\non Peruvian Miocene and Italian Pliocene fossil assemblages. The shark taxa\nthat are included in the final, composite dataset (which consists of more than\none thousand images) are representative of both extinct and extant genera,\nnamely, Carcharhinus, Carcharias, Carcharocles, Chlamydoselachus,\nCosmopolitodus, Galeocerdo, Hemipristis, Notorynchus, Prionace and Squatina. We\ndeveloped a CNN, named SharkNet-X, specifically tailored on our recognition\ntask, reaching a 5-fold cross validated mean accuracy of 0.85 to identify\nimages containing a single shark tooth. Furthermore, we elaborated a\nvisualization of the features extracted from images using the last dense layer\nof the CNN, achieved through the application of the clustering technique t-SNE.\nIn addition, in order to understand and explain the behaviour of the CNN while\ngiving a paleontological point of view on the results, we introduced the\nexplainability method SHAP. To the best of our knowledge, this is the first\ninstance in which this method is applied to the field of palaeontology. The\nmain goal of this work is to showcase how Deep Learning techniques can aid in\nidentifying isolated fossil shark teeth, paving the way for developing new\ninformation tools for automating the recognition and classification of fossils.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f4f566e141211a5611ee64d8610bbbd9aa41c20e",
      "published_date": "2024-05-07",
      "downloaded_date": "2025-01-31",
      "filename": "Barucci-Artificial Intelligence-powered fossil shark tooth identification Unleashing the potential of Convol....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.04189v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2309.14383v1": {
      "title": "Towards using Cough for Respiratory Disease Diagnosis by leveraging Artificial Intelligence: A Survey",
      "authors": [
        "Aneeqa Ijaz",
        "Muhammad Nabeel",
        "Usama Masood",
        "Tahir Mahmood",
        "Mydah Sajid Hashmi",
        "Iryna Posokhova",
        "Ali Rizwan",
        "Ali Imran"
      ],
      "abstract": "Cough acoustics contain multitudes of vital information about\npathomorphological alterations in the respiratory system. Reliable and accurate\ndetection of cough events by investigating the underlying cough latent features\nand disease diagnosis can play an indispensable role in revitalizing the\nhealthcare practices. The recent application of Artificial Intelligence (AI)\nand advances of ubiquitous computing for respiratory disease prediction has\ncreated an auspicious trend and myriad of future possibilities in the medical\ndomain. In particular, there is an expeditiously emerging trend of Machine\nlearning (ML) and Deep Learning (DL)-based diagnostic algorithms exploiting\ncough signatures. The enormous body of literature on cough-based AI algorithms\ndemonstrate that these models can play a significant role for detecting the\nonset of a specific respiratory disease. However, it is pertinent to collect\nthe information from all relevant studies in an exhaustive manner for the\nmedical experts and AI scientists to analyze the decisive role of AI/ML. This\nsurvey offers a comprehensive overview of the cough data-driven ML/DL detection\nand preliminary diagnosis frameworks, along with a detailed list of significant\nfeatures. We investigate the mechanism that causes cough and the latent cough\nfeatures of the respiratory modalities. We also analyze the customized cough\nmonitoring application, and their AI-powered recognition algorithms. Challenges\nand prospective future research directions to develop practical, robust, and\nubiquitous solutions are also discussed in detail.",
      "citation_count": 49,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2b16dd5e553ccb1ca2214f17eb87b6a8236f1fd2",
      "published_date": "2023-09-24",
      "downloaded_date": "2025-01-31",
      "filename": "Ijaz-Towards using Cough for Respiratory Disease Diagnosis by leveraging Artificial Intelligence A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.14383v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ]
    },
    "2206.11233v3": {
      "title": "Automatic autism spectrum disorder detection using artificial intelligence methods with MRI neuroimaging: A review",
      "authors": [
        "Parisa Moridian",
        "Navid Ghassemi",
        "Mahboobeh Jafari",
        "Salam Salloum-Asfar",
        "Delaram Sadeghi",
        "Marjane Khodatars",
        "Afshin Shoeibi",
        "Abbas Khosravi",
        "Sai Ho Ling",
        "Abdulhamit Subasi",
        "Roohallah Alizadehsani",
        "Juan M. Gorriz",
        "Sara A Abdulla",
        "U. Rajendra Acharya"
      ],
      "abstract": "Autism spectrum disorder (ASD) is a brain condition characterized by diverse\nsigns and symptoms that appear in early childhood. ASD is also associated with\ncommunication deficits and repetitive behavior in affected individuals. Various\nASD detection methods have been developed, including neuroimaging modalities\nand psychological tests. Among these methods, magnetic resonance imaging (MRI)\nimaging modalities are of paramount importance to physicians. Clinicians rely\non MRI modalities to diagnose ASD accurately. The MRI modalities are\nnon-invasive methods that include functional (fMRI) and structural (sMRI)\nneuroimaging methods. However, diagnosing ASD with fMRI and sMRI for\nspecialists is often laborious and time-consuming; therefore, several\ncomputer-aided design systems (CADS) based on artificial intelligence (AI) have\nbeen developed to assist specialist physicians. Conventional machine learning\n(ML) and deep learning (DL) are the most popular schemes of AI used for\ndiagnosing ASD. This study aims to review the automated detection of ASD using\nAI. We review several CADS that have been developed using ML techniques for the\nautomated diagnosis of ASD using MRI modalities. There has been very limited\nwork on the use of DL techniques to develop automated diagnostic models for\nASD. A summary of the studies developed using DL is provided in the\nSupplementary Appendix. Then, the challenges encountered during the automated\ndiagnosis of ASD using MRI and AI techniques are described in detail.\nAdditionally, a graphical comparison of studies using ML and DL to diagnose ASD\nautomatically is discussed. We suggest future approaches to detecting ASDs\nusing AI techniques and MRI neuroimaging.",
      "citation_count": 56,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7d8d989194afb78158206b9803907e2c0bd228bb",
      "published_date": "2022-06-20",
      "downloaded_date": "2025-01-31",
      "filename": "Moridian-Automatic autism spectrum disorder detection using artificial intelligence methods with MRI neuroima....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.11233v3",
      "categories": [
        "q-bio.NC",
        "cs.LG",
        "eess.IV"
      ]
    },
    "2311.05665v1": {
      "title": "Explainable artificial intelligence for Healthcare applications using Random Forest Classifier with LIME and SHAP",
      "authors": [
        "Mrutyunjaya Panda",
        "Soumya Ranjan Mahanta"
      ],
      "abstract": "With the advances in computationally efficient artificial Intelligence (AI)\ntechniques and their numerous applications in our everyday life, there is a\npressing need to understand the computational details hidden in black box AI\ntechniques such as most popular machine learning and deep learning techniques;\nthrough more detailed explanations. The origin of explainable AI (xAI) is\ncoined from these challenges and recently gained more attention by the\nresearchers by adding explainability comprehensively in traditional AI systems.\nThis leads to develop an appropriate framework for successful applications of\nxAI in real life scenarios with respect to innovations, risk mitigation,\nethical issues and logical values to the users. In this book chapter, an\nin-depth analysis of several xAI frameworks and methods including LIME (Local\nInterpretable Model-agnostic Explanations) and SHAP (SHapley Additive\nexPlanations) are provided. Random Forest Classifier as black box AI is used on\na publicly available Diabetes symptoms dataset with LIME and SHAP for better\ninterpretations. The results obtained are interesting in terms of transparency,\nvalid and trustworthiness in diabetes disease prediction.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-11-09",
      "downloaded_date": "2025-01-31",
      "filename": "Panda-Explainable artificial intelligence for Healthcare applications using Random Forest Classifier with ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.05665v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2405.13082v4": {
      "title": "A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis",
      "authors": [
        "Haocong Rao",
        "Minlin Zeng",
        "Xuejiao Zhao",
        "Chunyan Miao"
      ],
      "abstract": "Recent years have witnessed an increasing global population affected by\nneurodegenerative diseases (NDs), which traditionally require extensive\nhealthcare resources and human effort for medical diagnosis and monitoring. As\na crucial disease-related motor symptom, human gait can be exploited to\ncharacterize different NDs. The current advances in artificial intelligence\n(AI) models enable automatic gait analysis for NDs identification and\nclassification, opening a new avenue to facilitate faster and more\ncost-effective diagnosis of NDs. In this paper, we provide a comprehensive\nsurvey on recent progress of machine learning and deep learning based AI\ntechniques applied to diagnosis of five typical NDs through gait. We provide an\noverview of the process of AI-assisted NDs diagnosis, and present a systematic\ntaxonomy of existing gait data and AI models. Meanwhile, a novel quality\nevaluation criterion is proposed to quantitatively assess the quality of\nexisting studies. Through an extensive review and analysis of 169 studies, we\npresent recent technical advancements, discuss existing challenges, potential\nsolutions, and future directions in this field. Finally, we envision the\nprospective utilization of 3D skeleton data for human gait representation and\nthe development of more efficient AI models for NDs diagnosis.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/dc3c5e42d714027610fe255228e9c2d87baa5720",
      "published_date": "2024-05-21",
      "downloaded_date": "2025-01-31",
      "filename": "Rao-A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.13082v4",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    "2006.13427v1": {
      "title": "Using Deep Learning and Explainable Artificial Intelligence in Patients' Choices of Hospital Levels",
      "authors": [
        "Lichin Chen",
        "Yu Tsao",
        "Ji-Tian Sheu"
      ],
      "abstract": "In countries that enabled patients to choose their own providers, a common\nproblem is that the patients did not make rational decisions, and hence, fail\nto use healthcare resources efficiently. This might cause problems such as\noverwhelming tertiary facilities with mild condition patients, thus limiting\ntheir capacity of treating acute and critical patients. To address such\nmaldistributed patient volume, it is essential to oversee patients choices\nbefore further evaluation of a policy or resource allocation. This study used\nnationwide insurance data, accumulated possible features discussed in existing\nliterature, and used a deep neural network to predict the patients choices of\nhospital levels. This study also used explainable artificial intelligence\nmethods to interpret the contribution of features for the general public and\nindividuals. In addition, we explored the effectiveness of changing data\nrepresentations. The results showed that the model was able to predict with\nhigh area under the receiver operating characteristics curve (AUC) (0.90),\naccuracy (0.90), sensitivity (0.94), and specificity (0.97) with highly\nimbalanced label. Generally, social approval of the provider by the general\npublic (positive or negative) and the number of practicing physicians serving\nper ten thousand people of the located area are listed as the top effecting\nfeatures. The changing data representation had a positive effect on the\nprediction improvement. Deep learning methods can process highly imbalanced\ndata and achieve high accuracy. The effecting features affect the general\npublic and individuals differently. Addressing the sparsity and discrete nature\nof insurance data leads to better prediction. Applications using deep learning\ntechnology are promising in health policy making. More work is required to\ninterpret models and practice implementation.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c8c57dd2b8c2a4636719778d49148ad97289d31f",
      "published_date": "2020-06-24",
      "downloaded_date": "2025-01-31",
      "filename": "Chen-Using Deep Learning and Explainable Artificial Intelligence in Patients Choices of Hospital Levels.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2006.13427v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2212.07058v1": {
      "title": "Explainable Artificial Intelligence in Retinal Imaging for the detection of Systemic Diseases",
      "authors": [
        "Ayushi Raj Bhatt",
        "Rajkumar Vaghashiya",
        "Meghna Kulkarni",
        "Dr Prakash Kamaraj"
      ],
      "abstract": "Explainable Artificial Intelligence (AI) in the form of an interpretable and\nsemiautomatic approach to stage grading ocular pathologies such as Diabetic\nretinopathy, Hypertensive retinopathy, and other retinopathies on the backdrop\nof major systemic diseases. The experimental study aims to evaluate an\nexplainable staged grading process without using deep Convolutional Neural\nNetworks (CNNs) directly. Many current CNN-based deep neural networks used for\ndiagnosing retinal disorders might have appreciable performance but fail to\npinpoint the basis driving their decisions. To improve these decisions'\ntransparency, we have proposed a clinician-in-the-loop assisted intelligent\nworkflow that performs a retinal vascular assessment on the fundus images to\nderive quantifiable and descriptive parameters. The retinal vessel parameters\nmeta-data serve as hyper-parameters for better interpretation and\nexplainability of decisions. The semiautomatic methodology aims to have a\nfederated approach to AI in healthcare applications with more inputs and\ninterpretations from clinicians. The baseline process involved in the machine\nlearning pipeline through image processing techniques for optic disc detection,\nvessel segmentation, and arteriole/venule identification.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d43ee04705a4181147980af6698ace0faee0486e",
      "published_date": "2022-12-14",
      "downloaded_date": "2025-01-31",
      "filename": "Bhatt-Explainable Artificial Intelligence in Retinal Imaging for the detection of Systemic Diseases.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.07058v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2202.00132v2": {
      "title": "Submodularity In Machine Learning and Artificial Intelligence",
      "authors": [
        "Jeff Bilmes"
      ],
      "abstract": "In this manuscript, we offer a gentle review of submodularity and\nsupermodularity and their properties. We offer a plethora of submodular\ndefinitions; a full description of a number of example submodular functions and\ntheir generalizations; example discrete constraints; a discussion of basic\nalgorithms for maximization, minimization, and other operations; a brief\noverview of continuous submodular extensions; and some historical applications.\nWe then turn to how submodularity is useful in machine learning and artificial\nintelligence. This includes summarization, and we offer a complete account of\nthe differences between and commonalities amongst sketching, coresets,\nextractive and abstractive summarization in NLP, data distillation and\ncondensation, and data subset selection and feature selection. We discuss a\nvariety of ways to produce a submodular function useful for machine learning,\nincluding heuristic hand-crafting, learning or approximately learning a\nsubmodular function or aspects thereof, and some advantages of the use of a\nsubmodular function as a coreset producer. We discuss submodular combinatorial\ninformation functions, and how submodularity is useful for clustering, data\npartitioning, parallel machine learning, active and semi-supervised learning,\nprobabilistic modeling, and structured norms and loss functions.",
      "citation_count": 49,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4f789ee52aaeac38123af0f957f841d40db34f0b",
      "published_date": "2022-01-31",
      "downloaded_date": "2025-02-01",
      "filename": "Bilmes-Submodularity In Machine Learning and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.00132v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2410.05577v1": {
      "title": "Underwater Object Detection in the Era of Artificial Intelligence: Current, Challenge, and Future",
      "authors": [
        "Long Chen",
        "Yuzhi Huang",
        "Junyu Dong",
        "Qi Xu",
        "Sam Kwong",
        "Huimin Lu",
        "Huchuan Lu",
        "Chongyi Li"
      ],
      "abstract": "Underwater object detection (UOD), aiming to identify and localise the\nobjects in underwater images or videos, presents significant challenges due to\nthe optical distortion, water turbidity, and changing illumination in\nunderwater scenes. In recent years, artificial intelligence (AI) based methods,\nespecially deep learning methods, have shown promising performance in UOD. To\nfurther facilitate future advancements, we comprehensively study AI-based UOD.\nIn this survey, we first categorise existing algorithms into traditional\nmachine learning-based methods and deep learning-based methods, and summarise\nthem by considering learning strategy, experimental dataset, utilised features\nor frameworks, and learning stage. Next, we discuss the potential challenges\nand suggest possible solutions and new directions. We also perform both\nquantitative and qualitative evaluations of mainstream algorithms across\nmultiple benchmark datasets by considering the diverse and biased experimental\nsetups. Finally, we introduce two off-the-shelf detection analysis tools,\nDiagnosis and TIDE, which well-examine the effects of object characteristics\nand various types of errors on detectors. These tools help identify the\nstrengths and weaknesses of detectors, providing insigts for further\nimprovement. The source codes, trained models, utilised datasets, detection\nresults, and detection analysis tools are public available at\n\\url{https://github.com/LongChenCV/UODReview}, and will be regularly updated.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9eb44d46ca8a083898b4d46399e693dcb92e7137",
      "published_date": "2024-10-08",
      "downloaded_date": "2025-02-01",
      "filename": "Chen-Underwater Object Detection in the Era of Artificial Intelligence Current Challenge and Future.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.05577v1",
      "categories": [
        "cs.CV"
      ]
    },
    "1906.02090v2": {
      "title": "Artificial Intelligence in Clinical Health Care Applications: Viewpoint",
      "authors": [
        "Michael van Hartskamp",
        "Sergio Consoli",
        "Wim Verhaegh",
        "Milan PetkoviÄ",
        "Anja van de Stolpe"
      ],
      "abstract": "The idea of Artificial Intelligence (AI) has a long history. It turned out,\nhowever, that reaching intelligence at human levels is more complicated than\noriginally anticipated. Currently we are experiencing a renewed interest in AI,\nfueled by an enormous increase in computing power and an even larger increase\nin data, in combination with improved AI technologies like deep learning.\nHealthcare is considered the next domain to be revolutionized by Artificial\nIntelligence. While AI approaches are excellently suited to develop certain\nalgorithms, for biomedical applications there are specific challenges. We\npropose recommendations to improve AI projects in the biomedical space and\nespecially clinical healthcare.",
      "citation_count": 47,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4e9cf07116c726e4662ef9f124dfd00df2dfc918",
      "published_date": "2019-06-05",
      "downloaded_date": "2025-02-01",
      "filename": "Hartskamp-Artificial Intelligence in Clinical Health Care Applications Viewpoint.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1906.02090v2",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2101.01781v1": {
      "title": "A Review of Artificial Intelligence Technologies for Early Prediction of Alzheimer's Disease",
      "authors": [
        "Kuo Yang",
        "Emad A. Mohammed"
      ],
      "abstract": "Alzheimer's Disease (AD) is a severe brain disorder, destroying memories and\nbrain functions. AD causes chronically, progressively, and irreversibly\ncognitive declination and brain damages. The reliable and effective evaluation\nof early dementia has become essential research with medical imaging\ntechnologies and computer-aided algorithms. This trend has moved to modern\nArtificial Intelligence (AI) technologies motivated by deeplearning success in\nimage classification and natural language processing. The purpose of this\nreview is to provide an overview of the latest research involving deep-learning\nalgorithms in evaluating the process of dementia, diagnosing the early stage of\nAD, and discussing an outlook for this research. This review introduces various\napplications of modern AI algorithms in AD diagnosis, including Convolutional\nNeural Network (CNN), Recurrent Neural Network (RNN), Automatic Image\nSegmentation, Autoencoder, Graph CNN (GCN), Ensemble Learning, and Transfer\nLearning. The advantages and disadvantages of the proposed methods and their\nperformance are discussed. The conclusion section summarizes the primary\ncontributions and medical imaging preprocessing techniques applied in the\nreviewed research. Finally, we discuss the limitations and future outlooks.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/656568f92cda5792598a051550557eda55d94271",
      "published_date": "2020-12-22",
      "downloaded_date": "2025-02-01",
      "filename": "Yang-A Review of Artificial Intelligence Technologies for Early Prediction of Alzheimers Disease.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.01781v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2002.06177v3": {
      "title": "The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",
      "authors": [
        "Gary Marcus"
      ],
      "abstract": "Recent research in artificial intelligence and machine learning has largely\nemphasized general-purpose learning and ever-larger training sets and more and\nmore compute. In contrast, I propose a hybrid, knowledge-driven,\nreasoning-based approach, centered around cognitive models, that could provide\nthe substrate for a richer, more robust AI than is currently possible.",
      "citation_count": 327,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/97d69e7e8c04714bf58dcbe5ae7454db69b657a7",
      "published_date": "2020-02-14",
      "downloaded_date": "2025-02-01",
      "filename": "Marcus-The Next Decade in AI Four Steps Towards Robust Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2002.06177v3",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2; I.2.6"
      ]
    },
    "1810.02689v2": {
      "title": "Hows and Whys of Artificial Intelligence for Public Sector Decisions: Explanation and Evaluation",
      "authors": [
        "Alun Preece",
        "Rob Ashelford",
        "Harry Armstrong",
        "Dave Braines"
      ],
      "abstract": "Evaluation has always been a key challenge in the development of artificial\nintelligence (AI) based software, due to the technical complexity of the\nsoftware artifact and, often, its embedding in complex sociotechnical\nprocesses. Recent advances in machine learning (ML) enabled by deep neural\nnetworks has exacerbated the challenge of evaluating such software due to the\nopaque nature of these ML-based artifacts. A key related issue is the\n(in)ability of such systems to generate useful explanations of their outputs,\nand we argue that the explanation and evaluation problems are closely linked.\nThe paper models the elements of a ML-based AI system in the context of public\nsector decision (PSD) applications involving both artificial and human\nintelligence, and maps these elements against issues in both evaluation and\nexplanation, showing how the two are related. We consider a number of common\nPSD application patterns in the light of our model, and identify a set of key\nissues connected to explanation and evaluation in each case. Finally, we\npropose multiple strategies to promote wider adoption of AI/ML technologies in\nPSD, where each is distinguished by a focus on different elements of our model,\nallowing PSD policy makers to adopt an approach that best fits their context\nand concerns.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/185312818a973bbc2b346b7f0e72fb7743ebe326",
      "published_date": "2018-09-28",
      "downloaded_date": "2025-02-01",
      "filename": "Preece-Hows and Whys of Artificial Intelligence for Public Sector Decisions Explanation and Evaluation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1810.02689v2",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2501.15838v1": {
      "title": "CrySPAI: A new Crystal Structure Prediction Software Based on Artificial Intelligence",
      "authors": [
        "Zongguo Wang",
        "Ziyi Chen",
        "Yang Yuan",
        "Yangang Wang"
      ],
      "abstract": "Crystal structure predictions based on the combination of first-principles\ncalculations and machine learning have achieved significant success in\nmaterials science. However, most of these approaches are limited to predicting\nspecific systems, which hinders their application to unknown or unexplored\ndomains. In this paper, we present CrySPAI, a crystal structure prediction\npackage developed using artificial intelligence (AI) to predict energetically\nstable crystal structures of inorganic materials given their chemical\ncompositions. The software consists of three key modules, an evolutionary\noptimization algorithm (EOA) that searches for all possible crystal structure\nconfigurations, density functional theory (DFT) that provides the accurate\nenergy values for these structures, and a deep neural network (DNN) that learns\nthe relationship between crystal structures and their corresponding energies.\nTo optimize the process across these modules, a distributed framework is\nimplemented to parallelize tasks, and an automated workflow has been integrated\ninto CrySPAI for seamless execution. This paper reports the development and\nimplementation of AI AI-based CrySPAI Crystal Prediction Software tool and its\nunique features.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cc7f382c4ee4ab93cab2b28a10143446adc0d390",
      "published_date": "2025-01-27",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-CrySPAI A new Crystal Structure Prediction Software Based on Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.15838v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ]
    },
    "2311.15807v1": {
      "title": "Exploring Artificial Intelligence Methods for Energy Prediction in Healthcare Facilities: An In-Depth Extended Systematic Review",
      "authors": [
        "Marjan FatehiJananloo",
        "Helen Stopps",
        "J. J. McArthur"
      ],
      "abstract": "Hospitals, due to their complexity and unique requirements, play a pivotal\nrole in global energy consumption patterns. This study conducted a\ncomprehensive literature review, utilizing the PRISMA framework, of articles\nthat employed machine learning and artificial intelligence techniques for\npredicting energy consumption in hospital buildings. Of the 1884 publications\nidentified, 17 were found to address this specific domain and have been\nthoroughly reviewed to establish the state-of-the-art and identify gaps where\nfuture research is needed. This review revealed a diverse range of data inputs\ninfluencing energy prediction, with occupancy and meteorological data emerging\nas significant predictors. However, many studies failed to delve deep into the\nimplications of their data choices, and gaps were evident regarding the\nunderstanding of time dynamics, operational status, and preprocessing methods.\nMachine learning, especially deep learning models like ANNs, have shown\npotential in this domain, yet they come with challenges, including\ninterpretability and computational demands. The findings underscore the immense\npotential of AI in optimizing hospital energy consumption but also highlight\nthe need for more comprehensive and granular research. Key areas for future\nresearch include the optimization of ANN approaches, new optimization and data\nintegration techniques, the integration of real-time data into Intelligent\nEnergy Management Systems, and increasing focus on long-term energy\nforecasting.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a498113397775669c5debd50c331b985d43b9b3d",
      "published_date": "2023-11-27",
      "downloaded_date": "2025-02-01",
      "filename": "FatehiJananloo-Exploring Artificial Intelligence Methods for Energy Prediction in Healthcare Facilities An In-Depth....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.15807v1",
      "categories": [
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "A.1; I.2; J.2"
      ]
    },
    "2202.11452v3": {
      "title": "Deep Learning Reproducibility and Explainable AI (XAI)",
      "authors": [
        "A. -M. Leventi-Peetz",
        "T. Ãstreich"
      ],
      "abstract": "The nondeterminism of Deep Learning (DL) training algorithms and its\ninfluence on the explainability of neural network (NN) models are investigated\nin this work with the help of image classification examples. To discuss the\nissue, two convolutional neural networks (CNN) have been trained and their\nresults compared. The comparison serves the exploration of the feasibility of\ncreating deterministic, robust DL models and deterministic explainable\nartificial intelligence (XAI) in practice. Successes and limitation of all here\ncarried out efforts are described in detail. The source code of the attained\ndeterministic models has been listed in this work. Reproducibility is indexed\nas a development-phase-component of the Model Governance Framework, proposed by\nthe EU within their excellence in AI approach. Furthermore, reproducibility is\na requirement for establishing causality for the interpretation of model\nresults and building of trust towards the overwhelming expansion of AI systems\napplications. Problems that have to be solved on the way to reproducibility and\nways to deal with some of them, are examined in this work.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6a1beca93452b40339ac27e1107a140318e4c787",
      "published_date": "2022-02-23",
      "downloaded_date": "2025-02-01",
      "filename": "Leventi-Peetz-Deep Learning Reproducibility and Explainable AI XAI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.11452v3",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2405.07657v1": {
      "title": "Beyond traditional Magnetic Resonance processing with Artificial Intelligence",
      "authors": [
        "Amir Jahangiri",
        "Vladislav Orekhov"
      ],
      "abstract": "Smart signal processing approaches using Artificial Intelligence are gaining\nmomentum in NMR applications. In this study, we demonstrate that AI offers new\nopportunities beyond tasks addressed by traditional techniques. We developed\nand trained several artificial neural networks in our new toolbox Magnetic\nResonance with Artificial intelligence (MR-Ai) to solve three \"impossible\"\nproblems: quadrature detection using only Echo (or Anti-Echo) modulation from\nthe traditional Echo/Anti-Echo scheme; accessing uncertainty of signal\nintensity at each point in a spectrum processed by any given method; and\ndefining a reference-free score for quantitative access of NMR spectrum\nquality. Our findings highlight the potential of AI techniques to revolutionize\nNMR processing and analysis.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/33e168f34878ffc27a493ac46e87b09c9733fa01",
      "published_date": "2024-05-13",
      "downloaded_date": "2025-02-01",
      "filename": "Jahangiri-Beyond traditional Magnetic Resonance processing with Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.07657v1",
      "categories": [
        "physics.bio-ph",
        "cs.LG",
        "eess.SP"
      ]
    },
    "2103.15990v7": {
      "title": "An Overview of Human Activity Recognition Using Wearable Sensors: Healthcare and Artificial Intelligence",
      "authors": [
        "Rex Liu",
        "Albara Ah Ramli",
        "Huanle Zhang",
        "Erik Henricson",
        "Xin Liu"
      ],
      "abstract": "With the rapid development of the internet of things (IoT) and artificial\nintelligence (AI) technologies, human activity recognition (HAR) has been\napplied in a variety of domains such as security and surveillance, human-robot\ninteraction, and entertainment. Even though a number of surveys and review\npapers have been published, there is a lack of HAR overview papers focusing on\nhealthcare applications that use wearable sensors. Therefore, we fill in the\ngap by presenting this overview paper. In particular, we present our projects\nto illustrate the system design of HAR applications for healthcare. Our\nprojects include early mobility identification of human activities for\nintensive care unit (ICU) patients and gait analysis of Duchenne muscular\ndystrophy (DMD) patients. We cover essential components of designing HAR\nsystems including sensor factors (e.g., type, number, and placement location),\nAI model selection (e.g., classical machine learning models versus deep\nlearning models), and feature engineering. In addition, we highlight the\nchallenges of such healthcare-oriented HAR systems and propose several research\nopportunities for both the medical and the computer science community.",
      "citation_count": 41,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ddbf23d95ef88abf02d7baf0bb2e91496e6ccff9",
      "published_date": "2021-03-29",
      "downloaded_date": "2025-02-01",
      "filename": "Liu-An Overview of Human Activity Recognition Using Wearable Sensors Healthcare and Artificial Intellige....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.15990v7",
      "categories": [
        "cs.HC",
        "cs.LG",
        "eess.SP"
      ]
    },
    "2409.17516v1": {
      "title": "Functional Classification of Spiking Signal Data Using Artificial Intelligence Techniques: A Review",
      "authors": [
        "Danial Sharifrazi",
        "Nouman Javed",
        "Javad Hassannataj Joloudari",
        "Roohallah Alizadehsani",
        "Prasad N. Paradkar",
        "Ru-San Tan",
        "U. Rajendra Acharya",
        "Asim Bhatti"
      ],
      "abstract": "Human brain neuron activities are incredibly significant nowadays. Neuronal\nbehavior is assessed by analyzing signal data such as electroencephalography\n(EEG), which can offer scientists valuable information about diseases and\nhuman-computer interaction. One of the difficulties researchers confront while\nevaluating these signals is the existence of large volumes of spike data.\nSpikes are some considerable parts of signal data that can happen as a\nconsequence of vital biomarkers or physical issues such as electrode movements.\nHence, distinguishing types of spikes is important. From this spot, the spike\nclassification concept commences. Previously, researchers classified spikes\nmanually. The manual classification was not precise enough as it involves\nextensive analysis. Consequently, Artificial Intelligence (AI) was introduced\ninto neuroscience to assist clinicians in classifying spikes correctly. This\nreview discusses the importance and use of AI in spike classification, focusing\non the recognition of neural activity noises. The task is divided into three\nmain components: preprocessing, classification, and evaluation. Existing\nmethods are introduced and their importance is determined. The review also\nhighlights the need for more efficient algorithms. The primary goal is to\nprovide a perspective on spike classification for future research and provide a\ncomprehensive understanding of the methodologies and issues involved. The\nreview organizes materials in the spike classification field for future\nstudies. In this work, numerous studies were extracted from different\ndatabases. The PRISMA-related research guidelines were then used to choose\npapers. Then, research studies based on spike classification using machine\nlearning and deep learning approaches with effective preprocessing were\nselected.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6154c5798c925a8f8a6d5be22eb0b63d2b781181",
      "published_date": "2024-09-26",
      "downloaded_date": "2025-02-01",
      "filename": "Sharifrazi-Functional Classification of Spiking Signal Data Using Artificial Intelligence Techniques A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.17516v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ]
    },
    "2411.10486v1": {
      "title": "Artificial Intelligence for Infectious Disease Prediction and Prevention: A Comprehensive Review",
      "authors": [
        "Selestine Melchane",
        "Youssef Elmir",
        "Farid Kacimi",
        "Larbi Boubchir"
      ],
      "abstract": "Artificial Intelligence (AI) and infectious diseases prediction have recently\nexperienced a common development and advancement. Machine learning (ML)\napparition, along with deep learning (DL) emergence, extended many approaches\nagainst diseases apparition and their spread. And despite their outstanding\nresults in predicting infectious diseases, conflicts appeared regarding the\ntypes of data used and how they can be studied, analyzed, and exploited using\nvarious emerging methods. This has led to some ongoing discussions in the\nfield. This research aims not only to provide an overview of what has been\naccomplished, but also to highlight the difficulties related to the types of\ndata used, and the learning methods applied for each research objective. It\ncategorizes these contributions into three areas: predictions using Public\nHealth Data to prevent the spread of a transmissible disease within a region;\npredictions using Patients' Medical Data to detect whether a person is infected\nby a transmissible disease; and predictions using both Public and patient\nmedical data to estimate the extent of disease spread in a population. The\npaper also critically assesses the potential of AI and outlines its limitations\nin infectious disease management.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c7f79c4fea0ee9888a9c165f4de5e073cc2eaf0d",
      "published_date": "2024-11-14",
      "downloaded_date": "2025-02-01",
      "filename": "Melchane-Artificial Intelligence for Infectious Disease Prediction and Prevention A Comprehensive Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.10486v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.PE"
      ]
    },
    "2404.03044v1": {
      "title": "The Artificial Intelligence Ontology: LLM-assisted construction of AI concept hierarchies",
      "authors": [
        "Marcin P. Joachimiak",
        "Mark A. Miller",
        "J. Harry Caufield",
        "Ryan Ly",
        "Nomi L. Harris",
        "Andrew Tritt",
        "Christopher J. Mungall",
        "Kristofer E. Bouchard"
      ],
      "abstract": "The Artificial Intelligence Ontology (AIO) is a systematization of artificial\nintelligence (AI) concepts, methodologies, and their interrelations. Developed\nvia manual curation, with the additional assistance of large language models\n(LLMs), AIO aims to address the rapidly evolving landscape of AI by providing a\ncomprehensive framework that encompasses both technical and ethical aspects of\nAI technologies. The primary audience for AIO includes AI researchers,\ndevelopers, and educators seeking standardized terminology and concepts within\nthe AI domain. The ontology is structured around six top-level branches:\nNetworks, Layers, Functions, LLMs, Preprocessing, and Bias, each designed to\nsupport the modular composition of AI methods and facilitate a deeper\nunderstanding of deep learning architectures and ethical considerations in AI.\n  AIO's development utilized the Ontology Development Kit (ODK) for its\ncreation and maintenance, with its content being dynamically updated through\nAI-driven curation support. This approach not only ensures the ontology's\nrelevance amidst the fast-paced advancements in AI but also significantly\nenhances its utility for researchers, developers, and educators by simplifying\nthe integration of new AI concepts and methodologies.\n  The ontology's utility is demonstrated through the annotation of AI methods\ndata in a catalog of AI research publications and the integration into the\nBioPortal ontology resource, highlighting its potential for cross-disciplinary\nresearch. The AIO ontology is open source and is available on GitHub\n(https://github.com/berkeleybop/artificial-intelligence-ontology) and BioPortal\n(https://bioportal.bioontology.org/ontologies/AIO).",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a75715361490ae49001e2b3377e40da3c4715ca5",
      "published_date": "2024-04-03",
      "downloaded_date": "2025-02-01",
      "filename": "Joachimiak-The Artificial Intelligence Ontology LLM-assisted construction of AI concept hierarchies.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.03044v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1808.06355v1": {
      "title": "Deep learning, deep change? Mapping the development of the Artificial Intelligence General Purpose Technology",
      "authors": [
        "J. Klinger",
        "J. Mateos-Garcia",
        "K. Stathoulopoulos"
      ],
      "abstract": "General Purpose Technologies (GPTs) that can be applied in many industries\nare an important driver of economic growth and national and regional\ncompetitiveness. In spite of this, the geography of their development and\ndiffusion has not received significant attention in the literature. We address\nthis with an analysis of Deep Learning (DL), a core technique in Artificial\nIntelligence (AI) increasingly being recognized as the latest GPT. We identify\nDL papers in a novel dataset from ArXiv, a popular preprints website, and use\nCrunchBase, a technology business directory to measure industrial capabilities\nrelated to it. After showing that DL conforms with the definition of a GPT,\nhaving experienced rapid growth and diffusion into new fields where it has\ngenerated an impact, we describe changes in its geography. Our analysis shows\nChina's rise in AI rankings and relative decline in several European countries.\nWe also find that initial volatility in the geography of DL has been followed\nby consolidation, suggesting that the window of opportunity for new entrants\nmight be closing down as new DL research hubs become dominant. Finally, we\nstudy the regional drivers of DL clustering. We find that competitive DL\nclusters tend to be based in regions combining research and industrial\nactivities related to it. This could be because GPT developers and adopters\nlocated close to each other can collaborate and share knowledge more easily,\nthus overcoming coordination failures in GPT deployment. Our analysis also\nreveals a Chinese comparative advantage in DL after we control for other\nexplanatory factors, perhaps underscoring the importance of access to data and\nsupportive policies for the successful development of this complex, `omni-use'\ntechnology.",
      "citation_count": 45,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/41be7ddd569b64e65c2945480f2a5996bb762697",
      "published_date": "2018-08-20",
      "downloaded_date": "2025-02-01",
      "filename": "Klinger-Deep learning deep change Mapping the development of the Artificial Intelligence General Purpose Tec....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1808.06355v1",
      "categories": [
        "cs.CY",
        "econ.EM",
        "62P20"
      ]
    },
    "2403.07017v1": {
      "title": "Mathematics of multi-agent learning systems at the interface of game theory and artificial intelligence",
      "authors": [
        "Long Wang",
        "Feng Fu",
        "Xingru Chen"
      ],
      "abstract": "Evolutionary Game Theory (EGT) and Artificial Intelligence (AI) are two\nfields that, at first glance, might seem distinct, but they have notable\nconnections and intersections. The former focuses on the evolution of behaviors\n(or strategies) in a population, where individuals interact with others and\nupdate their strategies based on imitation (or social learning). The more\nsuccessful a strategy is, the more prevalent it becomes over time. The latter,\nmeanwhile, is centered on machine learning algorithms and (deep) neural\nnetworks. It is often from a single-agent perspective but increasingly involves\nmulti-agent environments, in which intelligent agents adjust their strategies\nbased on feedback and experience, somewhat akin to the evolutionary process yet\ndistinct in their self-learning capacities. In light of the key components\nnecessary to address real-world problems, including (i) learning and\nadaptation, (ii) cooperation and competition, (iii) robustness and stability,\nand altogether (iv) population dynamics of individual agents whose strategies\nevolve, the cross-fertilization of ideas between both fields will contribute to\nthe advancement of mathematics of multi-agent learning systems, in particular,\nto the nascent domain of ``collective cooperative intelligence'' bridging\nevolutionary dynamics and multi-agent reinforcement learning.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/12a13bf61ef300c5a6a0bc1659648187d7abb54c",
      "published_date": "2024-03-09",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Mathematics of multi-agent learning systems at the interface of game theory and artificial intellige....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.07017v1",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ]
    },
    "2012.08296v1": {
      "title": "Gegelati: Lightweight Artificial Intelligence through Generic and Evolvable Tangled Program Graphs",
      "authors": [
        "Karol Desnos",
        "Nicolas Sourbier",
        "Pierre-Yves Raumer",
        "Olivier Gesny",
        "Maxime Pelcat"
      ],
      "abstract": "Tangled Program Graph (TPG) is a reinforcement learning technique based on\ngenetic programming concepts. On state-of-the-art learning environments, TPGs\nhave been shown to offer comparable competence with Deep Neural Networks\n(DNNs), for a fraction of their computational and storage cost. This lightness\nof TPGs, both for training and inference, makes them an interesting model to\nimplement Artificial Intelligences (AIs) on embedded systems with limited\ncomputational and storage resources. In this paper, we introduce the Gegelati\nlibrary for TPGs. Besides introducing the general concepts and features of the\nlibrary, two main contributions are detailed in the paper: 1/ The\nparallelization of the deterministic training process of TPGs, for supporting\nheterogeneous Multiprocessor Systems-on-Chips (MPSoCs). 2/ The support for\ncustomizable instruction sets and data types within the genetically evolved\nprograms of the TPG model. The scalability of the parallel training process is\ndemonstrated through experiments on architectures ranging from a high-end\n24-core processor to a low-power heterogeneous MPSoC. The impact of\ncustomizable instructions on the outcome of a training process is demonstrated\non a state-of-the-art reinforcement learning environment. CCS Concepts:\n$\\bullet$ Computer systems organization $\\rightarrow$ Embedded systems;\n$\\bullet$ Computing methodologies $\\rightarrow$ Machine learning.",
      "citation_count": 12,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fc00f85e8e41efbffd730d8a810784d0c6d14c2c",
      "published_date": "2020-12-15",
      "downloaded_date": "2025-02-01",
      "filename": "Desnos-Gegelati Lightweight Artificial Intelligence through Generic and Evolvable Tangled Program Graphs.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.08296v1",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    "1701.01214v1": {
      "title": "A Review of Neural Network Based Machine Learning Approaches for Rotor Angle Stability Control",
      "authors": [
        "Reza Yousefian",
        "Sukumar Kamalasadan"
      ],
      "abstract": "This paper reviews the current status and challenges of Neural Networks (NNs)\nbased machine learning approaches for modern power grid stability control\nincluding their design and implementation methodologies. NNs are widely\naccepted as Artificial Intelligence (AI) approaches offering an alternative way\nto control complex and ill-defined problems. In this paper various application\nof NNs for power system rotor angle stabilization and control problem is\ndiscussed. The main focus of this paper is on the use of Reinforcement Learning\n(RL) and Supervised Learning (SL) algorithms in power system wide-area control\n(WAC). Generally, these algorithms due to their capability in modeling\nnonlinearities and uncertainties are used for transient classification,\nneuro-control, wide-area monitoring and control, renewable energy management\nand control, and so on. The works of researchers in the field of conventional\nand renewable energy systems are reported and categorized. Paper concludes by\npresenting, comparing and evaluating various learning techniques and\ninfrastructure configurations based on efficiency.",
      "citation_count": 13,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/26a4e6ca002c72523e85ded6dd98d6c99d807421",
      "published_date": "2017-01-05",
      "downloaded_date": "2025-02-01",
      "filename": "Yousefian-A Review of Neural Network Based Machine Learning Approaches for Rotor Angle Stability Control.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1701.01214v1",
      "categories": [
        "cs.SY",
        "cs.NE"
      ]
    },
    "2410.09635v1": {
      "title": "Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health",
      "authors": [
        "Abdullah Mamun",
        "Lawrence D. Devoe",
        "Mark I. Evans",
        "David W. Britt",
        "Judith Klein-Seetharaman",
        "Hassan Ghasemzadeh"
      ],
      "abstract": "Early detection of intrapartum risk enables interventions to potentially\nprevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,\nthere is no accurate automated system to predict such events to assist with\nclinical decision-making. To fill this gap, we propose \"Artificial Intelligence\n(AI) for Modeling and Explaining Neonatal Health\" (AIMEN), a deep learning\nframework that not only predicts adverse labor outcomes from maternal, fetal,\nobstetrical, and intrapartum risk factors but also provides the model's\nreasoning behind the predictions made. The latter can provide insights into\nwhat modifications in the input variables of the model could have changed the\npredicted outcome. We address the challenges of imbalance and small datasets by\nsynthesizing additional training data using Adaptive Synthetic Sampling\n(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN\nuses an ensemble of fully-connected neural networks as the backbone for its\nclassification with the data augmentation supported by either ADASYN or CTGAN.\nAIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in\nclassification. AIMEN can predict a high risk for adverse labor outcomes with\nan average F1 score of 0.784. It also provides counterfactual explanations that\ncan be achieved by changing 2 to 3 attributes on average. Resources available:\nhttps://github.com/ab9mamun/AIMEN.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f7eca68cb516c54023868543646c99a5da2f4e6b",
      "published_date": "2024-10-12",
      "downloaded_date": "2025-02-01",
      "filename": "Mamun-Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.09635v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2210.13462v1": {
      "title": "Artificial Intelligence-Based Methods for Fusion of Electronic Health Records and Imaging Data",
      "authors": [
        "Farida Mohsen",
        "Hazrat Ali",
        "Nady El Hajj",
        "Zubair Shah"
      ],
      "abstract": "Healthcare data are inherently multimodal, including electronic health\nrecords (EHR), medical images, and multi-omics data. Combining these multimodal\ndata sources contributes to a better understanding of human health and provides\noptimal personalized healthcare. Advances in artificial intelligence (AI)\ntechnologies, particularly machine learning (ML), enable the fusion of these\ndifferent data modalities to provide multimodal insights. To this end, in this\nscoping review, we focus on synthesizing and analyzing the literature that uses\nAI techniques to fuse multimodal medical data for different clinical\napplications. More specifically, we focus on studies that only fused EHR with\nmedical imaging data to develop various AI methods for clinical applications.\nWe present a comprehensive analysis of the various fusion strategies, the\ndiseases and clinical outcomes for which multimodal fusion was used, the ML\nalgorithms used to perform multimodal fusion for each clinical application, and\nthe available multimodal medical datasets. We followed the PRISMA-ScR\nguidelines. We searched Embase, PubMed, Scopus, and Google Scholar to retrieve\nrelevant studies. We extracted data from 34 studies that fulfilled the\ninclusion criteria. In our analysis, a typical workflow was observed: feeding\nraw data, fusing different data modalities by applying conventional machine\nlearning (ML) or deep learning (DL) algorithms, and finally, evaluating the\nmultimodal fusion through clinical outcome predictions. Specifically, early\nfusion was the most used technique in most applications for multimodal learning\n(22 out of 34 studies). We found that multimodality fusion models outperformed\ntraditional single-modality models for the same task. Disease diagnosis and\nprediction were the most common clinical outcomes (reported in 20 and 10\nstudies, respectively) from a clinical outcome perspective.",
      "citation_count": 73,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4f3c2c93d5e12a4d96e4bdcaf5ae6f393a808d17",
      "published_date": "2022-10-23",
      "downloaded_date": "2025-02-01",
      "filename": "Mohsen-Artificial Intelligence-Based Methods for Fusion of Electronic Health Records and Imaging Data.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.13462v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    "2307.13704v3": {
      "title": "eXplainable Artificial Intelligence (XAI) in aging clock models",
      "authors": [
        "Alena Kalyakulina",
        "Igor Yusipov",
        "Alexey Moskalev",
        "Claudio Franceschi",
        "Mikhail Ivanchenko"
      ],
      "abstract": "eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of\nmachine learning, aiming to unravel the predictions of complex models. XAI is\nespecially required in sensitive applications, e.g. in health care, when\ndiagnosis, recommendations and treatment choices might rely on the decisions\nmade by artificial intelligence systems. AI approaches have become widely used\nin aging research as well, in particular, in developing biological clock models\nand identifying biomarkers of aging and age-related diseases. However, the\npotential of XAI here awaits to be fully appreciated. We discuss the\napplication of XAI for developing the \"aging clocks\" and present a\ncomprehensive analysis of the literature categorized by the focus on particular\nphysiological systems.",
      "citation_count": 15,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/aa17a3bfe65dc43171d717bb0f9366f962c02499",
      "published_date": "2023-07-21",
      "downloaded_date": "2025-02-01",
      "filename": "Kalyakulina-eXplainable Artificial Intelligence XAI in aging clock models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.13704v3",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "I.2.1; J.3"
      ]
    },
    "2311.02115v2": {
      "title": "Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging",
      "authors": [
        "Emma A. M. Stanley",
        "Raissa Souza",
        "Anthony Winder",
        "Vedant Gulve",
        "Kimberly Amador",
        "Matthias Wilms",
        "Nils D. Forkert"
      ],
      "abstract": "Artificial intelligence (AI) models trained using medical images for clinical\ntasks often exhibit bias in the form of disparities in performance between\nsubgroups. Since not all sources of biases in real-world medical imaging data\nare easily identifiable, it is challenging to comprehensively assess how those\nbiases are encoded in models, and how capable bias mitigation methods are at\nameliorating performance disparities. In this article, we introduce a novel\nanalysis framework for systematically and objectively investigating the impact\nof biases in medical images on AI models. We developed and tested this\nframework for conducting controlled in silico trials to assess bias in medical\nimaging AI using a tool for generating synthetic magnetic resonance images with\nknown disease effects and sources of bias. The feasibility is showcased by\nusing three counterfactual bias scenarios to measure the impact of simulated\nbias effects on a convolutional neural network (CNN) classifier and the\nefficacy of three bias mitigation strategies. The analysis revealed that the\nsimulated biases resulted in expected subgroup performance disparities when the\nCNN was trained on the synthetic datasets. Moreover, reweighing was identified\nas the most successful bias mitigation strategy for this setup, and we\ndemonstrated how explainable AI methods can aid in investigating the\nmanifestation of bias in the model using this framework. Developing fair AI\nmodels is a considerable challenge given that many and often unknown sources of\nbiases can be present in medical imaging datasets. In this work, we present a\nnovel methodology to objectively study the impact of biases and mitigation\nstrategies on deep learning pipelines, which can support the development of\nclinical AI that is robust and responsible.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e6e6f21ab99713b942e96b43f351b322dba3b923",
      "published_date": "2023-11-03",
      "downloaded_date": "2025-02-01",
      "filename": "Stanley-Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.02115v2",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    "2107.02295v1": {
      "title": "A Review of Explainable Artificial Intelligence in Manufacturing",
      "authors": [
        "Georgios Sofianidis",
        "JoÅ¾e M. RoÅ¾anec",
        "Dunja MladeniÄ",
        "Dimosthenis Kyriazis"
      ],
      "abstract": "The implementation of Artificial Intelligence (AI) systems in the\nmanufacturing domain enables higher production efficiency, outstanding\nperformance, and safer operations, leveraging powerful tools such as deep\nlearning and reinforcement learning techniques. Despite the high accuracy of\nthese models, they are mostly considered black boxes: they are unintelligible\nto the human. Opaqueness affects trust in the system, a factor that is critical\nin the context of decision-making. We present an overview of Explainable\nArtificial Intelligence (XAI) techniques as a means of boosting the\ntransparency of models. We analyze different metrics to evaluate these\ntechniques and describe several application scenarios in the manufacturing\ndomain.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ff30ee5403a085051e85bbb53ef233f9ae4d70bb",
      "published_date": "2021-07-05",
      "downloaded_date": "2025-02-01",
      "filename": "Sofianidis-A Review of Explainable Artificial Intelligence in Manufacturing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.02295v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "1907.07291v1": {
      "title": "Adversarial Security Attacks and Perturbations on Machine Learning and Deep Learning Methods",
      "authors": [
        "Arif Siddiqi"
      ],
      "abstract": "The ever-growing big data and emerging artificial intelligence (AI) demand\nthe use of machine learning (ML) and deep learning (DL) methods. Cybersecurity\nalso benefits from ML and DL methods for various types of applications. These\nmethods however are susceptible to security attacks. The adversaries can\nexploit the training and testing data of the learning models or can explore the\nworkings of those models for launching advanced future attacks. The topic of\nadversarial security attacks and perturbations within the ML and DL domains is\na recent exploration and a great interest is expressed by the security\nresearchers and practitioners. The literature covers different adversarial\nsecurity attacks and perturbations on ML and DL methods and those have their\nown presentation styles and merits. A need to review and consolidate knowledge\nthat is comprehending of this increasingly focused and growing topic of\nresearch; however, is the current demand of the research communities. In this\nreview paper, we specifically aim to target new researchers in the\ncybersecurity domain who may seek to acquire some basic knowledge on the\nmachine learning and deep learning models and algorithms, as well as some of\nthe relevant adversarial security attacks and perturbations.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5b8348e3bb22c31e1b3b29179ebf8a776807812a",
      "published_date": "2019-07-17",
      "downloaded_date": "2025-02-01",
      "filename": "Siddiqi-Adversarial Security Attacks and Perturbations on Machine Learning and Deep Learning Methods.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.07291v1",
      "categories": [
        "cs.LG",
        "cs.CR",
        "stat.ML"
      ]
    },
    "2410.20304v1": {
      "title": "Deep Learning, Machine Learning -- Digital Signal and Image Processing: From Theory to Application",
      "authors": [
        "Weiche Hsieh",
        "Ziqian Bi",
        "Junyu Liu",
        "Benji Peng",
        "Sen Zhang",
        "Xuanhe Pan",
        "Jiawei Xu",
        "Jinlang Wang",
        "Keyu Chen",
        "Caitlyn Heqi Yin",
        "Pohsun Feng",
        "Yizhu Wen",
        "Tianyang Wang",
        "Ming Li",
        "Jintao Ren",
        "Qian Niu",
        "Silin Chen",
        "Ming Liu"
      ],
      "abstract": "Digital Signal Processing (DSP) and Digital Image Processing (DIP) with\nMachine Learning (ML) and Deep Learning (DL) are popular research areas in\nComputer Vision and related fields. We highlight transformative applications in\nimage enhancement, filtering techniques, and pattern recognition. By\nintegrating frameworks like the Discrete Fourier Transform (DFT), Z-Transform,\nand Fourier Transform methods, we enable robust data manipulation and feature\nextraction essential for AI-driven tasks. Using Python, we implement algorithms\nthat optimize real-time data processing, forming a foundation for scalable,\nhigh-performance solutions in computer vision. This work illustrates the\npotential of ML and DL to advance DSP and DIP methodologies, contributing to\nartificial intelligence, automated feature extraction, and applications across\ndiverse domains.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-10-27",
      "downloaded_date": "2025-02-01",
      "filename": "Hsieh-Deep Learning Machine Learning -- Digital Signal and Image Processing From Theory to Application.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.20304v1",
      "categories": [
        "cs.CV",
        "cs.GR",
        "eess.IV",
        "eess.SP"
      ]
    },
    "2103.11148v2": {
      "title": "Predictive Maintenance -- Bridging Artificial Intelligence and IoT",
      "authors": [
        "G. G. Samatas",
        "S. S. Moumgiakmas",
        "G. A. Papakostas"
      ],
      "abstract": "This paper highlights the trends in the field of predictive maintenance with\nthe use of machine learning. With the continuous development of the Fourth\nIndustrial Revolution, through IoT, the technologies that use artificial\nintelligence are evolving. As a result, industries have been using these\ntechnologies to optimize their production. Through scientific research\nconducted for this paper, conclusions were drawn about the trends in Predictive\nMaintenance applications with the use of machine learning bridging Artificial\nIntelligence and IoT. These trends are related to the types of industries in\nwhich Predictive Maintenance was applied, the models of artificial intelligence\nwere implemented, mainly of machine learning and the types of sensors that are\napplied through the IoT to the applications. Six sectors were presented and the\nproduction sector was dominant as it accounted for 54.54% of total\npublications. In terms of artificial intelligence models, the most prevalent\namong ten were the Artificial Neural Networks, Support Vector Machine and\nRandom Forest with 27.84%, 17.72% and 13.92% respectively. Finally, twelve\ncategories of sensors emerged, of which the most widely used were the sensors\nof temperature and vibration with percentages of 60.71% and 46.42%\ncorrespondingly.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-03-20",
      "downloaded_date": "2025-02-01",
      "filename": "Samatas-Predictive Maintenance -- Bridging Artificial Intelligence and IoT.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.11148v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "cs.SY",
        "eess.SY",
        "B.8.1; I.2; I.5.4"
      ]
    },
    "2408.12837v2": {
      "title": "Underwater SONAR Image Classification and Analysis using LIME-based Explainable Artificial Intelligence",
      "authors": [
        "Purushothaman Natarajan",
        "Athira Nambiar"
      ],
      "abstract": "Deep learning techniques have revolutionized image classification by\nmimicking human cognition and automating complex decision-making processes.\nHowever, the deployment of AI systems in the wild, especially in high-security\ndomains such as defence, is curbed by the lack of explainability of the model.\nTo this end, eXplainable AI (XAI) is an emerging area of research that is\nintended to explore the unexplained hidden black box nature of deep neural\nnetworks. This paper explores the application of the eXplainable Artificial\nIntelligence (XAI) tool to interpret the underwater image classification\nresults, one of the first works in the domain to the best of our knowledge. Our\nstudy delves into the realm of SONAR image classification using a custom\ndataset derived from diverse sources, including the Seabed Objects KLSG\ndataset, the camera SONAR dataset, the mine SONAR images dataset, and the SCTD\ndataset. An extensive analysis of transfer learning techniques for image\nclassification using benchmark Convolutional Neural Network (CNN) architectures\nsuch as VGG16, ResNet50, InceptionV3, DenseNet121, etc. is carried out. On top\nof this classification model, a post-hoc XAI technique, viz. Local\nInterpretable Model-Agnostic Explanations (LIME) are incorporated to provide\ntransparent justifications for the model's decisions by perturbing input data\nlocally to see how predictions change. Furthermore, Submodular Picks LIME\n(SP-LIME) a version of LIME particular to images, that perturbs the image based\non the submodular picks is also extensively studied. To this end, two\nsubmodular optimization algorithms i.e. Quickshift and Simple Linear Iterative\nClustering (SLIC) are leveraged towards submodular picks. The extensive\nanalysis of XAI techniques highlights interpretability of the results in a more\nhuman-compliant way, thus boosting our confidence and reliability.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/37680eb9155f763f62ff99ea4bd8176efb0fc529",
      "published_date": "2024-08-23",
      "downloaded_date": "2025-02-01",
      "filename": "Natarajan-Underwater SONAR Image Classification and Analysis using LIME-based Explainable Artificial Intellige....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.12837v2",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "68T07 (Primary) 68T45, 68U10 (Secondary)",
        "I.4.8; I.2.10; I.5.4"
      ]
    },
    "2109.08904v1": {
      "title": "Towards Resilient Artificial Intelligence: Survey and Research Issues",
      "authors": [
        "Oliver Eigner",
        "Sebastian Eresheim",
        "Peter Kieseberg",
        "Lukas Daniel Klausner",
        "Martin Pirker",
        "Torsten Priebe",
        "Simon Tjoa",
        "Fiammetta Marulli",
        "Francesco Mercaldo"
      ],
      "abstract": "Artificial intelligence (AI) systems are becoming critical components of\ntoday's IT landscapes. Their resilience against attacks and other environmental\ninfluences needs to be ensured just like for other IT assets. Considering the\nparticular nature of AI, and machine learning (ML) in particular, this paper\nprovides an overview of the emerging field of resilient AI and presents\nresearch issues the authors identify as potential future work.",
      "citation_count": 17,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f870974f59b405de02a2d0fff52b14fb9bc8815b",
      "published_date": "2021-09-18",
      "downloaded_date": "2025-02-01",
      "filename": "Eigner-Towards Resilient Artificial Intelligence Survey and Research Issues.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2109.08904v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CY"
      ]
    },
    "2409.17783v1": {
      "title": "Advanced Classification of Hot Subdwarf Binaries Using Artificial Intelligence Techniques and Gaia DR3 data",
      "authors": [
        "C. Viscasillas VÃ¡zquez",
        "E. Solano",
        "A. Ulla",
        "M. Ambrosch",
        "M. A. Ãlvarez",
        "M. Manteiga",
        "L. Magrini",
        "R. SantoveÃ±a-GÃ³mez",
        "C. Dafonte",
        "E. PÃ©rez-FernÃ¡ndez",
        "A. Aller",
        "A. Drazdauskas",
        "Å . Mikolaitis",
        "C. Rodrigo"
      ],
      "abstract": "Hot subdwarfs are compact blue evolved objects, burning helium in their cores\nsurrounded by a tiny hydrogen envelope. Most models agree on a common envelope\nbinary evolution scenario in the Red Giant phase. However, the binarity rate\nfor these objects is yet unsolved. We aim to develop a novel classification\nmethod for identifying hot subdwarf binaries within large datasets using\nArtificial Intelligence methods and Gaia DR3 data. The results will be compared\nwith those obtained previously using VOSA (Virtual Observatory Sed Analyzer) on\ncoincident samples. The methods include several machine learning techniques. We\nused Support Vector Machines (SVM) to classify 3084 hot subdwarf stars based on\ntheir color-magnitude properties. Of these, 2815 objects have Gaia Data Release\n3 BP/RP spectra, which were classified using Self-Organizing Maps (SOM) and\nConvolutional Neural Networks (CNN). The findings demonstrate a high agreement\nlevel (70-90%) with VOSA's classification, indicating that machine learning\nmethods effectively classify sources with an accuracy comparable to human\ninspection or non-AI techniques. SVM in a radial basis function achieves 70.97%\nreproducibility for binary targets using photometry. CNN reaches 84.94% for\nbinary detection using spectroscopy. We also found that the single-binary\ndifferences are especially observable on the infrared flux in our GDR3 BP/BR\nspectra, at wavelengths larger than 700 nm. We found that all our methods are\neffective in discerning between single and binary systems and are consistent\nwith the results previously obtained with VOSA. In global terms, considering\nall quality metrics, CNN is the method that provides the best accuracy. The\nmethods are also effective for detecting peculiarities in the spectra. Further\nresearch is needed to refine our techniques and enhance automated\nclassification reliability, especially for large-scale surveys.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7781f8e4326665ccfcc3e2e32dc792152ddbd5c8",
      "published_date": "2024-09-26",
      "downloaded_date": "2025-02-01",
      "filename": "VÃ¡zquez-Advanced Classification of Hot Subdwarf Binaries Using Artificial Intelligence Techniques and Gaia D....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.17783v1",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA",
        "astro-ph.IM"
      ]
    },
    "2004.04686v1": {
      "title": "Machine Learning in Artificial Intelligence: Towards a Common Understanding",
      "authors": [
        "Niklas KÃ¼hl",
        "Marc Goutier",
        "Robin Hirt",
        "Gerhard Satzger"
      ],
      "abstract": "The application of \"machine learning\" and \"artificial intelligence\" has\nbecome popular within the last decade. Both terms are frequently used in\nscience and media, sometimes interchangeably, sometimes with different\nmeanings. In this work, we aim to clarify the relationship between these terms\nand, in particular, to specify the contribution of machine learning to\nartificial intelligence. We review relevant literature and present a conceptual\nframework which clarifies the role of machine learning to build (artificial)\nintelligent agents. Hence, we seek to provide more terminological clarity and a\nstarting point for (interdisciplinary) discussions and future research.",
      "citation_count": 40,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6fe0389eee6b623bee7f6f413ab76d5b99ca4a70",
      "published_date": "2020-03-27",
      "downloaded_date": "2025-02-01",
      "filename": "KÃ¼hl-Machine Learning in Artificial Intelligence Towards a Common Understanding.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.04686v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2006.04013v6": {
      "title": "AI from concrete to abstract: demystifying artificial intelligence to the general public",
      "authors": [
        "Rubens Lacerda Queiroz",
        "FÃ¡bio Ferrentini Sampaio",
        "Cabral Lima",
        "Priscila Machado Vieira Lima"
      ],
      "abstract": "Artificial Intelligence (AI) has been adopted in a wide range of domains.\nThis shows the imperative need to develop means to endow common people with a\nminimum understanding of what AI means. Combining visual programming and WiSARD\nweightless artificial neural networks, this article presents a new methodology,\nAI from concrete to abstract (AIcon2abs), to enable general people (including\nchildren) to achieve this goal. The main strategy adopted by is to promote a\ndemystification of artificial intelligence via practical activities related to\nthe development of learning machines, as well as through the observation of\ntheir learning process. Thus, it is possible to provide subjects with skills\nthat contributes to making them insightful actors in debates and decisions\ninvolving the adoption of artificial intelligence mechanisms. Currently,\nexisting approaches to the teaching of basic AI concepts through programming\ntreat machine intelligence as an external element/module. After being trained,\nthat external module is coupled to the main application being developed by the\nlearners. In the methodology herein presented, both training and classification\ntasks are blocks that compose the main program, just as the other programming\nconstructs. As a beneficial side effect of AIcon2abs, the difference between a\nprogram capable of learning from data and a conventional computer program\nbecomes more evident. In addition, the simplicity of the WiSARD weightless\nartificial neural network model enables easy visualization and understanding of\ntraining and classification tasks internal realization.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-06-07",
      "downloaded_date": "2025-02-01",
      "filename": "Queiroz-AI from concrete to abstract demystifying artificial intelligence to the general public.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2006.04013v6",
      "categories": [
        "cs.CY",
        "K.4.0; K.3.0"
      ]
    },
    "2405.09547v1": {
      "title": "Explainable Self-Organizing Artificial Intelligence Captures Landscape Changes Correlated with Human Impact Data",
      "authors": [
        "John M. Wandeto",
        "Birgitta Dresp-Langley"
      ],
      "abstract": "Novel methods of analysis are needed to help advance our understanding of the\nintricate interplay between landscape changes, population dynamics, and\nsustainable development. Self organized machine learning has been highly\nsuccessful in the analysis of visual data the human expert eye may not be able\nto see. Thus, subtle but significant changes in fine visual detail in images\nrelating to trending alterations in natural or urban landscapes may remain\nundetected. In the course of time, such changes may be the cause or the\nconsequence of measurable human impact. Capturing such change in imaging data\nas early as possible can make critical information readily available to\ncitizens, professionals and policymakers. This promotes change awareness, and\nfacilitates early decision making for action. Here, we use unsupervised\nArtificial Intelligence (AI) that exploits principles of self-organized\nbiological visual learning for the analysis of imaging time series. The\nquantization error in the output of a Self Organizing Map prototype is\nexploited as a computational metric of variability and change. Given the proven\nsensitivity of this neural network metric to the intensity and polarity of\nimage pixel colour, it is shown to capture critical changes in urban\nlandscapes. This is achieved here on imaging data for two regions of geographic\ninterest in Las Vegas County, Nevada, USA. The SOM analysis is combined with\nthe statistical analysis of demographic data revealing human impacts. These\nlatter are significantly correlated with the structural change trends in the\nnumerical data for the specific regions of interest. By correlating data\nrelative to the impact of human activities with numerical data indicating\nstructural evolution, human footprint related environmental changes can be\npredictably scaled.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-02-29",
      "downloaded_date": "2025-02-01",
      "filename": "Wandeto-Explainable Self-Organizing Artificial Intelligence Captures Landscape Changes Correlated with Human....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.09547v1",
      "categories": [
        "eess.SP",
        "cs.CY"
      ]
    },
    "2212.10565v1": {
      "title": "Analysis of Explainable Artificial Intelligence Methods on Medical Image Classification",
      "authors": [
        "Vinay Jogani",
        "Joy Purohit",
        "Ishaan Shivhare",
        "Seema C Shrawne"
      ],
      "abstract": "The use of deep learning in computer vision tasks such as image\nclassification has led to a rapid increase in the performance of such systems.\nDue to this substantial increment in the utility of these systems, the use of\nartificial intelligence in many critical tasks has exploded. In the medical\ndomain, medical image classification systems are being adopted due to their\nhigh accuracy and near parity with human physicians in many tasks. However,\nthese artificial intelligence systems are extremely complex and are considered\nblack boxes by scientists, due to the difficulty in interpreting what exactly\nled to the predictions made by these models. When these systems are being used\nto assist high-stakes decision-making, it is extremely important to be able to\nunderstand, verify and justify the conclusions reached by the model. The\nresearch techniques being used to gain insight into the black-box models are in\nthe field of explainable artificial intelligence (XAI). In this paper, we\nevaluated three different XAI methods across two convolutional neural network\nmodels trained to classify lung cancer from histopathological images. We\nvisualized the outputs and analyzed the performance of these methods, in order\nto better understand how to apply explainable artificial intelligence in the\nmedical domain.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-12-10",
      "downloaded_date": "2025-02-01",
      "filename": "Jogani-Analysis of Explainable Artificial Intelligence Methods on Medical Image Classification.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.10565v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    "2110.09231v2": {
      "title": "Machine Learning Featurizations for AI Hacking of Political Systems",
      "authors": [
        "Nathan E Sanders",
        "Bruce Schneier"
      ],
      "abstract": "What would the inputs be to a machine whose output is the destabilization of\na robust democracy, or whose emanations could disrupt the political power of\nnations? In the recent essay \"The Coming AI Hackers,\" Schneier (2021) proposed\na future application of artificial intelligences to discover, manipulate, and\nexploit vulnerabilities of social, economic, and political systems at speeds\nfar greater than humans' ability to recognize and respond to such threats. This\nwork advances the concept by applying to it theory from machine learning,\nhypothesizing some possible \"featurization\" (input specification and\ntransformation) frameworks for AI hacking. Focusing on the political domain, we\ndevelop graph and sequence data representations that would enable the\napplication of a range of deep learning models to predict attributes and\noutcomes of political, particularly legislative, systems. We explore possible\ndata models, datasets, predictive tasks, and actionable applications associated\nwith each framework. We speculate about the likely practical impact and\nfeasibility of such models, and conclude by discussing their ethical\nimplications.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/38d69761538105bd1ef4e8f51b19aa96d7194f4a",
      "published_date": "2021-10-08",
      "downloaded_date": "2025-02-01",
      "filename": "Sanders-Machine Learning Featurizations for AI Hacking of Political Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.09231v2",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2102.08354v1": {
      "title": "Topological Deep Learning: Classification Neural Networks",
      "authors": [
        "Mustafa Hajij",
        "Kyle Istvan"
      ],
      "abstract": "Topological deep learning is a formalism that is aimed at introducing\ntopological language to deep learning for the purpose of utilizing the minimal\nmathematical structures to formalize problems that arise in a generic deep\nlearning problem. This is the first of a sequence of articles with the purpose\nof introducing and studying this formalism. In this article, we define and\nstudy the classification problem in machine learning in a topological setting.\nUsing this topological framework, we show when the classification problem is\npossible or not possible in the context of neural networks. Finally, we\ndemonstrate how our topological setting immediately illuminates aspects of this\nproblem that are not as readily apparent using traditional tools.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/986bbe940ee30e32f7a891298503a29b7560028c",
      "published_date": "2021-02-16",
      "downloaded_date": "2025-02-01",
      "filename": "Hajij-Topological Deep Learning Classification Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.08354v1",
      "categories": [
        "cs.LG",
        "math.AT",
        "stat.ML"
      ]
    },
    "2303.01259v1": {
      "title": "Explainable Artificial Intelligence and Cybersecurity: A Systematic Literature Review",
      "authors": [
        "Carlos Mendes",
        "Tatiane Nogueira Rios"
      ],
      "abstract": "Cybersecurity vendors consistently apply AI (Artificial Intelligence) to\ntheir solutions and many cybersecurity domains can benefit from AI technology.\nHowever, black-box AI techniques present some difficulties in comprehension and\nadoption by its operators, given that their decisions are not always humanly\nunderstandable (as is usually the case with deep neural networks, for example).\nSince it aims to make the operation of AI algorithms more interpretable for its\nusers and developers, XAI (eXplainable Artificial Intelligence) can be used to\naddress this issue. Through a systematic literature review, this work seeks to\ninvestigate the current research scenario on XAI applied to cybersecurity,\naiming to discover which XAI techniques have been applied in cybersecurity, and\nwhich areas of cybersecurity have already benefited from this technology.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-02-27",
      "downloaded_date": "2025-02-01",
      "filename": "Mendes-Explainable Artificial Intelligence and Cybersecurity A Systematic Literature Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.01259v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    "1807.08195v1": {
      "title": "Creativity and Artificial Intelligence: A Digital Art Perspective",
      "authors": [
        "Bo Xing",
        "Tshilidzi Marwala"
      ],
      "abstract": "This paper describes the application of artificial intelligence to the\ncreation of digital art. AI is a computational paradigm that codifies\nintelligence into machines. There are generally three types of artificial\nintelligence and these are machine learning, evolutionary programming and soft\ncomputing. Machine learning is the statistical approach to building intelligent\nsystems. Evolutionary programming is the use of natural evolutionary systems to\ndesign intelligent machines. Some of the evolutionary programming systems\ninclude genetic algorithm which is inspired by the principles of evolution and\nswarm optimization which is inspired by the swarming of birds, fish, ants etc.\nSoft computing includes techniques such as agent based modelling and fuzzy\nlogic. Opportunities on the applications of these to digital art are explored.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2a5b383b2a0d1db12f5f5646aa4288372bc9515f",
      "published_date": "2018-07-21",
      "downloaded_date": "2025-02-01",
      "filename": "Xing-Creativity and Artificial Intelligence A Digital Art Perspective.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1807.08195v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "2305.07511v1": {
      "title": "eXplainable Artificial Intelligence on Medical Images: A Survey",
      "authors": [
        "Matteus Vargas SimÃ£o da Silva",
        "Rodrigo Reis Arrais",
        "Jhessica Victoria Santos da Silva",
        "Felipe Souza TÃ¢nios",
        "Mateus Antonio Chinelatto",
        "Natalia Backhaus Pereira",
        "Renata De Paris",
        "Lucas Cesar Ferreira Domingos",
        "Rodrigo DÃ³ria VillaÃ§a",
        "Vitor Lopes Fabris",
        "Nayara Rossi Brito da Silva",
        "Ana Claudia Akemi Matsuki de Faria",
        "Jose Victor Nogueira Alves da Silva",
        "Fabiana Cristina Queiroz de Oliveira Marucci",
        "Francisco Alves de Souza Neto",
        "Danilo Xavier Silva",
        "Vitor Yukio Kondo",
        "Claudio Filipi GonÃ§alves dos Santos"
      ],
      "abstract": "Over the last few years, the number of works about deep learning applied to\nthe medical field has increased enormously. The necessity of a rigorous\nassessment of these models is required to explain these results to all people\ninvolved in medical exams. A recent field in the machine learning area is\nexplainable artificial intelligence, also known as XAI, which targets to\nexplain the results of such black box models to permit the desired assessment.\nThis survey analyses several recent studies in the XAI field applied to medical\ndiagnosis research, allowing some explainability of the machine learning\nresults in several different diseases, such as cancers and COVID-19.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c8573c9770e8c4cc28fc037e49e2c6f8af3c5cea",
      "published_date": "2023-05-12",
      "downloaded_date": "2025-02-01",
      "filename": "Silva-eXplainable Artificial Intelligence on Medical Images A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.07511v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "eess.IV"
      ]
    },
    "2108.11451v4": {
      "title": "From Statistical Relational to Neurosymbolic Artificial Intelligence: a Survey",
      "authors": [
        "Giuseppe Marra",
        "Sebastijan DumanÄiÄ",
        "Robin Manhaeve",
        "Luc De Raedt"
      ],
      "abstract": "This survey explores the integration of learning and reasoning in two\ndifferent fields of artificial intelligence: neurosymbolic and statistical\nrelational artificial intelligence. Neurosymbolic artificial intelligence\n(NeSy) studies the integration of symbolic reasoning and neural networks, while\nstatistical relational artificial intelligence (StarAI) focuses on integrating\nlogic with probabilistic graphical models. This survey identifies seven shared\ndimensions between these two subfields of AI. These dimensions can be used to\ncharacterize different NeSy and StarAI systems. They are concerned with (1) the\napproach to logical inference, whether model or proof-based; (2) the syntax of\nthe used logical theories; (3) the logical semantics of the systems and their\nextensions to facilitate learning; (4) the scope of learning, encompassing\neither parameter or structure learning; (5) the presence of symbolic and\nsubsymbolic representations; (6) the degree to which systems capture the\noriginal logic, probabilistic, and neural paradigms; and (7) the classes of\nlearning tasks the systems are applied to. By positioning various NeSy and\nStarAI systems along these dimensions and pointing out similarities and\ndifferences between them, this survey contributes fundamental concepts for\nunderstanding the integration of learning and reasoning.",
      "citation_count": 49,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/edaf14777326d374f691b6c10df0ab720e2026a3",
      "published_date": "2021-08-25",
      "downloaded_date": "2025-02-01",
      "filename": "Marra-From Statistical Relational to Neurosymbolic Artificial Intelligence a Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.11451v4",
      "categories": [
        "cs.AI"
      ]
    },
    "2407.20197v1": {
      "title": "Learning Random Numbers to Realize Appendable Memory System for Artificial Intelligence to Acquire New Knowledge after Deployment",
      "authors": [
        "Kazunori D Yamada"
      ],
      "abstract": "In this study, we developed a learning method for constructing a neural\nnetwork system capable of memorizing data and recalling it without parameter\nupdates. The system we built using this method is called the Appendable Memory\nsystem. The Appendable Memory system enables an artificial intelligence (AI) to\nacquire new knowledge even after deployment. It consists of two AIs: the\nMemorizer and the Recaller. This system is a key-value store built using neural\nnetworks. The Memorizer receives data and stores it in the Appendable Memory\nvector, which is dynamically updated when the AI acquires new knowledge.\nMeanwhile, the Recaller retrieves information from the Appendable Memory\nvector. What we want to teach AI in this study are the operations of memorizing\nand recalling information. However, traditional machine learning methods make\nAI learn features inherent in the learning dataset. We demonstrate that the\nsystems we intend to create cannot be realized by current machine learning\nmethods, that is, by merely repeating the input and output learning sequences\nwith AI. Instead, we propose a method to teach AI to learn operations, by\ncompletely removing the features contained in the learning dataset.\nSpecifically, we probabilized all the data involved in learning. This measure\nprevented AI from learning the features of the data. The learning method\nproposed in the study differs from traditional machine learning methods and\nprovides fundamental approaches for building an AI system that can store\ninformation in a finite memory and recall it at a later date.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/74534f9a36b3e75b7daa7cdd3edfdbe3c2e836d6",
      "published_date": "2024-07-29",
      "downloaded_date": "2025-02-01",
      "filename": "Yamada-Learning Random Numbers to Realize Appendable Memory System for Artificial Intelligence to Acquire N....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.20197v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ]
    },
    "2012.01007v2": {
      "title": "Reviewing the Need for Explainable Artificial Intelligence (xAI)",
      "authors": [
        "Julie Gerlings",
        "Arisa Shollo",
        "Ioanna Constantiou"
      ],
      "abstract": "The diffusion of artificial intelligence (AI) applications in organizations\nand society has fueled research on explaining AI decisions. The explainable AI\n(xAI) field is rapidly expanding with numerous ways of extracting information\nand visualizing the output of AI technologies (e.g. deep neural networks). Yet,\nwe have a limited understanding of how xAI research addresses the need for\nexplainable AI. We conduct a systematic review of xAI literature on the topic\nand identify four thematic debates central to how xAI addresses the black-box\nproblem. Based on this critical analysis of the xAI scholarship we synthesize\nthe findings into a future research agenda to further the xAI body of\nknowledge.",
      "citation_count": 64,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ba114923ff55abaca136fa64ad097d68971652e1",
      "published_date": "2020-12-02",
      "downloaded_date": "2025-02-01",
      "filename": "Gerlings-Reviewing the Need for Explainable Artificial Intelligence xAI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.01007v2",
      "categories": [
        "cs.HC"
      ]
    },
    "2111.11295v1": {
      "title": "Artificial Intelligence Technology analysis using Artificial Intelligence patent through Deep Learning model and vector space model",
      "authors": [
        "Yongmin Yoo",
        "Dongjin Lim",
        "Kyungsun Kim"
      ],
      "abstract": "Thanks to rapid development of artificial intelligence technology in recent\nyears, the current artificial intelligence technology is contributing to many\npart of society. Education, environment, medical care, military, tourism,\neconomy, politics, etc. are having a very large impact on society as a whole.\nFor example, in the field of education, there is an artificial intelligence\ntutoring system that automatically assigns tutors based on student's level. In\nthe field of economics, there are quantitative investment methods that\nautomatically analyze large amounts of data to find investment laws to create\ninvestment models or predict changes in financial markets. As such, artificial\nintelligence technology is being used in various fields. So, it is very\nimportant to know exactly what factors have an important influence on each\nfield of artificial intelligence technology and how the relationship between\neach field is connected. Therefore, it is necessary to analyze artificial\nintelligence technology in each field. In this paper, we analyze patent\ndocuments related to artificial intelligence technology. We propose a method\nfor keyword analysis within factors using artificial intelligence patent data\nsets for artificial intelligence technology analysis. This is a model that\nrelies on feature engineering based on deep learning model named KeyBERT, and\nusing vector space model. A case study of collecting and analyzing artificial\nintelligence patent data was conducted to show how the proposed model can be\napplied to real world problems.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/dd1ccc3c6584b45a3c2eb7e04e75bfd154952592",
      "published_date": "2021-11-08",
      "downloaded_date": "2025-02-01",
      "filename": "Yoo-Artificial Intelligence Technology analysis using Artificial Intelligence patent through Deep Learni....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.11295v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2210.16273v1": {
      "title": "SEMPAI: a Self-Enhancing Multi-Photon Artificial Intelligence for prior-informed assessment of muscle function and pathology",
      "authors": [
        "Alexander MÃ¼hlberg",
        "Paul Ritter",
        "Simon Langer",
        "ChloÃ« Goossens",
        "Stefanie NÃ¼bler",
        "Dominik Schneidereit",
        "Oliver Taubmann",
        "Felix Denzinger",
        "Dominik NÃ¶renberg",
        "Michael Haug",
        "Wolfgang H. Goldmann",
        "Andreas K. Maier",
        "Oliver Friedrich",
        "Lucas Kreiss"
      ],
      "abstract": "Deep learning (DL) shows notable success in biomedical studies. However, most\nDL algorithms work as a black box, exclude biomedical experts, and need\nextensive data. We introduce the Self-Enhancing Multi-Photon Artificial\nIntelligence (SEMPAI), that integrates hypothesis-driven priors in a\ndata-driven DL approach for research on multiphoton microscopy (MPM) of muscle\nfibers. SEMPAI utilizes meta-learning to optimize prior integration, data\nrepresentation, and neural network architecture simultaneously. This allows\nhypothesis testing and provides interpretable feedback about the origin of\nbiological information in MPM images. SEMPAI performs joint learning of several\ntasks to enable prediction for small datasets. The method is applied on an\nextensive multi-study dataset resulting in the largest joint analysis of\npathologies and function for single muscle fibers. SEMPAI outperforms\nstate-of-the-art biomarkers in six of seven predictive tasks, including those\nwith scarce data. SEMPAI's DL models with integrated priors are superior to\nthose without priors and to prior-only machine learning approaches.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-10-28",
      "downloaded_date": "2025-02-01",
      "filename": "MÃ¼hlberg-SEMPAI a Self-Enhancing Multi-Photon Artificial Intelligence for prior-informed assessment of muscle....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.16273v1",
      "categories": [
        "cs.CV",
        "cs.LG",
        "q-bio.QM",
        "I.2.6; I.4; I.5; J.3"
      ]
    },
    "2305.13927v1": {
      "title": "Optimizing National Security Strategies through LLM-Driven Artificial Intelligence Integration",
      "authors": [
        "Dmitry I Mikhailov"
      ],
      "abstract": "As artificial intelligence and machine learning continue to advance, we must\nunderstand their strategic importance in national security. This paper focuses\non unique AI applications in the military, emphasizes strategic imperatives for\nsuccess, and aims to rekindle excitement about AI's role in national security.\nWe will examine the United States progress in AI and ML from a military\nstandpoint, discuss the importance of securing these technologies from\nadversaries, and explore the challenges and risks associated with their\nintegration. Finally, we will highlight the strategic significance of AI to\nnational security and a set of strategic imperatives for military leaders and\npolicymakers",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3877d1d7e2b340677b858c0bdb632d1248fdcd08",
      "published_date": "2023-05-07",
      "downloaded_date": "2025-02-01",
      "filename": "Mikhailov-Optimizing National Security Strategies through LLM-Driven Artificial Intelligence Integration.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.13927v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "I.2.1"
      ]
    },
    "1606.08514v4": {
      "title": "Towards Verified Artificial Intelligence",
      "authors": [
        "Sanjit A. Seshia",
        "Dorsa Sadigh",
        "S. Shankar Sastry"
      ],
      "abstract": "Verified artificial intelligence (AI) is the goal of designing AI-based\nsystems that that have strong, ideally provable, assurances of correctness with\nrespect to mathematically-specified requirements. This paper considers Verified\nAI from a formal methods perspective. We describe five challenges for achieving\nVerified AI, and five corresponding principles for addressing these challenges.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2016-06-27",
      "downloaded_date": "2025-02-01",
      "filename": "Seshia-Towards Verified Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1606.08514v4",
      "categories": [
        "cs.AI"
      ]
    },
    "2101.08014v4": {
      "title": "5G D2D Transmission Mode Selection Performance & Cluster Limits Evaluation of Distributed Artificial Intelligence and Machine Learning Techniques",
      "authors": [
        "Iacovos Ioannou",
        "Christophoros Christophorou",
        "Vasos Vassiliou",
        "Andreas Pitsillides"
      ],
      "abstract": "5G D2D Communication promises improvements in energy and spectral efficiency,\noverall system capacity, and higher data rates. However, to achieve optimum\nresults it is important to select wisely the Transmission mode of the D2D\nDevice to form clusters in the most fruitful positions in terms of Sum Rate and\nPower Consumption. Towards this end, this paper investigates the use of\nDistributed Artificial Intelligence (DAI) and innovative to D2D, Machine\nLearning (ML) approaches to achieve satisfactory results in terms of Spectral\nEfficiency (SE), Power Consumption (PC) and execution time, with the creation\nof clusters and backhauling D2D network under existing Base Station/Small Cell.\nAdditionally, one of the major factors that affect the creation of high-quality\nclusters under a D2D network is the number of the Devices. Therefore, this\npaper focuses on a small (<=200) number of Devices, with the purpose to\nidentify the limits of each approach in terms of number of devices.\nSpecifically, to identify where it is beneficial to form a cluster, investigate\nthe critical point that gains increases rapidly and at the end examine the\napplicability of 5G requirements. Additionally, prior work presented a\nDistributed Artificial Intelligence (DAI) Solution/Framework in D2D and a DAIS\nTransmission Mode Selection (TMS) plan was proposed. In this paper DAIS is\nfurther examined, improved in terms of thresholds evaluation, evaluated, and\ncompared with other approaches (AI/ML). The results obtained demonstrate the\nexceptional performance of DAIS, compared to all other related approaches in\nterms of SE, PC, execution time and cluster formation efficiency. Also, results\nshow that the investigated AI/ML approaches are also beneficial for\nTransmission Mode Selection (TMS) in 5G D2D communication, even with a smaller\n(i.e., >=5 D2D Relay,>=50 D2D Multi Hop Relay) numbers of devices as a lower\nlimits.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3dea18fbc7b6ee0f6b1a261ce888b66315062f43",
      "published_date": "2021-01-20",
      "downloaded_date": "2025-02-01",
      "filename": "Ioannou-5G D2D Transmission Mode Selection Performance  Cluster Limits Evaluation of Distributed Artificial ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.08014v4",
      "categories": [
        "cs.NI"
      ]
    },
    "2003.11336v3": {
      "title": "Mapping the Landscape of Artificial Intelligence Applications against COVID-19",
      "authors": [
        "Joseph Bullock",
        "Alexandra Luccioni",
        "Katherine Hoffmann Pham",
        "Cynthia Sin Nga Lam",
        "Miguel Luengo-Oroz"
      ],
      "abstract": "COVID-19, the disease caused by the SARS-CoV-2 virus, has been declared a\npandemic by the World Health Organization, which has reported over 18 million\nconfirmed cases as of August 5, 2020. In this review, we present an overview of\nrecent studies using Machine Learning and, more broadly, Artificial\nIntelligence, to tackle many aspects of the COVID-19 crisis. We have identified\napplications that address challenges posed by COVID-19 at different scales,\nincluding: molecular, by identifying new or existing drugs for treatment;\nclinical, by supporting diagnosis and evaluating prognosis based on medical\nimaging and non-invasive measures; and societal, by tracking both the epidemic\nand the accompanying infodemic using multiple data sources. We also review\ndatasets, tools, and resources needed to facilitate Artificial Intelligence\nresearch, and discuss strategic considerations related to the operational\nimplementation of multidisciplinary partnerships and open science. We highlight\nthe need for international cooperation to maximize the potential of AI in this\nand future pandemics.",
      "citation_count": 391,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9f6034d02bf0766c021489bfe498488b0fd5eff5",
      "published_date": "2020-03-25",
      "downloaded_date": "2025-02-01",
      "filename": "Bullock-Mapping the Landscape of Artificial Intelligence Applications against COVID-19.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2003.11336v3",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ]
    },
    "2208.06981v1": {
      "title": "Explainable Artificial Intelligence for Assault Sentence Prediction in New Zealand",
      "authors": [
        "Harry Rodger",
        "Andrew Lensen",
        "Marcin Betkier"
      ],
      "abstract": "The judiciary has historically been conservative in its use of Artificial\nIntelligence, but recent advances in machine learning have prompted scholars to\nreconsider such use in tasks like sentence prediction. This paper investigates\nby experimentation the potential use of explainable artificial intelligence for\npredicting imprisonment sentences in assault cases in New Zealand's courts. We\npropose a proof-of-concept explainable model and verify in practice that it is\nfit for purpose, with predicted sentences accurate to within one year. We\nfurther analyse the model to understand the most influential phrases in\nsentence length prediction. We conclude the paper with an evaluative discussion\nof the future benefits and risks of different ways of using such an AI model in\nNew Zealand's courts.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5aa0d11df9b8dc5b808305f67a18a01c56ca9848",
      "published_date": "2022-08-15",
      "downloaded_date": "2025-02-01",
      "filename": "Rodger-Explainable Artificial Intelligence for Assault Sentence Prediction in New Zealand.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2208.06981v1",
      "categories": [
        "cs.LG",
        "cs.CL",
        "cs.CY",
        "cs.NE"
      ]
    },
    "2303.12942v2": {
      "title": "A Survey on Explainable Artificial Intelligence for Cybersecurity",
      "authors": [
        "Gaith Rjoub",
        "Jamal Bentahar",
        "Omar Abdel Wahab",
        "Rabeb Mizouni",
        "Alyssa Song",
        "Robin Cohen",
        "Hadi Otrok",
        "Azzam Mourad"
      ],
      "abstract": "The black-box nature of artificial intelligence (AI) models has been the\nsource of many concerns in their use for critical applications. Explainable\nArtificial Intelligence (XAI) is a rapidly growing research field that aims to\ncreate machine learning models that can provide clear and interpretable\nexplanations for their decisions and actions. In the field of network\ncybersecurity, XAI has the potential to revolutionize the way we approach\nnetwork security by enabling us to better understand the behavior of cyber\nthreats and to design more effective defenses. In this survey, we review the\nstate of the art in XAI for cybersecurity in network systems and explore the\nvarious approaches that have been proposed to address this important problem.\nThe review follows a systematic classification of network-driven cybersecurity\nthreats and issues. We discuss the challenges and limitations of current XAI\nmethods in the context of cybersecurity and outline promising directions for\nfuture research.",
      "citation_count": 16,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/20c27659690854435c020b8b5ba8dee0683920cd",
      "published_date": "2023-03-07",
      "downloaded_date": "2025-02-01",
      "filename": "Rjoub-A Survey on Explainable Artificial Intelligence for Cybersecurity.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.12942v2",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ]
    },
    "2409.17336v1": {
      "title": "The Technology of Outrage: Bias in Artificial Intelligence",
      "authors": [
        "Will Bridewell",
        "Paul F. Bello",
        "Selmer Bringsjord"
      ],
      "abstract": "Artificial intelligence and machine learning are increasingly used to offload\ndecision making from people. In the past, one of the rationales for this\nreplacement was that machines, unlike people, can be fair and unbiased.\nEvidence suggests otherwise. We begin by entertaining the ideas that algorithms\ncan replace people and that algorithms cannot be biased. Taken as axioms, these\nstatements quickly lead to absurdity. Spurred on by this result, we investigate\nthe slogans more closely and identify equivocation surrounding the word 'bias.'\nWe diagnose three forms of outrage-intellectual, moral, and political-that are\nat play when people react emotionally to algorithmic bias. Then we suggest\nthree practical approaches to addressing bias that the AI community could take,\nwhich include clarifying the language around bias, developing new auditing\nmethods for intelligent systems, and building certain capabilities into these\nsystems. We conclude by offering a moral regarding the conversations about\nalgorithmic bias that may transfer to other areas of artificial intelligence.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fbbb38647b7e3d2d00b79002347c3bdf8cfa809e",
      "published_date": "2024-09-25",
      "downloaded_date": "2025-02-01",
      "filename": "Bridewell-The Technology of Outrage Bias in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.17336v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2404.05762v1": {
      "title": "Evaluating the Effectiveness of Artificial Intelligence in Predicting Adverse Drug Reactions among Cancer Patients: A Systematic Review and Meta-Analysis",
      "authors": [
        "Fatma Zahra Abdeldjouad",
        "Menaouer Brahami",
        "Mohammed Sabri"
      ],
      "abstract": "Adverse drug reactions considerably impact patient outcomes and healthcare\ncosts in cancer therapy. Using artificial intelligence to predict adverse drug\nreactions in real time could revolutionize oncology treatment. This study aims\nto assess the performance of artificial intelligence models in predicting\nadverse drug reactions in patients with cancer. This is the first systematic\nreview and meta-analysis. Scopus, PubMed, IEEE Xplore, and ACM Digital Library\ndatabases were searched for studies in English, French, and Arabic from January\n1, 2018, to August 20, 2023. The inclusion criteria were: (1) peer-reviewed\nresearch articles; (2) use of artificial intelligence algorithms (machine\nlearning, deep learning, knowledge graphs); (3) study aimed to predict adverse\ndrug reactions (cardiotoxicity, neutropenia, nephrotoxicity, hepatotoxicity);\n(4) study was on cancer patients. The data were extracted and evaluated by\nthree reviewers for study quality. Of the 332 screened articles, 17 studies\n(5%) involving 93,248 oncology patients from 17 countries were included in the\nsystematic review, of which ten studies synthesized the meta-analysis. A\nrandom-effects model was created to pool the sensitivity, specificity, and AUC\nof the included studies. The pooled results were 0.82 (95% CI:0.69, 0.9), 0.84\n(95% CI:0.75, 0.9), and 0.83 (95% CI:0.77, 0.87) for sensitivity, specificity,\nand AUC, respectively, of ADR predictive models. Biomarkers proved their\neffectiveness in predicting ADRs, yet they were adopted by only half of the\nreviewed studies. The use of AI in cancer treatment shows great potential, with\nmodels demonstrating high specificity and sensitivity in predicting ADRs.\nHowever, standardized research and multicenter studies are needed to improve\nthe quality of evidence. AI can enhance cancer patient care by bridging the gap\nbetween data-driven insights and clinical expertise.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/50d6c2b15d3d06cf9a8389166dcc5fa0dd8100e0",
      "published_date": "2024-04-06",
      "downloaded_date": "2025-02-01",
      "filename": "Abdeldjouad-Evaluating the Effectiveness of Artificial Intelligence in Predicting Adverse Drug Reactions among C....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.05762v1",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2103.01179v2": {
      "title": "Noncoding RNAs and deep learning neural network discriminate multi-cancer types",
      "authors": [
        "Anyou Wang",
        "Rong Hai",
        "Paul J Rider",
        "Qianchuan He"
      ],
      "abstract": "Detecting cancers at early stages can dramatically reduce mortality rates.\nTherefore, practical cancer screening at the population level is needed. Here,\nwe develop a comprehensive detection system to classify all common cancer\ntypes. By integrating artificial intelligence deep learning neural network and\nnoncoding RNA biomarkers selected from massive data, our system can accurately\ndetect cancer vs healthy object with 96.3% of AUC of ROC (Area Under Curve of a\nReceiver Operating Characteristic curve). Intriguinely, with no more than 6\nbiomarkers, our approach can easily discriminate any individual cancer type vs\nnormal with 99% to 100% AUC. Furthermore, a comprehensive marker panel can\nsimultaneously multi-classify all common cancers with a stable 78% of accuracy\nat heterological cancerous tissues and conditions. This provides a valuable\nframework for large scale cancer screening. The AI models and plots of results\nwere available in https://combai.org/ai/cancerdetection/",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4a65b34b620d2a1cd7a12ff493eb55f94759ee02",
      "published_date": "2021-03-01",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Noncoding RNAs and deep learning neural network discriminate multi-cancer types.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.01179v2",
      "categories": [
        "q-bio.MN",
        "cs.LG"
      ]
    },
    "2307.16235v1": {
      "title": "Spiking Neural Networks and Bio-Inspired Supervised Deep Learning: A Survey",
      "authors": [
        "Gabriele Lagani",
        "Fabrizio Falchi",
        "Claudio Gennaro",
        "Giuseppe Amato"
      ],
      "abstract": "For a long time, biology and neuroscience fields have been a great source of\ninspiration for computer scientists, towards the development of Artificial\nIntelligence (AI) technologies. This survey aims at providing a comprehensive\nreview of recent biologically-inspired approaches for AI. After introducing the\nmain principles of computation and synaptic plasticity in biological neurons,\nwe provide a thorough presentation of Spiking Neural Network (SNN) models, and\nwe highlight the main challenges related to SNN training, where traditional\nbackprop-based optimization is not directly applicable. Therefore, we discuss\nrecent bio-inspired training methods, which pose themselves as alternatives to\nbackprop, both for traditional and spiking networks. Bio-Inspired Deep Learning\n(BIDL) approaches towards advancing the computational capabilities and\nbiological plausibility of current models.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/04558d901a628b19faa2cf1d014895cb7f1eda16",
      "published_date": "2023-07-30",
      "downloaded_date": "2025-02-01",
      "filename": "Lagani-Spiking Neural Networks and Bio-Inspired Supervised Deep Learning A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.16235v1",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    "1903.04442v1": {
      "title": "Physics Enhanced Artificial Intelligence",
      "authors": [
        "Patrick O'Driscoll",
        "Jaehoon Lee",
        "Bo Fu"
      ],
      "abstract": "We propose that intelligently combining models from the domains of Artificial\nIntelligence or Machine Learning with Physical and Expert models will yield a\nmore \"trustworthy\" model than any one model from a single domain, given a\ncomplex and narrow enough problem. Based on mean-variance portfolio theory and\nbias-variance trade-off analysis, we prove combining models from various\ndomains produces a model that has lower risk, increasing user trust. We call\nsuch combined models - physics enhanced artificial intelligence (PEAI), and\nsuggest use cases for PEAI.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8f222ebbb1f7842a9fac62ce057b20c16379ab63",
      "published_date": "2019-03-11",
      "downloaded_date": "2025-02-01",
      "filename": "O'Driscoll-Physics Enhanced Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1903.04442v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2401.07358v2": {
      "title": "Harnessing Machine Learning for Discerning AI-Generated Synthetic Images",
      "authors": [
        "Yuyang Wang",
        "Yizhi Hao",
        "Amando Xu Cong"
      ],
      "abstract": "In the realm of digital media, the advent of AI-generated synthetic images\nhas introduced significant challenges in distinguishing between real and\nfabricated visual content. These images, often indistinguishable from authentic\nones, pose a threat to the credibility of digital media, with potential\nimplications for disinformation and fraud. Our research addresses this\nchallenge by employing machine learning techniques to discern between\nAI-generated and genuine images. Central to our approach is the CIFAKE dataset,\na comprehensive collection of images labeled as \"Real\" and \"Fake\". We refine\nand adapt advanced deep learning architectures like ResNet, VGGNet, and\nDenseNet, utilizing transfer learning to enhance their precision in identifying\nsynthetic images. We also compare these with a baseline model comprising a\nvanilla Support Vector Machine (SVM) and a custom Convolutional Neural Network\n(CNN). The experimental results were significant, demonstrating that our\noptimized deep learning models outperform traditional methods, with DenseNet\nachieving an accuracy of 97.74%. Our application study contributes by applying\nand optimizing these advanced models for synthetic image detection, conducting\na comparative analysis using various metrics, and demonstrating their superior\ncapability in identifying AI-generated images over traditional machine learning\ntechniques. This research not only advances the field of digital media\nintegrity but also sets a foundation for future explorations into the ethical\nand technical dimensions of AI-generated content in digital media.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4d8f31d398a5fffa28411c7fe64167931c98b964",
      "published_date": "2024-01-14",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Harnessing Machine Learning for Discerning AI-Generated Synthetic Images.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.07358v2",
      "categories": [
        "cs.CV"
      ]
    },
    "2307.05232v2": {
      "title": "A Survey From Distributed Machine Learning to Distributed Deep Learning",
      "authors": [
        "Mohammad Dehghani",
        "Zahra Yazdanparast"
      ],
      "abstract": "Artificial intelligence has made remarkable progress in handling complex\ntasks, thanks to advances in hardware acceleration and machine learning\nalgorithms. However, to acquire more accurate outcomes and solve more complex\nissues, algorithms should be trained with more data. Processing this huge\namount of data could be time-consuming and require a great deal of computation.\nTo address these issues, distributed machine learning has been proposed, which\ninvolves distributing the data and algorithm across several machines. There has\nbeen considerable effort put into developing distributed machine learning\nalgorithms, and different methods have been proposed so far. We divide these\nalgorithms in classification and clustering (traditional machine learning),\ndeep learning and deep reinforcement learning groups. Distributed deep learning\nhas gained more attention in recent years and most of the studies have focused\non this approach. Therefore, we mostly concentrate on this category. Based on\nthe investigation of the mentioned algorithms, we highlighted the limitations\nthat should be addressed in future research.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/54870c48442553596e466e7d952d36391df6dfb8",
      "published_date": "2023-07-11",
      "downloaded_date": "2025-02-01",
      "filename": "Dehghani-A Survey From Distributed Machine Learning to Distributed Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.05232v2",
      "categories": [
        "cs.LG",
        "cs.DC"
      ]
    },
    "2205.10535v1": {
      "title": "Deep Learning vs. Gradient Boosting: Benchmarking state-of-the-art machine learning algorithms for credit scoring",
      "authors": [
        "Marc Schmitt"
      ],
      "abstract": "Artificial intelligence (AI) and machine learning (ML) have become vital to\nremain competitive for financial services companies around the globe. The two\nmodels currently competing for the pole position in credit risk management are\ndeep learning (DL) and gradient boosting machines (GBM). This paper benchmarked\nthose two algorithms in the context of credit scoring using three distinct\ndatasets with different features to account for the reality that model\nchoice/power is often dependent on the underlying characteristics of the\ndataset. The experiment has shown that GBM tends to be more powerful than DL\nand has also the advantage of speed due to lower computational requirements.\nThis makes GBM the winner and choice for credit scoring. However, it was also\nshown that the outperformance of GBM is not always guaranteed and ultimately\nthe concrete problem scenario or dataset will determine the final model choice.\nOverall, based on this study both algorithms can be considered state-of-the-art\nfor binary classification tasks on structured datasets, while GBM should be the\ngo-to solution for most problem scenarios due to easier use, significantly\nfaster training time, and superior accuracy.",
      "citation_count": 17,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f302b3027c6ccb7e9e79da09ddbd52da936d011c",
      "published_date": "2022-05-21",
      "downloaded_date": "2025-02-01",
      "filename": "Schmitt-Deep Learning vs Gradient Boosting Benchmarking state-of-the-art machine learning algorithms for cre....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.10535v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "q-fin.CP",
        "q-fin.RM"
      ]
    },
    "2412.04495v1": {
      "title": "Artificial intelligence and cybersecurity in banking sector: opportunities and risks",
      "authors": [
        "Ana Kovacevic",
        "Sonja D. Radenkovic",
        "Dragana Nikolic"
      ],
      "abstract": "The rapid advancements in artificial intelligence (AI) have presented new\nopportunities for enhancing efficiency and economic competitiveness across\nvarious industries, espcially in banking. Machine learning (ML), as a subset of\nartificial intelligence, enables systems to adapt and learn from vast datasets,\nrevolutionizing decision-making processes, fraud detection, and customer\nservice automation. However, these innovations also introduce new challenges,\nparticularly in the realm of cybersecurity. Adversarial attacks, such as data\npoisoning and evasion attacks, represent critical threats to machine learning\nmodels, exploiting vulnerabilities to manipulate outcomes or compromise\nsensitive information. Furthermore, this study highlights the dual-use nature\nof AI tools, which can be used by malicious users. To address these challenges,\nthe paper emphasizes the importance of developing machine learning models with\nkey characteristics such as security, trust, resilience and robustness. These\nfeatures are essential to mitigating risks and ensuring the secure deployment\nof AI technologies in banking sectors, where the protection of financial data\nis paramount. The findings underscore the urgent need for enhanced\ncybersecurity frameworks and continuous improvements in defensive mechanisms.\nBy exploring both opportunities and risks, this paper aims to guide the\nresponsible integration of AI in the banking sector, paving the way for\ninnovation while safeguarding against emerging threats.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-11-28",
      "downloaded_date": "2025-02-01",
      "filename": "Kovacevic-Artificial intelligence and cybersecurity in banking sector opportunities and risks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.04495v1",
      "categories": [
        "cs.CR"
      ]
    },
    "2101.06220v2": {
      "title": "Player-AI Interaction: What Neural Network Games Reveal About AI as Play",
      "authors": [
        "Jichen Zhu",
        "Jennifer Villareale",
        "Nithesh Javvaji",
        "Sebastian Risi",
        "Mathias LÃ¶we",
        "Rush Weigelt",
        "Casper Harteveld"
      ],
      "abstract": "The advent of artificial intelligence (AI) and machine learning (ML) bring\nhuman-AI interaction to the forefront of HCI research. This paper argues that\ngames are an ideal domain for studying and experimenting with how humans\ninteract with AI. Through a systematic survey of neural network games (n = 38),\nwe identified the dominant interaction metaphors and AI interaction patterns in\nthese games. In addition, we applied existing human-AI interaction guidelines\nto further shed light on player-AI interaction in the context of AI-infused\nsystems. Our core finding is that AI as play can expand current notions of\nhuman-AI interaction, which are predominantly productivity-based. In\nparticular, our work suggests that game and UX designers should consider flow\nto structure the learning curve of human-AI interaction, incorporate\ndiscovery-based learning to play around with the AI and observe the\nconsequences, and offer users an invitation to play to explore new forms of\nhuman-AI interaction.",
      "citation_count": 38,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ae52cd12aa115846f5a447f9973515d83234ca1b",
      "published_date": "2021-01-15",
      "downloaded_date": "2025-02-01",
      "filename": "Zhu-Player-AI Interaction What Neural Network Games Reveal About AI as Play.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.06220v2",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    "2309.01025v1": {
      "title": "Review: Artificial Intelligence for Liquid-Vapor Phase-Change Heat Transfer",
      "authors": [
        "Youngjoon Suh",
        "Aparna Chandramowlishwaran",
        "Yoonjin Won"
      ],
      "abstract": "Artificial intelligence (AI) is shifting the paradigm of two-phase heat\ntransfer research. Recent innovations in AI and machine learning uniquely offer\nthe potential for collecting new types of physically meaningful features that\nhave not been addressed in the past, for making their insights available to\nother domains, and for solving for physical quantities based on first\nprinciples for phase-change thermofluidic systems. This review outlines core\nideas of current AI technologies connected to thermal energy science to\nillustrate how they can be used to push the limit of our knowledge boundaries\nabout boiling and condensation phenomena. AI technologies for meta-analysis,\ndata extraction, and data stream analysis are described with their potential\nchallenges, opportunities, and alternative approaches. Finally, we offer\noutlooks and perspectives regarding physics-centered machine learning,\nsustainable cyberinfrastructures, and multidisciplinary efforts that will help\nfoster the growing trend of AI for phase-change heat and mass transfer.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-09-02",
      "downloaded_date": "2025-02-01",
      "filename": "Suh-Review Artificial Intelligence for Liquid-Vapor Phase-Change Heat Transfer.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.01025v1",
      "categories": [
        "physics.app-ph"
      ]
    },
    "2309.07064v2": {
      "title": "A Comprehensive Analysis of the Role of Artificial Intelligence and Machine Learning in Modern Digital Forensics and Incident Response",
      "authors": [
        "Dipo Dunsin",
        "Mohamed C. Ghanem",
        "Karim Ouazzane",
        "Vassil Vassilev"
      ],
      "abstract": "In the dynamic landscape of digital forensics, the integration of Artificial\nIntelligence (AI) and Machine Learning (ML) stands as a transformative\ntechnology, poised to amplify the efficiency and precision of digital forensics\ninvestigations. However, the use of ML and AI in digital forensics is still in\nits nascent stages. As a result, this paper gives a thorough and in-depth\nanalysis that goes beyond a simple survey and review. The goal is to look\nclosely at how AI and ML techniques are used in digital forensics and incident\nresponse. This research explores cutting-edge research initiatives that cross\ndomains such as data collection and recovery, the intricate reconstruction of\ncybercrime timelines, robust big data analysis, pattern recognition,\nsafeguarding the chain of custody, and orchestrating responsive strategies to\nhacking incidents. This endeavour digs far beneath the surface to unearth the\nintricate ways AI-driven methodologies are shaping these crucial facets of\ndigital forensics practice. While the promise of AI in digital forensics is\nevident, the challenges arising from increasing database sizes and evolving\ncriminal tactics necessitate ongoing collaborative research and refinement\nwithin the digital forensics profession. This study examines the contributions,\nlimitations, and gaps in the existing research, shedding light on the potential\nand limitations of AI and ML techniques. By exploring these different research\nareas, we highlight the critical need for strategic planning, continual\nresearch, and development to unlock AI's full potential in digital forensics\nand incident response. Ultimately, this paper underscores the significance of\nAI and ML integration in digital forensics, offering insights into their\nbenefits, drawbacks, and broader implications for tackling modern cyber\nthreats.",
      "citation_count": 26,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/13c0364cc7efe33f6ea84e8d5f9905fa65dbfc54",
      "published_date": "2023-09-13",
      "downloaded_date": "2025-02-01",
      "filename": "Dunsin-A Comprehensive Analysis of the Role of Artificial Intelligence and Machine Learning in Modern Digit....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.07064v2",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ]
    },
    "2105.01798v2": {
      "title": "Pervasive AI for IoT applications: A Survey on Resource-efficient Distributed Artificial Intelligence",
      "authors": [
        "Emna Baccour",
        "Naram Mhaisen",
        "Alaa Awad Abdellatif",
        "Aiman Erbad",
        "Amr Mohamed",
        "Mounir Hamdi",
        "Mohsen Guizani"
      ],
      "abstract": "Artificial intelligence (AI) has witnessed a substantial breakthrough in a\nvariety of Internet of Things (IoT) applications and services, spanning from\nrecommendation systems to robotics control and military surveillance. This is\ndriven by the easier access to sensory data and the enormous scale of\npervasive/ubiquitous devices that generate zettabytes (ZB) of real-time data\nstreams. Designing accurate models using such data streams, to predict future\ninsights and revolutionize the decision-taking process, inaugurates pervasive\nsystems as a worthy paradigm for a better quality-of-life. The confluence of\npervasive computing and artificial intelligence, Pervasive AI, expanded the\nrole of ubiquitous IoT systems from mainly data collection to executing\ndistributed computations with a promising alternative to centralized learning,\npresenting various challenges. In this context, a wise cooperation and resource\nscheduling should be envisaged among IoT devices (e.g., smartphones, smart\nvehicles) and infrastructure (e.g. edge nodes, and base stations) to avoid\ncommunication and computation overheads and ensure maximum performance. In this\npaper, we conduct a comprehensive survey of the recent techniques developed to\novercome these resource challenges in pervasive AI systems. Specifically, we\nfirst present an overview of the pervasive computing, its architecture, and its\nintersection with artificial intelligence. We then review the background,\napplications and performance metrics of AI, particularly Deep Learning (DL) and\nonline learning, running in a ubiquitous system. Next, we provide a deep\nliterature review of communication-efficient techniques, from both algorithmic\nand system perspectives, of distributed inference, training and online learning\ntasks across the combination of IoT devices, edge devices and cloud servers.\nFinally, we discuss our future vision and research challenges.",
      "citation_count": 76,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1f47fc5d783e517147f66c4c1a1465e8bab35c63",
      "published_date": "2021-05-04",
      "downloaded_date": "2025-02-01",
      "filename": "Baccour-Pervasive AI for IoT applications A Survey on Resource-efficient Distributed Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.01798v2",
      "categories": [
        "cs.DC",
        "cs.AI"
      ]
    },
    "2007.03153v1": {
      "title": "High-speed Millimeter-wave 5G/6G Image Transmission via Artificial Intelligence",
      "authors": [
        "Shaolin Liao",
        "Lu Ou"
      ],
      "abstract": "Artificial Intelligence (AI) has been used to jointly optimize a mmWave\nCompressed Sensing (CS) for high-speed 5G/6G image transmission. Specifically,\nwe have developed a Dictionary Learning Compressed Sensing neural Network\n(DL-CSNet) to realize three key functionalities: 1) to learn the dictionary\nbasis of the images for transmission; 2) to optimize the Hadamard measurement\nmatrix; and 3) to reconstruct the lossless images with the learned dictionary\nbasis. A 94-GHz prototype has been built and up to one order of image\ntransmission speed increase has been realized for letters ``A\" to ``Z\".",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fe3bccb63c257acfc17c7cb37750fa5a35c74d65",
      "published_date": "2020-07-07",
      "downloaded_date": "2025-02-01",
      "filename": "Liao-High-speed Millimeter-wave 5G6G Image Transmission via Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.03153v1",
      "categories": [
        "eess.IV"
      ]
    },
    "2101.09126v1": {
      "title": "Will Artificial Intelligence supersede Earth System and Climate Models?",
      "authors": [
        "Christopher Irrgang",
        "Niklas Boers",
        "Maike Sonnewald",
        "Elizabeth A. Barnes",
        "Christopher Kadow",
        "Joanna Staneva",
        "Jan Saynisch-Wagner"
      ],
      "abstract": "We outline a perspective of an entirely new research branch in Earth and\nclimate sciences, where deep neural networks and Earth system models are\ndismantled as individual methodological approaches and reassembled as learning,\nself-validating, and interpretable Earth system model-network hybrids.\nFollowing this path, we coin the term \"Neural Earth System Modelling\" (NESYM)\nand highlight the necessity of a transdisciplinary discussion platform,\nbringing together Earth and climate scientists, big data analysts, and AI\nexperts. We examine the concurrent potential and pitfalls of Neural Earth\nSystem Modelling and discuss the open question whether artificial intelligence\nwill not only infuse Earth system modelling, but ultimately render them\nobsolete.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-01-22",
      "downloaded_date": "2025-02-01",
      "filename": "Irrgang-Will Artificial Intelligence supersede Earth System and Climate Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.09126v1",
      "categories": [
        "stat.ML",
        "cs.LG",
        "physics.ao-ph"
      ]
    },
    "1812.04814v1": {
      "title": "Linking Artificial Intelligence Principles",
      "authors": [
        "Yi Zeng",
        "Enmeng Lu",
        "Cunqing Huangfu"
      ],
      "abstract": "Artificial Intelligence principles define social and ethical considerations\nto develop future AI. They come from research institutes, government\norganizations and industries. All versions of AI principles are with different\nconsiderations covering different perspectives and making different emphasis.\nNone of them can be considered as complete and can cover the rest AI principle\nproposals. Here we introduce LAIP, an effort and platform for linking and\nanalyzing different Artificial Intelligence Principles. We want to explicitly\nestablish the common topics and links among AI Principles proposed by different\norganizations and investigate on their uniqueness. Based on these efforts, for\nthe long-term future of AI, instead of directly adopting any of the AI\nprinciples, we argue for the necessity of incorporating various AI Principles\ninto a comprehensive framework and focusing on how they can interact and\ncomplete each other.",
      "citation_count": 74,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f1fdc5810312ea877c18ce995c57394cb31c8713",
      "published_date": "2018-12-12",
      "downloaded_date": "2025-02-01",
      "filename": "Zeng-Linking Artificial Intelligence Principles.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1812.04814v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "2001.00627v1": {
      "title": "Artificial Intelligence in Surgery",
      "authors": [
        "Xiao-Yun Zhou",
        "Yao Guo",
        "Mali Shen",
        "Guang-Zhong Yang"
      ],
      "abstract": "Artificial Intelligence (AI) is gradually changing the practice of surgery\nwith the advanced technological development of imaging, navigation and robotic\nintervention. In this article, the recent successful and influential\napplications of AI in surgery are reviewed from pre-operative planning and\nintra-operative guidance to the integration of surgical robots. We end with\nsummarizing the current state, emerging trends and major challenges in the\nfuture development of AI in surgery.",
      "citation_count": 20,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/da65443c52f3ec97215769fefa917f0a1156acff",
      "published_date": "2019-12-23",
      "downloaded_date": "2025-02-01",
      "filename": "Zhou-Artificial Intelligence in Surgery.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2001.00627v1",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "eess.IV"
      ]
    },
    "2206.04992v3": {
      "title": "Artificial Intelligence Enabled NOMA Towards Next Generation Multiple Access",
      "authors": [
        "Xiaoxia Xu",
        "Yuanwei Liu",
        "Xidong Mu",
        "Qimei Chen",
        "Hao Jiang",
        "Zhiguo Ding"
      ],
      "abstract": "This article focuses on the application of artificial intelligence (AI) in\nnon-orthogonal multiple-access (NOMA), which aims to achieve automated,\nadaptive, and high-efficiency multi-user communications towards next generation\nmultiple access (NGMA). First, the limitations of current scenario-specific\nmultiple-antenna NOMA schemes are discussed, and the importance of AI for NGMA\nis highlighted. Then, to achieve the vision of NGMA, a novel cluster-free NOMA\nframework is proposed for providing scenario-adaptive NOMA communications, and\nseveral promising machine learning solutions are identified. To elaborate\nfurther, novel centralized and distributed machine learning paradigms are\nconceived for efficiently employing the proposed cluster-free NOMA framework in\nsingle-cell and multi-cell networks, where numerical results are provided to\ndemonstrate the effectiveness. Furthermore, the interplays between the proposed\ncluster-free NOMA and emerging wireless techniques are presented. Finally,\nseveral open research issues of AI enabled NGMA are discussed.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-06-10",
      "downloaded_date": "2025-02-01",
      "filename": "Xu-Artificial Intelligence Enabled NOMA Towards Next Generation Multiple Access.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.04992v3",
      "categories": [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    },
    "2111.09537v3": {
      "title": "The Prominence of Artificial Intelligence in COVID-19",
      "authors": [
        "MD Abdullah Al Nasim",
        "Aditi Dhali",
        "Faria Afrin",
        "Noshin Tasnim Zaman",
        "Nazmul Karimm",
        "Md Mahim Anjum Haque"
      ],
      "abstract": "In December 2019, a novel virus called COVID-19 had caused an enormous number\nof causalities to date. The battle with the novel Coronavirus is baffling and\nhorrifying after the Spanish Flu 2019. While the front-line doctors and medical\nresearchers have made significant progress in controlling the spread of the\nhighly contiguous virus, technology has also proved its significance in the\nbattle. Moreover, Artificial Intelligence has been adopted in many medical\napplications to diagnose many diseases, even baffling experienced doctors.\nTherefore, this survey paper explores the methodologies proposed that can aid\ndoctors and researchers in early and inexpensive methods of diagnosis of the\ndisease. Most developing countries have difficulties carrying out tests using\nthe conventional manner, but a significant way can be adopted with Machine and\nDeep Learning. On the other hand, the access to different types of medical\nimages has motivated the researchers. As a result, a mammoth number of\ntechniques are proposed. This paper first details the background knowledge of\nthe conventional methods in the Artificial Intelligence domain. Following that,\nwe gather the commonly used datasets and their use cases to date. In addition,\nwe also show the percentage of researchers adopting Machine Learning over Deep\nLearning. Thus we provide a thorough analysis of this scenario. Lastly, in the\nresearch challenges, we elaborate on the problems faced in COVID-19 research,\nand we address the issues with our understanding to build a bright and healthy\nenvironment.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-11-18",
      "downloaded_date": "2025-02-01",
      "filename": "Nasim-The Prominence of Artificial Intelligence in COVID-19.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.09537v3",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2107.06015v2": {
      "title": "A Classification of Artificial Intelligence Systems for Mathematics Education",
      "authors": [
        "Steven Van Vaerenbergh",
        "AdriÃ¡n PÃ©rez-Suay"
      ],
      "abstract": "This chapter provides an overview of the different Artificial Intelligence\n(AI) systems that are being used in contemporary digital tools for Mathematics\nEducation (ME). It is aimed at researchers in AI and Machine Learning (ML), for\nwhom we shed some light on the specific technologies that are being used in\neducational applications; and at researchers in ME, for whom we clarify: i)\nwhat the possibilities of the current AI technologies are, ii) what is still\nout of reach and iii) what is to be expected in the near future. We start our\nanalysis by establishing a high-level taxonomy of AI tools that are found as\ncomponents in digital ME applications. Then, we describe in detail how these AI\ntools, and in particular ML, are being used in two key applications,\nspecifically AI-based calculators and intelligent tutoring systems. We finish\nthe chapter with a discussion about student modeling systems and their\nrelationship to artificial general intelligence.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-07-13",
      "downloaded_date": "2025-02-01",
      "filename": "Vaerenbergh-A Classification of Artificial Intelligence Systems for Mathematics Education.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.06015v2",
      "categories": [
        "cs.CY",
        "cs.AI",
        "math.HO"
      ]
    },
    "2310.13715v1": {
      "title": "Digital Deception: Generative Artificial Intelligence in Social Engineering and Phishing",
      "authors": [
        "Marc Schmitt",
        "Ivan Flechais"
      ],
      "abstract": "The advancement of Artificial Intelligence (AI) and Machine Learning (ML) has\nprofound implications for both the utility and security of our digital\ninteractions. This paper investigates the transformative role of Generative AI\nin Social Engineering (SE) attacks. We conduct a systematic review of social\nengineering and AI capabilities and use a theory of social engineering to\nidentify three pillars where Generative AI amplifies the impact of SE attacks:\nRealistic Content Creation, Advanced Targeting and Personalization, and\nAutomated Attack Infrastructure. We integrate these elements into a conceptual\nmodel designed to investigate the complex nature of AI-driven SE attacks - the\nGenerative AI Social Engineering Framework. We further explore human\nimplications and potential countermeasures to mitigate these risks. Our study\naims to foster a deeper understanding of the risks, human implications, and\ncountermeasures associated with this emerging paradigm, thereby contributing to\na more secure and trustworthy human-computer interaction.",
      "citation_count": 18,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ec9e1baf7f7f2fdc529790edf9af23c320581d67",
      "published_date": "2023-10-15",
      "downloaded_date": "2025-02-01",
      "filename": "Schmitt-Digital Deception Generative Artificial Intelligence in Social Engineering and Phishing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.13715v1",
      "categories": [
        "cs.CR",
        "cs.CY",
        "cs.HC"
      ]
    },
    "2205.01296v2": {
      "title": "Visual Knowledge Discovery with Artificial Intelligence: Challenges and Future Directions",
      "authors": [
        "Boris Kovalerchuk",
        "RÄzvan Andonie",
        "Nuno Datia",
        "Kawa Nazemi",
        "Ebad Banissi"
      ],
      "abstract": "This volume is devoted to the emerging field of Integrated Visual Knowledge\nDiscovery that combines advances in Artificial Intelligence/Machine Learning\n(AI/ML) and Visualization/Visual Analytics. Chapters included are extended\nversions of the selected AI and Visual Analytics papers and related symposia at\nthe recent International Information Visualization Conferences (IV2019 and\nIV2020). AI/ML face a long-standing challenge of explaining models to humans.\nModels explanation is fundamentally human activity, not only an algorithmic\none. In this chapter we aim to present challenges and future directions within\nthe field of Visual Analytics, Visual Knowledge Discovery and AI/ML, and to\ndiscuss the role of visualization in visual AI/ML. In addition, we describe\nprogress in emerging Full 2D ML, natural language processing, and AI/ML in\nmultidimensional data aided by visual means.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b3c91ad274b699401641abdaf10c0c1d6e955d7c",
      "published_date": "2022-05-03",
      "downloaded_date": "2025-02-01",
      "filename": "Kovalerchuk-Visual Knowledge Discovery with Artificial Intelligence Challenges and Future Directions.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.01296v2",
      "categories": [
        "cs.AI"
      ]
    },
    "1909.00560v2": {
      "title": "Edge Intelligence: The Confluence of Edge Computing and Artificial Intelligence",
      "authors": [
        "Shuiguang Deng",
        "Hailiang Zhao",
        "Weijia Fang",
        "Jianwei Yin",
        "Schahram Dustdar",
        "Albert Y. Zomaya"
      ],
      "abstract": "Along with the rapid developments in communication technologies and the surge\nin the use of mobile devices, a brand-new computation paradigm, Edge Computing,\nis surging in popularity. Meanwhile, Artificial Intelligence (AI) applications\nare thriving with the breakthroughs in deep learning and the many improvements\nin hardware architectures. Billions of data bytes, generated at the network\nedge, put massive demands on data processing and structural optimization. Thus,\nthere exists a strong demand to integrate Edge Computing and AI, which gives\nbirth to Edge Intelligence. In this paper, we divide Edge Intelligence into AI\nfor edge (Intelligence-enabled Edge Computing) and AI on edge (Artificial\nIntelligence on Edge). The former focuses on providing more optimal solutions\nto key problems in Edge Computing with the help of popular and effective AI\ntechnologies while the latter studies how to carry out the entire process of\nbuilding AI models, i.e., model training and inference, on the edge. This paper\nprovides insights into this new inter-disciplinary field from a broader\nperspective. It discusses the core concepts and the research road-map, which\nshould provide the necessary background for potential future research\ninitiatives in Edge Intelligence.",
      "citation_count": 564,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/40fb2468c3a77c68fe703a6e614f4ad25bd4e3dd",
      "published_date": "2019-09-02",
      "downloaded_date": "2025-02-01",
      "filename": "Deng-Edge Intelligence The Confluence of Edge Computing and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1909.00560v2",
      "categories": [
        "cs.NI",
        "cs.DC"
      ]
    },
    "2407.02731v1": {
      "title": "Artificial intelligence and machine learning generated conjectures with TxGraffiti",
      "authors": [
        "Randy Davila"
      ],
      "abstract": "\\emph{TxGraffiti} is a machine learning and heuristic based artificial\nintelligence designed to automate the task of conjecturing in mathematics.\nSince its inception, TxGraffiti has generated many surprising conjectures\nleading to publication in respectable mathematical journals. In this paper we\noutline the machine learning and heuristic techniques implemented by\nTxGraffiti. We also recall its contributions to the mathematical literature and\nannounce a new online version of the program available for anyone curious to\nexplore conjectures in graph theory.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-07-03",
      "downloaded_date": "2025-02-01",
      "filename": "Davila-Artificial intelligence and machine learning generated conjectures with TxGraffiti.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.02731v1",
      "categories": [
        "cs.AI",
        "math.CO"
      ]
    },
    "2412.01829v1": {
      "title": "Explainable Artificial Intelligence for Medical Applications: A Review",
      "authors": [
        "Qiyang Sun",
        "Alican Akman",
        "BjÃ¶rn W. Schuller"
      ],
      "abstract": "The continuous development of artificial intelligence (AI) theory has\npropelled this field to unprecedented heights, owing to the relentless efforts\nof scholars and researchers. In the medical realm, AI takes a pivotal role,\nleveraging robust machine learning (ML) algorithms. AI technology in medical\nimaging aids physicians in X-ray, computed tomography (CT) scans, and magnetic\nresonance imaging (MRI) diagnoses, conducts pattern recognition and disease\nprediction based on acoustic data, delivers prognoses on disease types and\ndevelopmental trends for patients, and employs intelligent health management\nwearable devices with human-computer interaction technology to name but a few.\nWhile these well-established applications have significantly assisted in\nmedical field diagnoses, clinical decision-making, and management,\ncollaboration between the medical and AI sectors faces an urgent challenge: How\nto substantiate the reliability of decision-making? The underlying issue stems\nfrom the conflict between the demand for accountability and result transparency\nin medical scenarios and the black-box model traits of AI. This article reviews\nrecent research grounded in explainable artificial intelligence (XAI), with an\nemphasis on medical practices within the visual, audio, and multimodal\nperspectives. We endeavour to categorise and synthesise these practices, aiming\nto provide support and guidance for future researchers and healthcare\nprofessionals.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c87d6af4730f41903c1d792cb7f9701bc88cf3eb",
      "published_date": "2024-11-15",
      "downloaded_date": "2025-02-01",
      "filename": "Sun-Explainable Artificial Intelligence for Medical Applications A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.01829v1",
      "categories": [
        "cs.LG",
        "cs.CV"
      ]
    },
    "2311.18614v1": {
      "title": "Anatomy and Physiology of Artificial Intelligence in PET Imaging",
      "authors": [
        "Tyler J. Bradshaw",
        "Alan B. McMillan"
      ],
      "abstract": "The influence of artificial intelligence (AI) within the field of nuclear\nmedicine has been rapidly growing. Many researchers and clinicians are seeking\nto apply AI within PET, and clinicians will soon find themselves engaging with\nAI-based applications all along the chain of molecular imaging, from image\nreconstruction to enhanced reporting. This expanding presence of AI in PET\nimaging will result in greater demand for educational resources for those\nunfamiliar with AI. The objective of this article to is provide an illustrated\nguide to the core principles of modern AI, with specific focus on aspects that\nare most likely to be encountered in PET imaging. We describe convolutional\nneural networks, algorithm training, and explain the components of the commonly\nused U-Net for segmentation and image synthesis.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/866945d2a4b5284da57be43146a3189001e9569a",
      "published_date": "2023-11-30",
      "downloaded_date": "2025-02-01",
      "filename": "Bradshaw-Anatomy and Physiology of Artificial Intelligence in PET Imaging.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.18614v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2307.06521v1": {
      "title": "Artificial Intelligence for Drug Discovery: Are We There Yet?",
      "authors": [
        "Catrin Hasselgren",
        "Tudor I. Oprea"
      ],
      "abstract": "Drug discovery is adapting to novel technologies such as data science,\ninformatics, and artificial intelligence (AI) to accelerate effective treatment\ndevelopment while reducing costs and animal experiments. AI is transforming\ndrug discovery, as indicated by increasing interest from investors, industrial\nand academic scientists, and legislators. Successful drug discovery requires\noptimizing properties related to pharmacodynamics, pharmacokinetics, and\nclinical outcomes. This review discusses the use of AI in the three pillars of\ndrug discovery: diseases, targets, and therapeutic modalities, with a focus on\nsmall molecule drugs. AI technologies, such as generative chemistry, machine\nlearning, and multi-property optimization, have enabled several compounds to\nenter clinical trials. The scientific community must carefully vet known\ninformation to address the reproducibility crisis. The full potential of AI in\ndrug discovery can only be realized with sufficient ground truth and\nappropriate human intervention at later pipeline stages.",
      "citation_count": 42,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0900126a594d07ac519299b559b21b73d2e4ee5a",
      "published_date": "2023-07-13",
      "downloaded_date": "2025-02-01",
      "filename": "Hasselgren-Artificial Intelligence for Drug Discovery Are We There Yet.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.06521v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ]
    },
    "2102.12516v1": {
      "title": "A Large-Scale, Automated Study of Language Surrounding Artificial Intelligence",
      "authors": [
        "Autumn Toney"
      ],
      "abstract": "This work presents a large-scale analysis of artificial intelligence (AI) and\nmachine learning (ML) references within news articles and scientific\npublications between 2011 and 2019. We implement word association measurements\nthat automatically identify shifts in language co-occurring with AI/ML and\nquantify the strength of these word associations. Our results highlight the\nevolution of perceptions and definitions around AI/ML and detect emerging\napplication areas, models, and systems (e.g., blockchain and cybersecurity).\nRecent small-scale, manual studies have explored AI/ML discourse within the\ngeneral public, the policymaker community, and researcher community, but are\nlimited in their scalability and longevity. Our methods provide new views into\npublic perceptions and subject-area expert discussions of AI/ML and greatly\nexceed the explanative power of prior work.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fabbc42780f13ac5db94f00bb5a518943a49b211",
      "published_date": "2021-02-24",
      "downloaded_date": "2025-02-01",
      "filename": "Toney-A Large-Scale Automated Study of Language Surrounding Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.12516v1",
      "categories": [
        "cs.CL"
      ]
    },
    "2111.00881v1": {
      "title": "Artificial Intelligence in the Low-Level Realm -- A Survey",
      "authors": [
        "Vahid Mohammadi Safarzadeh",
        "Hamed Ghasr Loghmani"
      ],
      "abstract": "Resource-aware machine learning has been a trending topic in recent years,\nfocusing on making ML computational aspects more exploitable by the edge\ndevices in the Internet of Things. This paper attempts to review a conceptually\nand practically related area concentrated on efforts and challenges for\napplying ML in the operating systems' main tasks in a low-resource environment.\nArtificial Intelligence has been integrated into the operating system with\napplications such as voice or image recognition. However, this integration is\nonly in user space. Here, we seek methods and efforts that exploit AI\napproaches, specifically machine learning, in the OSes' primary\nresponsibilities. We provide the improvements that ML can bring to OS to make\nthem more trustworthy. In other words, the main question to be answered is how\nAI has played/can play a role directly in improving the traditional OS kernel\nmain tasks. Also, the challenges and limitations in the way of this combination\nare provided.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-09-19",
      "downloaded_date": "2025-02-01",
      "filename": "Safarzadeh-Artificial Intelligence in the Low-Level Realm -- A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.00881v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2004.12059v2": {
      "title": "SAIA: Split Artificial Intelligence Architecture for Mobile Healthcare System",
      "authors": [
        "Di Zhuang",
        "Nam Nguyen",
        "Keyu Chen",
        "J. Morris Chang"
      ],
      "abstract": "As the advancement of deep learning (DL), the Internet of Things and cloud\ncomputing techniques for biomedical and healthcare problems, mobile healthcare\nsystems have received unprecedented attention. Since DL techniques usually\nrequire enormous amount of computation, most of them cannot be directly\ndeployed on the resource-constrained mobile and IoT devices. Hence, most of the\nmobile healthcare systems leverage the cloud computing infrastructure, where\nthe data collected by the mobile and IoT devices would be transmitted to the\ncloud computing platforms for analysis. However, in the contested environments,\nrelying on the cloud might not be practical at all times. For instance, the\nsatellite communication might be denied or disrupted. We propose SAIA, a Split\nArtificial Intelligence Architecture for mobile healthcare systems. Unlike\ntraditional approaches for artificial intelligence (AI) which solely exploits\nthe computational power of the cloud server, SAIA could not only relies on the\ncloud computing infrastructure while the wireless communication is available,\nbut also utilizes the lightweight AI solutions that work locally on the client\nside, hence, it can work even when the communication is impeded. In SAIA, we\npropose a meta-information based decision unit, that could tune whether a\nsample captured by the client should be operated by the embedded AI (i.e.,\nkeeping on the client) or the networked AI (i.e., sending to the server), under\ndifferent conditions. In our experimental evaluation, extensive experiments\nhave been conducted on two popular healthcare datasets. Our results show that\nSAIA consistently outperforms its baselines in terms of both effectiveness and\nefficiency.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-04-25",
      "downloaded_date": "2025-02-01",
      "filename": "Zhuang-SAIA Split Artificial Intelligence Architecture for Mobile Healthcare System.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.12059v2",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ]
    },
    "1908.02134v1": {
      "title": "Adapting SQuaRE for Quality Assessment of Artificial Intelligence Systems",
      "authors": [
        "Hiroshi Kuwajima",
        "Fuyuki Ishikawa"
      ],
      "abstract": "More and more software practitioners are tackling towards industrial\napplications of artificial intelligence (AI) systems, especially those based on\nmachine learning (ML). However, many of existing principles and approaches to\ntraditional systems do not work effectively for the system behavior obtained by\ntraining not by logical design. In addition, unique kinds of requirements are\nemerging such as fairness and explainability. To provide clear guidance to\nunderstand and tackle these difficulties, we present an analysis on what\nquality concepts we should evaluate for AI systems. We base our discussion on\nISO/IEC 25000 series, known as SQuaRE, and identify how it should be adapted\nfor the unique nature of ML and $\\textit{Ethics guidelines for trustworthy AI}$\nfrom European Commission. We thus provide holistic insights for quality of AI\nsystems by incorporating the ML nature and AI ethics to the traditional\nsoftware quality concepts.",
      "citation_count": 30,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7f4cb5546bab43fa01988385fb89546e57485b69",
      "published_date": "2019-07-31",
      "downloaded_date": "2025-02-01",
      "filename": "Kuwajima-Adapting SQuaRE for Quality Assessment of Artificial Intelligence Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1908.02134v1",
      "categories": [
        "cs.CY",
        "cs.LG",
        "cs.SE"
      ]
    },
    "1803.06818v3": {
      "title": "Artificial Intelligence Enabled Software Defined Networking: A Comprehensive Overview",
      "authors": [
        "Majd Latah",
        "Levent Toker"
      ],
      "abstract": "Software defined networking (SDN) represents a promising networking\narchitecture that combines central management and network programmability. SDN\nseparates the control plane from the data plane and moves the network\nmanagement to a central point, called the controller, that can be programmed\nand used as the brain of the network. Recently, the research community has\nshowed an increased tendency to benefit from the recent advancements in the\nartificial intelligence (AI) field to provide learning abilities and better\ndecision making in SDN. In this study, we provide a detailed overview of the\nrecent efforts to include AI in SDN. Our study showed that the research efforts\nfocused on three main sub-fields of AI namely: machine learning,\nmeta-heuristics and fuzzy inference systems. Accordingly, in this work we\ninvestigate their different application areas and potential use, as well as the\nimprovements achieved by including AI-based techniques in the SDN paradigm.",
      "citation_count": 97,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ee80f09a345980ca1d0fe2b0cc3a517532ce449c",
      "published_date": "2018-03-19",
      "downloaded_date": "2025-02-01",
      "filename": "Latah-Artificial Intelligence Enabled Software Defined Networking A Comprehensive Overview.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1803.06818v3",
      "categories": [
        "cs.AI",
        "cs.NI"
      ]
    },
    "1804.08150v4": {
      "title": "Deep Learning in Spiking Neural Networks",
      "authors": [
        "Amirhossein Tavanaei",
        "Masoud Ghodrati",
        "Saeed Reza Kheradpisheh",
        "Timothee Masquelier",
        "Anthony S. Maida"
      ],
      "abstract": "In recent years, deep learning has been a revolution in the field of machine\nlearning, for computer vision in particular. In this approach, a deep\n(multilayer) artificial neural network (ANN) is trained in a supervised manner\nusing backpropagation. Huge amounts of labeled examples are required, but the\nresulting classification accuracy is truly impressive, sometimes outperforming\nhumans. Neurons in an ANN are characterized by a single, static,\ncontinuous-valued activation. Yet biological neurons use discrete spikes to\ncompute and transmit information, and the spike times, in addition to the spike\nrates, matter. Spiking neural networks (SNNs) are thus more biologically\nrealistic than ANNs, and arguably the only viable option if one wants to\nunderstand how the brain computes. SNNs are also more hardware friendly and\nenergy-efficient than ANNs, and are thus appealing for technology, especially\nfor portable devices. However, training deep SNNs remains a challenge. Spiking\nneurons' transfer function is usually non-differentiable, which prevents using\nbackpropagation. Here we review recent supervised and unsupervised methods to\ntrain deep SNNs, and compare them in terms of accuracy, but also computational\ncost and hardware friendliness. The emerging picture is that SNNs still lag\nbehind ANNs in terms of accuracy, but the gap is decreasing, and can even\nvanish on some tasks, while the SNNs typically require much fewer operations.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-04-22",
      "downloaded_date": "2025-02-01",
      "filename": "Tavanaei-Deep Learning in Spiking Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1804.08150v4",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    "1912.13122v7": {
      "title": "Towards Regulated Deep Learning",
      "authors": [
        "AndrÃ©s GarcÃ­a-Camino"
      ],
      "abstract": "Regulation of Multi-Agent Systems (MAS) and Declarative Electronic\nInstitutions (DEIs) was a multidisciplinary research topic of the past decade\ninvolving (Physical and Software) Agents and Law since the beginning, but\nrecently evolved towards News-claimed Robot Lawyer since 2016. One of these\nfirst proposals of restricting the behaviour of Software Agents was Electronic\nInstitutions.However, with the recent reformulation of Artificial Neural\nNetworks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal\nissues regarding the use of DL has raised concerns in the Artificial\nIntelligence (AI) Community. Now that the Regulation of MAS is almost correctly\naddressed, we propose the Regulation of Artificial Neural Networks as\nAgent-based Training of a special type of regulated Artificial Neural Network\nthat we call Institutional Neural Network (INN).The main purpose of this paper\nis to bring attention to Artificial Teaching (AT) and to give a tentative\nanswer showing a proof-of-concept implementation of Regulated Deep Learning\n(RDL). This paper introduces the former concept and provide $I^*$, a language\npreviously used to model declaratively and extend Electronic Institutions, as a\nmeans to regulate the execution of Artificial Neural Networks and their\ninteractions with Artificial Teachers (ATs)",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2f141d660281b62e83c6187f98c6af027a614c0e",
      "published_date": "2019-12-31",
      "downloaded_date": "2025-02-01",
      "filename": "GarcÃ­a-Camino-Towards Regulated Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1912.13122v7",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.MA",
        "cs.PL"
      ]
    },
    "1905.10985v2": {
      "title": "AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence",
      "authors": [
        "Jeff Clune"
      ],
      "abstract": "Perhaps the most ambitious scientific quest in human history is the creation\nof general artificial intelligence, which roughly means AI that is as smart or\nsmarter than humans. The dominant approach in the machine learning community is\nto attempt to discover each of the pieces required for intelligence, with the\nimplicit assumption that some future group will complete the Herculean task of\nfiguring out how to combine all of those pieces into a complex thinking\nmachine. I call this the \"manual AI approach\". This paper describes another\nexciting path that ultimately may be more successful at producing general AI.\nIt is based on the clear trend in machine learning that hand-designed solutions\neventually are replaced by more effective, learned solutions. The idea is to\ncreate an AI-generating algorithm (AI-GA), which automatically learns how to\nproduce general AI. Three Pillars are essential for the approach: (1)\nmeta-learning architectures, (2) meta-learning the learning algorithms\nthemselves, and (3) generating effective learning environments. I argue that\neither approach could produce general AI first, and both are scientifically\nworthwhile irrespective of which is the fastest path. Because both are\npromising, yet the ML community is currently committed to the manual approach,\nI argue that our community should increase its research investment in the AI-GA\napproach. To encourage such research, I describe promising work in each of the\nThree Pillars. I also discuss AI-GA-specific safety and ethical considerations.\nBecause it it may be the fastest path to general AI and because it is\ninherently scientifically interesting to understand the conditions in which a\nsimple algorithm can produce general AI (as happened on Earth where Darwinian\nevolution produced human intelligence), I argue that the pursuit of AI-GAs\nshould be considered a new grand challenge of computer science research.",
      "citation_count": 107,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/42525a5143c6a87d3ab466684dfa471dc43a5bd0",
      "published_date": "2019-05-27",
      "downloaded_date": "2025-02-01",
      "filename": "Clune-AI-GAs AI-generating algorithms an alternate paradigm for producing general artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1905.10985v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2212.11854v4": {
      "title": "Data-Centric Artificial Intelligence",
      "authors": [
        "Johannes Jakubik",
        "Michael VÃ¶ssing",
        "Niklas KÃ¼hl",
        "Jannis Walk",
        "Gerhard Satzger"
      ],
      "abstract": "Data-centric artificial intelligence (data-centric AI) represents an emerging\nparadigm emphasizing that the systematic design and engineering of data is\nessential for building effective and efficient AI-based systems. The objective\nof this article is to introduce practitioners and researchers from the field of\nInformation Systems (IS) to data-centric AI. We define relevant terms, provide\nkey characteristics to contrast the data-centric paradigm to the model-centric\none, and introduce a framework for data-centric AI. We distinguish data-centric\nAI from related concepts and discuss its longer-term implications for the IS\ncommunity.",
      "citation_count": 150,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/12c6be503e4e5b7c9cb1810152d4364f26628a8d",
      "published_date": "2022-12-22",
      "downloaded_date": "2025-02-01",
      "filename": "Jakubik-Data-Centric Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.11854v4",
      "categories": [
        "cs.AI"
      ]
    },
    "2210.07327v1": {
      "title": "Machine Learning vs. Deep Learning in 5G Networks -- A Comparison of Scientific Impact",
      "authors": [
        "Ilker Turker",
        "Serhat Orkun Tan"
      ],
      "abstract": "Introduction of fifth generation (5G) wireless network technology has matched\nthe crucial need for high capacity and speed needs of the new generation mobile\napplications. Recent advances in Artificial Intelligence (AI) also empowered 5G\ncellular networks with two mainstreams as machine learning (ML) and deep\nlearning (DL) techniques. Our study aims to uncover the differences in\nscientific impact for these two techniques by the means of statistical\nbibliometrics. The performed analysis includes citation performance with\nrespect to indexing types, funding availability, journal or conference\npublishing options together with distributions of these metrics along years to\nevaluate the popularity trends in a detailed manner. Web of Science (WoS)\ndatabase host 2245 papers for ML and 1407 papers for DL-related studies. DL\nstudies, starting with 9% rate in 2013, has reached to 45% rate in 2022 among\nall DL and ML-related studies. Results related to scientific impact indicate\nthat DL studies get slightly more average normalized citation (2.256) compared\nto ML studies (2.118) in 5G, while SCI-Expanded indexed papers in both sides\ntend to have similar citation performance (3.165 and 3.162 respectively).\nML-related studies those are indexed in ESCI show twice citation performance\ncompared to DL. Conference papers in DL domain and journal papers in ML domain\nare superior in scientific interest to their counterparts with minor\ndifferences. Highest citation performance for ML studies is achieved for year\n2014, while this peak is observed for 2017 for DL studies. We can conclude that\nboth publication and citation rate for DL-related papers tend to increase and\noutperform ML-based studies in 5G domain by the means of citation metrics.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-10-13",
      "downloaded_date": "2025-02-01",
      "filename": "Turker-Machine Learning vs Deep Learning in 5G Networks -- A Comparison of Scientific Impact.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.07327v1",
      "categories": [
        "cs.DL",
        "cs.AI"
      ]
    },
    "2207.05329v1": {
      "title": "Deep Learning with Coherent VCSEL Neural Networks",
      "authors": [
        "Zaijun Chen",
        "Alexander Sludds",
        "Ronald Davis",
        "Ian Christen",
        "Liane Bernstein",
        "Tobias Heuser",
        "Niels Heermeier",
        "James A. Lott",
        "Stephan Reitzenstein",
        "Ryan Hamerly",
        "Dirk Englund"
      ],
      "abstract": "Deep neural networks (DNNs) are reshaping the field of information\nprocessing. With their exponential growth challenging existing electronic\nhardware, optical neural networks (ONNs) are emerging to process DNN tasks in\nthe optical domain with high clock rates, parallelism and low-loss data\ntransmission. However, to explore the potential of ONNs, it is necessary to\ninvestigate the full-system performance incorporating the major DNN elements,\nincluding matrix algebra and nonlinear activation. Existing challenges to ONNs\nare high energy consumption due to low electro-optic (EO) conversion\nefficiency, low compute density due to large device footprint and channel\ncrosstalk, and long latency due to the lack of inline nonlinearity. Here we\nexperimentally demonstrate an ONN system that simultaneously overcomes all\nthese challenges. We exploit neuron encoding with volume-manufactured\nmicron-scale vertical-cavity surface-emitting laser (VCSEL) transmitter arrays\nthat exhibit high EO conversion (<5 attojoule/symbol with $V_\\pi$=4 mV), high\noperation bandwidth (up to 25 GS/s), and compact footprint (<0.01 mm$^2$ per\ndevice). Photoelectric multiplication allows low-energy matrix operations at\nthe shot-noise quantum limit. Homodyne detection-based nonlinearity enables\nnonlinear activation with instantaneous response. The full-system energy\nefficiency and compute density reach 7 femtojoules per operation (fJ/OP) and 25\nTeraOP/(mm$^2\\cdot$ s), both representing a >100-fold improvement over\nstate-of-the-art digital computers, with substantially several more orders of\nmagnitude for future improvement. Beyond neural network inference, its feature\nof rapid weight updating is crucial for training deep learning models. Our\ntechnique opens an avenue to large-scale optoelectronic processors to\naccelerate machine learning tasks from data centers to decentralized edge\ndevices.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-07-12",
      "downloaded_date": "2025-02-01",
      "filename": "Chen-Deep Learning with Coherent VCSEL Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2207.05329v1",
      "categories": [
        "cs.ET",
        "physics.optics"
      ]
    },
    "2107.03178v1": {
      "title": "Levels of explainable artificial intelligence for human-aligned conversational explanations",
      "authors": [
        "Richard Dazeley",
        "Peter Vamplew",
        "Cameron Foale",
        "Charlotte Young",
        "Sunil Aryal",
        "Francisco Cruz"
      ],
      "abstract": "Over the last few years there has been rapid research growth into eXplainable\nArtificial Intelligence (XAI) and the closely aligned Interpretable Machine\nLearning (IML). Drivers for this growth include recent legislative changes and\nincreased investments by industry and governments, along with increased concern\nfrom the general public. People are affected by autonomous decisions every day\nand the public need to understand the decision-making process to accept the\noutcomes. However, the vast majority of the applications of XAI/IML are focused\non providing low-level `narrow' explanations of how an individual decision was\nreached based on a particular datum. While important, these explanations rarely\nprovide insights into an agent's: beliefs and motivations; hypotheses of other\n(human, animal or AI) agents' intentions; interpretation of external cultural\nexpectations; or, processes used to generate its own explanation. Yet all of\nthese factors, we propose, are essential to providing the explanatory depth\nthat people require to accept and trust the AI's decision-making. This paper\naims to define levels of explanation and describe how they can be integrated to\ncreate a human-aligned conversational explanation system. In so doing, this\npaper will survey current approaches and discuss the integration of different\ntechnologies to achieve these levels with Broad eXplainable Artificial\nIntelligence (Broad-XAI), and thereby move towards high-level `strong'\nexplanations.",
      "citation_count": 86,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/47dc11152d8b90e794a32cc0d55e6115d9290c46",
      "published_date": "2021-07-07",
      "downloaded_date": "2025-02-01",
      "filename": "Dazeley-Levels of explainable artificial intelligence for human-aligned conversational explanations.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.03178v1",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    "1907.05505v1": {
      "title": "Artificial Intelligence as a Services (AI-aaS) on Software-Defined Infrastructure",
      "authors": [
        "Saeedeh Parsaeefard",
        "Iman Tabrizian",
        "Alberto Leon-Garcia"
      ],
      "abstract": "This paper investigates a paradigm for offering artificial intelligence as a\nservice (AI-aaS) on software-defined infrastructures (SDIs). The increasing\ncomplexity of networking and computing infrastructures is already driving the\nintroduction of automation in networking and cloud computing management\nsystems. Here we consider how these automation mechanisms can be leveraged to\noffer AI-aaS. Use cases for AI-aaS are easily found in addressing smart\napplications in sectors such as transportation, manufacturing, energy, water,\nair quality, and emissions. We propose an architectural scheme based on SDIs\nwhere each AI-aaS application is comprised of a monitoring, analysis, policy,\nexecution plus knowledge (MAPE-K) loop (MKL). Each application is composed as\none or more specific service chains embedded in SDI, some of which will include\na Machine Learning (ML) pipeline. Our model includes a new training plane and\nan AI-aaS plane to deal with the model-development and operational phases of AI\napplications. We also consider the role of an ML/MKL sandbox in ensuring\ncoherency and consistency in the operation of multiple parallel MKL loops. We\npresent experimental measurement results for three AI-aaS applications deployed\non the SAVI testbed: 1. Compressing monitored data in SDI using autoencoders;\n2. Traffic monitoring to allocate CPUs resources to VNFs; and 3. Highway\nsegment classification in smart transportation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-07-11",
      "downloaded_date": "2025-02-01",
      "filename": "Parsaeefard-Artificial Intelligence as a Services AI-aaS on Software-Defined Infrastructure.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.05505v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    "2305.05668v1": {
      "title": "Neurosymbolic Artificial Intelligence (NSAI) based Algorithm for predicting the Impact Strength of Additive Manufactured Polylactic Acid (PLA) Specimens",
      "authors": [
        "Akshansh Mishra",
        "Vijaykumar S Jatti"
      ],
      "abstract": "In this study, we introduce application of Neurosymbolic Artificial\nIntelligence (NSAI) for predicting the impact strength of additive manufactured\npolylactic acid (PLA) components, representing the first-ever use of NSAI in\nthe domain of additive manufacturing. The NSAI model amalgamates the advantages\nof neural networks and symbolic AI, offering a more robust and accurate\nprediction than traditional machine learning techniques. Experimental data was\ncollected and synthetically augmented to 1000 data points, enhancing the\nmodel's precision. The Neurosymbolic model was developed using a neural network\narchitecture comprising input, two hidden layers, and an output layer, followed\nby a decision tree regressor representing the symbolic component. The model's\nperformance was benchmarked against a Simple Artificial Neural Network (ANN)\nmodel by assessing mean squared error (MSE) and R-squared (R2) values for both\ntraining and validation datasets. The results reveal that the Neurosymbolic\nmodel surpasses the Simple ANN model, attaining lower MSE and higher R2 values\nfor both training and validation sets. This innovative application of the\nNeurosymbolic approach in estimating the impact strength of additive\nmanufactured PLA components underscores its potential for optimizing the\nadditive manufacturing process. Future research could investigate further\nrefinements to the Neurosymbolic model, extend its application to other\nmaterials and additive manufacturing processes, and incorporate real-time\nmonitoring and control for enhanced process optimization.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b32c70039eb9f3eb3e89e31775548f1f7214e4a3",
      "published_date": "2023-05-07",
      "downloaded_date": "2025-02-01",
      "filename": "Mishra-Neurosymbolic Artificial Intelligence NSAI based Algorithm for predicting the Impact Strength of Add....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.05668v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1907.03370v1": {
      "title": "Artificial Intelligence Alter Egos: Who benefits from Robo-investing?",
      "authors": [
        "Catherine D'Hondt",
        "Rudy De Winne",
        "Eric Ghysels",
        "Steve Raymond"
      ],
      "abstract": "Artificial intelligence, or AI, enhancements are increasingly shaping our\ndaily lives. Financial decision-making is no exception to this. We introduce\nthe notion of AI Alter Egos, which are shadow robo-investors, and use a unique\ndata set covering brokerage accounts for a large cross-section of investors\nover a sample from January 2003 to March 2012, which includes the 2008\nfinancial crisis, to assess the benefits of robo-investing. We have detailed\ninvestor characteristics and records of all trades. Our data set consists of\ninvestors typically targeted for robo-advising. We explore robo-investing\nstrategies commonly used in the industry, including some involving advanced\nmachine learning methods. The man versus machine comparison allows us to shed\nlight on potential benefits the emerging robo-advising industry may provide to\ncertain segments of the population, such as low income and/or high risk averse\ninvestors.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-07-08",
      "downloaded_date": "2025-02-01",
      "filename": "D'Hondt-Artificial Intelligence Alter Egos Who benefits from Robo-investing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.03370v1",
      "categories": [
        "q-fin.PM",
        "econ.EM",
        "q-fin.ST"
      ]
    },
    "1907.04105v1": {
      "title": "On the Semantic Interpretability of Artificial Intelligence Models",
      "authors": [
        "Vivian S. Silva",
        "AndrÃ© Freitas",
        "Siegfried Handschuh"
      ],
      "abstract": "Artificial Intelligence models are becoming increasingly more powerful and\naccurate, supporting or even replacing humans' decision making. But with\nincreased power and accuracy also comes higher complexity, making it hard for\nusers to understand how the model works and what the reasons behind its\npredictions are. Humans must explain and justify their decisions, and so do the\nAI models supporting them in this process, making semantic interpretability an\nemerging field of study. In this work, we look at interpretability from a\nbroader point of view, going beyond the machine learning scope and covering\ndifferent AI fields such as distributional semantics and fuzzy logic, among\nothers. We examine and classify the models according to their nature and also\nbased on how they introduce interpretability features, analyzing how each\napproach affects the final users and pointing to gaps that still need to be\naddressed to provide more human-centered interpretability solutions.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0b4f56dc95ac2985a371e31a62ee171676cfdaea",
      "published_date": "2019-07-09",
      "downloaded_date": "2025-02-01",
      "filename": "Silva-On the Semantic Interpretability of Artificial Intelligence Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.04105v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    "1911.09606v2": {
      "title": "An Introduction to Symbolic Artificial Intelligence Applied to Multimedia",
      "authors": [
        "Guilherme Lima",
        "Rodrigo Costa",
        "Marcio Ferreira Moreno"
      ],
      "abstract": "In this chapter, we give an introduction to symbolic artificial intelligence\n(AI) and discuss its relation and application to multimedia. We begin by\ndefining what symbolic AI is, what distinguishes it from non-symbolic\napproaches, such as machine learning, and how it can used in the construction\nof advanced multimedia applications. We then introduce description logic (DL)\nand use it to discuss symbolic representation and reasoning. DL is the logical\nunderpinning of OWL, the most successful family of ontology languages. After\ndiscussing DL, we present OWL and related Semantic Web technologies, such as\nRDF and SPARQL. We conclude the chapter by discussing a hybrid model for\nmultimedia representation, called Hyperknowledge. Throughout the text, we make\nreferences to technologies and extensions specifically designed to solve the\nkinds of problems that arise in multimedia representation.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/174f9a60cc524df3ad17fcf556e42ca177e3e4ac",
      "published_date": "2019-11-21",
      "downloaded_date": "2025-02-01",
      "filename": "Lima-An Introduction to Symbolic Artificial Intelligence Applied to Multimedia.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.09606v2",
      "categories": [
        "cs.AI",
        "cs.MM"
      ]
    },
    "2107.06708v2": {
      "title": "MDE4QAI: Towards Model-Driven Engineering for Quantum Artificial Intelligence",
      "authors": [
        "Armin Moin",
        "Moharram Challenger",
        "Atta Badii",
        "Stephan GÃ¼nnemann"
      ],
      "abstract": "Over the past decade, Artificial Intelligence (AI) has provided enormous new\npossibilities and opportunities, but also new demands and requirements for\nsoftware systems. In particular, Machine Learning (ML) has proven useful in\nalmost every vertical application domain. In the decade ahead, an unprecedented\nparadigm shift from classical computing towards Quantum Computing (QC), with\nperhaps a quantum-classical hybrid model, is expected. We argue that the\nModel-Driven Engineering (MDE) paradigm can be an enabler and a facilitator,\nwhen it comes to the quantum and the quantum-classical hybrid applications.\nThis includes not only automated code generation, but also automated model\nchecking and verification, as well as model analysis in the early design\nphases, and model-to-model transformations both at the design-time and at the\nruntime. In this paper, the vision is focused on MDE for Quantum AI,\nparticularly Quantum ML for the Internet of Things (IoT) and smart\nCyber-Physical Systems (CPS) applications.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-07-14",
      "downloaded_date": "2025-02-01",
      "filename": "Moin-MDE4QAI Towards Model-Driven Engineering for Quantum Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.06708v2",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.ET"
      ]
    },
    "2210.08966v5": {
      "title": "Artificial Intelligence for Scientific Research: Authentic Research Education Framework",
      "authors": [
        "Sergey V Samsonau",
        "Aziza Kurbonova",
        "Lu Jiang",
        "Hazem Lashen",
        "Jiamu Bai",
        "Theresa Merchant",
        "Ruoxi Wang",
        "Laiba Mehnaz",
        "Zecheng Wang",
        "Ishita Patil"
      ],
      "abstract": "We report a framework that enables the wide adoption of authentic research\neducational methodology at various schools by addressing common barriers. The\nguiding principles we present were applied to implement a program in which\nteams of students with complementary skills develop useful artificial\nintelligence (AI) solutions for researchers in natural sciences. To accomplish\nthis, we work with research laboratories that reveal/specify their needs, and\nthen our student teams work on the discovery, design, and development of an AI\nsolution for unique problems using a consulting-like arrangement. To date, our\ngroup has been operating at New York University (NYU) for seven consecutive\nsemesters, has engaged more than a hundred students, ranging from first-year\ncollege students to master's candidates, and has worked with more than twenty\nprojects and collaborators. While creating education benefits for students, our\napproach also directly benefits scientists, who get an opportunity to evaluate\nthe usefulness of machine learning for their specific needs.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/66cf998a1085f180ead49e6f46220a7be5fedfbf",
      "published_date": "2022-09-19",
      "downloaded_date": "2025-02-01",
      "filename": "Samsonau-Artificial Intelligence for Scientific Research Authentic Research Education Framework.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.08966v5",
      "categories": [
        "cs.CY"
      ]
    },
    "2304.07889v2": {
      "title": "Ontology for Healthcare Artificial Intelligence Privacy in Brazil",
      "authors": [
        "Tiago Andres Vaz",
        "JosÃ© Miguel Silva Dora",
        "LuÃ­s da Cunha Lamb",
        "Suzi Alves Camey"
      ],
      "abstract": "This article details the creation of a novel domain ontology at the\nintersection of epidemiology, medicine, statistics, and computer science. Using\nthe terminology defined by current legislation, the article outlines a\nsystematic approach to handling hospital data anonymously in preparation for\nits use in Artificial Intelligence (AI) applications in healthcare. The\ndevelopment process consisted of 7 pragmatic steps, including defining scope,\nselecting knowledge, reviewing important terms, constructing classes that\ndescribe designs used in epidemiological studies, machine learning paradigms,\ntypes of data and attributes, risks that anonymized data may be exposed to,\nprivacy attacks, techniques to mitigate re-identification, privacy models, and\nmetrics for measuring the effects of anonymization. The article concludes by\ndemonstrating the practical implementation of this ontology in hospital\nsettings for the development and validation of AI.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/78c61b13efd28ce73bd3bc9371915350dedf2f7d",
      "published_date": "2023-04-16",
      "downloaded_date": "2025-02-01",
      "filename": "Vaz-Ontology for Healthcare Artificial Intelligence Privacy in Brazil.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.07889v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2406.10117v1": {
      "title": "Trustworthy Artificial Intelligence in the Context of Metrology",
      "authors": [
        "Tameem Adel",
        "Sam Bilson",
        "Mark Levene",
        "Andrew Thompson"
      ],
      "abstract": "We review research at the National Physical Laboratory (NPL) in the area of\ntrustworthy artificial intelligence (TAI), and more specifically trustworthy\nmachine learning (TML), in the context of metrology, the science of\nmeasurement. We describe three broad themes of TAI: technical, socio-technical\nand social, which play key roles in ensuring that the developed models are\ntrustworthy and can be relied upon to make responsible decisions. From a\nmetrology perspective we emphasise uncertainty quantification (UQ), and its\nimportance within the framework of TAI to enhance transparency and trust in the\noutputs of AI systems. We then discuss three research areas within TAI that we\nare working on at NPL, and examine the certification of AI systems in terms of\nadherence to the characteristics of TAI.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/83f6657bf66ac540f731edab87074720590b1f74",
      "published_date": "2024-06-14",
      "downloaded_date": "2025-02-01",
      "filename": "Adel-Trustworthy Artificial Intelligence in the Context of Metrology.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.10117v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2412.04045v1": {
      "title": "AI4EF: Artificial Intelligence for Energy Efficiency in the Building Sector",
      "authors": [
        "Alexandros Menelaos Tzortzis",
        "Georgios Kormpakis",
        "Sotiris Pelekis",
        "Ariadni Michalitsi-Psarrou",
        "Evangelos Karakolis",
        "Christos Ntanos",
        "Dimitris Askounis"
      ],
      "abstract": "AI4EF, Artificial Intelligence for Energy Efficiency, is an advanced,\nuser-centric tool designed to support decision-making in building energy\nretrofitting and efficiency optimization. Leveraging machine learning (ML) and\ndata-driven insights, AI4EF enables stakeholders such as public sector\nrepresentatives, energy consultants, and building owners to model, analyze, and\npredict energy consumption, retrofit costs, and environmental impacts of\nbuilding upgrades. Featuring a modular framework, AI4EF includes customizable\nbuilding retrofitting, photovoltaic installation assessment, and predictive\nmodeling tools that allow users to input building parameters and receive\ntailored recommendations for achieving energy savings and carbon reduction\ngoals. Additionally, the platform incorporates a Training Playground for data\nscientists to refine ML models used by said framework. Finally, AI4EF provides\naccess to the Enershare Data Space to facilitate seamless data sharing and\naccess within the ecosystem. Its compatibility with open-source identity\nmanagement, Keycloak, enhances security and accessibility, making it adaptable\nfor various regulatory and organizational contexts. This paper presents an\narchitectural overview of AI4EF, its application in energy efficiency\nscenarios, and its potential for advancing sustainable energy practices through\nartificial intelligence (AI).",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bbce6bb4b1abc763816fee4c92b6c372902b1bff",
      "published_date": "2024-12-05",
      "downloaded_date": "2025-02-01",
      "filename": "Tzortzis-AI4EF Artificial Intelligence for Energy Efficiency in the Building Sector.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.04045v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2202.01319v1": {
      "title": "Deep Learning for Epidemiologists: An Introduction to Neural Networks",
      "authors": [
        "Stylianos Serghiou",
        "Kathryn Rough"
      ],
      "abstract": "Deep learning methods are increasingly being applied to problems in medicine\nand healthcare. However, few epidemiologists have received formal training in\nthese methods. To bridge this gap, this article introduces to the fundamentals\nof deep learning from an epidemiological perspective. Specifically, this\narticle reviews core concepts in machine learning (overfitting, regularization,\nhyperparameters), explains several fundamental deep learning architectures\n(convolutional neural networks, recurrent neural networks), and summarizes\ntraining, evaluation, and deployment of models. We aim to enable the reader to\nengage with and critically evaluate medical applications of deep learning,\nfacilitating a dialogue between computer scientists and epidemiologists that\nwill improve the safety and efficacy of applications of this technology.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-02-02",
      "downloaded_date": "2025-02-01",
      "filename": "Serghiou-Deep Learning for Epidemiologists An Introduction to Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.01319v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2212.06330v1": {
      "title": "Generative artificial intelligence-enabled dynamic detection of nicotine-related circuits",
      "authors": [
        "Changwei Gong",
        "Changhong Jing",
        "Ye Li",
        "Xinan Liu",
        "Zuxin Chen",
        "Shuqiang Wang"
      ],
      "abstract": "The identification of addiction-related circuits is critical for explaining\naddiction processes and developing addiction treatments. And models of\nfunctional addiction circuits developed from functional imaging are an\neffective tool for discovering and verifying addiction circuits. However,\nanalyzing functional imaging data of addiction and detecting functional\naddiction circuits still have challenges. We have developed a data-driven and\nend-to-end generative artificial intelligence(AI) framework to address these\ndifficulties. The framework integrates dynamic brain network modeling and novel\nnetwork architecture networks architecture, including temporal graph\nTransformer and contrastive learning modules. A complete workflow is formed by\nour generative AI framework: the functional imaging data, from neurobiological\nexperiments, and computational modeling, to end-to-end neural networks, is\ntransformed into dynamic nicotine addiction-related circuits. It enables the\ndetection of addiction-related brain circuits with dynamic properties and\nreveals the underlying mechanisms of addiction.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-12-13",
      "downloaded_date": "2025-02-01",
      "filename": "Gong-Generative artificial intelligence-enabled dynamic detection of nicotine-related circuits.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.06330v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2105.05080v1": {
      "title": "ANDREAS: Artificial intelligence traiNing scheDuler foR accElerAted resource clusterS",
      "authors": [
        "Federica Filippini",
        "Danilo Ardagna",
        "Marco Lattuada",
        "Edoardo Amaldi",
        "Michele Ciavotta",
        "Maciek Riedl",
        "Katarzyna Materka",
        "PaweÅ Skrzypek",
        "Fabrizio Magugliani",
        "Marco Cicala"
      ],
      "abstract": "Artificial Intelligence (AI) and Deep Learning (DL) algorithms are currently\napplied to a wide range of products and solutions. DL training jobs are highly\nresource demanding and they experience great benefits when exploiting AI\naccelerators (e.g., GPUs). However, the effective management of GPU-powered\nclusters comes with great challenges. Among these, efficient scheduling and\nresource allocation solutions are crucial to maximize performance and minimize\nData Centers operational costs. In this paper we propose ANDREAS, an advanced\nscheduling solution that tackles these problems jointly, aiming at optimizing\nDL training runtime workloads and their energy consumption in accelerated\nclusters. Experiments based on simulation demostrate that we can achieve a cost\nreduction between 30 and 62% on average with respect to first-principle methods\nwhile the validation on a real cluster shows a worst case deviation below 13%\nbetween actual and predicted costs, proving the effectiveness of ANDREAS\nsolution in practical scenarios.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-05-11",
      "downloaded_date": "2025-02-01",
      "filename": "Filippini-ANDREAS Artificial intelligence traiNing scheDuler foR accElerAted resource clusterS.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.05080v1",
      "categories": [
        "cs.DC",
        "cs.AI"
      ]
    },
    "1912.11084v2": {
      "title": "Where Are We? Using Scopus to Map the Literature at the Intersection Between Artificial Intelligence and Research on Crime",
      "authors": [
        "Gian Maria Campedelli"
      ],
      "abstract": "Research on Artificial Intelligence (AI) applications has spread over many\nscientific disciplines. Scientists have tested the power of intelligent\nalgorithms developed to predict (or learn from) natural, physical and social\nphenomena. This also applies to crime-related research problems. Nonetheless,\nstudies that map the current state of the art at the intersection between AI\nand crime are lacking. What are the current research trends in terms of topics\nin this area? What is the structure of scientific collaboration when\nconsidering works investigating criminal issues using machine learning, deep\nlearning, and AI in general? What are the most active countries in this\nspecific scientific sphere? Using data retrieved from the Scopus database, this\nwork quantitatively analyzes 692 published works at the intersection between AI\nand crime employing network science to respond to these questions. Results show\nthat researchers are mainly focusing on cyber-related criminal topics and that\nrelevant themes such as algorithmic discrimination, fairness, and ethics are\nconsiderably overlooked. Furthermore, data highlight the extremely disconnected\nstructure of co-authorship networks. Such disconnectedness may represent a\nsubstantial obstacle to a more solid community of scientists interested in\nthese topics. Additionally, the graph of scientific collaboration indicates\nthat countries that are more prone to engage in international partnerships are\ngenerally less central in the network. This means that scholars working in\nhighly productive countries (e.g. the United States, China) tend to mostly\ncollaborate domestically. Finally, current issues and future developments\nwithin this scientific area are also discussed.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-12-23",
      "downloaded_date": "2025-02-01",
      "filename": "Campedelli-Where Are We Using Scopus to Map the Literature at the Intersection Between Artificial Intelligence ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1912.11084v2",
      "categories": [
        "cs.DL",
        "cs.CY",
        "cs.LG"
      ]
    },
    "2403.03581v1": {
      "title": "Enhancing ASD detection accuracy: a combined approach of machine learning and deep learning models with natural language processing",
      "authors": [
        "Sergio Rubio-MartÃ­n",
        "MarÃ­a Teresa GarcÃ­a-OrdÃ¡s",
        "MartÃ­n BayÃ³n-GutiÃ©rrez",
        "Natalia Prieto-FernÃ¡ndez",
        "JosÃ© Alberto BenÃ­tez-Andrades"
      ],
      "abstract": "Purpose: Our study explored the use of artificial intelligence (AI) to\ndiagnose autism spectrum disorder (ASD). It focused on machine learning (ML)\nand deep learning (DL) to detect ASD from text inputs on social media,\naddressing challenges in traditional ASD diagnosis.\n  Methods: We used natural language processing (NLP), ML, and DL models\n(including decision trees, XGB, KNN, RNN, LSTM, Bi-LSTM, BERT, and BERTweet) to\nanalyze 404,627 tweets, classifying them based on ASD or non-ASD authors. A\nsubset of 90,000 tweets was used for model training and testing.\n  Results: Our AI models showed high accuracy, with an 88% success rate in\nidentifying texts from individuals with ASD.\n  Conclusion: The study demonstrates AI's potential in improving ASD diagnosis,\nespecially in children, highlighting the importance of early detection.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-03-06",
      "downloaded_date": "2025-02-01",
      "filename": "Rubio-MartÃ­n-Enhancing ASD detection accuracy a combined approach of machine learning and deep learning models wi....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.03581v1",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    "1809.01254v1": {
      "title": "Collaborative Artificial Intelligence (AI) for User-Cell association in Ultra-Dense Cellular Systems",
      "authors": [
        "Kenza Hamidouche",
        "Ali Taleb Zadeh Kasgari",
        "Walid Saad",
        "Mehdi Bennis",
        "Merouane Debbah"
      ],
      "abstract": "In this paper, the problem of cell association between small base stations\n(SBSs) and users in dense wireless networks is studied using artificial\nintelligence (AI) techniques. The problem is formulated as a mean-field game in\nwhich the users' goal is to maximize their data rate by exploiting local data\nand the data available at neighboring users via an imitation process. Such a\ncollaborative learning process prevents the users from exchanging their data\ndirectly via the cellular network's limited backhaul links and, thus, allows\nthem to improve their cell association policy collaboratively with minimum\ncomputing. To solve this problem, a neural Q-learning learning algorithm is\nproposed that enables the users to predict their reward function using a neural\nnetwork whose input is the SBSs selected by neighboring users and the local\ndata of the considered user. Simulation results show that the proposed\nimitation-based mechanism for cell association converges faster to the optimal\nsolution, compared with conventional cell association mechanisms without\nimitation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-09-04",
      "downloaded_date": "2025-02-01",
      "filename": "Hamidouche-Collaborative Artificial Intelligence AI for User-Cell association in Ultra-Dense Cellular Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1809.01254v1",
      "categories": [
        "cs.IT",
        "math.IT"
      ]
    },
    "2212.06662v2": {
      "title": "Selected Trends in Artificial Intelligence for Space Applications",
      "authors": [
        "Dario Izzo",
        "Gabriele Meoni",
        "Pablo GÃ³mez",
        "Dominik Dold",
        "Alexander Zoechbauer"
      ],
      "abstract": "The development and adoption of artificial intelligence (AI) technologies in\nspace applications is growing quickly as the consensus increases on the\npotential benefits introduced. As more and more aerospace engineers are\nbecoming aware of new trends in AI, traditional approaches are revisited to\nconsider the applications of emerging AI technologies. Already at the time of\nwriting, the scope of AI-related activities across academia, the aerospace\nindustry and space agencies is so wide that an in-depth review would not fit in\nthese pages. In this chapter we focus instead on two main emerging trends we\nbelieve capture the most relevant and exciting activities in the field:\ndifferentiable intelligence and on-board machine learning. Differentiable\nintelligence, in a nutshell, refers to works making extensive use of automatic\ndifferentiation frameworks to learn the parameters of machine learning or\nrelated models. Onboard machine learning considers the problem of moving\ninference, as well as learning, onboard. Within these fields, we discuss a few\nselected projects originating from the European Space Agency's (ESA) Advanced\nConcepts Team (ACT), giving priority to advanced topics going beyond the\ntransposition of established AI techniques and practices to the space domain.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-12-10",
      "downloaded_date": "2025-02-01",
      "filename": "Izzo-Selected Trends in Artificial Intelligence for Space Applications.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.06662v2",
      "categories": [
        "cs.LG",
        "astro-ph.IM",
        "cs.AI",
        "cs.NE"
      ]
    },
    "2012.09303v1": {
      "title": "Infrastructure for Artificial Intelligence, Quantum and High Performance Computing",
      "authors": [
        "William Gropp",
        "Sujata Banerjee",
        "Ian Foster"
      ],
      "abstract": "High Performance Computing (HPC), Artificial Intelligence (AI)/Machine\nLearning (ML), and Quantum Computing (QC) and communications offer immense\nopportunities for innovation and impact on society. Researchers in these areas\ndepend on access to computing infrastructure, but these resources are in short\nsupply and are typically siloed in support of their research communities,\nmaking it more difficult to pursue convergent and interdisciplinary research.\nSuch research increasingly depends on complex workflows that require different\nresources for each stage. This paper argues that a more-holistic approach to\ncomputing infrastructure, one that recognizes both the convergence of some\ncapabilities and the complementary capabilities from new computing approaches,\nbe it commercial cloud to Quantum Computing, is needed to support computer\nscience research.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-12-16",
      "downloaded_date": "2025-02-01",
      "filename": "Gropp-Infrastructure for Artificial Intelligence Quantum and High Performance Computing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.09303v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.PF"
      ]
    },
    "2410.02955v1": {
      "title": "AiBAT: Artificial Intelligence/Instructions for Build, Assembly, and Test",
      "authors": [
        "Benjamin Nuernberger",
        "Anny Liu",
        "Heather Stefanini",
        "Richard Otis",
        "Amanda Towler",
        "R. Peter Dillon"
      ],
      "abstract": "Instructions for Build, Assembly, and Test (IBAT) refers to the process used\nwhenever any operation is conducted on hardware, including tests, assembly, and\nmaintenance. Currently, the generation of IBAT documents is time-intensive, as\nusers must manually reference and transfer information from engineering\ndiagrams and parts lists into IBAT instructions. With advances in machine\nlearning and computer vision, however, it is possible to have an artificial\nintelligence (AI) model perform the partial filling of the IBAT template,\nfreeing up engineer time for more highly skilled tasks. AiBAT is a novel system\nfor assisting users in authoring IBATs. It works by first analyzing assembly\ndrawing documents, extracting information and parsing it, and then filling in\nIBAT templates with the extracted information. Such assisted authoring has\npotential to save time and reduce cost. This paper presents an overview of the\nAiBAT system, including promising preliminary results and discussion on future\nwork.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-10-03",
      "downloaded_date": "2025-02-01",
      "filename": "Nuernberger-AiBAT Artificial IntelligenceInstructions for Build Assembly and Test.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.02955v1",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.ET",
        "cs.HC"
      ]
    },
    "2501.17676v1": {
      "title": "Explainable Artificial Intelligence for identifying profitability predictors in Financial Statements",
      "authors": [
        "Marco Piazza",
        "Mauro Passacantando",
        "Francesca Magli",
        "Federica Doni",
        "Andrea Amaduzzi",
        "Enza Messina"
      ],
      "abstract": "The interconnected nature of the economic variables influencing a firm's\nperformance makes the prediction of a company's earning trend a challenging\ntask. Existing methodologies often rely on simplistic models and financial\nratios failing to capture the complexity of interacting influences. In this\npaper, we apply Machine Learning techniques to raw financial statements data\ntaken from AIDA, a Database comprising Italian listed companies' data from 2013\nto 2022.\n  We present a comparative study of different models and following the European\nAI regulations, we complement our analysis by applying explainability\ntechniques to the proposed models. In particular, we propose adopting an\neXplainable Artificial Intelligence method based on Game Theory to identify the\nmost sensitive features and make the result more interpretable.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2025-01-29",
      "downloaded_date": "2025-02-01",
      "filename": "Piazza-Explainable Artificial Intelligence for identifying profitability predictors in Financial Statements.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.17676v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2207.14642v1": {
      "title": "Active Distribution System Coordinated Control Method via Artificial Intelligence",
      "authors": [
        "Matthew Lau",
        "Kayla Thames",
        "Sakis Meliopoulos"
      ],
      "abstract": "The increasing deployment of end use power resources in distribution systems\ncreated active distribution systems. Uncontrolled active distribution systems\nexhibit wide variations of voltage and loading throughout the day as some of\nthese resources operate under max power tracking control of highly variable\nwind and solar irradiation while others exhibit random variations and/or\ndependency on weather conditions. It is necessary to control the system to\nprovide power reliably and securely under normal voltages and frequency.\nClassical optimization approaches to control the system towards this goal\nsuffer from the dimensionality of the problem and the need for a global\noptimization approach to coordinate a huge number of small resources.\nArtificial Intelligence (AI) methods offer an alternative that can provide a\npractical approach to this problem. We suggest that neural networks with\nself-attention mechanisms have the potential to aid in the optimization of the\nsystem. In this paper, we present this approach and provide promising\npreliminary results.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-07-12",
      "downloaded_date": "2025-02-01",
      "filename": "Lau-Active Distribution System Coordinated Control Method via Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2207.14642v1",
      "categories": [
        "eess.SY",
        "cs.LG",
        "cs.SY",
        "90-03",
        "I.2.8"
      ]
    },
    "2307.10991v2": {
      "title": "Dense Sample Deep Learning",
      "authors": [
        "Stephen JosÃ¨ Hanson",
        "Vivek Yadav",
        "Catherine Hanson"
      ],
      "abstract": "Deep Learning (DL) , a variant of the neural network algorithms originally\nproposed in the 1980s, has made surprising progress in Artificial Intelligence\n(AI), ranging from language translation, protein folding, autonomous cars, and\nmore recently human-like language models (CHATbots), all that seemed\nintractable until very recently. Despite the growing use of Deep Learning (DL)\nnetworks, little is actually understood about the learning mechanisms and\nrepresentations that makes these networks effective across such a diverse range\nof applications. Part of the answer must be the huge scale of the architecture\nand of course the large scale of the data, since not much has changed since\n1987. But the nature of deep learned representations remain largely unknown.\nUnfortunately training sets with millions or billions of tokens have unknown\ncombinatorics and Networks with millions or billions of hidden units cannot\neasily be visualized and their mechanisms cannot be easily revealed. In this\npaper, we explore these questions with a large (1.24M weights; VGG) DL in a\nnovel high density sample task (5 unique tokens with at minimum 500 exemplars\nper token) which allows us to more carefully follow the emergence of category\nstructure and feature construction. We use various visualization methods for\nfollowing the emergence of the classification and the development of the\ncoupling of feature detectors and structures that provide a type of graphical\nbootstrapping, From these results we harvest some basic observations of the\nlearning dynamics of DL and propose a new theory of complex feature\nconstruction based on our results.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-07-20",
      "downloaded_date": "2025-02-01",
      "filename": "Hanson-Dense Sample Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.10991v2",
      "categories": [
        "cs.AI",
        "q-bio.NC",
        "stat.ML"
      ]
    },
    "2208.03836v1": {
      "title": "Artificial Intelligence and Machine Learning for Quantum Technologies",
      "authors": [
        "Mario Krenn",
        "Jonas Landgraf",
        "Thomas Foesel",
        "Florian Marquardt"
      ],
      "abstract": "In recent years, the dramatic progress in machine learning has begun to\nimpact many areas of science and technology significantly. In the present\nperspective article, we explore how quantum technologies are benefiting from\nthis revolution. We showcase in illustrative examples how scientists in the\npast few years have started to use machine learning and more broadly methods of\nartificial intelligence to analyze quantum measurements, estimate the\nparameters of quantum devices, discover new quantum experimental setups,\nprotocols, and feedback strategies, and generally improve aspects of quantum\ncomputing, quantum communication, and quantum simulation. We highlight open\nchallenges and future possibilities and conclude with some speculative visions\nfor the next decade.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-08-07",
      "downloaded_date": "2025-02-01",
      "filename": "Krenn-Artificial Intelligence and Machine Learning for Quantum Technologies.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2208.03836v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2102.04661v1": {
      "title": "Security and Privacy for Artificial Intelligence: Opportunities and Challenges",
      "authors": [
        "Ayodeji Oseni",
        "Nour Moustafa",
        "Helge Janicke",
        "Peng Liu",
        "Zahir Tari",
        "Athanasios Vasilakos"
      ],
      "abstract": "The increased adoption of Artificial Intelligence (AI) presents an\nopportunity to solve many socio-economic and environmental challenges; however,\nthis cannot happen without securing AI-enabled technologies. In recent years,\nmost AI models are vulnerable to advanced and sophisticated hacking techniques.\nThis challenge has motivated concerted research efforts into adversarial AI,\nwith the aim of developing robust machine and deep learning models that are\nresilient to different types of adversarial scenarios. In this paper, we\npresent a holistic cyber security review that demonstrates adversarial attacks\nagainst AI applications, including aspects such as adversarial knowledge and\ncapabilities, as well as existing methods for generating adversarial examples\nand existing cyber defence models. We explain mathematical AI models,\nespecially new variants of reinforcement and federated learning, to demonstrate\nhow attack vectors would exploit vulnerabilities of AI models. We also propose\na systematic framework for demonstrating attack techniques against AI\napplications and reviewed several cyber defences that would protect AI\napplications against those attacks. We also highlight the importance of\nunderstanding the adversarial goals and their capabilities, especially the\nrecent attacks against industry applications, to develop adaptive defences that\nassess to secure AI applications. Finally, we describe the main challenges and\nfuture research directions in the domain of security and privacy of AI\ntechnologies.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-02-09",
      "downloaded_date": "2025-02-01",
      "filename": "Oseni-Security and Privacy for Artificial Intelligence Opportunities and Challenges.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.04661v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    "2110.00931v4": {
      "title": "Exploration of Artificial Intelligence-oriented Power System Dynamic Simulators",
      "authors": [
        "Tannan Xiao",
        "Ying Chen",
        "Jianquan Wang",
        "Shaowei Huang",
        "Weilin Tong",
        "Tirui He"
      ],
      "abstract": "With the rapid development of artificial intelligence (AI), it is foreseeable\nthat the accuracy and efficiency of dynamic analysis for future power system\nwill be greatly improved by the integration of dynamic simulators and AI. To\nexplore the interaction mechanism of power system dynamic simulations and AI, a\ngeneral design of an AI-oriented power system dynamic simulator is proposed,\nwhich consists of a high-performance simulator with neural network\nsupportability and flexible external and internal application programming\ninterfaces (APIs). With the support of APIs, simulation-assisted AI and\nAI-assisted simulation form a comprehensive interaction mechanism between power\nsystem dynamic simulations and AI. A prototype of this design is implemented\nand made public based on a highly efficient electromechanical simulator. Tests\nof this prototype are carried out under four scenarios including sample\ngeneration, AI-based stability prediction, data-driven dynamic component\nmodeling, and AI-aided stability control, which prove the validity,\nflexibility, and efficiency of the design and implementation of the AI-oriented\npower system dynamic simulator.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-10-03",
      "downloaded_date": "2025-02-01",
      "filename": "Xiao-Exploration of Artificial Intelligence-oriented Power System Dynamic Simulators.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.00931v4",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ]
    },
    "1802.04451v2": {
      "title": "Blockchain and Artificial Intelligence",
      "authors": [
        "Tshilidzi Marwala",
        "Bo Xing"
      ],
      "abstract": "It is undeniable that artificial intelligence (AI) and blockchain concepts\nare spreading at a phenomenal rate. Both technologies have distinct degree of\ntechnological complexity and multi-dimensional business implications. However,\na common misunderstanding about blockchain concept, in particular, is that\nblockchain is decentralized and is not controlled by anyone. But the underlying\ndevelopment of a blockchain system is still attributed to a cluster of core\ndevelopers. Take smart contract as an example, it is essentially a collection\nof codes (or functions) and data (or states) that are programmed and deployed\non a blockchain (say, Ethereum) by different human programmers. It is thus,\nunfortunately, less likely to be free of loopholes and flaws. In this article,\nthrough a brief overview about how artificial intelligence could be used to\ndeliver bug-free smart contract so as to achieve the goal of blockchain 2.0, we\nto emphasize that the blockchain implementation can be assisted or enhanced via\nvarious AI techniques. The alliance of AI and blockchain is expected to create\nnumerous possibilities.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-02-13",
      "downloaded_date": "2025-02-01",
      "filename": "Marwala-Blockchain and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1802.04451v2",
      "categories": [
        "cs.AI"
      ]
    },
    "1908.02150v3": {
      "title": "Industrial Artificial Intelligence",
      "authors": [
        "Jay Lee",
        "Jaskaran Singh",
        "Moslem Azamfar"
      ],
      "abstract": "Artificial Intelligence (AI) is a cognitive science to enables human to\nexplore many intelligent ways to model our sensing and reasoning processes.\nIndustrial AI is a systematic discipline to enable engineers to systematically\ndevelop and deploy AI algorithms with repeating and consistent successes. In\nthis paper, the key enablers for this transformative technology along with\ntheir significant advantages are discussed. In addition, this research explains\nLighthouse Factories as an emerging status applying to the top manufacturers\nthat have implemented Industrial AI in their manufacturing ecosystem and gained\nsignificant financial benefits. It is believed that this research will work as\na guideline and roadmap for researchers and industries towards the real-world\nimplementation of Industrial AI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-08-04",
      "downloaded_date": "2025-02-01",
      "filename": "Lee-Industrial Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1908.02150v3",
      "categories": [
        "cs.CY"
      ]
    },
    "2301.10823v3": {
      "title": "Reflective Artificial Intelligence",
      "authors": [
        "Peter R. Lewis",
        "Stefan Sarkadi"
      ],
      "abstract": "Artificial Intelligence (AI) is about making computers that do the sorts of\nthings that minds can do, and as we progress towards this goal, we tend to\nincreasingly delegate human tasks to machines. However, AI systems usually do\nthese tasks with an unusual imbalance of insight and understanding: new, deeper\ninsights are present, yet many important qualities that a human mind would have\npreviously brought to the activity are utterly absent. Therefore, it is crucial\nto ask which features of minds have we replicated, which are missing, and if\nthat matters. One core feature that humans bring to tasks, when dealing with\nthe ambiguity, emergent knowledge, and social context presented by the world,\nis reflection. Yet this capability is utterly missing from current mainstream\nAI. In this paper we ask what reflective AI might look like. Then, drawing on\nnotions of reflection in complex systems, cognitive science, and agents, we\nsketch an architecture for reflective AI agents, and highlight ways forward.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-01-25",
      "downloaded_date": "2025-02-01",
      "filename": "Lewis-Reflective Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2301.10823v3",
      "categories": [
        "cs.AI"
      ]
    },
    "2308.02435v1": {
      "title": "Designing Fiduciary Artificial Intelligence",
      "authors": [
        "Sebastian Benthall",
        "David Shekman"
      ],
      "abstract": "A fiduciary is a trusted agent that has the legal duty to act with loyalty\nand care towards a principal that employs them. When fiduciary organizations\ninteract with users through a digital interface, or otherwise automate their\noperations with artificial intelligence, they will need to design these AI\nsystems to be compliant with their duties. This article synthesizes recent work\nin computer science and law to develop a procedure for designing and auditing\nFiduciary AI. The designer of a Fiduciary AI should understand the context of\nthe system, identify its principals, and assess the best interests of those\nprincipals. Then the designer must be loyal with respect to those interests,\nand careful in an contextually appropriate way. We connect the steps in this\nprocedure to dimensions of Trustworthy AI, such as privacy and alignment.\nFiduciary AI is a promising means to address the incompleteness of data\nsubject's consent when interacting with complex technical systems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-07-27",
      "downloaded_date": "2025-02-01",
      "filename": "Benthall-Designing Fiduciary Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.02435v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2209.12014v1": {
      "title": "Asset Pricing and Deep Learning",
      "authors": [
        "Chen Zhang"
      ],
      "abstract": "Traditional machine learning methods have been widely studied in financial\ninnovation. My study focuses on the application of deep learning methods on\nasset pricing. I investigate various deep learning methods for asset pricing,\nespecially for risk premia measurement. All models take the same set of\npredictive signals (firm characteristics, systematic risks and macroeconomics).\nI demonstrate high performance of all kinds of state-of-the-art (SOTA) deep\nlearning methods, and figure out that RNNs with memory mechanism and attention\nhave the best performance in terms of predictivity. Furthermore, I demonstrate\nlarge economic gains to investors using deep learning forecasts. The results of\nmy comparative experiments highlight the importance of domain knowledge and\nfinancial theory when designing deep learning models. I also show return\nprediction tasks bring new challenges to deep learning. The time varying\ndistribution causes distribution shift problem, which is essential for\nfinancial time series prediction. I demonstrate that deep learning methods can\nimprove asset risk premium measurement. Due to the booming deep learning\nstudies, they can constantly promote the study of underlying financial\nmechanisms behind asset pricing. I also propose a promising research method\nthat learning from data and figuring out the underlying economic mechanisms\nthrough explainable artificial intelligence (AI) methods. My findings not only\njustify the value of deep learning in blooming fintech development, but also\nhighlight their prospects and advantages over traditional machine learning\nmethods.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-09-24",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Asset Pricing and Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.12014v1",
      "categories": [
        "q-fin.ST",
        "cs.LG",
        "q-fin.PR"
      ]
    },
    "2207.12750v1": {
      "title": "SPAIC: A Spike-based Artificial Intelligence Computing Framework",
      "authors": [
        "Chaofei Hong",
        "Mengwen Yuan",
        "Mengxiao Zhang",
        "Xiao Wang",
        "Chegnjun Zhang",
        "Jiaxin Wang",
        "Gang Pan",
        "Zhaohui Wu",
        "Huajin Tang"
      ],
      "abstract": "Neuromorphic computing is an emerging research field that aims to develop new\nintelligent systems by integrating theories and technologies from\nmulti-disciplines such as neuroscience and deep learning. Currently, there have\nbeen various software frameworks developed for the related fields, but there is\na lack of an efficient framework dedicated for spike-based computing models and\nalgorithms. In this work, we present a Python based spiking neural network\n(SNN) simulation and training framework, aka SPAIC that aims to support\nbrain-inspired model and algorithm researches integrated with features from\nboth deep learning and neuroscience. To integrate different methodologies from\nthe two overwhelming disciplines, and balance between flexibility and\nefficiency, SPAIC is designed with neuroscience-style frontend and deep\nlearning backend structure. We provide a wide range of examples including\nneural circuits Simulation, deep SNN learning and neuromorphic applications,\ndemonstrating the concise coding style and wide usability of our framework. The\nSPAIC is a dedicated spike-based artificial intelligence computing platform,\nwhich will significantly facilitate the design, prototype and validation of new\nmodels, theories and applications. Being user-friendly, flexible and\nhigh-performance, it will help accelerate the rapid growth and wide\napplicability of neuromorphic computing research.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-07-26",
      "downloaded_date": "2025-02-01",
      "filename": "Hong-SPAIC A Spike-based Artificial Intelligence Computing Framework.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2207.12750v1",
      "categories": [
        "cs.NE"
      ]
    },
    "2405.18297v3": {
      "title": "Artificial Intelligence Satellite Telecommunication Testbed using Commercial Off-The-Shelf Chipsets",
      "authors": [
        "Luis M. GarcÃ©s-SocarrÃ¡s",
        "Amirhossein Nik",
        "Flor Ortiz",
        "Juan A. VÃ¡squez-Peralvo",
        "Jorge L. GonzÃ¡lez-Rios",
        "Mouhamad Chehailty",
        "Marcele Kuhfuss",
        "Eva Lagunas",
        "Jan Thoemel",
        "Sumit Kumar",
        "Vishal Singh",
        "Juan C. Merlano Duncan",
        "Sahar Malmir",
        "Swetha Varadajulu",
        "Jorge Querol",
        "Symeon Chatzinotas"
      ],
      "abstract": "The Artificial Intelligence Satellite Telecommunications Testbed (AISTT),\npart of the ESA project SPAICE, is focused on the transformation of the\nsatellite payload by using artificial intelligence (AI) and machine learning\n(ML) methodologies over available commercial off-the-shelf (COTS) AI-capable\nchips for onboard processing. The objectives include validating artificial\nintelligence-driven SATCOM scenarios such as interference detection, spectrum\nsharing, radio resource management, decoding, and beamforming. The study\nhighlights hardware selection and payload architecture. Preliminary results\nshow that ML models significantly improve signal quality, spectral efficiency,\nand throughput compared to conventional payload. Moreover, the testbed aims to\nevaluate the performance and the use of AI-capable COTS chips in onboard SATCOM\ncontexts.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-05-28",
      "downloaded_date": "2025-02-01",
      "filename": "GarcÃ©s-SocarrÃ¡s-Artificial Intelligence Satellite Telecommunication Testbed using Commercial Off-The-Shelf Chipsets.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.18297v3",
      "categories": [
        "eess.SP"
      ]
    },
    "2002.11000v1": {
      "title": "Distributed Ledger for Provenance Tracking of Artificial Intelligence Assets",
      "authors": [
        "Philipp LÃ¼thi",
        "Thibault Gagnaux",
        "Marcel Gygli"
      ],
      "abstract": "High availability of data is responsible for the current trends in Artificial\nIntelligence (AI) and Machine Learning (ML). However, high-grade datasets are\nreluctantly shared between actors because of lacking trust and fear of losing\ncontrol. Provenance tracing systems are a possible measure to build trust by\nimproving transparency. Especially the tracing of AI assets along complete AI\nvalue chains bears various challenges such as trust, privacy, confidentiality,\ntraceability, and fair remuneration. In this paper we design a graph-based\nprovenance model for AI assets and their relations within an AI value chain.\nMoreover, we propose a protocol to exchange AI assets securely to selected\nparties. The provenance model and exchange protocol are then combined and\nimplemented as a smart contract on a permission-less blockchain. We show how\nthe smart contract enables the tracing of AI assets in an existing industry use\ncase while solving all challenges. Consequently, our smart contract helps to\nincrease traceability and transparency, encourages trust between actors and\nthus fosters collaboration between them.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-02-25",
      "downloaded_date": "2025-02-01",
      "filename": "LÃ¼thi-Distributed Ledger for Provenance Tracking of Artificial Intelligence Assets.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2002.11000v1",
      "categories": [
        "cs.CR"
      ]
    },
    "2310.06278v1": {
      "title": "BC4LLM: Trusted Artificial Intelligence When Blockchain Meets Large Language Models",
      "authors": [
        "Haoxiang Luo",
        "Jian Luo",
        "Athanasios V. Vasilakos"
      ],
      "abstract": "In recent years, artificial intelligence (AI) and machine learning (ML) are\nreshaping society's production methods and productivity, and also changing the\nparadigm of scientific research. Among them, the AI language model represented\nby ChatGPT has made great progress. Such large language models (LLMs) serve\npeople in the form of AI-generated content (AIGC) and are widely used in\nconsulting, healthcare, and education. However, it is difficult to guarantee\nthe authenticity and reliability of AIGC learning data. In addition, there are\nalso hidden dangers of privacy disclosure in distributed AI training. Moreover,\nthe content generated by LLMs is difficult to identify and trace, and it is\ndifficult to cross-platform mutual recognition. The above information security\nissues in the coming era of AI powered by LLMs will be infinitely amplified and\naffect everyone's life. Therefore, we consider empowering LLMs using blockchain\ntechnology with superior security features to propose a vision for trusted AI.\nThis paper mainly introduces the motivation and technical route of blockchain\nfor LLM (BC4LLM), including reliable learning corpus, secure training process,\nand identifiable generated content. Meanwhile, this paper also reviews the\npotential applications and future challenges, especially in the frontier\ncommunication networks field, including network resource allocation, dynamic\nspectrum sharing, and semantic communication. Based on the above work combined\nand the prospect of blockchain and LLMs, it is expected to help the early\nrealization of trusted AI and provide guidance for the academic community.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-10-10",
      "downloaded_date": "2025-02-01",
      "filename": "Luo-BC4LLM Trusted Artificial Intelligence When Blockchain Meets Large Language Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.06278v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2012.12262v1": {
      "title": "The Last State of Artificial Intelligence in Project Management",
      "authors": [
        "Mohammad Reza Davahli"
      ],
      "abstract": "Artificial intelligence (AI) has been used to advance different fields, such\nas education, healthcare, and finance. However, the application of AI in the\nfield of project management (PM) has not progressed equally. This paper reports\non a systematic review of the published studies used to investigate the\napplication of AI in PM. This systematic review identified relevant papers\nusing Web of Science, Science Direct, and Google Scholar databases. Of the 652\narticles found, 58 met the predefined criteria and were included in the review.\nIncluded papers were classified per the following dimensions: PM knowledge\nareas, PM processes, and AI techniques. The results indicated that the\napplication of AI in PM was in its early stages and AI models have not applied\nfor multiple PM processes especially in processes groups of project stakeholder\nmanagement, project procurements management, and project communication\nmanagement. However, the most popular PM processes among included papers were\nproject effort prediction and cost estimation, and the most popular AI\ntechniques were support vector machines, neural networks, and genetic\nalgorithms.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-12-16",
      "downloaded_date": "2025-02-01",
      "filename": "Davahli-The Last State of Artificial Intelligence in Project Management.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.12262v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2202.09859v1": {
      "title": "Cooperative Artificial Intelligence",
      "authors": [
        "Tobias Baumann"
      ],
      "abstract": "In the future, artificial learning agents are likely to become increasingly\nwidespread in our society. They will interact with both other learning agents\nand humans in a variety of complex settings including social dilemmas. We argue\nthat there is a need for research on the intersection between game theory and\nartificial intelligence, with the goal of achieving cooperative artificial\nintelligence that can navigate social dilemmas well. We consider the problem of\nhow an external agent can promote cooperation between artificial learners by\ndistributing additional rewards and punishments based on observing the actions\nof the learners. We propose a rule for automatically learning how to create the\nright incentives by considering the anticipated parameter updates of each\nagent. Using this learning rule leads to cooperation with high social welfare\nin matrix games in which the agents would otherwise learn to defect with high\nprobability. We show that the resulting cooperative outcome is stable in\ncertain games even if the planning agent is turned off after a given number of\nepisodes, while other games require ongoing intervention to maintain mutual\ncooperation. Finally, we reflect on what the goals of multi-agent reinforcement\nlearning should be in the first place, and discuss the necessary building\nblocks towards the goal of building cooperative AI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-02-20",
      "downloaded_date": "2025-02-01",
      "filename": "Baumann-Cooperative Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.09859v1",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ]
    },
    "2206.13475v3": {
      "title": "Thermodynamics-inspired Explanations of Artificial Intelligence",
      "authors": [
        "Shams Mehdi",
        "Pratyush Tiwary"
      ],
      "abstract": "In recent years, predictive machine learning methods have gained prominence\nin various scientific domains. However, due to their black-box nature, it is\nessential to establish trust in these models before accepting them as accurate.\nOne promising strategy for assigning trust involves employing explanation\ntechniques that elucidate the rationale behind a black-box model's predictions\nin a manner that humans can understand. However, assessing the degree of human\ninterpretability of the rationale generated by such methods is a nontrivial\nchallenge. In this work, we introduce interpretation entropy as a universal\nsolution for assessing the degree of human interpretability associated with any\nlinear model. Using this concept and drawing inspiration from classical\nthermodynamics, we present Thermodynamics-inspired Explainable Representations\nof AI and other black-box Paradigms (TERP), a method for generating accurate,\nand human-interpretable explanations for black-box predictions in a\nmodel-agnostic manner. To demonstrate the wide-ranging applicability of TERP,\nwe successfully employ it to explain various black-box model architectures,\nincluding deep learning Autoencoders, Recurrent Neural Networks, and\nConvolutional Neural Networks, across diverse domains such as molecular\nsimulations, text, and image classification.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-06-27",
      "downloaded_date": "2025-02-01",
      "filename": "Mehdi-Thermodynamics-inspired Explanations of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.13475v3",
      "categories": [
        "cond-mat.stat-mech",
        "cond-mat.dis-nn",
        "cs.LG",
        "physics.comp-ph"
      ]
    },
    "2010.15551v1": {
      "title": "Investigating the Robustness of Artificial Intelligent Algorithms with Mixture Experiments",
      "authors": [
        "Jiayi Lian",
        "Laura Freeman",
        "Yili Hong",
        "Xinwei Deng"
      ],
      "abstract": "Artificial intelligent (AI) algorithms, such as deep learning and XGboost,\nare used in numerous applications including computer vision, autonomous\ndriving, and medical diagnostics. The robustness of these AI algorithms is of\ngreat interest as inaccurate prediction could result in safety concerns and\nlimit the adoption of AI systems. In this paper, we propose a framework based\non design of experiments to systematically investigate the robustness of AI\nclassification algorithms. A robust classification algorithm is expected to\nhave high accuracy and low variability under different application scenarios.\nThe robustness can be affected by a wide range of factors such as the imbalance\nof class labels in the training dataset, the chosen prediction algorithm, the\nchosen dataset of the application, and a change of distribution in the training\nand test datasets. To investigate the robustness of AI classification\nalgorithms, we conduct a comprehensive set of mixture experiments to collect\nprediction performance results. Then statistical analyses are conducted to\nunderstand how various factors affect the robustness of AI classification\nalgorithms. We summarize our findings and provide suggestions to practitioners\nin AI applications.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-10-10",
      "downloaded_date": "2025-02-01",
      "filename": "Lian-Investigating the Robustness of Artificial Intelligent Algorithms with Mixture Experiments.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2010.15551v1",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    "2207.13190v1": {
      "title": "How does artificial intelligence contribute to iEEG research?",
      "authors": [
        "Julia Berezutskaya",
        "Anne-Lise Saive",
        "Karim Jerbi",
        "Marcel van Gerven"
      ],
      "abstract": "Artificial intelligence (AI) is a fast-growing field focused on modeling and\nmachine implementation of various cognitive functions with an increasing number\nof applications in computer vision, text processing, robotics, neurotechnology,\nbio-inspired computing and others. In this chapter, we describe how AI methods\ncan be applied in the context of intracranial electroencephalography (iEEG)\nresearch. IEEG data is unique as it provides extremely high-quality signals\nrecorded directly from brain tissue. Applying advanced AI models to these data\ncarries the potential to further our understanding of many fundamental\nquestions in neuroscience. At the same time, as an invasive technique, iEEG\nlends itself well to long-term, mobile brain-computer interface applications,\nparticularly for communication in severely paralyzed individuals. We provide a\ndetailed overview of these two research directions in the application of AI\ntechniques to iEEG. That is, (1) the development of computational models that\ntarget fundamental questions about the neurobiological nature of cognition\n(AI-iEEG for neuroscience) and (2) applied research on monitoring and\nidentification of event-driven brain states for the development of clinical\nbrain-computer interface systems (AI-iEEG for neurotechnology). We explain key\nmachine learning concepts, specifics of processing and modeling iEEG data and\ndetails of state-of-the-art iEEG-based neurotechnology and brain-computer\ninterfaces.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-07-26",
      "downloaded_date": "2025-02-01",
      "filename": "Berezutskaya-How does artificial intelligence contribute to iEEG research.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2207.13190v1",
      "categories": [
        "q-bio.NC"
      ]
    },
    "2306.06123v3": {
      "title": "Adversarial attacks and defenses in explainable artificial intelligence: A survey",
      "authors": [
        "Hubert Baniecki",
        "Przemyslaw Biecek"
      ],
      "abstract": "Explainable artificial intelligence (XAI) methods are portrayed as a remedy\nfor debugging and trusting statistical and deep learning models, as well as\ninterpreting their predictions. However, recent advances in adversarial machine\nlearning (AdvML) highlight the limitations and vulnerabilities of\nstate-of-the-art explanation methods, putting their security and\ntrustworthiness into question. The possibility of manipulating, fooling or\nfairwashing evidence of the model's reasoning has detrimental consequences when\napplied in high-stakes decision-making and knowledge discovery. This survey\nprovides a comprehensive overview of research concerning adversarial attacks on\nexplanations of machine learning models, as well as fairness metrics. We\nintroduce a unified notation and taxonomy of methods facilitating a common\nground for researchers and practitioners from the intersecting research fields\nof AdvML and XAI. We discuss how to defend against attacks and design robust\ninterpretation methods. We contribute a list of existing insecurities in XAI\nand outline the emerging research directions in adversarial XAI (AdvXAI).\nFuture work should address improving explanation methods and evaluation\nprotocols to take into account the reported safety issues.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-06-06",
      "downloaded_date": "2025-02-01",
      "filename": "Baniecki-Adversarial attacks and defenses in explainable artificial intelligence A survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.06123v3",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    "1907.07374v5": {
      "title": "A Survey on Explainable Artificial Intelligence (XAI): Towards Medical XAI",
      "authors": [
        "Erico Tjoa",
        "Cuntai Guan"
      ],
      "abstract": "Recently, artificial intelligence and machine learning in general have\ndemonstrated remarkable performances in many tasks, from image processing to\nnatural language processing, especially with the advent of deep learning. Along\nwith research progress, they have encroached upon many different fields and\ndisciplines. Some of them require high level of accountability and thus\ntransparency, for example the medical sector. Explanations for machine\ndecisions and predictions are thus needed to justify their reliability. This\nrequires greater interpretability, which often means we need to understand the\nmechanism underlying the algorithms. Unfortunately, the blackbox nature of the\ndeep learning is still unresolved, and many machine decisions are still poorly\nunderstood. We provide a review on interpretabilities suggested by different\nresearch works and categorize them. The different categories show different\ndimensions in interpretability research, from approaches that provide\n\"obviously\" interpretable information to the studies of complex patterns. By\napplying the same categorization to interpretability in medical research, it is\nhoped that (1) clinicians and practitioners can subsequently approach these\nmethods with caution, (2) insights into interpretability will be born with more\nconsiderations for medical practices, and (3) initiatives to push forward\ndata-based, mathematically- and technically-grounded medical education are\nencouraged.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-07-17",
      "downloaded_date": "2025-02-01",
      "filename": "Tjoa-A Survey on Explainable Artificial Intelligence XAI Towards Medical XAI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.07374v5",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2005.09512v1": {
      "title": "Applying Genetic Programming to Improve Interpretability in Machine Learning Models",
      "authors": [
        "Leonardo Augusto Ferreira",
        "Frederico Gadelha GuimarÃ£es",
        "Rodrigo Silva"
      ],
      "abstract": "Explainable Artificial Intelligence (or xAI) has become an important research\ntopic in the fields of Machine Learning and Deep Learning. In this paper, we\npropose a Genetic Programming (GP) based approach, named Genetic Programming\nExplainer (GPX), to the problem of explaining decisions computed by AI systems.\nThe method generates a noise set located in the neighborhood of the point of\ninterest, whose prediction should be explained, and fits a local explanation\nmodel for the analyzed sample. The tree structure generated by GPX provides a\ncomprehensible analytical, possibly non-linear, symbolic expression which\nreflects the local behavior of the complex model. We considered three machine\nlearning techniques that can be recognized as complex black-box models: Random\nForest, Deep Neural Network and Support Vector Machine in twenty data sets for\nregression and classifications problems. Our results indicate that the GPX is\nable to produce more accurate understanding of complex models than the state of\nthe art. The results validate the proposed approach as a novel way to deploy GP\nto improve interpretability.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-05-18",
      "downloaded_date": "2025-02-01",
      "filename": "Ferreira-Applying Genetic Programming to Improve Interpretability in Machine Learning Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.09512v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "cs.SC",
        "F.3.1; I.1.4; I.2.2; I.2.6"
      ]
    },
    "2202.10169v2": {
      "title": "Machine Learning Operations: A Survey on MLOps Tool Support",
      "authors": [
        "Nipuni Hewage",
        "Dulani Meedeniya"
      ],
      "abstract": "Machine Learning (ML) has become a fast-growing, trending approach in\nsolution development in practice. Deep Learning (DL) which is a subset of ML,\nlearns using deep neural networks to simulate the human brain. It trains\nmachines to learn techniques and processes individually using computer\nalgorithms, which is also considered to be a role of Artificial Intelligence\n(AI). In this paper, we study current technical issues related to software\ndevelopment and delivery in organizations that work on ML projects. Therefore,\nthe importance of the Machine Learning Operations (MLOps) concept, which can\ndeliver appropriate solutions for such concerns, is discussed. We investigate\ncommercially available MLOps tool support in software development. The\ncomparison between MLOps tools analyzes the performance of each system and its\nuse cases. Moreover, we examine the features and usability of MLOps tools to\nidentify the most appropriate tool support for given scenarios. Finally, we\nrecognize that there is a shortage in the availability of a fully functional\nMLOps platform on which processes can be automated by reducing human\nintervention.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-02-21",
      "downloaded_date": "2025-02-01",
      "filename": "Hewage-Machine Learning Operations A Survey on MLOps Tool Support.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.10169v2",
      "categories": [
        "cs.SE",
        "A.1; D.2.6; K.6.3"
      ]
    },
    "1704.08111v3": {
      "title": "A Popperian Falsification of Artificial Intelligence -- Lighthill Defended",
      "authors": [
        "Steven Meyer"
      ],
      "abstract": "The area of computation called artificial intelligence (AI) is falsified by\ndescribing a previous 1972 falsification of AI by British mathematical\nphysicist James Lighthill. How Lighthill's arguments continue to apply to\ncurrent AI is explained. It is argued that AI should use the Popperian\nscientific method in which it is the duty of scientists to attempt to falsify\ntheories and if theories are falsified to replace or modify them. The paper\ndescribes the Popperian method and discusses Paul Nurse's application of the\nmethod to cell biology that also involves questions of mechanism and behavior.\nIt is shown how Lighthill's falsifying arguments especially combinatorial\nexplosion continue to apply to modern AI. Various skeptical arguments against\nthe assumptions of AI mostly by physicists especially against Hilbert's\nphilosophical programme that defined knowledge and truth as provable formal\nsentences. John von Neumann's arguments from natural complexity against neural\nnetworks and evolutionary algorithms are discussed. Next the game of chess is\ndiscussed to show how modern chess experts have reacted to computer chess\nprograms. It is shown that currently chess masters can defeat any chess program\nusing Kasperov's arguments from his 1997 Deep Blue match and aftermath. The\ngame of 'go' and climate models are discussed to show computer applications\nwhere combinatorial explosion may not apply. The paper concludes by advocating\nstudying computation as Peter Naur's Dataology.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-04-23",
      "downloaded_date": "2025-02-01",
      "filename": "Meyer-A Popperian Falsification of Artificial Intelligence -- Lighthill Defended.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1704.08111v3",
      "categories": [
        "cs.AI",
        "I.1; I.1.2"
      ]
    },
    "1808.01053v1": {
      "title": "Optimizing Space-Air-Ground Integrated Networks by Artificial Intelligence",
      "authors": [
        "Nei Kato",
        "Zubair Md. Fadlullah",
        "Fengxiao Tang",
        "Bomin Mao",
        "Shigenori Tani",
        "Atsushi Okamura",
        "Jiajia Liu"
      ],
      "abstract": "It is widely acknowledged that the development of traditional terrestrial\ncommunication technologies cannot provide all users with fair and high quality\nservices due to the scarce network resource and limited coverage areas. To\ncomplement the terrestrial connection, especially for users in rural,\ndisaster-stricken, or other difficult-to-serve areas, satellites, unmanned\naerial vehicles (UAVs), and balloons have been utilized to relay the\ncommunication signals. On the basis, Space-Air-Ground Integrated Networks\n(SAGINs) have been proposed to improve the users' Quality of Experience (QoE).\nHowever, compared with existing networks such as ad hoc networks and cellular\nnetworks, the SAGINs are much more complex due to the various characteristics\nof three network segments. To improve the performance of SAGINs, researchers\nare facing many unprecedented challenges. In this paper, we propose the\nArtificial Intelligence (AI) technique to optimize the SAGINs, as the AI\ntechnique has shown its predominant advantages in many applications. We first\nanalyze several main challenges of SAGINs and explain how these problems can be\nsolved by AI. Then, we consider the satellite traffic balance as an example and\npropose a deep learning based method to improve the traffic control\nperformance. Simulation results evaluate that the deep learning technique can\nbe an efficient tool to improve the performance of SAGINs.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-08-03",
      "downloaded_date": "2025-02-01",
      "filename": "Kato-Optimizing Space-Air-Ground Integrated Networks by Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1808.01053v1",
      "categories": [
        "cs.NI"
      ]
    },
    "2112.01577v1": {
      "title": "Artificial Intelligence-driven Image Analysis of Bacterial Cells and Biofilms",
      "authors": [
        "Shankarachary Ragi",
        "Md Hafizur Rahman",
        "Jamison Duckworth",
        "Kalimuthu Jawaharraj",
        "Parvathi Chundi",
        "Venkataramana Gadhamshetty"
      ],
      "abstract": "The current study explores an artificial intelligence framework for measuring\nthe structural features from microscopy images of the bacterial biofilms.\nDesulfovibrio alaskensis G20 (DA-G20) grown on mild steel surfaces is used as a\nmodel for sulfate reducing bacteria that are implicated in microbiologically\ninfluenced corrosion problems. Our goal is to automate the process of\nextracting the geometrical properties of the DA-G20 cells from the scanning\nelectron microscopy (SEM) images, which is otherwise a laborious and costly\nprocess. These geometric properties are a biofilm phenotype that allow us to\nunderstand how the biofilm structurally adapts to the surface properties of the\nunderlying metals, which can lead to better corrosion prevention solutions. We\nadapt two deep learning models: (a) a deep convolutional neural network (DCNN)\nmodel to achieve semantic segmentation of the cells, (d) a mask\nregion-convolutional neural network (Mask R-CNN) model to achieve instance\nsegmentation of the cells. These models are then integrated with moment\ninvariants approach to measure the geometric characteristics of the segmented\ncells. Our numerical studies confirm that the Mask-RCNN and DCNN methods are\n227x and 70x faster respectively, compared to the traditional method of manual\nidentification and measurement of the cell geometric properties by the domain\nexperts.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-12-02",
      "downloaded_date": "2025-02-01",
      "filename": "Ragi-Artificial Intelligence-driven Image Analysis of Bacterial Cells and Biofilms.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2112.01577v1",
      "categories": [
        "q-bio.QM"
      ]
    },
    "2306.02009v1": {
      "title": "Weight Bank Addition Photonic Accelerator for Artificial Intelligence",
      "authors": [
        "Wenwen Zhang",
        "Hao Zhang"
      ],
      "abstract": "Neural networks powered by artificial intelligence play a pivotal role in\ncurrent estimation and classification applications due to the escalating\ncomputational demands of evolving deep learning systems. The hindrances posed\nby existing computational limitations threaten to impede the further\nprogression of these neural networks. In response to these issues, we propose\nneuromorphic networks founded on photonics that offer superior processing speed\nthan electronic counterparts, thereby enhancing support for real time, three\ndimensional, and virtual reality applications. The weight bank, an integral\ncomponent of these networks has a direct bearing on their overall performance.\nOur study demonstrates the implementation of a weight bank utilizing parallelly\ncascaded micro ring resonators. We present our observations on neuromorphic\nnetworks based on silicon on insulators, where cascaded MRRs play a crucial\nrole in mitigating interchannel and intrachannel cross talk, a persistent issue\nin wavelength division multiplexing systems. Additionally, we design a standard\nsilicon photonic accelerator to perform weight addition. Optimized to offer\nincreased speed and reduced energy consumption, this photonic accelerator\nensures comparable processing power to electronic devices.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-06-03",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Weight Bank Addition Photonic Accelerator for Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.02009v1",
      "categories": [
        "physics.optics",
        "cs.ET"
      ]
    },
    "1712.03779v1": {
      "title": "Artificial Intelligence and Statistics",
      "authors": [
        "Bin Yu",
        "Karl Kumbier"
      ],
      "abstract": "Artificial intelligence (AI) is intrinsically data-driven. It calls for the\napplication of statistical concepts through human-machine collaboration during\ngeneration of data, development of algorithms, and evaluation of results. This\npaper discusses how such human-machine collaboration can be approached through\nthe statistical concepts of population, question of interest,\nrepresentativeness of training data, and scrutiny of results (PQRS). The PQRS\nworkflow provides a conceptual framework for integrating statistical ideas with\nhuman input into AI products and research. These ideas include experimental\ndesign principles of randomization and local control as well as the principle\nof stability to gain reproducibility and interpretability of algorithms and\ndata results. We discuss the use of these principles in the contexts of\nself-driving cars, automated medical diagnoses, and examples from the authors'\ncollaborative research.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-12-08",
      "downloaded_date": "2025-02-01",
      "filename": "Yu-Artificial Intelligence and Statistics.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1712.03779v1",
      "categories": [
        "stat.ML",
        "cs.AI"
      ]
    },
    "2202.12998v4": {
      "title": "Integrated multimodal artificial intelligence framework for healthcare applications",
      "authors": [
        "Luis R. Soenksen",
        "Yu Ma",
        "Cynthia Zeng",
        "Leonard D. J. Boussioux",
        "Kimberly Villalobos Carballo",
        "Liangyuan Na",
        "Holly M. Wiberg",
        "Michael L. Li",
        "Ignacio Fuentes",
        "Dimitris Bertsimas"
      ],
      "abstract": "Artificial intelligence (AI) systems hold great promise to improve healthcare\nover the next decades. Specifically, AI systems leveraging multiple data\nsources and input modalities are poised to become a viable method to deliver\nmore accurate results and deployable pipelines across a wide range of\napplications. In this work, we propose and evaluate a unified Holistic AI in\nMedicine (HAIM) framework to facilitate the generation and testing of AI\nsystems that leverage multimodal inputs. Our approach uses generalizable data\npre-processing and machine learning modeling stages that can be readily adapted\nfor research and deployment in healthcare environments. We evaluate our HAIM\nframework by training and characterizing 14,324 independent models based on\nHAIM-MIMIC-MM, a multimodal clinical database (N=34,537 samples) containing\n7,279 unique hospitalizations and 6,485 patients, spanning all possible input\ncombinations of 4 data modalities (i.e., tabular, time-series, text, and\nimages), 11 unique data sources and 12 predictive tasks. We show that this\nframework can consistently and robustly produce models that outperform similar\nsingle-source approaches across various healthcare demonstrations (by 6-33%),\nincluding 10 distinct chest pathology diagnoses, along with length-of-stay and\n48-hour mortality predictions. We also quantify the contribution of each\nmodality and data source using Shapley values, which demonstrates the\nheterogeneity in data modality importance and the necessity of multimodal\ninputs across different healthcare-relevant tasks. The generalizable properties\nand flexibility of our Holistic AI in Medicine (HAIM) framework could offer a\npromising pathway for future multimodal predictive systems in clinical and\noperational healthcare settings.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-02-25",
      "downloaded_date": "2025-02-01",
      "filename": "Soenksen-Integrated multimodal artificial intelligence framework for healthcare applications.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.12998v4",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2109.13273v3": {
      "title": "Design of quantum optical experiments with logic artificial intelligence",
      "authors": [
        "Alba Cervera-Lierta",
        "Mario Krenn",
        "AlÃ¡n Aspuru-Guzik"
      ],
      "abstract": "Logic Artificial Intelligence (AI) is a subfield of AI where variables can\ntake two defined arguments, True or False, and are arranged in clauses that\nfollow the rules of formal logic. Several problems that span from physical\nsystems to mathematical conjectures can be encoded into these clauses and\nsolved by checking their satisfiability (SAT). In contrast to machine learning\napproaches where the results can be approximations or local minima, Logic AI\ndelivers formal and mathematically exact solutions to those problems. In this\nwork, we propose the use of logic AI for the design of optical quantum\nexperiments. We show how to map into a SAT problem the experimental preparation\nof an arbitrary quantum state and propose a logic-based algorithm, called\nKlaus, to find an interpretable representation of the photonic setup that\ngenerates it. We compare the performance of Klaus with the state-of-the-art\nalgorithm for this purpose based on continuous optimization. We also combine\nboth logic and numeric strategies to find that the use of logic AI\nsignificantly improves the resolution of this problem, paving the path to\ndeveloping more formal-based approaches in the context of quantum physics\nexperiments.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-09-27",
      "downloaded_date": "2025-02-01",
      "filename": "Cervera-Lierta-Design of quantum optical experiments with logic artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2109.13273v3",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LO"
      ]
    },
    "2404.12841v1": {
      "title": "Explainable Deepfake Video Detection using Convolutional Neural Network and CapsuleNet",
      "authors": [
        "Gazi Hasin Ishrak",
        "Zalish Mahmud",
        "MD. Zami Al Zunaed Farabe",
        "Tahera Khanom Tinni",
        "Tanzim Reza",
        "Mohammad Zavid Parvez"
      ],
      "abstract": "Deepfake technology, derived from deep learning, seamlessly inserts\nindividuals into digital media, irrespective of their actual participation. Its\nfoundation lies in machine learning and Artificial Intelligence (AI).\nInitially, deepfakes served research, industry, and entertainment. While the\nconcept has existed for decades, recent advancements render deepfakes nearly\nindistinguishable from reality. Accessibility has soared, empowering even\nnovices to create convincing deepfakes. However, this accessibility raises\nsecurity concerns.The primary deepfake creation algorithm, GAN (Generative\nAdversarial Network), employs machine learning to craft realistic images or\nvideos. Our objective is to utilize CNN (Convolutional Neural Network) and\nCapsuleNet with LSTM to differentiate between deepfake-generated frames and\noriginals. Furthermore, we aim to elucidate our model's decision-making process\nthrough Explainable AI, fostering transparent human-AI relationships and\noffering practical examples for real-life scenarios.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-04-19",
      "downloaded_date": "2025-02-01",
      "filename": "Ishrak-Explainable Deepfake Video Detection using Convolutional Neural Network and CapsuleNet.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.12841v1",
      "categories": [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    },
    "1909.06862v1": {
      "title": "CogRF: A New Frontier for Machine Learning and Artificial Intelligence for 6G RF Systems",
      "authors": [
        "Tarun Cousik",
        "Rubayet Shafin",
        "Zhou Zhou",
        "Kaleb Kleine",
        "Jeffrey Reed",
        "Lingjia Liu"
      ],
      "abstract": "The concept of CogRF, a novel tunable radio frequency (RF) frontend that uses\nartificial intelligence (AI) to meet mission requirements for beyond 5G and 6G\nsystems, is introduced. CogRF utilizes AI as the core to control and operate RF\nsystem components with the objective of optimizing the overall system\nperformance. An overview of the vital elements that make up CogRF as well as\nthe overall hierarchy of the envisioned CogRF system is provided, and potential\nRF components and control parameters are discussed. AI-powered flexible RF\nfront ends, provide new opportunities to identify to enhance security, speed up\noptimization of device configurations, further refine radio design, improve\nexisting spectrum sharing operations, and develop device health analytics. Top\nresearch challenges for CogRF systems have also been described and potential\nresearch directions are provided.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-09-15",
      "downloaded_date": "2025-02-01",
      "filename": "Cousik-CogRF A New Frontier for Machine Learning and Artificial Intelligence for 6G RF Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1909.06862v1",
      "categories": [
        "eess.SP",
        "cs.NI"
      ]
    },
    "1701.03868v1": {
      "title": "Minimally Naturalistic Artificial Intelligence",
      "authors": [
        "Steven Stenberg Hansen"
      ],
      "abstract": "The rapid advancement of machine learning techniques has re-energized\nresearch into general artificial intelligence. While the idea of\ndomain-agnostic meta-learning is appealing, this emerging field must come to\nterms with its relationship to human cognition and the statistics and structure\nof the tasks humans perform. The position of this article is that only by\naligning our agents' abilities and environments with those of humans do we\nstand a chance at developing general artificial intelligence (GAI). A broad\nreading of the famous 'No Free Lunch' theorem is that there is no universally\noptimal inductive bias or, equivalently, bias-free learning is impossible. This\nfollows from the fact that there are an infinite number of ways to extrapolate\ndata, any of which might be the one used by the data generating environment; an\ninductive bias prefers some of these extrapolations to others, which lowers\nperformance in environments using these adversarial extrapolations. We may\nposit that the optimal GAI is the one that maximally exploits the statistics of\nits environment to create its inductive bias; accepting the fact that this\nagent is guaranteed to be extremely sub-optimal for some alternative\nenvironments. This trade-off appears benign when thinking about the environment\nas being the physical universe, as performance on any fictive universe is\nobviously irrelevant. But, we should expect a sharper inductive bias if we\nfurther constrain our environment. Indeed, we implicitly do so by defining GAI\nin terms of accomplishing that humans consider useful. One common version of\nthis is need the for 'common-sense reasoning', which implicitly appeals to the\nstatistics of physical universe as perceived by humans.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-01-14",
      "downloaded_date": "2025-02-01",
      "filename": "Hansen-Minimally Naturalistic Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1701.03868v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2107.10429v1": {
      "title": "Shedding some light on Light Up with Artificial Intelligence",
      "authors": [
        "Libo Sun",
        "James Browning",
        "Roberto Perera"
      ],
      "abstract": "The Light-Up puzzle, also known as the AKARI puzzle, has never been solved\nusing modern artificial intelligence (AI) methods. Currently, the most widely\nused computational technique to autonomously develop solutions involve\nevolution theory algorithms. This project is an effort to apply new AI\ntechniques for solving the Light-up puzzle faster and more computationally\nefficient. The algorithms explored for producing optimal solutions include hill\nclimbing, simulated annealing, feed-forward neural network (FNN), and\nconvolutional neural network (CNN). Two algorithms were developed for hill\nclimbing and simulated annealing using 2 actions (add and remove light bulb)\nversus 3 actions(add, remove, or move light-bulb to a different cell). Both\nhill climbing and simulated annealing algorithms showed a higher accuracy for\nthe case of 3 actions. The simulated annealing showed to significantly\noutperform hill climbing, FNN, CNN, and an evolutionary theory algorithm\nachieving 100% accuracy in 30 unique board configurations. Lastly, while FNN\nand CNN algorithms showed low accuracies, computational times were\nsignificantly faster compared to the remaining algorithms. The GitHub\nrepository for this project can be found at\nhttps://github.com/rperera12/AKARI-LightUp-GameSolver-with-DeepNeuralNetworks-and-HillClimb-or-SimulatedAnnealing.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-07-22",
      "downloaded_date": "2025-02-01",
      "filename": "Sun-Shedding some light on Light Up with Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.10429v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2408.07584v1": {
      "title": "Detection and tracking of barchan dunes using Artificial Intelligence",
      "authors": [
        "Esteban AndrÃ©s CÃºÃ±ez BenalcÃ¡zar",
        "Erick de Moraes Franklin"
      ],
      "abstract": "Barchans are crescent-shape dunes ubiquitous on Earth and other celestial\nbodies, which are organized in barchan fields where they interact with each\nother. Over the last decades, satellite images have been largely employed to\ndetect barchans on Earth and on the surface of Mars, with AI (Artificial\nIntelligence) becoming an important tool for monitoring those bedforms.\nHowever, automatic detection reported in previous works is limited to isolated\ndunes and does not identify successfully groups of interacting barchans. In\nthis paper, we inquire into the automatic detection and tracking of barchans by\ncarrying out experiments and exploring the acquired images using AI. After\ntraining a neural network with images from controlled experiments where complex\ninteractions took place between dunes, we did the same for satellite images\nfrom Earth and Mars. We show, for the first time, that a neural network trained\nproperly can identify and track barchans interacting with each other in\ndifferent environments, using different image types (contrasts, colors, points\nof view, resolutions, etc.), with confidence scores (accuracy) above 70%. Our\nresults represent a step further for automatically monitoring barchans, with\nimportant applications for human activities on Earth, Mars and other celestial\nbodies.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-08-14",
      "downloaded_date": "2025-02-01",
      "filename": "BenalcÃ¡zar-Detection and tracking of barchan dunes using Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.07584v1",
      "categories": [
        "physics.geo-ph"
      ]
    },
    "2001.03238v1": {
      "title": "Open Challenges and Issues: Artificial Intelligence for Transactive Management",
      "authors": [
        "Asma Khatun",
        "Sk. Golam Sarowar Hossain"
      ],
      "abstract": "The advancement of Artificial Intelligence (AI) has improved the automation\nof energy managements. In smart energy management or in a smart grid framework,\nall the devices and the distributed resources and renewable resources are\nembedded which leads to reduce cost. A smart energy management system,\nTransactive management (TM) is a concept to improve the efficiency and\nreliability of the power system. The aim of this article is to look for the\ncurrent development of TM methods based on AI and Machine Learning (ML)\ntechnology. In AI paradigm, MultiAgent System (MAS) based method is an active\nresearch area and are still in evolution. Hence this article describes how MAS\nbased method applied in TM. This paper also finds that MAS based method faces\nmajor difficulty to design or set up goal to various agents and describes how\nML technique can contribute to that solution. A brief comparison analysis\nbetween MAS and ML techniques are also presented. At the end, this article\nsummarizes the most relevant open challenges and issues on the AI based methods\nfor transactive energy management.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-01-02",
      "downloaded_date": "2025-02-01",
      "filename": "Khatun-Open Challenges and Issues Artificial Intelligence for Transactive Management.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2001.03238v1",
      "categories": [
        "cs.MA"
      ]
    },
    "2212.00582v1": {
      "title": "Understanding the Energy Consumption of HPC Scale Artificial Intelligence",
      "authors": [
        "Danilo Carastan dos Santos"
      ],
      "abstract": "This paper contributes towards better understanding the energy consumption\ntrade-offs of HPC scale Artificial Intelligence (AI), and more specifically\nDeep Learning (DL) algorithms. For this task we developed benchmark-tracker, a\nbenchmark tool to evaluate the speed and energy consumption of DL algorithms in\nHPC environments. We exploited hardware counters and Python libraries to\ncollect energy information through software, which enabled us to instrument a\nknown AI benchmark tool, and to evaluate the energy consumption of numerous DL\nalgorithms and models. Through an experimental campaign, we show a case example\nof the potential of benchmark-tracker to measure the computing speed and the\nenergy consumption for training and inference DL algorithms, and also the\npotential of Benchmark-Tracker to help better understanding the energy behavior\nof DL algorithms in HPC platforms. This work is a step forward to better\nunderstand the energy consumption of Deep Learning in HPC, and it also\ncontributes with a new tool to help HPC DL developers to better balance the HPC\ninfrastructure in terms of speed and energy consumption.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-11-14",
      "downloaded_date": "2025-02-01",
      "filename": "Santos-Understanding the Energy Consumption of HPC Scale Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.00582v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2202.07446v1": {
      "title": "Relational Artificial Intelligence",
      "authors": [
        "Virginia Dignum"
      ],
      "abstract": "The impact of Artificial Intelligence does not depend only on fundamental\nresearch and technological developments, but for a large part on how these\nsystems are introduced into society and used in everyday situations. Even\nthough AI is traditionally associated with rational decision making,\nunderstanding and shaping the societal impact of AI in all its facets requires\na relational perspective. A rational approach to AI, where computational\nalgorithms drive decision making independent of human intervention, insights\nand emotions, has shown to result in bias and exclusion, laying bare societal\nvulnerabilities and insecurities. A relational approach, that focus on the\nrelational nature of things, is needed to deal with the ethical, legal,\nsocietal, cultural, and environmental implications of AI. A relational approach\nto AI recognises that objective and rational reasoning cannot does not always\nresult in the 'right' way to proceed because what is 'right' depends on the\ndynamics of the situation in which the decision is taken, and that rather than\nsolving ethical problems the focus of design and use of AI must be on asking\nthe ethical question. In this position paper, I start with a general discussion\nof current conceptualisations of AI followed by an overview of existing\napproaches to governance and responsible development and use of AI. Then, I\nreflect over what should be the bases of a social paradigm for AI and how this\nshould be embedded in relational, feminist and non-Western philosophies, in\nparticular the Ubuntu philosophy.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-02-04",
      "downloaded_date": "2025-02-01",
      "filename": "Dignum-Relational Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.07446v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "1411.1373v9": {
      "title": "Ethical Artificial Intelligence",
      "authors": [
        "Bill Hibbard"
      ],
      "abstract": "This book-length article combines several peer reviewed papers and new\nmaterial to analyze the issues of ethical artificial intelligence (AI). The\nbehavior of future AI systems can be described by mathematical equations, which\nare adapted to analyze possible unintended AI behaviors and ways that AI\ndesigns can avoid them. This article makes the case for utility-maximizing\nagents and for avoiding infinite sets in agent definitions. It shows how to\navoid agent self-delusion using model-based utility functions and how to avoid\nagents that corrupt their reward generators (sometimes called \"perverse\ninstantiation\") using utility functions that evaluate outcomes at one point in\ntime from the perspective of humans at a different point in time. It argues\nthat agents can avoid unintended instrumental actions (sometimes called \"basic\nAI drives\" or \"instrumental goals\") by accurately learning human values. This\narticle defines a self-modeling agent framework and shows how it can avoid\nproblems of resource limits, being predicted by other agents, and inconsistency\nbetween the agent's utility function and its definition (one version of this\nproblem is sometimes called \"motivated value selection\"). This article also\ndiscusses how future AI will differ from current AI, the politics of AI, and\nthe ultimate use of AI to help understand the nature of the universe and our\nplace in it.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2014-11-05",
      "downloaded_date": "2025-02-01",
      "filename": "Hibbard-Ethical Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1411.1373v9",
      "categories": [
        "cs.AI"
      ]
    },
    "1905.06871v1": {
      "title": "Artificial intelligence technology in oncology: a new technological paradigm",
      "authors": [
        "Mario Coccia"
      ],
      "abstract": "Artificial Intelligence (AI) technology is based on theory and development of\ncomputer systems able to perform tasks that normally require human\nintelligence. In this context, deep learning is a family of computational\nmethods that allow an algorithm to program itself by learning from a large set\nof examples that demonstrate the desired behavior. Application of these methods\nto medical imaging can assist pathologists in the detection of cancer subtype,\ngene mutations and/or metastases for applying appropriate therapies. The\npurpose of this study is to show the emerging application of AI in medical\nimaging to detect lung and breast cancer. Moreover, this study shows the\ncomparative evolutionary pathways of this emerging technology for three\ncritical cancers: lung, breast and thyroid. A main finding of this study is the\nrecognition that, since the late 1990, the sharp increase of technological\ntrajectories of AI technology applied in cancer imaging seems to be driven by\nhigh rates of mortality of some types of cancer (e.g., lung and breast) in\norder to find new techniques for a more accurate detection, characterization\nand monitoring as well as to apply efficiently anticancer therapies that\nincrease the progression-free survival of patients: the so-called\nmortality-driven AI technological trajectories. Results also suggest that this\nnew technology can generate a technological paradigm shift for diagnostic\nassessment of any cancer type. However, application of these methods to medical\nimaging requires further assessment and validation to assist pathologists to\nincrease the efficiency of their workflow in both routine tasks and critical\ncases of diagnostics.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-05-14",
      "downloaded_date": "2025-02-01",
      "filename": "Coccia-Artificial intelligence technology in oncology a new technological paradigm.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1905.06871v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2408.16002v1": {
      "title": "Artificial Neural Network and Deep Learning: Fundamentals and Theory",
      "authors": [
        "M. M. Hammad"
      ],
      "abstract": "\"Artificial Neural Network and Deep Learning: Fundamentals and Theory\" offers\na comprehensive exploration of the foundational principles and advanced\nmethodologies in neural networks and deep learning. This book begins with\nessential concepts in descriptive statistics and probability theory, laying a\nsolid groundwork for understanding data and probability distributions. As the\nreader progresses, they are introduced to matrix calculus and gradient\noptimization, crucial for training and fine-tuning neural networks. The book\ndelves into multilayer feed-forward neural networks, explaining their\narchitecture, training processes, and the backpropagation algorithm. Key\nchallenges in neural network optimization, such as activation function\nsaturation, vanishing and exploding gradients, and weight initialization, are\nthoroughly discussed. The text covers various learning rate schedules and\nadaptive algorithms, providing strategies to optimize the training process.\nTechniques for generalization and hyperparameter tuning, including Bayesian\noptimization and Gaussian processes, are also presented to enhance model\nperformance and prevent overfitting. Advanced activation functions are explored\nin detail, categorized into sigmoid-based, ReLU-based, ELU-based,\nmiscellaneous, non-standard, and combined types. Each activation function is\nexamined for its properties and applications, offering readers a deep\nunderstanding of their impact on neural network behavior. The final chapter\nintroduces complex-valued neural networks, discussing complex numbers,\nfunctions, and visualizations, as well as complex calculus and backpropagation\nalgorithms. This book equips readers with the knowledge and skills necessary to\ndesign, and optimize advanced neural network models, contributing to the\nongoing advancements in artificial intelligence.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-08-12",
      "downloaded_date": "2025-02-01",
      "filename": "Hammad-Artificial Neural Network and Deep Learning Fundamentals and Theory.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.16002v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2103.01938v1": {
      "title": "Medical Imaging and Machine Learning",
      "authors": [
        "Rohan Shad",
        "John P. Cunningham",
        "Euan A. Ashley",
        "Curtis P. Langlotz",
        "William Hiesinger"
      ],
      "abstract": "Advances in computing power, deep learning architectures, and expert labelled\ndatasets have spurred the development of medical imaging artificial\nintelligence systems that rival clinical experts in a variety of scenarios. The\nNational Institutes of Health in 2018 identified key focus areas for the future\nof artificial intelligence in medical imaging, creating a foundational roadmap\nfor research in image acquisition, algorithms, data standardization, and\ntranslatable clinical decision support systems. Among the key issues raised in\nthe report: data availability, need for novel computing architectures and\nexplainable AI algorithms, are still relevant despite the tremendous progress\nmade over the past few years alone. Furthermore, translational goals of data\nsharing, validation of performance for regulatory approval, generalizability\nand mitigation of unintended bias must be accounted for early in the\ndevelopment process. In this perspective paper we explore challenges unique to\nhigh dimensional clinical imaging data, in addition to highlighting some of the\ntechnical and ethical considerations in developing high-dimensional,\nmulti-modality, machine learning systems for clinical decision support.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-03-02",
      "downloaded_date": "2025-02-01",
      "filename": "Shad-Medical Imaging and Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.01938v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    "1311.5998v1": {
      "title": "A brief network analysis of Artificial Intelligence publication",
      "authors": [
        "Yunpeng Li",
        "Jie Liu",
        "Yong Deng"
      ],
      "abstract": "In this paper, we present an illustration to the history of Artificial\nIntelligence(AI) with a statistical analysis of publish since 1940. We\ncollected and mined through the IEEE publish data base to analysis the\ngeological and chronological variance of the activeness of research in AI. The\nconnections between different institutes are showed. The result shows that the\nleading community of AI research are mainly in the USA, China, the Europe and\nJapan. The key institutes, authors and the research hotspots are revealed. It\nis found that the research institutes in the fields like Data Mining, Computer\nVision, Pattern Recognition and some other fields of Machine Learning are quite\nconsistent, implying a strong interaction between the community of each field.\nIt is also showed that the research of Electronic Engineering and Industrial or\nCommercial applications are very active in California. Japan is also publishing\na lot of papers in robotics. Due to the limitation of data source, the result\nmight be overly influenced by the number of published articles, which is to our\nbest improved by applying network keynode analysis on the research community\ninstead of merely count the number of publish.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2013-11-23",
      "downloaded_date": "2025-02-01",
      "filename": "Li-A brief network analysis of Artificial Intelligence publication.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1311.5998v1",
      "categories": [
        "cs.AI",
        "cs.DL"
      ]
    },
    "2412.20380v1": {
      "title": "Artificial Intelligence for Quantum Error Correction: A Comprehensive Review",
      "authors": [
        "Zihao Wang",
        "Hao Tang"
      ],
      "abstract": "Quantum Error Correction (QEC) is the process of detecting and correcting\nerrors in quantum systems, which are prone to decoherence and quantum noise.\nQEC is crucial for developing stable and highly accurate quantum computing\nsystems, therefore, several research efforts have been made to develop the best\nQEC strategy. Recently, Google's breakthrough shows great potential to improve\nthe accuracy of the existing error correction methods. This survey provides a\ncomprehensive review of advancements in the use of artificial intelligence (AI)\ntools to enhance QEC schemes for existing Noisy Intermediate Scale Quantum\n(NISQ) systems. Specifically, we focus on machine learning (ML) strategies and\nspan from unsupervised, supervised, semi-supervised, to reinforcement learning\nmethods. It is clear from the evidence, that these methods have recently shown\nsuperior efficiency and accuracy in the QEC pipeline compared to conventional\napproaches. Our review covers more than 150 relevant studies, offering a\ncomprehensive overview of progress and perspective in this field. We organized\nthe reviewed literature on the basis of the AI strategies employed and\nimprovements in error correction performance. We also discuss challenges ahead\nsuch as data sparsity caused by limited quantum error datasets and scalability\nissues as the number of quantum bits (qubits) in quantum systems kept\nincreasing very fast. We conclude the paper with summary of existing works and\nfuture research directions aimed at deeper integration of AI techniques into\nQEC strategies.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-12-29",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Artificial Intelligence for Quantum Error Correction A Comprehensive Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.20380v1",
      "categories": [
        "quant-ph"
      ]
    },
    "2203.03715v1": {
      "title": "Needs and Artificial Intelligence",
      "authors": [
        "Soheil Human",
        "Ryan Watkins"
      ],
      "abstract": "Throughout their history, homo sapiens have used technologies to better\nsatisfy their needs. The relation between needs and technology is so\nfundamental that the US National Research Council defined the distinguishing\ncharacteristic of technology as its goal \"to make modifications in the world to\nmeet human needs\". Artificial intelligence (AI) is one of the most promising\nemerging technologies of our time. Similar to other technologies, AI is\nexpected \"to meet [human] needs\". In this article, we reflect on the\nrelationship between needs and AI, and call for the realisation of needs-aware\nAI systems. We argue that re-thinking needs for, through, and by AI can be a\nvery useful means towards the development of realistic approaches for\nSustainable, Human-centric, Accountable, Lawful, and Ethical (HALE) AI systems.\nWe discuss some of the most critical gaps, barriers, enablers, and drivers of\nco-creating future AI-based socio-technical systems in which [human] needs are\nwell considered and met. Finally, we provide an overview of potential threats\nand HALE considerations that should be carefully taken into account, and call\nfor joint, immediate, and interdisciplinary efforts and collaborations.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-02-18",
      "downloaded_date": "2025-02-01",
      "filename": "Human-Needs and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.03715v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2411.19855v2": {
      "title": "Artificial intelligence contribution to translation industry: looking back and forward",
      "authors": [
        "Mohammed Q. Shormani"
      ],
      "abstract": "This study provides a comprehensive analysis of artificial intelligence (AI)\ncontribution to translation industry (ACTI) research, synthesizing it over\nforty-one years from 1980-2024. 13220 articles were retrieved from three\nsources, namely WoS, Scopus, and Lens. We provided two types of analysis, viz.,\nscientometric and thematic, focusing on cluster, subject categories, keywords,\nburstness, centrality and research centers as for the former. For the latter,\nwe thematically review 18 articles, selected purposefully from the articles\ninvolved, centering on purpose, approach, findings, and contribution to ACTI\nfuture directions. The findings reveal that in the past AI contribution to\ntranslation industry was not rigorous, resulting in rule-based machine\ntranslation and statistical machine translation whose output was not\nsatisfactory. However, the more AI develops, the more machine translation\ndevelops, incorporating Neural Networking Algorithms and (Deep) Language\nLearning Models like ChatGPT whose translation output has developed\nconsiderably. However, much rigorous research is still needed to overcome\nseveral problems encountering translation industry, specifically concerning\nlow-source languages, multi-dialectical and free word order languages, and\ncultural and religious registers.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-11-29",
      "downloaded_date": "2025-02-01",
      "filename": "Shormani-Artificial intelligence contribution to translation industry looking back and forward.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.19855v2",
      "categories": [
        "cs.CL",
        "cs-CL",
        "F.2.2; I.2.7"
      ]
    },
    "2112.04263v1": {
      "title": "Artificial Intelligence Powered Mobile Networks: From Cognition to Decision",
      "authors": [
        "Guiyang Luo",
        "Quan Yuan",
        "Jinglin Li",
        "Shangguang Wang",
        "Fangchun Yang"
      ],
      "abstract": "Mobile networks (MN) are anticipated to provide unprecedented opportunities\nto enable a new world of connected experiences and radically shift the way\npeople interact with everything. MN are becoming more and more complex, driven\nby ever-increasingly complicated configuration issues and blossoming new\nservice requirements. This complexity poses significant challenges in\ndeployment, management, operation, optimization, and maintenance, since they\nrequire a complete understanding and cognition of MN. Artificial intelligence\n(AI), which deals with the simulation of intelligent behavior in computers, has\ndemonstrated enormous success in many application domains, suggesting its\npotential in cognizing the state of MN and making intelligent decisions. In\nthis paper, we first propose an AI-powered mobile network architecture and\ndiscuss challenges in terms of cognition complexity, decisions with\nhigh-dimensional action space, and self-adaption to system dynamics. Then,\npotential solutions that are associated with AI are discussed. Finally, we\npropose a deep learning approach that directly maps the state of MN to\nperceived QoS, integrating cognition with the decision. Our proposed approach\nhelps operators in making more intelligent decisions to guarantee QoS.\nMeanwhile, the effectiveness and advantages of our proposed approach are\ndemonstrated on a real-world dataset, involving $31261$ users over $77$\nstations within $5$ days.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-12-08",
      "downloaded_date": "2025-02-01",
      "filename": "Luo-Artificial Intelligence Powered Mobile Networks From Cognition to Decision.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2112.04263v1",
      "categories": [
        "cs.NI"
      ]
    },
    "2305.20046v2": {
      "title": "Assessing Language Disorders using Artificial Intelligence: a Paradigm Shift",
      "authors": [
        "Charalambos Themistocleous",
        "Kyrana Tsapkini",
        "Dimitrios Kokkinakis"
      ],
      "abstract": "Speech, language, and communication deficits are present in most\nneurodegenerative syndromes. They enable the early detection, diagnosis,\ntreatment planning, and monitoring of neurocognitive disease progression as\npart of traditional neurological assessment. Nevertheless, standard speech and\nlanguage evaluation is time-consuming and resource-intensive for clinicians. We\nargue that using machine learning methodologies, natural language processing,\nand modern artificial intelligence (AI) for Language Assessment is an\nimprovement over conventional manual assessment. Using these methodologies,\nComputational Language Assessment (CLA) accomplishes three goals: (i) provides\na neuro-cognitive evaluation of speech, language, and communication in elderly\nand high-risk individuals for dementia; (ii) facilitates the diagnosis,\nprognosis, and therapy efficacy in at-risk and language-impaired populations;\nand (iii) allows easier extensibility to assess patients from a wide range of\nlanguages. By employing AI models, CLA may inform neurocognitive theory on the\nrelationship between language symptoms and their neural bases. Finally, it\nsignals a paradigm shift by significantly advancing our ability to optimize the\nprevention and treatment of elderly individuals with communication disorders,\nallowing them to age gracefully with social engagement.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-05-31",
      "downloaded_date": "2025-02-01",
      "filename": "Themistocleous-Assessing Language Disorders using Artificial Intelligence a Paradigm Shift.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.20046v2",
      "categories": [
        "cs.CL"
      ]
    },
    "2501.03203v1": {
      "title": "Detecting AI-Generated Text in Educational Content: Leveraging Machine Learning and Explainable AI for Academic Integrity",
      "authors": [
        "Ayat A. Najjar",
        "Huthaifa I. Ashqar",
        "Omar A. Darwish",
        "Eman Hammad"
      ],
      "abstract": "This study seeks to enhance academic integrity by providing tools to detect\nAI-generated content in student work using advanced technologies. The findings\npromote transparency and accountability, helping educators maintain ethical\nstandards and supporting the responsible integration of AI in education. A key\ncontribution of this work is the generation of the CyberHumanAI dataset, which\nhas 1000 observations, 500 of which are written by humans and the other 500\nproduced by ChatGPT. We evaluate various machine learning (ML) and deep\nlearning (DL) algorithms on the CyberHumanAI dataset comparing human-written\nand AI-generated content from Large Language Models (LLMs) (i.e., ChatGPT).\nResults demonstrate that traditional ML algorithms, specifically XGBoost and\nRandom Forest, achieve high performance (83% and 81% accuracies respectively).\nResults also show that classifying shorter content seems to be more challenging\nthan classifying longer content. Further, using Explainable Artificial\nIntelligence (XAI) we identify discriminative features influencing the ML\nmodel's predictions, where human-written content tends to use a practical\nlanguage (e.g., use and allow). Meanwhile AI-generated text is characterized by\nmore abstract and formal terms (e.g., realm and employ). Finally, a comparative\nanalysis with GPTZero show that our narrowly focused, simple, and fine-tuned\nmodel can outperform generalized systems like GPTZero. The proposed model\nachieved approximately 77.5% accuracy compared to GPTZero's 48.5% accuracy when\ntasked to classify Pure AI, Pure Human, and mixed class. GPTZero showed a\ntendency to classify challenging and small-content cases as either mixed or\nunrecognized while our proposed model showed a more balanced performance across\nthe three classes.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2025-01-06",
      "downloaded_date": "2025-02-01",
      "filename": "Najjar-Detecting AI-Generated Text in Educational Content Leveraging Machine Learning and Explainable AI fo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.03203v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2205.02900v2": {
      "title": "New-Onset Diabetes Assessment Using Artificial Intelligence-Enhanced Electrocardiography",
      "authors": [
        "Neil Jethani",
        "Aahlad Puli",
        "Hao Zhang",
        "Leonid Garber",
        "Lior Jankelson",
        "Yindalon Aphinyanaphongs",
        "Rajesh Ranganath"
      ],
      "abstract": "Undiagnosed diabetes is present in 21.4% of adults with diabetes. Diabetes\ncan remain asymptomatic and undetected due to limitations in screening rates.\nTo address this issue, questionnaires, such as the American Diabetes\nAssociation (ADA) Risk test, have been recommended for use by physicians and\nthe public. Based on evidence that blood glucose concentration can affect\ncardiac electrophysiology, we hypothesized that an artificial intelligence\n(AI)-enhanced electrocardiogram (ECG) could identify adults with new-onset\ndiabetes. We trained a neural network to estimate HbA1c using a 12-lead ECG and\nreadily available demographics. We retrospectively assembled a dataset\ncomprised of patients with paired ECG and HbA1c data. The population of\npatients who receive both an ECG and HbA1c may a biased sample of the complete\noutpatient population, so we adjusted the importance placed on each patient to\ngenerate a more representative pseudo-population. We found ECG-based assessment\noutperforms the ADA Risk test, achieving a higher area under the curve (0.80\nvs. 0.68) and positive predictive value (13% vs. 9%) -- 2.6 times the\nprevalence of diabetes in the cohort. The AI-enhanced ECG significantly\noutperforms electrophysiologist interpretation of the ECG, suggesting that the\ntask is beyond current clinical capabilities. Given the prevalence of ECGs in\nclinics and via wearable devices, such a tool would make precise, automated\ndiabetes assessment widely accessible.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-05-05",
      "downloaded_date": "2025-02-01",
      "filename": "Jethani-New-Onset Diabetes Assessment Using Artificial Intelligence-Enhanced Electrocardiography.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.02900v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2208.14445v1": {
      "title": "Artificial intelligence-based locoregional markers of brain peritumoral microenvironment",
      "authors": [
        "Zahra Riahi Samani",
        "Drew Parker",
        "Hamed Akbari",
        "Spyridon Bakas",
        "Ronald L. Wolf",
        "Steven Brem",
        "Ragini Verma"
      ],
      "abstract": "In malignant primary brain tumors, cancer cells infiltrate into the\nperitumoral brain structures which results in inevitable recurrence.\nQuantitative assessment of infiltrative heterogeneity in the peritumoral\nregion, the area where biopsy or resection can be hazardous, is important for\nclinical decision making. Previous work on characterizing the infiltrative\nheterogeneity in the peritumoral region used various imaging modalities, but\ninformation of extracellular free water movement restriction has been limitedly\nexplored. Here, we derive a unique set of Artificial Intelligence (AI)-based\nmarkers capturing the heterogeneity of tumor infiltration, by characterizing\nfree water movement restriction in the peritumoral region using Diffusion\nTensor Imaging (DTI)-based free water volume fraction maps. A novel voxel-wise\ndeep learning-based peritumoral microenvironment index (PMI) is first extracted\nby leveraging the widely different water diffusivity properties of\nglioblastomas and brain metastases as regions with and without infiltrations in\nthe peritumoral tissue. Descriptive characteristics of locoregional hubs of\nuniformly high PMI values are extracted as AI-based markers to capture distinct\naspects of infiltrative heterogeneity. The proposed markers are applied to two\nclinical use cases on an independent population of 275 adult-type diffuse\ngliomas (CNS WHO grade 4), analyzing the duration of survival among\nIsocitrate-Dehydrogenase 1 (IDH1)-wildtypes and the differences with\nIDH1-mutants. Our findings provide a panel of markers as surrogates of\ninfiltration that captures unique insight about underlying biology of\nperitumoral microstructural heterogeneity, establishing them as biomarkers of\nprognosis pertaining to survival and molecular stratification, with potential\napplicability in clinical decision making.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-08-29",
      "downloaded_date": "2025-02-01",
      "filename": "Samani-Artificial intelligence-based locoregional markers of brain peritumoral microenvironment.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2208.14445v1",
      "categories": [
        "q-bio.QM",
        "cs.CV",
        "eess.IV"
      ]
    },
    "2311.11883v1": {
      "title": "Efficient Neural Networks for Tiny Machine Learning: A Comprehensive Review",
      "authors": [
        "Minh Tri LÃª",
        "Pierre Wolinski",
        "Julyan Arbel"
      ],
      "abstract": "The field of Tiny Machine Learning (TinyML) has gained significant attention\ndue to its potential to enable intelligent applications on resource-constrained\ndevices. This review provides an in-depth analysis of the advancements in\nefficient neural networks and the deployment of deep learning models on\nultra-low power microcontrollers (MCUs) for TinyML applications. It begins by\nintroducing neural networks and discussing their architectures and resource\nrequirements. It then explores MEMS-based applications on ultra-low power MCUs,\nhighlighting their potential for enabling TinyML on resource-constrained\ndevices. The core of the review centres on efficient neural networks for\nTinyML. It covers techniques such as model compression, quantization, and\nlow-rank factorization, which optimize neural network architectures for minimal\nresource utilization on MCUs. The paper then delves into the deployment of deep\nlearning models on ultra-low power MCUs, addressing challenges such as limited\ncomputational capabilities and memory resources. Techniques like model pruning,\nhardware acceleration, and algorithm-architecture co-design are discussed as\nstrategies to enable efficient deployment. Lastly, the review provides an\noverview of current limitations in the field, including the trade-off between\nmodel complexity and resource constraints. Overall, this review paper presents\na comprehensive analysis of efficient neural networks and deployment strategies\nfor TinyML on ultra-low-power MCUs. It identifies future research directions\nfor unlocking the full potential of TinyML applications on resource-constrained\ndevices.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-11-20",
      "downloaded_date": "2025-02-01",
      "filename": "LÃª-Efficient Neural Networks for Tiny Machine Learning A Comprehensive Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.11883v1",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.CO"
      ]
    },
    "2010.08569v1": {
      "title": "Generalizable Machine Learning in Neuroscience using Graph Neural Networks",
      "authors": [
        "Paul Y. Wang",
        "Sandalika Sapra",
        "Vivek Kurien George",
        "Gabriel A. Silva"
      ],
      "abstract": "Although a number of studies have explored deep learning in neuroscience, the\napplication of these algorithms to neural systems on a microscopic scale, i.e.\nparameters relevant to lower scales of organization, remains relatively novel.\nMotivated by advances in whole-brain imaging, we examined the performance of\ndeep learning models on microscopic neural dynamics and resulting emergent\nbehaviors using calcium imaging data from the nematode C. elegans. We show that\nneural networks perform remarkably well on both neuron-level dynamics\nprediction, and behavioral state classification. In addition, we compared the\nperformance of structure agnostic neural networks and graph neural networks to\ninvestigate if graph structure can be exploited as a favorable inductive bias.\nTo perform this experiment, we designed a graph neural network which explicitly\ninfers relations between neurons from neural activity and leverages the\ninferred graph structure during computations. In our experiments, we found that\ngraph neural networks generally outperformed structure agnostic models and\nexcel in generalization on unseen organisms, implying a potential path to\ngeneralizable machine learning in neuroscience.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-10-16",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Generalizable Machine Learning in Neuroscience using Graph Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2010.08569v1",
      "categories": [
        "cs.LG",
        "q-bio.NC"
      ]
    },
    "2110.00942v1": {
      "title": "Artificial Intelligence For Breast Cancer Detection: Trends & Directions",
      "authors": [
        "Shahid Munir Shah",
        "Rizwan Ahmed Khan",
        "Sheeraz Arif",
        "Unaiza Sajid"
      ],
      "abstract": "In the last decade, researchers working in the domain of computer vision and\nArtificial Intelligence (AI) have beefed up their efforts to come up with the\nautomated framework that not only detects but also identifies stage of breast\ncancer. The reason for this surge in research activities in this direction are\nmainly due to advent of robust AI algorithms (deep learning), availability of\nhardware that can train those robust and complex AI algorithms and\naccessibility of large enough dataset required for training AI algorithms.\nDifferent imaging modalities that have been exploited by researchers to\nautomate the task of breast cancer detection are mammograms, ultrasound,\nmagnetic resonance imaging, histopathological images or any combination of\nthem. This article analyzes these imaging modalities and presents their\nstrengths, limitations and enlists resources from where their datasets can be\naccessed for research purpose. This article then summarizes AI and computer\nvision based state-of-the-art methods proposed in the last decade, to detect\nbreast cancer using various imaging modalities. Generally, in this article we\nhave focused on to review frameworks that have reported results using\nmammograms as it is most widely used breast imaging modality that serves as\nfirst test that medical practitioners usually prescribe for the detection of\nbreast cancer. Second reason of focusing on mammogram imaging modalities is the\navailability of its labeled datasets. Datasets availability is one of the most\nimportant aspect for the development of AI based frameworks as such algorithms\nare data hungry and generally quality of dataset affects performance of AI\nbased algorithms. In a nutshell, this research article will act as a primary\nresource for the research community working in the field of automated breast\nimaging analysis.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-10-03",
      "downloaded_date": "2025-02-01",
      "filename": "Shah-Artificial Intelligence For Breast Cancer Detection Trends  Directions.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.00942v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    "1909.05459v1": {
      "title": "Application of Convolutional Neural Networks for Stellar Spectral Classification",
      "authors": [
        "Kaushal Sharma",
        "Ajit Kembhavi",
        "Aniruddha Kembhavi",
        "T. Sivarani",
        "Sheelu Abraham",
        "Kaustubh Vaghmare"
      ],
      "abstract": "Due to the ever-expanding volume of observed spectroscopic data from surveys\nsuch as SDSS and LAMOST, it has become important to apply artificial\nintelligence (AI) techniques for analysing stellar spectra to solve spectral\nclassification and regression problems like the determination of stellar\natmospheric parameters Teff, log g, [Fe/H]. We propose an automated approach\nfor the classification of stellar spectra in the optical region using\nConvolutional Neural Networks. Traditional machine learning (ML) methods with\n\"shallow\" architecture (usually up to 2 hidden layers) have been trained for\nthese purposes in the past. However, deep learning methods with a larger number\nof hidden layers allow the use of finer details in the spectrum which results\nin improved accuracy and better generalisation. Studying finer spectral\nsignatures also enables us to determine accurate differential stellar\nparameters and find rare objects. We examine various machine and deep learning\nalgorithms like Artificial Neural Networks (ANN), Random Forest (RF), and\nConvolutional Neural Network (CNN) to classify stellar spectra using the Jacoby\nAtlas, ELODIE and MILES spectral libraries as training samples. We test the\nperformance of the trained networks on the Indo-U.S. Library of Coude Feed\nStellar Spectra (CFLIB). We show that using convolutional neural networks, we\nare able to lower the error up to 1.23 spectral sub-classes as compared to that\nof 2 sub-classes achieved in the past studies with ML approach. We further\napply the trained model to classify stellar spectra retrieved from the SDSS\ndatabase with SNR>20.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-09-12",
      "downloaded_date": "2025-02-01",
      "filename": "Sharma-Application of Convolutional Neural Networks for Stellar Spectral Classification.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1909.05459v1",
      "categories": [
        "astro-ph.SR",
        "astro-ph.IM"
      ]
    },
    "2212.03412v1": {
      "title": "Artificial Intelligence Security Competition (AISC)",
      "authors": [
        "Yinpeng Dong",
        "Peng Chen",
        "Senyou Deng",
        "Lianji L",
        "Yi Sun",
        "Hanyu Zhao",
        "Jiaxing Li",
        "Yunteng Tan",
        "Xinyu Liu",
        "Yangyi Dong",
        "Enhui Xu",
        "Jincai Xu",
        "Shu Xu",
        "Xuelin Fu",
        "Changfeng Sun",
        "Haoliang Han",
        "Xuchong Zhang",
        "Shen Chen",
        "Zhimin Sun",
        "Junyi Cao",
        "Taiping Yao",
        "Shouhong Ding",
        "Yu Wu",
        "Jian Lin",
        "Tianpeng Wu",
        "Ye Wang",
        "Yu Fu",
        "Lin Feng",
        "Kangkang Gao",
        "Zeyu Liu",
        "Yuanzhe Pang",
        "Chengqi Duan",
        "Huipeng Zhou",
        "Yajie Wang",
        "Yuhang Zhao",
        "Shangbo Wu",
        "Haoran Lyu",
        "Zhiyu Lin",
        "Yifei Gao",
        "Shuang Li",
        "Haonan Wang",
        "Jitao Sang",
        "Chen Ma",
        "Junhao Zheng",
        "Yijia Li",
        "Chao Shen",
        "Chenhao Lin",
        "Zhichao Cui",
        "Guoshuai Liu",
        "Huafeng Shi",
        "Kun Hu",
        "Mengxin Zhang"
      ],
      "abstract": "The security of artificial intelligence (AI) is an important research area\ntowards safe, reliable, and trustworthy AI systems. To accelerate the research\non AI security, the Artificial Intelligence Security Competition (AISC) was\norganized by the Zhongguancun Laboratory, China Industrial Control Systems\nCyber Emergency Response Team, Institute for Artificial Intelligence, Tsinghua\nUniversity, and RealAI as part of the Zhongguancun International Frontier\nTechnology Innovation Competition (https://www.zgc-aisc.com/en). The\ncompetition consists of three tracks, including Deepfake Security Competition,\nAutonomous Driving Security Competition, and Face Recognition Security\nCompetition. This report will introduce the competition rules of these three\ntracks and the solutions of top-ranking teams in each track.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-12-07",
      "downloaded_date": "2025-02-01",
      "filename": "Dong-Artificial Intelligence Security Competition AISC.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.03412v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2107.14046v1": {
      "title": "Audit and Assurance of AI Algorithms: A framework to ensure ethical algorithmic practices in Artificial Intelligence",
      "authors": [
        "Ramya Akula",
        "Ivan Garibay"
      ],
      "abstract": "Algorithms are becoming more widely used in business, and businesses are\nbecoming increasingly concerned that their algorithms will cause significant\nreputational or financial damage. We should emphasize that any of these damages\nstem from situations in which the United States lacks strict legislative\nprohibitions or specified protocols for measuring damages. As a result,\ngovernments are enacting legislation and enforcing prohibitions, regulators are\nfining businesses, and the judiciary is debating whether or not to make\nartificially intelligent computer models as the decision-makers in the eyes of\nthe law. From autonomous vehicles and banking to medical care, housing, and\nlegal decisions, there will soon be enormous amounts of algorithms that make\ndecisions with limited human interference. Governments, businesses, and society\nwould have an algorithm audit, which would have systematic verification that\nalgorithms are lawful, ethical, and secure, similar to financial audits. A\nmodern market, auditing, and assurance of algorithms developed to\nprofessionalize and industrialize AI, machine learning, and related algorithms.\nStakeholders of this emerging field include policymakers and regulators, along\nwith industry experts and entrepreneurs. In addition, we foresee audit\nthresholds and frameworks providing valuable information to all who are\nconcerned with governance and standardization. This paper aims to review the\ncritical areas required for auditing and assurance and spark discussion in this\nnovel field of study and practice.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-07-14",
      "downloaded_date": "2025-02-01",
      "filename": "Akula-Audit and Assurance of AI Algorithms A framework to ensure ethical algorithmic practices in Artifici....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.14046v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2402.05122v1": {
      "title": "History of generative Artificial Intelligence (AI) chatbots: past, present, and future development",
      "authors": [
        "Md. Al-Amin",
        "Mohammad Shazed Ali",
        "Abdus Salam",
        "Arif Khan",
        "Ashraf Ali",
        "Ahsan Ullah",
        "Md Nur Alam",
        "Shamsul Kabir Chowdhury"
      ],
      "abstract": "This research provides an in-depth comprehensive review of the progress of\nchatbot technology over time, from the initial basic systems relying on rules\nto today's advanced conversational bots powered by artificial intelligence.\nSpanning many decades, the paper explores the major milestones, innovations,\nand paradigm shifts that have driven the evolution of chatbots. Looking back at\nthe very basic statistical model in 1906 via the early chatbots, such as ELIZA\nand ALICE in the 1960s and 1970s, the study traces key innovations leading to\ntoday's advanced conversational agents, such as ChatGPT and Google Bard. The\nstudy synthesizes insights from academic literature and industry sources to\nhighlight crucial milestones, including the introduction of Turing tests,\ninfluential projects such as CALO, and recent transformer-based models. Tracing\nthe path forward, the paper highlights how natural language processing and\nmachine learning have been integrated into modern chatbots for more\nsophisticated capabilities. This chronological survey of the chatbot landscape\nprovides a holistic reference to understand the technological and historical\nfactors propelling conversational AI. By synthesizing learnings from this\nhistorical analysis, the research offers important context about the\ndevelopmental trajectory of chatbots and their immense future potential across\nvarious field of application which could be the potential take ways for the\nrespective research community and stakeholders.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-02-04",
      "downloaded_date": "2025-02-01",
      "filename": "Al-Amin-History of generative Artificial Intelligence AI chatbots past present and future development.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.05122v1",
      "categories": [
        "cs.GL",
        "cs.CL",
        "cs.HC"
      ]
    },
    "2204.00914v1": {
      "title": "Artificial Intelligence for 6G Networks: Technology Advancement and Standardization",
      "authors": [
        "Muhammad K. Shehzad",
        "Luca Rose",
        "M. Majid Butt",
        "Istvan Z. Kovacs",
        "Mohamad Assaad",
        "Mohsen Guizani"
      ],
      "abstract": "With the deployment of 5G networks, standards organizations have started\nworking on the design phase for sixth-generation (6G) networks. 6G networks\nwill be immensely complex, requiring more deployment time, cost and management\nefforts. On the other hand, mobile network operators demand these networks to\nbe intelligent, self-organizing, and cost-effective to reduce operating\nexpenses (OPEX). Machine learning (ML), a branch of artificial intelligence\n(AI), is the answer to many of these challenges providing pragmatic solutions,\nwhich can entirely change the future of wireless network technologies. By using\nsome case study examples, we briefly examine the most compelling problems,\nparticularly at the physical (PHY) and link layers in cellular networks where\nML can bring significant gains. We also review standardization activities in\nrelation to the use of ML in wireless networks and future timeline on readiness\nof standardization bodies to adapt to these changes. Finally, we highlight\nmajor issues in ML use in the wireless technology, and provide potential\ndirections to mitigate some of them in 6G wireless networks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-04-02",
      "downloaded_date": "2025-02-01",
      "filename": "Shehzad-Artificial Intelligence for 6G Networks Technology Advancement and Standardization.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2204.00914v1",
      "categories": [
        "eess.SP"
      ]
    },
    "2309.04069v2": {
      "title": "Inferring physical laws by artificial intelligence based causal models",
      "authors": [
        "Jorawar Singh",
        "Kishor Bharti",
        "Arvind"
      ],
      "abstract": "The advances in Artificial Intelligence (AI) and Machine Learning (ML) have\nopened up many avenues for scientific research, and are adding new dimensions\nto the process of knowledge creation. However, even the most powerful and\nversatile of ML applications till date are primarily in the domain of analysis\nof associations and boil down to complex data fitting. Judea Pearl has pointed\nout that Artificial General Intelligence must involve interventions involving\nthe acts of doing and imagining. Any machine assisted scientific discovery thus\nmust include casual analysis and interventions. In this context, we propose a\ncausal learning model of physical principles, which not only recognizes\ncorrelations but also brings out casual relationships. We use the principles of\ncausal inference and interventions to study the cause-and-effect relationships\nin the context of some well-known physical phenomena. We show that this\ntechnique can not only figure out associations among data, but is also able to\ncorrectly ascertain the cause-and-effect relations amongst the variables,\nthereby strengthening (or weakening) our confidence in the proposed model of\nthe underlying physical process.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-09-08",
      "downloaded_date": "2025-02-01",
      "filename": "Singh-Inferring physical laws by artificial intelligence based causal models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.04069v2",
      "categories": [
        "cs.AI",
        "physics.data-an",
        "quant-ph"
      ]
    },
    "2410.11896v1": {
      "title": "Study on the Helpfulness of Explainable Artificial Intelligence",
      "authors": [
        "Tobias Labarta",
        "Elizaveta Kulicheva",
        "Ronja Froelian",
        "Christian GeiÃler",
        "Xenia Melman",
        "Julian von Klitzing"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) is essential for building advanced\nmachine learning-powered applications, especially in critical domains such as\nmedical diagnostics or autonomous driving. Legal, business, and ethical\nrequirements motivate using effective XAI, but the increasing number of\ndifferent methods makes it challenging to pick the right ones. Further, as\nexplanations are highly context-dependent, measuring the effectiveness of XAI\nmethods without users can only reveal a limited amount of information,\nexcluding human factors such as the ability to understand it. We propose to\nevaluate XAI methods via the user's ability to successfully perform a proxy\ntask, designed such that a good performance is an indicator for the explanation\nto provide helpful information. In other words, we address the helpfulness of\nXAI for human decision-making. Further, a user study on state-of-the-art\nmethods was conducted, showing differences in their ability to generate trust\nand skepticism and the ability to judge the rightfulness of an AI decision\ncorrectly. Based on the results, we highly recommend using and extending this\napproach for more objective-based human-centered user studies to measure XAI\nperformance in an end-to-end fashion.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-10-14",
      "downloaded_date": "2025-02-01",
      "filename": "Labarta-Study on the Helpfulness of Explainable Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.11896v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "68T37, 91E99",
        "I.2.0; I.2.3; H.5.2; H.1.2; K.4.2"
      ]
    },
    "2411.00846v1": {
      "title": "Explainable Artificial Intelligence for Dependent Features: Additive Effects of Collinearity",
      "authors": [
        "Ahmed M Salih"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) emerged to reveal the internal\nmechanism of machine learning models and how the features affect the prediction\noutcome. Collinearity is one of the big issues that XAI methods face when\nidentifying the most informative features in the model. Current XAI approaches\nassume the features in the models are independent and calculate the effect of\neach feature toward model prediction independently from the rest of the\nfeatures. However, such assumption is not realistic in real life applications.\nWe propose an Additive Effects of Collinearity (AEC) as a novel XAI method that\naim to considers the collinearity issue when it models the effect of each\nfeature in the model on the outcome. AEC is based on the idea of dividing\nmultivariate models into several univariate models in order to examine their\nimpact on each other and consequently on the outcome. The proposed method is\nimplemented using simulated and real data to validate its efficiency comparing\nwith the a state of arts XAI method. The results indicate that AEC is more\nrobust and stable against the impact of collinearity when it explains AI models\ncompared with the state of arts XAI method.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-10-30",
      "downloaded_date": "2025-02-01",
      "filename": "Salih-Explainable Artificial Intelligence for Dependent Features Additive Effects of Collinearity.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.00846v1",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2402.06487v1": {
      "title": "Le Nozze di Giustizia. Interactions between Artificial Intelligence, Law, Logic, Language and Computation with some case studies in Traffic Regulations and Health Care",
      "authors": [
        "Joost J. Joosten",
        "Manuela Montoya GarcÃ­a"
      ],
      "abstract": "An important aim of this paper is to convey some basics of mathematical logic\nto the legal community working with Artificial Intelligence. After analysing\nwhat AI is, we decide to delimit ourselves to rule-based AI leaving Neural\nNetworks and Machine Learning aside. Rule based AI allows for Formal methods\nwhich are described in a rudimentary form. We will then see how mathematical\nlogic interacts with legal rule-based AI practice. We shall see how\nmathematical logic imposes limitations and complications to AI applications. We\nclassify the limitations and interactions between mathematical logic and legal\nAI in three categories: logical, computational and mathematical. The examples\nto showcase the interactions will largely come from European traffic\nregulations. The paper closes off with some reflections on how and where AI\ncould be used and on basic mechanisms that shape society.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-02-09",
      "downloaded_date": "2025-02-01",
      "filename": "Joosten-Le Nozze di Giustizia Interactions between Artificial Intelligence Law Logic Language and Computatio....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.06487v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "2205.10325v1": {
      "title": "Classifying Human Activities using Machine Learning and Deep Learning Techniques",
      "authors": [
        "Sanku Satya Uday",
        "Satti Thanuja Pavani",
        "T. Jaya Lakshmi",
        "Rohit Chivukula"
      ],
      "abstract": "Human Activity Recognition (HAR) describes the machines ability to recognize\nhuman actions. Nowadays, most people on earth are health conscious, so people\nare more interested in tracking their daily activities using Smartphones or\nSmart Watches, which can help them manage their daily routines in a healthy\nway. With this objective, Kaggle has conducted a competition to classify 6\ndifferent human activities distinctly based on the inertial signals obtained\nfrom 30 volunteers smartphones. The main challenge in HAR is to overcome the\ndifficulties of separating human activities based on the given data such that\nno two activities overlap. In this experimentation, first, Data visualization\nis done on expert generated features with the help of t distributed Stochastic\nNeighborhood Embedding followed by applying various Machine Learning techniques\nlike Logistic Regression, Linear SVC, Kernel SVM, Decision trees to better\nclassify the 6 distinct human activities. Moreover, Deep Learning techniques\nlike Long Short-Term Memory (LSTM), Bi-Directional LSTM, Recurrent Neural\nNetwork (RNN), and Gated Recurrent Unit (GRU) are trained using raw time series\ndata. Finally, metrics like Accuracy, Confusion matrix, precision and recall\nare used to evaluate the performance of the Machine Learning and Deep Learning\nmodels. Experiment results proved that the Linear Support Vector Classifier in\nmachine learning and Gated Recurrent Unit in Deep Learning provided better\naccuracy for human activity recognition compared to other classifiers.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-05-19",
      "downloaded_date": "2025-02-01",
      "filename": "Uday-Classifying Human Activities using Machine Learning and Deep Learning Techniques.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.10325v1",
      "categories": [
        "cs.LG",
        "eess.SP"
      ]
    },
    "1907.01368v1": {
      "title": "Pathologist-Level Grading of Prostate Biopsies with Artificial Intelligence",
      "authors": [
        "Peter StrÃ¶m",
        "Kimmo Kartasalo",
        "Henrik Olsson",
        "Leslie Solorzano",
        "Brett Delahunt",
        "Daniel M. Berney",
        "David G. Bostwick",
        "Andrew J. Evans",
        "David J. Grignon",
        "Peter A. Humphrey",
        "Kenneth A. Iczkowski",
        "James G. Kench",
        "Glen Kristiansen",
        "Theodorus H. van der Kwast",
        "Katia R. M. Leite",
        "Jesse K. McKenney",
        "Jon Oxley",
        "Chin-Chen Pan",
        "Hemamali Samaratunga",
        "John R. Srigley",
        "Hiroyuki Takahashi",
        "Toyonori Tsuzuki",
        "Murali Varma",
        "Ming Zhou",
        "Johan Lindberg",
        "Cecilia BergstrÃ¶m",
        "Pekka Ruusuvuori",
        "Carolina WÃ¤hlby",
        "Henrik GrÃ¶nberg",
        "Mattias Rantalainen",
        "Lars Egevad",
        "Martin Eklund"
      ],
      "abstract": "Background: An increasing volume of prostate biopsies and a world-wide\nshortage of uro-pathologists puts a strain on pathology departments.\nAdditionally, the high intra- and inter-observer variability in grading can\nresult in over- and undertreatment of prostate cancer. Artificial intelligence\n(AI) methods may alleviate these problems by assisting pathologists to reduce\nworkload and harmonize grading.\n  Methods: We digitized 6,682 needle biopsies from 976 participants in the\npopulation based STHLM3 diagnostic study to train deep neural networks for\nassessing prostate biopsies. The networks were evaluated by predicting the\npresence, extent, and Gleason grade of malignant tissue for an independent test\nset comprising 1,631 biopsies from 245 men. We additionally evaluated grading\nperformance on 87 biopsies individually graded by 23 experienced urological\npathologists from the International Society of Urological Pathology. We\nassessed discriminatory performance by receiver operating characteristics (ROC)\nand tumor extent predictions by correlating predicted millimeter cancer length\nagainst measurements by the reporting pathologist. We quantified the\nconcordance between grades assigned by the AI and the expert urological\npathologists using Cohen's kappa.\n  Results: The performance of the AI to detect and grade cancer in prostate\nneedle biopsy samples was comparable to that of international experts in\nprostate pathology. The AI achieved an area under the ROC curve of 0.997 for\ndistinguishing between benign and malignant biopsy cores, and 0.999 for\ndistinguishing between men with or without prostate cancer. The correlation\nbetween millimeter cancer predicted by the AI and assigned by the reporting\npathologist was 0.96. For assigning Gleason grades, the AI achieved an average\npairwise kappa of 0.62. This was within the range of the corresponding values\nfor the expert pathologists (0.60 to 0.73).",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-07-02",
      "downloaded_date": "2025-02-01",
      "filename": "StrÃ¶m-Pathologist-Level Grading of Prostate Biopsies with Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.01368v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ]
    },
    "2501.14809v1": {
      "title": "Towards Foundation Models: Evaluation of Geoscience Artificial Intelligence with Uncertainty",
      "authors": [
        "Samuel Myren",
        "Nidhi Parikh",
        "Rosalyn Rael",
        "Garrison Flynn",
        "Dave Higdon",
        "Emily Casleton"
      ],
      "abstract": "Artificial intelligence (AI) has transformed the geoscience community with\ndeep learning models (DLMs) that are trained to complete specific tasks within\nworkflows. This success has led to the development of geoscience foundation\nmodels (FMs), which promise to accomplish multiple tasks within a workflow or\nreplace the workflow altogether. However, lack of robust evaluation frameworks,\neven for traditional DLMs, leaves the geoscience community ill prepared for the\ninevitable adoption of FMs. We address this gap by designing an evaluation\nframework that jointly incorporates three crucial aspects to current DLMs and\nfuture FMs: performance uncertainty, learning efficiency, and overlapping\ntraining-test data splits. To target the three aspects, we meticulously\nconstruct the training, validation, and test splits using clustering methods\ntailored to geoscience data and enact an expansive training design to segregate\nperformance uncertainty arising from stochastic training processes and random\ndata sampling. The framework's ability to guard against misleading declarations\nof model superiority is demonstrated through evaluation of PhaseNet, a popular\nseismic phase picking DLM, under 3 training approaches. Furthermore, we show\nhow the performance gains due to overlapping training-test data can lead to\nbiased FM evaluation. Our framework helps practitioners choose the best model\nfor their problem and set performance expectations by explicitly analyzing\nmodel performance at varying budgets of training data.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2025-01-15",
      "downloaded_date": "2025-02-01",
      "filename": "Myren-Towards Foundation Models Evaluation of Geoscience Artificial Intelligence with Uncertainty.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.14809v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.geo-ph"
      ]
    },
    "1812.05659v1": {
      "title": "Artificial Intelligence Assisted Infrastructure Assessment Using Mixed Reality Systems",
      "authors": [
        "Enes Karaaslan",
        "Ulas Bagci",
        "F. Necati Catbas"
      ],
      "abstract": "Conventional methods for visual assessment of civil infrastructures have\ncertain limitations, such as subjectivity of the collected data, long\ninspection time, and high cost of labor. Although some new technologies i.e.\nrobotic techniques that are currently in practice can collect objective,\nquantified data, the inspectors own expertise is still critical in many\ninstances since these technologies are not designed to work interactively with\nhuman inspector. This study aims to create a smart, human centered method that\noffers significant contributions to infrastructure inspection, maintenance,\nmanagement practice, and safety for the bridge owners. By developing a smart\nMixed Reality framework, which can be integrated into a wearable holographic\nheadset device, a bridge inspector, for example, can automatically analyze a\ncertain defect such as a crack that he or she sees on an element, display its\ndimension information in real-time along with the condition state. Such systems\ncan potentially decrease the time and cost of infrastructure inspections by\naccelerating essential tasks of the inspector such as defect measurement,\ncondition assessment and data processing to management systems. The human\ncentered artificial intelligence will help the inspector collect more\nquantified and objective data while incorporating inspectors professional\njudgement. This study explains in detail the described system and related\nmethodologies of implementing attention guided semi supervised deep learning\ninto mixed reality technology, which interacts with the human inspector during\nassessment. Thereby, the inspector and the AI will collaborate or communicate\nfor improved visual inspection.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-12-09",
      "downloaded_date": "2025-02-01",
      "filename": "Karaaslan-Artificial Intelligence Assisted Infrastructure Assessment Using Mixed Reality Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1812.05659v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    "2404.00897v3": {
      "title": "Machine Learning Robustness: A Primer",
      "authors": [
        "Houssem Ben Braiek",
        "Foutse Khomh"
      ],
      "abstract": "This chapter explores the foundational concept of robustness in Machine\nLearning (ML) and its integral role in establishing trustworthiness in\nArtificial Intelligence (AI) systems. The discussion begins with a detailed\ndefinition of robustness, portraying it as the ability of ML models to maintain\nstable performance across varied and unexpected environmental conditions. ML\nrobustness is dissected through several lenses: its complementarity with\ngeneralizability; its status as a requirement for trustworthy AI; its\nadversarial vs non-adversarial aspects; its quantitative metrics; and its\nindicators such as reproducibility and explainability. The chapter delves into\nthe factors that impede robustness, such as data bias, model complexity, and\nthe pitfalls of underspecified ML pipelines. It surveys key techniques for\nrobustness assessment from a broad perspective, including adversarial attacks,\nencompassing both digital and physical realms. It covers non-adversarial data\nshifts and nuances of Deep Learning (DL) software testing methodologies. The\ndiscussion progresses to explore amelioration strategies for bolstering\nrobustness, starting with data-centric approaches like debiasing and\naugmentation. Further examination includes a variety of model-centric methods\nsuch as transfer learning, adversarial training, and randomized smoothing.\nLastly, post-training methods are discussed, including ensemble techniques,\npruning, and model repairs, emerging as cost-effective strategies to make\nmodels more resilient against the unpredictable. This chapter underscores the\nongoing challenges and limitations in estimating and achieving ML robustness by\nexisting approaches. It offers insights and directions for future research on\nthis crucial concept, as a prerequisite for trustworthy AI systems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-04-01",
      "downloaded_date": "2025-02-01",
      "filename": "Braiek-Machine Learning Robustness A Primer.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.00897v3",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ]
    },
    "2203.08890v1": {
      "title": "The Mathematics of Artificial Intelligence",
      "authors": [
        "Gitta Kutyniok"
      ],
      "abstract": "We currently witness the spectacular success of artificial intelligence in\nboth science and public life. However, the development of a rigorous\nmathematical foundation is still at an early stage. In this survey article,\nwhich is based on an invited lecture at the International Congress of\nMathematicians 2022, we will in particular focus on the current \"workhorse\" of\nartificial intelligence, namely deep neural networks. We will present the main\ntheoretical directions along with several exemplary results and discuss key\nopen problems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-03-16",
      "downloaded_date": "2025-02-01",
      "filename": "Kutyniok-The Mathematics of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.08890v1",
      "categories": [
        "cs.LG",
        "math.HO",
        "stat.ML",
        "Primary 68T07, Secondary 41A25, 42C15, 35C20, 65D18"
      ]
    },
    "2206.04179v1": {
      "title": "Automating Ambiguity: Challenges and Pitfalls of Artificial Intelligence",
      "authors": [
        "Abeba Birhane"
      ],
      "abstract": "Machine learning (ML) and artificial intelligence (AI) tools increasingly\npermeate every possible social, political, and economic sphere; sorting,\ntaxonomizing and predicting complex human behaviour and social phenomena.\nHowever, from fallacious and naive groundings regarding complex adaptive\nsystems to datasets underlying models, these systems are beset by problems,\nchallenges, and limitations. They remain opaque and unreliable, and fail to\nconsider societal and structural oppressive systems, disproportionately\nnegatively impacting those at the margins of society while benefiting the most\npowerful.\n  The various challenges, problems and pitfalls of these systems are a hot\ntopic of research in various areas, such as critical data/algorithm studies,\nscience and technology studies (STS), embodied and enactive cognitive science,\ncomplexity science, Afro-feminism, and the broadly construed emerging field of\nFairness, Accountability, and Transparency (FAccT). Yet, these fields of\nenquiry often proceed in silos. This thesis weaves together seemingly disparate\nfields of enquiry to examine core scientific and ethical challenges, pitfalls,\nand problems of AI.\n  In this thesis I, a) review the historical and cultural ecology from which AI\nresearch emerges, b) examine the shaky scientific grounds of machine prediction\nof complex behaviour illustrating how predicting complex behaviour with\nprecision is impossible in principle, c) audit large scale datasets behind\ncurrent AI demonstrating how they embed societal historical and structural\ninjustices, d) study the seemingly neutral values of ML research and put\nforward 67 prominent values underlying ML research, e) examine some of the\ninsidious and worrying applications of computer vision research, and f) put\nforward a framework for approaching challenges, failures and problems\nsurrounding ML systems as well as alternative ways forward.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-06-08",
      "downloaded_date": "2025-02-01",
      "filename": "Birhane-Automating Ambiguity Challenges and Pitfalls of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.04179v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2309.06029v1": {
      "title": "Artificially Intelligent Opinion Polling",
      "authors": [
        "Roberto Cerina",
        "Raymond Duch"
      ],
      "abstract": "We seek to democratise public-opinion research by providing practitioners\nwith a general methodology to make representative inference from cheap,\nhigh-frequency, highly unrepresentative samples. We focus specifically on\nsamples which are readily available in moderate sizes. To this end, we provide\ntwo major contributions: 1) we introduce a general sample-selection process\nwhich we name online selection, and show it is a special-case of selection on\nthe dependent variable. We improve MrP for severely biased samples by\nintroducing a bias-correction term in the style of King and Zeng to the\nlogistic-regression framework. We show this bias-corrected model outperforms\ntraditional MrP under online selection, and achieves performance similar to\nrandom-sampling in a vast array of scenarios; 2) we present a protocol to use\nLarge Language Models (LLMs) to extract structured, survey-like data from\nsocial-media. We provide a prompt-style that can be easily adapted to a variety\nof survey designs. We show that LLMs agree with human raters with respect to\nthe demographic, socio-economic and political characteristics of these online\nusers. The end-to-end implementation takes unrepresentative, unsrtuctured\nsocial media data as inputs, and produces timely high-quality area-level\nestimates as outputs. This is Artificially Intelligent Opinion Polling. We show\nthat our AI polling estimates of the 2020 election are highly accurate, on-par\nwith estimates produced by state-level polling aggregators such as\nFiveThirtyEight, or from MrP models fit to extremely expensive high-quality\nsamples.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-09-12",
      "downloaded_date": "2025-02-01",
      "filename": "Cerina-Artificially Intelligent Opinion Polling.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.06029v1",
      "categories": [
        "stat.ME"
      ]
    },
    "2307.08423v3": {
      "title": "Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems",
      "authors": [
        "Xuan Zhang",
        "Limei Wang",
        "Jacob Helwig",
        "Youzhi Luo",
        "Cong Fu",
        "Yaochen Xie",
        "Meng Liu",
        "Yuchao Lin",
        "Zhao Xu",
        "Keqiang Yan",
        "Keir Adams",
        "Maurice Weiler",
        "Xiner Li",
        "Tianfan Fu",
        "Yucheng Wang",
        "Haiyang Yu",
        "YuQing Xie",
        "Xiang Fu",
        "Alex Strasser",
        "Shenglong Xu",
        "Yi Liu",
        "Yuanqi Du",
        "Alexandra Saxton",
        "Hongyi Ling",
        "Hannah Lawrence",
        "Hannes StÃ¤rk",
        "Shurui Gui",
        "Carl Edwards",
        "Nicholas Gao",
        "Adriana Ladera",
        "Tailin Wu",
        "Elyssa F. Hofgard",
        "Aria Mansouri Tehrani",
        "Rui Wang",
        "Ameya Daigavane",
        "Montgomery Bohde",
        "Jerry Kurtin",
        "Qian Huang",
        "Tuong Phung",
        "Minkai Xu",
        "Chaitanya K. Joshi",
        "Simon V. Mathis",
        "Kamyar Azizzadenesheli",
        "Ada Fang",
        "AlÃ¡n Aspuru-Guzik",
        "Erik Bekkers",
        "Michael Bronstein",
        "Marinka Zitnik",
        "Anima Anandkumar",
        "Stefano Ermon",
        "Pietro LiÃ²",
        "Rose Yu",
        "Stephan GÃ¼nnemann",
        "Jure Leskovec",
        "Heng Ji",
        "Jimeng Sun",
        "Regina Barzilay",
        "Tommi Jaakkola",
        "Connor W. Coley",
        "Xiaoning Qian",
        "Xiaofeng Qian",
        "Tess Smidt",
        "Shuiwang Ji"
      ],
      "abstract": "Advances in artificial intelligence (AI) are fueling a new paradigm of\ndiscoveries in natural sciences. Today, AI has started to advance natural\nsciences by improving, accelerating, and enabling our understanding of natural\nphenomena at a wide range of spatial and temporal scales, giving rise to a new\narea of research known as AI for science (AI4Science). Being an emerging\nresearch paradigm, AI4Science is unique in that it is an enormous and highly\ninterdisciplinary area. Thus, a unified and technical treatment of this field\nis needed yet challenging. This work aims to provide a technically thorough\naccount of a subarea of AI4Science; namely, AI for quantum, atomistic, and\ncontinuum systems. These areas aim at understanding the physical world from the\nsubatomic (wavefunctions and electron density), atomic (molecules, proteins,\nmaterials, and interactions), to macro (fluids, climate, and subsurface) scales\nand form an important subarea of AI4Science. A unique advantage of focusing on\nthese areas is that they largely share a common set of challenges, thereby\nallowing a unified and foundational treatment. A key common challenge is how to\ncapture physics first principles, especially symmetries, in natural systems by\ndeep learning methods. We provide an in-depth yet intuitive account of\ntechniques to achieve equivariance to symmetry transformations. We also discuss\nother common technical challenges, including explainability,\nout-of-distribution generalization, knowledge transfer with foundation and\nlarge language models, and uncertainty quantification. To facilitate learning\nand education, we provide categorized lists of resources that we found to be\nuseful. We strive to be thorough and unified and hope this initial effort may\ntrigger more community interests and efforts to further advance AI4Science.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-07-17",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Artificial Intelligence for Science in Quantum Atomistic and Continuum Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.08423v3",
      "categories": [
        "cs.LG",
        "physics.comp-ph"
      ]
    },
    "1610.07862v2": {
      "title": "Intelligence in Artificial Intelligence",
      "authors": [
        "Shoumen Palit Austin Datta"
      ],
      "abstract": "The elusive quest for intelligence in artificial intelligence prompts us to\nconsider that instituting human-level intelligence in systems may be (still) in\nthe realm of utopia. In about a quarter century, we have witnessed the winter\nof AI (1990) being transformed and transported to the zenith of tabloid fodder\nabout AI (2015). The discussion at hand is about the elements that constitute\nthe canonical idea of intelligence. The delivery of intelligence as a\npay-per-use-service, popping out of an app or from a shrink-wrapped software\ndefined point solution, is in contrast to the bio-inspired view of intelligence\nas an outcome, perhaps formed from a tapestry of events, cross-pollinated by\ninstances, each with its own microcosm of experiences and learning, which may\nnot be discrete all-or-none functions but continuous, over space and time. The\nenterprise world may not require, aspire or desire such an engaged solution to\nimprove its services for enabling digital transformation through the deployment\nof digital twins, for example. One might ask whether the \"work-flow on\nsteroids\" version of decision support may suffice for intelligence? Are we\nharking back to the era of rule based expert systems? The image conjured by the\npublicity machines offers deep solutions with human-level AI and preposterous\nclaims about capturing the \"brain in a box\" by 2020. Even emulating insects may\nbe difficult in terms of real progress. Perhaps we can try to focus on worms\n(Caenorhabditis elegans) which may be better suited for what business needs to\nquench its thirst for so-called intelligence in AI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2016-10-24",
      "downloaded_date": "2025-02-01",
      "filename": "Datta-Intelligence in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1610.07862v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2301.01560v1": {
      "title": "Identifying preflare spectral features using explainable artificial intelligence",
      "authors": [
        "Brandon Panos",
        "Lucia Kleint",
        "Jonas Zbinden"
      ],
      "abstract": "The prediction of solar flares is of practical and scientific interest;\nhowever, many machine learning methods used for this prediction task do not\nprovide the physical explanations behind a model's performance. We made use of\ntwo recently developed explainable artificial intelligence techniques called\ngradient-weighted class activation mapping (Grad-CAM) and expected gradients\n(EG) to reveal the decision-making process behind a high-performance neural\nnetwork that has been trained to distinguish between MgII spectra derived from\nflaring and nonflaring active regions, a fact that can be applied to the task\nof short timescale flare forecasting. The two techniques generate visual\nexplanations (heatmaps) that can be projected back onto the spectra, allowing\nfor the identification of features that are strongly associated with precursory\nflare activity. We automated the search for explainable interpretations on the\nlevel of individual wavelengths, and provide multiple examples of flare\nprediction using IRIS spectral data, finding that prediction scores in general\nincrease before flare onset. Large IRIS rasters that cover a significant\nportion of the active region and coincide with small preflare brightenings both\nin IRIS and SDO/AIA images tend to lead to better forecasts. The models reveal\nthat MgII triplet emission, flows, as well as broad and highly asymmetric\nspectra are all important for the task of flare prediction. Additionally, we\nfind that intensity is only weakly correlated to a spectrum's prediction score,\nmeaning that low intensity spectra can still be of great importance for the\nflare prediction task, and that $78$% of the time, the position of the model's\nmaximum attention along the slit during the preflare phase is predictive of the\nlocation of the flare's maximum UV emission",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-01-04",
      "downloaded_date": "2025-02-01",
      "filename": "Panos-Identifying preflare spectral features using explainable artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2301.01560v1",
      "categories": [
        "astro-ph.SR",
        "astro-ph.IM"
      ]
    },
    "2411.05027v1": {
      "title": "Generative Artificial Intelligence Meets Synthetic Aperture Radar: A Survey",
      "authors": [
        "Zhongling Huang",
        "Xidan Zhang",
        "Zuqian Tang",
        "Feng Xu",
        "Mihai Datcu",
        "Junwei Han"
      ],
      "abstract": "SAR images possess unique attributes that present challenges for both human\nobservers and vision AI models to interpret, owing to their electromagnetic\ncharacteristics. The interpretation of SAR images encounters various hurdles,\nwith one of the primary obstacles being the data itself, which includes issues\nrelated to both the quantity and quality of the data. The challenges can be\naddressed using generative AI technologies. Generative AI, often known as\nGenAI, is a very advanced and powerful technology in the field of artificial\nintelligence that has gained significant attention. The advancement has created\npossibilities for the creation of texts, photorealistic pictures, videos, and\nmaterial in various modalities. This paper aims to comprehensively investigate\nthe intersection of GenAI and SAR. First, we illustrate the common data\ngeneration-based applications in SAR field and compare them with computer\nvision tasks, analyzing the similarity, difference, and general challenges of\nthem. Then, an overview of the latest GenAI models is systematically reviewed,\nincluding various basic models and their variations targeting the general\nchallenges. Additionally, the corresponding applications in SAR domain are also\nincluded. Specifically, we propose to summarize the physical model based\nsimulation approaches for SAR, and analyze the hybrid modeling methods that\ncombine the GenAI and interpretable models. The evaluation methods that have\nbeen or could be applied to SAR, are also explored. Finally, the potential\nchallenges and future prospects are discussed. To our best knowledge, this\nsurvey is the first exhaustive examination of the interdiscipline of SAR and\nGenAI, encompassing a wide range of topics, including deep neural networks,\nphysical models, computer vision, and SAR images. The resources of this survey\nare open-source at \\url{https://github.com/XAI4SAR/GenAIxSAR}.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-11-05",
      "downloaded_date": "2025-02-01",
      "filename": "Huang-Generative Artificial Intelligence Meets Synthetic Aperture Radar A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.05027v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ]
    },
    "1811.06526v3": {
      "title": "Artificial Intelligence for Interstellar Travel",
      "authors": [
        "Andreas M. Hein",
        "Stephen Baxter"
      ],
      "abstract": "The large distances involved in interstellar travel require a high degree of\nspacecraft autonomy, realized by artificial intelligence. The breadth of tasks\nartificial intelligence could perform on such spacecraft involves maintenance,\ndata collection, designing and constructing an infrastructure using in-situ\nresources. Despite its importance, existing publications on artificial\nintelligence and interstellar travel are limited to cursory descriptions where\nlittle detail is given about the nature of the artificial intelligence. This\narticle explores the role of artificial intelligence for interstellar travel by\ncompiling use cases, exploring capabilities, and proposing typologies, system\nand mission architectures. Estimations for the required intelligence level for\nspecific types of interstellar probes are given, along with potential system\nand mission architectures, covering those proposed in the literature but also\npresenting novel ones. Finally, a generic design for interstellar probes with\nan AI payload is proposed. Given current levels of increase in computational\npower, a spacecraft with a similar computational power as the human brain would\nhave a mass from dozens to hundreds of tons in a 2050-2060 timeframe. Given\nthat the advent of the first interstellar missions and artificial general\nintelligence are estimated to be by the mid-21st century, a more in-depth\nexploration of the relationship between the two should be attempted, focusing\non neglected areas such as protecting the artificial intelligence payload from\nradiation in interstellar space and the role of artificial intelligence in\nself-replication.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-11-15",
      "downloaded_date": "2025-02-01",
      "filename": "Hein-Artificial Intelligence for Interstellar Travel.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1811.06526v3",
      "categories": [
        "physics.pop-ph",
        "physics.space-ph"
      ]
    },
    "2111.03598v1": {
      "title": "Quantum Algorithms for Unsupervised Machine Learning and Neural Networks",
      "authors": [
        "Jonas Landman"
      ],
      "abstract": "In this thesis, we investigate whether quantum algorithms can be used in the\nfield of machine learning for both long and near term quantum computers. We\nwill first recall the fundamentals of machine learning and quantum computing\nand then describe more precisely how to link them through linear algebra: we\nintroduce quantum algorithms to efficiently solve tasks such as matrix product\nor distance estimation. These results are then used to develop new quantum\nalgorithms for unsupervised machine learning, such as k-means and spectral\nclustering. This allows us to define many fundamental procedures, in particular\nin vector and graph analysis. We will also present new quantum algorithms for\nneural networks, or deep learning. For this, we introduce an algorithm to\nperform a quantum convolution product on images, as well as a new way to\nperform a fast tomography on quantum states. We prove that these quantum\nalgorithms are faster versions of equivalent classical algorithms, but exhibit\nrandom effects due to the quantum nature of the computation. Many simulations\nhave been carried out to study these effects and measure their learning\naccuracy on real data. Finally, we will present a quantum orthogonal neural\nnetwork circuit adapted to the currently available small and imperfect quantum\ncomputers. This allows us to perform real experiments to test our theory.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-11-05",
      "downloaded_date": "2025-02-01",
      "filename": "Landman-Quantum Algorithms for Unsupervised Machine Learning and Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.03598v1",
      "categories": [
        "quant-ph"
      ]
    },
    "2302.09656v5": {
      "title": "Credal Bayesian Deep Learning",
      "authors": [
        "Michele Caprio",
        "Souradeep Dutta",
        "Kuk Jin Jang",
        "Vivian Lin",
        "Radoslav Ivanov",
        "Oleg Sokolsky",
        "Insup Lee"
      ],
      "abstract": "Uncertainty quantification and robustness to distribution shifts are\nimportant goals in machine learning and artificial intelligence. Although\nBayesian Neural Networks (BNNs) allow for uncertainty in the predictions to be\nassessed, different sources of predictive uncertainty cannot be distinguished\nproperly. We present Credal Bayesian Deep Learning (CBDL). Heuristically, CBDL\nallows to train an (uncountably) infinite ensemble of BNNs, using only finitely\nmany elements. This is possible thanks to prior and likelihood finitely\ngenerated credal sets (FGCSs), a concept from the imprecise probability\nliterature. Intuitively, convex combinations of a finite collection of\nprior-likelihood pairs are able to represent infinitely many such pairs. After\ntraining, CBDL outputs a set of posteriors on the parameters of the neural\nnetwork. At inference time, such posterior set is used to derive a set of\npredictive distributions that is in turn utilized to distinguish between\n(predictive) aleatoric and epistemic uncertainties, and to quantify them. The\npredictive set also produces either (i) a collection of outputs enjoying\ndesirable probabilistic guarantees, or (ii) the single output that is deemed\nthe best, that is, the one having the highest predictive lower probability --\nanother imprecise-probabilistic concept. CBDL is more robust than single BNNs\nto prior and likelihood misspecification, and to distribution shift. We show\nthat CBDL is better at quantifying and disentangling different types of\n(predictive) uncertainties than single BNNs and ensemble of BNNs. In addition,\nwe apply CBDL to two case studies to demonstrate its downstream tasks\ncapabilities: one, for motion prediction in autonomous driving scenarios, and\ntwo, to model blood glucose and insulin dynamics for artificial pancreas\ncontrol. We show that CBDL performs better when compared to an ensemble of BNNs\nbaseline.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-02-19",
      "downloaded_date": "2025-02-01",
      "filename": "Caprio-Credal Bayesian Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.09656v5",
      "categories": [
        "cs.LG",
        "stat.ML",
        "Primary: 68T37, Secondary: 68T05, 68W25"
      ]
    },
    "2009.01575v2": {
      "title": "Deep Learning in Science",
      "authors": [
        "Stefano Bianchini",
        "Moritz MÃ¼ller",
        "Pierre Pelletier"
      ],
      "abstract": "Much of the recent success of Artificial Intelligence (AI) has been spurred\non by impressive achievements within a broader family of machine learning\nmethods, commonly referred to as Deep Learning (DL). This paper provides\ninsights on the diffusion and impact of DL in science. Through a Natural\nLanguage Processing (NLP) approach on the arXiv.org publication corpus, we\ndelineate the emerging DL technology and identify a list of relevant search\nterms. These search terms allow us to retrieve DL-related publications from Web\nof Science across all sciences. Based on that sample, we document the DL\ndiffusion process in the scientific system. We find i) an exponential growth in\nthe adoption of DL as a research tool across all sciences and all over the\nworld, ii) regional differentiation in DL application domains, and iii) a\ntransition from interdisciplinary DL applications to disciplinary research\nwithin application domains. In a second step, we investigate how the adoption\nof DL methods affects scientific development. Therefore, we empirically assess\nhow DL adoption relates to re-combinatorial novelty and scientific impact in\nthe health sciences. We find that DL adoption is negatively correlated with\nre-combinatorial novelty, but positively correlated with expectation as well as\nvariance of citation performance. Our findings suggest that DL does not (yet?)\nwork as an autopilot to navigate complex knowledge landscapes and overthrow\ntheir structure. However, the 'DL principle' qualifies for its versatility as\nthe nucleus of a general scientific method that advances science in a\nmeasurable way.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-09-03",
      "downloaded_date": "2025-02-01",
      "filename": "Bianchini-Deep Learning in Science.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.01575v2",
      "categories": [
        "cs.CY",
        "econ.EM"
      ]
    },
    "2108.02837v1": {
      "title": "Lossless Multi-Scale Constitutive Elastic Relations with Artificial Intelligence",
      "authors": [
        "Jaber Rezaei Mianroodi",
        "Shahed Rezaei",
        "Nima H. Siboni",
        "Bai-Xiang Xu",
        "Dierk Raabe"
      ],
      "abstract": "The elastic properties of materials derive from their electronic and atomic\nnature. However, simulating bulk materials fully at these scales is not\nfeasible, so that typically homogenized continuum descriptions are used\ninstead. A seamless and lossless transition of the constitutive description of\nthe elastic response of materials between these two scales has been so far\nelusive. Here we show how this problem can be overcome by using Artificial\nIntelligence (AI). A Convolutional Neural Network (CNN) model is trained, by\ntaking the structure image of a nanoporous material as input and the\ncorresponding elasticity tensor, calculated from Molecular Statics (MS), as\noutput. Trained with the atomistic data, the CNN model captures the size- and\npore-dependency of the material's elastic properties which, on the physics\nside, can stem from surfaces and non-local effects. Such effects are often\nignored in upscaling from atomistic to classical continuum theory. To\ndemonstrate the accuracy and the efficiency of the trained CNN model, a Finite\nElement Method (FEM) based result of an elastically deformed nanoporous beam\nequipped with the CNN as constitutive law is compared with that by a full\natomistic simulation. The good agreement between the atomistic simulations and\nthe FEM-AI combination for a system with size and surface effects establishes a\nnew lossless scale bridging approach to such problems. The trained CNN model\ndeviates from the atomistic result by 9.6\\% for porosity scenarios of up to\n90\\% but it is about 230 times faster than the MS calculation and does not\nrequire to change simulation methods between different scales. The efficiency\nof the CNN evaluation together with the preservation of important atomistic\neffects makes the trained model an effective atomistically-informed\nconstitutive model for macroscopic simulations of nanoporous materials and\nsolving of inverse problems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-08-05",
      "downloaded_date": "2025-02-01",
      "filename": "Mianroodi-Lossless Multi-Scale Constitutive Elastic Relations with Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.02837v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall",
        "cs.LG"
      ]
    },
    "2307.11332v1": {
      "title": "Beyond Convergence: Identifiability of Machine Learning and Deep Learning Models",
      "authors": [
        "Reza Sameni"
      ],
      "abstract": "Machine learning (ML) and deep learning models are extensively used for\nparameter optimization and regression problems. However, not all inverse\nproblems in ML are ``identifiable,'' indicating that model parameters may not\nbe uniquely determined from the available data and the data model's\ninput-output relationship. In this study, we investigate the notion of model\nparameter identifiability through a case study focused on parameter estimation\nfrom motion sensor data. Utilizing a bipedal-spring mass human walk dynamics\nmodel, we generate synthetic data representing diverse gait patterns and\nconditions. Employing a deep neural network, we attempt to estimate\nsubject-wise parameters, including mass, stiffness, and equilibrium leg length.\nThe results show that while certain parameters can be identified from the\nobservation data, others remain unidentifiable, highlighting that\nunidentifiability is an intrinsic limitation of the experimental setup,\nnecessitating a change in data collection and experimental scenarios. Beyond\nthis specific case study, the concept of identifiability has broader\nimplications in ML and deep learning. Addressing unidentifiability requires\nproven identifiable models (with theoretical support), multimodal data fusion\ntechniques, and advancements in model-based machine learning. Understanding and\nresolving unidentifiability challenges will lead to more reliable and accurate\napplications across diverse domains, transcending mere model convergence and\nenhancing the reliability of machine learning models.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-07-21",
      "downloaded_date": "2025-02-01",
      "filename": "Sameni-Beyond Convergence Identifiability of Machine Learning and Deep Learning Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.11332v1",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "1801.06044v1": {
      "title": "Analysis of the Relation between Artificial Intelligence and the Internet from the Perspective of Brain Science",
      "authors": [
        "Feng Liu",
        "Yong Shi",
        "Peijia Lia"
      ],
      "abstract": "Artificial intelligence (AI) like deep learning, cloud AI computation has\nbeen advancing at a rapid pace since 2014. There is no doubt that the\nprosperity of AI is inseparable with the development of the Internet. However,\nthere has been little attention to the link between AI and the internet. This\npaper explores them with brain insights mainly from four views:1) How is the\ngeneral relation between artificial intelligence and Internet of Things, cloud\ncomputing, big data and Industrial Internet from the perspective of brain\nscience. 2) Construction of a new AI system model with the Internet and brain\nscience.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-01-02",
      "downloaded_date": "2025-02-01",
      "filename": "Liu-Analysis of the Relation between Artificial Intelligence and the Internet from the Perspective of Br....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1801.06044v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2208.14937v1": {
      "title": "Explainable Artificial Intelligence Applications in Cyber Security: State-of-the-Art in Research",
      "authors": [
        "Zhibo Zhang",
        "Hussam Al Hamadi",
        "Ernesto Damiani",
        "Chan Yeob Yeun",
        "Fatma Taher"
      ],
      "abstract": "This survey presents a comprehensive review of current literature on\nExplainable Artificial Intelligence (XAI) methods for cyber security\napplications. Due to the rapid development of Internet-connected systems and\nArtificial Intelligence in recent years, Artificial Intelligence including\nMachine Learning (ML) and Deep Learning (DL) has been widely utilized in the\nfields of cyber security including intrusion detection, malware detection, and\nspam filtering. However, although Artificial Intelligence-based approaches for\nthe detection and defense of cyber attacks and threats are more advanced and\nefficient compared to the conventional signature-based and rule-based cyber\nsecurity strategies, most ML-based techniques and DL-based techniques are\ndeployed in the black-box manner, meaning that security experts and customers\nare unable to explain how such procedures reach particular conclusions. The\ndeficiencies of transparency and interpretability of existing Artificial\nIntelligence techniques would decrease human users' confidence in the models\nutilized for the defense against cyber attacks, especially in current\nsituations where cyber attacks become increasingly diverse and complicated.\nTherefore, it is essential to apply XAI in the establishment of cyber security\nmodels to create more explainable models while maintaining high accuracy and\nallowing human users to comprehend, trust, and manage the next generation of\ncyber defense mechanisms. Although there are papers reviewing Artificial\nIntelligence applications in cyber security areas and the vast literature on\napplying XAI in many fields including healthcare, financial services, and\ncriminal justice, the surprising fact is that there are currently no survey\nresearch articles that concentrate on XAI applications in cyber security.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-08-31",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Explainable Artificial Intelligence Applications in Cyber Security State-of-the-Art in Research.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2208.14937v1",
      "categories": [
        "cs.CR"
      ]
    },
    "2112.00190v1": {
      "title": "Is the use of Deep Learning and Artificial Intelligence an appropriate means to locate debris in the ocean without harming aquatic wildlife?",
      "authors": [
        "Zoe Moorton",
        "Zeyneb Kurt",
        "Wai Lok Woo"
      ],
      "abstract": "With the global issue of plastic debris ever expanding, it is about time that\nthe technology industry stepped in. This study aims to assess whether deep\nlearning can successfully distinguish between marine life and man-made debris\nunderwater. The aim is to find if we are safely able to clean up our oceans\nwith Artificial Intelligence without disrupting the delicate balance of the\naquatic ecosystems. The research explores the use of Convolutional Neural\nNetworks from the perspective of protecting the ecosystem, rather than\nprimarily collecting rubbish. We did this by building a custom-built, deep\nlearning model, with an original database including 1,644 underwater images and\nused a binary classification to sort synthesised material from aquatic life. We\nconcluded that although it is possible to safely distinguish between debris and\nlife, further exploration with a larger database and stronger CNN structure has\nthe potential for much more promising results.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-12-01",
      "downloaded_date": "2025-02-01",
      "filename": "Moorton-Is the use of Deep Learning and Artificial Intelligence an appropriate means to locate debris in the....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2112.00190v1",
      "categories": [
        "cs.LG",
        "cs.CV",
        "eess.IV"
      ]
    },
    "2410.19843v2": {
      "title": "Artificial intelligence for partial differential equations in computational mechanics: A review",
      "authors": [
        "Yizheng Wang",
        "Jinshuai Bai",
        "Zhongya Lin",
        "Qimin Wang",
        "Cosmin Anitescu",
        "Jia Sun",
        "Mohammad Sadegh Eshaghi",
        "Yuantong Gu",
        "Xi-Qiao Feng",
        "Xiaoying Zhuang",
        "Timon Rabczuk",
        "Yinghua Liu"
      ],
      "abstract": "In recent years, Artificial intelligence (AI) has become ubiquitous,\nempowering various fields, especially integrating artificial intelligence and\ntraditional science (AI for Science: Artificial intelligence for science),\nwhich has attracted widespread attention. In AI for Science, using artificial\nintelligence algorithms to solve partial differential equations (AI for PDEs:\nArtificial intelligence for partial differential equations) has become a focal\npoint in computational mechanics. The core of AI for PDEs is the fusion of data\nand partial differential equations (PDEs), which can solve almost any PDEs.\nTherefore, this article provides a comprehensive review of the research on AI\nfor PDEs, summarizing the existing algorithms and theories. The article\ndiscusses the applications of AI for PDEs in computational mechanics, including\nsolid mechanics, fluid mechanics, and biomechanics. The existing AI for PDEs\nalgorithms include those based on Physics-Informed Neural Networks (PINNs),\nDeep Energy Methods (DEM), Operator Learning, and Physics-Informed Neural\nOperator (PINO). AI for PDEs represents a new method of scientific simulation\nthat provides approximate solutions to specific problems using large amounts of\ndata, then fine-tuning according to specific physical laws, avoiding the need\nto compute from scratch like traditional algorithms. Thus, AI for PDEs is the\nprototype for future foundation models in computational mechanics, capable of\nsignificantly accelerating traditional numerical algorithms.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-10-21",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Artificial intelligence for partial differential equations in computational mechanics A review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.19843v2",
      "categories": [
        "eess.SY",
        "cs.LG",
        "cs.SY"
      ]
    },
    "2305.17473v3": {
      "title": "A Comprehensive Overview and Comparative Analysis on Deep Learning Models: CNN, RNN, LSTM, GRU",
      "authors": [
        "Farhad Mortezapour Shiri",
        "Thinagaran Perumal",
        "Norwati Mustapha",
        "Raihani Mohamed"
      ],
      "abstract": "Deep learning (DL) has emerged as a powerful subset of machine learning (ML)\nand artificial intelligence (AI), outperforming traditional ML methods,\nespecially in handling unstructured and large datasets. Its impact spans across\nvarious domains, including speech recognition, healthcare, autonomous vehicles,\ncybersecurity, predictive analytics, and more. However, the complexity and\ndynamic nature of real-world problems present challenges in designing effective\ndeep learning models. Consequently, several deep learning models have been\ndeveloped to address different problems and applications. In this article, we\nconduct a comprehensive survey of various deep learning models, including\nConvolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs),\nGenerative Models, Deep Reinforcement Learning (DRL), and Deep Transfer\nLearning. We examine the structure, applications, benefits, and limitations of\neach model. Furthermore, we perform an analysis using three publicly available\ndatasets: IMDB, ARAS, and Fruit-360. We compare the performance of six renowned\ndeep learning models: CNN, Simple RNN, Long Short-Term Memory (LSTM),\nBidirectional LSTM, Gated Recurrent Unit (GRU), and Bidirectional GRU.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-05-27",
      "downloaded_date": "2025-02-01",
      "filename": "Shiri-A Comprehensive Overview and Comparative Analysis on Deep Learning Models CNN RNN LSTM GRU.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.17473v3",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1510.02709v1": {
      "title": "Large-scale Artificial Neural Network: MapReduce-based Deep Learning",
      "authors": [
        "Kairan Sun",
        "Xu Wei",
        "Gengtao Jia",
        "Risheng Wang",
        "Ruizhi Li"
      ],
      "abstract": "Faced with continuously increasing scale of data, original back-propagation\nneural network based machine learning algorithm presents two non-trivial\nchallenges: huge amount of data makes it difficult to maintain both efficiency\nand accuracy; redundant data aggravates the system workload. This project is\nmainly focused on the solution to the issues above, combining deep learning\nalgorithm with cloud computing platform to deal with large-scale data. A\nMapReduce-based handwriting character recognizer will be designed in this\nproject to verify the efficiency improvement this mechanism will achieve on\ntraining and practical large-scale data. Careful discussion and experiment will\nbe developed to illustrate how deep learning algorithm works to train\nhandwritten digits data, how MapReduce is implemented on deep learning neural\nnetwork, and why this combination accelerates computation. Besides performance,\nthe scalability and robustness will be mentioned in this report as well. Our\nsystem comes with two demonstration software that visually illustrates our\nhandwritten digit recognition/encoding application.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2015-10-09",
      "downloaded_date": "2025-02-01",
      "filename": "Sun-Large-scale Artificial Neural Network MapReduce-based Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1510.02709v1",
      "categories": [
        "cs.DC",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2210.10010v1": {
      "title": "Vision Paper: Causal Inference for Interpretable and Robust Machine Learning in Mobility Analysis",
      "authors": [
        "Yanan Xin",
        "Natasa Tagasovska",
        "Fernando Perez-Cruz",
        "Martin Raubal"
      ],
      "abstract": "Artificial intelligence (AI) is revolutionizing many areas of our lives,\nleading a new era of technological advancement. Particularly, the\ntransportation sector would benefit from the progress in AI and advance the\ndevelopment of intelligent transportation systems. Building intelligent\ntransportation systems requires an intricate combination of artificial\nintelligence and mobility analysis. The past few years have seen rapid\ndevelopment in transportation applications using advanced deep neural networks.\nHowever, such deep neural networks are difficult to interpret and lack\nrobustness, which slows the deployment of these AI-powered algorithms in\npractice. To improve their usability, increasing research efforts have been\ndevoted to developing interpretable and robust machine learning methods, among\nwhich the causal inference approach recently gained traction as it provides\ninterpretable and actionable information. Moreover, most of these methods are\ndeveloped for image or sequential data which do not satisfy specific\nrequirements of mobility data analysis. This vision paper emphasizes research\nchallenges in deep learning-based mobility analysis that require\ninterpretability and robustness, summarizes recent developments in using causal\ninference for improving the interpretability and robustness of machine learning\nmethods, and highlights opportunities in developing causally-enabled machine\nlearning models tailored for mobility analysis. This research direction will\nmake AI in the transportation sector more interpretable and reliable, thus\ncontributing to safer, more efficient, and more sustainable future\ntransportation systems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-10-18",
      "downloaded_date": "2025-02-01",
      "filename": "Xin-Vision Paper Causal Inference for Interpretable and Robust Machine Learning in Mobility Analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.10010v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2; J.2"
      ]
    },
    "2407.06151v1": {
      "title": "Auto-PICNN: Automated machine learning for physics-informed convolutional neural networks",
      "authors": [
        "Wanyun Zhou",
        "Xiaowen Chu"
      ],
      "abstract": "Recent advances in deep learning for solving partial differential equations\n(PDEs) have introduced physics-informed neural networks (PINNs), which\nintegrate machine learning with physical laws. Physics-informed convolutional\nneural networks (PICNNs) extend PINNs by leveraging CNNs for enhanced\ngeneralization and efficiency. However, current PICNNs depend on manual design,\nand inappropriate designs may not effectively solve PDEs. Furthermore, due to\nthe diversity of physical problems, the ideal network architectures and loss\nfunctions vary across different PDEs. It is impractical to find the optimal\nPICNN architecture and loss function for each specific physical problem through\nextensive manual experimentation. To surmount these challenges, this paper uses\nautomated machine learning (AutoML) to automatically and efficiently search for\nthe loss functions and network architectures of PICNNs. We introduce novel\nsearch spaces for loss functions and network architectures and propose a\ntwo-stage search strategy. The first stage focuses on searching for factors and\nresidual adjustment operations that influence the loss function, while the\nsecond stage aims to find the best CNN architecture. Experimental results show\nthat our automatic searching method significantly outperforms the\nmanually-designed model on multiple datasets.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/14b9c75f42f342a7ae0f1c4e19cdeb680b9d30b6",
      "published_date": "2024-07-08",
      "downloaded_date": "2025-02-01",
      "filename": "Zhou-Auto-PICNN Automated machine learning for physics-informed convolutional neural networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.06151v1",
      "categories": [
        "cs.CE"
      ]
    },
    "2005.12150v2": {
      "title": "Design of a dynamic and self adapting system, supported with artificial intelligence, machine learning and real time intelligence for predictive cyber risk analytics in extreme environments, cyber risk in the colonisation of Mars",
      "authors": [
        "Petar Radanliev",
        "David De Roure",
        "Kevin Page",
        "Max Van Kleek",
        "Omar Santos",
        "La Treall Maddox",
        "Pete Burnap",
        "Eirini Anthi",
        "Carsten Maple"
      ],
      "abstract": "Multiple governmental agencies and private organisations have made\ncommitments for the colonisation of Mars. Such colonisation requires complex\nsystems and infrastructure that could be very costly to repair or replace in\ncases of cyber attacks. This paper surveys deep learning algorithms, IoT cyber\nsecurity and risk models, and established mathematical formulas to identify the\nbest approach for developing a dynamic and self adapting system for predictive\ncyber risk analytics supported with Artificial Intelligence and Machine\nLearning and real time intelligence in edge computing. The paper presents a new\nmathematical approach for integrating concepts for cognition engine design,\nedge computing and Artificial Intelligence and Machine Learning to automate\nanomaly detection. This engine instigates a step change by applying Artificial\nIntelligence and Machine Learning embedded at the edge of IoT networks, to\ndeliver safe and functional real time intelligence for predictive cyber risk\nanalytics. This will enhance capacities for risk analytics and assists in the\ncreation of a comprehensive and systematic understanding of the opportunities\nand threats that arise when edge computing nodes are deployed, and when\nArtificial Intelligence and Machine Learning technologies are migrated to the\nperiphery of the internet and into local IoT networks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-05-19",
      "downloaded_date": "2025-02-01",
      "filename": "Radanliev-Design of a dynamic and self adapting system supported with artificial intelligence machine learning....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.12150v2",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "68T01, 68T05, 97P80, 68T37",
        "I.1.2; D.4; G.1; G.3; H.4"
      ]
    },
    "2103.09985v2": {
      "title": "A deep learning theory for neural networks grounded in physics",
      "authors": [
        "Benjamin Scellier"
      ],
      "abstract": "In the last decade, deep learning has become a major component of artificial\nintelligence. The workhorse of deep learning is the optimization of loss\nfunctions by stochastic gradient descent (SGD). Traditionally in deep learning,\nneural networks are differentiable mathematical functions, and the loss\ngradients required for SGD are computed with the backpropagation algorithm.\nHowever, the computer architectures on which these neural networks are\nimplemented and trained suffer from speed and energy inefficiency issues, due\nto the separation of memory and processing in these architectures. To solve\nthese problems, the field of neuromorphic computing aims at implementing neural\nnetworks on hardware architectures that merge memory and processing, just like\nbrains do. In this thesis, we argue that building large, fast and efficient\nneural networks on neuromorphic architectures also requires rethinking the\nalgorithms to implement and train them. We present an alternative mathematical\nframework, also compatible with SGD, which offers the possibility to design\nneural networks in substrates that directly exploit the laws of physics. Our\nframework applies to a very broad class of models, namely those whose state or\ndynamics are described by variational equations. This includes physical systems\nwhose equilibrium state minimizes an energy function, and physical systems\nwhose trajectory minimizes an action functional. We present a simple procedure\nto compute the loss gradients in such systems, called equilibrium propagation\n(EqProp), which requires solely locally available information for each\ntrainable parameter. Since many models in physics and engineering can be\ndescribed by variational principles, our framework has the potential to be\napplied to a broad variety of physical systems whose applications extend to\nvarious fields of engineering, beyond neuromorphic computing.",
      "citation_count": 25,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c2909b0128df66eda670f6cfc3b44fd06257b318",
      "published_date": "2021-03-18",
      "downloaded_date": "2025-02-01",
      "filename": "Scellier-A deep learning theory for neural networks grounded in physics.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.09985v2",
      "categories": [
        "cs.LG"
      ]
    },
    "2411.13535v1": {
      "title": "Comparative Analysis of Machine Learning and Deep Learning Models for Classifying Squamous Epithelial Cells of the Cervix",
      "authors": [
        "Subhasish Das",
        "Satish K Panda",
        "Madhusmita Sethy",
        "Prajna Paramita Giri",
        "Ashwini K Nanda"
      ],
      "abstract": "The cervix is the narrow end of the uterus that connects to the vagina in the\nfemale reproductive system. Abnormal cell growth in the squamous epithelial\nlining of the cervix leads to cervical cancer in females. A Pap smear is a\ndiagnostic procedure used to detect cervical cancer by gently collecting cells\nfrom the surface of the cervix with a small brush and analyzing their changes\nunder a microscope. For population-based cervical cancer screening, visual\ninspection with acetic acid is a cost-effective method with high sensitivity.\nHowever, Pap smears are also suitable for mass screening due to their higher\nspecificity. The current Pap smear analysis method is manual, time-consuming,\nlabor-intensive, and prone to human error. Therefore, an artificial\nintelligence (AI)-based approach for automatic cell classification is needed.\nIn this study, we aimed to classify cells in Pap smear images into five\ncategories: superficial-intermediate, parabasal, koilocytes, dyskeratotic, and\nmetaplastic. Various machine learning (ML) algorithms, including Gradient\nBoosting, Random Forest, Support Vector Machine, and k-Nearest Neighbor, as\nwell as deep learning (DL) approaches like ResNet-50, were employed for this\nclassification task. The ML models demonstrated high classification accuracy;\nhowever, ResNet-50 outperformed the others, achieving a classification accuracy\nof 93.06%. This study highlights the efficiency of DL models for cell-level\nclassification and their potential to aid in the early diagnosis of cervical\ncancer from Pap smear images.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-11-20",
      "downloaded_date": "2025-02-01",
      "filename": "Das-Comparative Analysis of Machine Learning and Deep Learning Models for Classifying Squamous Epithelia....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.13535v1",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "1904.02441v1": {
      "title": "Malware Detection using Machine Learning and Deep Learning",
      "authors": [
        "Hemant Rathore",
        "Swati Agarwal",
        "Sanjay K. Sahay",
        "Mohit Sewak"
      ],
      "abstract": "Research shows that over the last decade, malware has been growing\nexponentially, causing substantial financial losses to various organizations.\nDifferent anti-malware companies have been proposing solutions to defend\nattacks from these malware. The velocity, volume, and the complexity of malware\nare posing new challenges to the anti-malware community. Current\nstate-of-the-art research shows that recently, researchers and anti-virus\norganizations started applying machine learning and deep learning methods for\nmalware analysis and detection. We have used opcode frequency as a feature\nvector and applied unsupervised learning in addition to supervised learning for\nmalware classification. The focus of this tutorial is to present our work on\ndetecting malware with 1) various machine learning algorithms and 2) deep\nlearning models. Our results show that the Random Forest outperforms Deep\nNeural Network with opcode frequency as a feature. Also in feature reduction,\nDeep Auto-Encoders are overkill for the dataset, and elementary function like\nVariance Threshold perform better than others. In addition to the proposed\nmethodologies, we will also discuss the additional issues and the unique\nchallenges in the domain, open research problems, limitations, and future\ndirections.",
      "citation_count": 80,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8d89d98a0048f432a3b15f4f135feff4cd87942a",
      "published_date": "2019-04-04",
      "downloaded_date": "2025-02-01",
      "filename": "Rathore-Malware Detection using Machine Learning and Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1904.02441v1",
      "categories": [
        "cs.CR",
        "cs.LG"
      ]
    },
    "2001.06545v3": {
      "title": "Machine learning and AI-based approaches for bioactive ligand discovery and GPCR-ligand recognition",
      "authors": [
        "Sebastian Raschka",
        "Benjamin Kaufman"
      ],
      "abstract": "In the last decade, machine learning and artificial intelligence applications\nhave received a significant boost in performance and attention in both academic\nresearch and industry. The success behind most of the recent state-of-the-art\nmethods can be attributed to the latest developments in deep learning. When\napplied to various scientific domains that are concerned with the processing of\nnon-tabular data, for example, image or text, deep learning has been shown to\noutperform not only conventional machine learning but also highly specialized\ntools developed by domain experts. This review aims to summarize AI-based\nresearch for GPCR bioactive ligand discovery with a particular focus on the\nmost recent achievements and research trends. To make this article accessible\nto a broad audience of computational scientists, we provide instructive\nexplanations of the underlying methodology, including overviews of the most\ncommonly used deep learning architectures and feature representations of\nmolecular data. We highlight the latest AI-based research that has led to the\nsuccessful discovery of GPCR bioactive ligands. However, an equal focus of this\nreview is on the discussion of machine learning-based technology that has been\napplied to ligand discovery in general and has the potential to pave the way\nfor successful GPCR bioactive ligand discovery in the future. This review\nconcludes with a brief outlook highlighting the recent research trends in deep\nlearning, such as active learning and semi-supervised learning, which have\ngreat potential for advancing bioactive ligand discovery.",
      "citation_count": 60,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/87c80904579108e9ebecf05d78e83497e78030a1",
      "published_date": "2020-01-17",
      "downloaded_date": "2025-02-01",
      "filename": "Raschka-Machine learning and AI-based approaches for bioactive ligand discovery and GPCR-ligand recognition.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2001.06545v3",
      "categories": [
        "q-bio.BM",
        "cs.LG"
      ]
    },
    "2412.01393v1": {
      "title": "Machine Learning Analysis of Anomalous Diffusion",
      "authors": [
        "Wenjie Cai",
        "Yi Hu",
        "Xiang Qu",
        "Hui Zhao",
        "Gongyi Wang",
        "Jing Li",
        "Zihan Huang"
      ],
      "abstract": "The rapid advancements in machine learning have made its application to\nanomalous diffusion analysis both essential and inevitable. This review\nsystematically introduces the integration of machine learning techniques for\nenhanced analysis of anomalous diffusion, focusing on two pivotal aspects:\nsingle trajectory characterization via machine learning and representation\nlearning of anomalous diffusion. We extensively compare various machine\nlearning methods, including both classical machine learning and deep learning,\nused for the inference of diffusion parameters and trajectory segmentation.\nAdditionally, platforms such as the Anomalous Diffusion Challenge that serve as\nbenchmarks for evaluating these methods are highlighted. On the other hand, we\noutline three primary strategies for representing anomalous diffusion: the\ncombination of predefined features, the feature vector from the penultimate\nlayer of neural network, and the latent representation from the autoencoder,\nanalyzing their applicability across various scenarios. This investigation\npaves the way for future research, offering valuable perspectives that can\nfurther enrich the study of anomalous diffusion and advance the application of\nartificial intelligence in statistical physics and biophysics.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/18b9df5f7f2b6c5cd065a1887fe163025b69bd1e",
      "published_date": "2024-12-02",
      "downloaded_date": "2025-02-01",
      "filename": "Cai-Machine Learning Analysis of Anomalous Diffusion.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.01393v1",
      "categories": [
        "cs.LG",
        "cond-mat.soft",
        "physics.bio-ph",
        "physics.data-an"
      ]
    },
    "2211.07643v2": {
      "title": "Secure and Privacy-Preserving Automated Machine Learning Operations into End-to-End Integrated IoT-Edge-Artificial Intelligence-Blockchain Monitoring System for Diabetes Mellitus Prediction",
      "authors": [
        "Alain Hennebelle",
        "Leila Ismail",
        "Huned Materwala",
        "Juma Al Kaabi",
        "Priya Ranjan",
        "Rajiv Janardhanan"
      ],
      "abstract": "Diabetes Mellitus, one of the leading causes of death worldwide, has no cure\nto date and can lead to severe health complications, such as retinopathy, limb\namputation, cardiovascular diseases, and neuronal disease, if left untreated.\nConsequently, it becomes crucial to take precautionary measures to\navoid/predict the occurrence of diabetes. Machine learning approaches have been\nproposed and evaluated in the literature for diabetes prediction. This paper\nproposes an IoT-edge-Artificial Intelligence (AI)-blockchain system for\ndiabetes prediction based on risk factors. The proposed system is underpinned\nby the blockchain to obtain a cohesive view of the risk factors data from\npatients across different hospitals and to ensure security and privacy of the\nuser's data. Furthermore, we provide a comparative analysis of different\nmedical sensors, devices, and methods to measure and collect the risk factors\nvalues in the system. Numerical experiments and comparative analysis were\ncarried out between our proposed system, using the most accurate random forest\n(RF) model, and the two most used state-of-the-art machine learning approaches,\nLogistic Regression (LR) and Support Vector Machine (SVM), using three\nreal-life diabetes datasets. The results show that the proposed system using RF\npredicts diabetes with 4.57% more accuracy on average compared to LR and SVM,\nwith 2.87 times more execution time. Data balancing without feature selection\ndoes not show significant improvement. The performance is improved by 1.14% and\n0.02% after feature selection for PIMA Indian and Sylhet datasets respectively,\nwhile it reduces by 0.89% for MIMIC III.",
      "citation_count": 18,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/471585ba2f2dd62e2d7fa2c7f777f994615949c9",
      "published_date": "2022-11-13",
      "downloaded_date": "2025-02-01",
      "filename": "Hennebelle-Secure and Privacy-Preserving Automated Machine Learning Operations into End-to-End Integrated IoT-E....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.07643v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2101.08635v1": {
      "title": "Neural Networks, Artificial Intelligence and the Computational Brain",
      "authors": [
        "Martin C. Nwadiugwu"
      ],
      "abstract": "In recent years, several studies have provided insight on the functioning of\nthe brain which consists of neurons and form networks via interconnection among\nthem by synapses. Neural networks are formed by interconnected systems of\nneurons, and are of two types, namely, the Artificial Neural Network (ANNs) and\nBiological Neural Network (interconnected nerve cells). The ANNs are\ncomputationally influenced by human neurons and are used in modelling neural\nsystems. The reasoning foundations of ANNs have been useful in anomaly\ndetection, in areas of medicine such as instant physician, electronic noses,\npattern recognition, and modelling biological systems. Advancing research in\nartificial intelligence using the architecture of the human brain seeks to\nmodel systems by studying the brain rather than looking to technology for brain\nmodels. This study explores the concept of ANNs as a simulator of the\nbiological neuron, and its area of applications. It also explores why\nbrain-like intelligence is needed and how it differs from computational\nframework by comparing neural networks to contemporary computers and their\nmodern day implementation.",
      "citation_count": 15,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f8ae5647baf0f529d157e260d0f1176a5c7618fe",
      "published_date": "2020-12-25",
      "downloaded_date": "2025-02-01",
      "filename": "Nwadiugwu-Neural Networks Artificial Intelligence and the Computational Brain.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.08635v1",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ]
    },
    "2311.10745v1": {
      "title": "\"Just a little bit on the outside for the whole time\": Social belonging confidence and the persistence of Machine Learning and Artificial Intelligence students",
      "authors": [
        "Katherine Mao",
        "Sharon Ferguson",
        "James Magarian",
        "Alison Olechowski"
      ],
      "abstract": "The growing field of machine learning (ML) and artificial intelligence (AI)\npresents a unique and unexplored case within persistence research, meaning it\nis unclear how past findings from engineering will apply to this developing\nfield. We conduct an exploratory study to gain an initial understanding of\npersistence in this field and identify fruitful directions for future work. One\nfactor that has been shown to predict persistence in engineering is belonging;\nwe study belonging through the lens of confidence, and discuss how attention to\nsocial belonging confidence may help to increase diversity in the profession.\nIn this research paper, we conduct a small set of interviews with students in\nML/AI courses. Thematic analysis of these interviews revealed initial\ndifferences in how students see a career in ML/AI, which diverge based on\ninterest and programming confidence. We identified how exposure and initiation,\nthe interpretation of ML and AI field boundaries, and beliefs of the skills\nrequired to succeed might influence students' intentions to persist. We discuss\ndifferences in how students describe being motivated by social belonging and\nthe importance of close mentorship. We motivate further persistence research in\nML/AI with particular focus on social belonging and close mentorship, the role\nof intersectional identity, and introductory ML/AI courses.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0f4f0212605d72deb49e535e9110edefc031b756",
      "published_date": "2023-10-30",
      "downloaded_date": "2025-02-01",
      "filename": "Mao-Just a little bit on the outside for the whole time Social belonging confidence and the persistence ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.10745v1",
      "categories": [
        "cs.CY",
        "cs.OH"
      ]
    },
    "2310.11293v5": {
      "title": "On the use of artificial intelligence in financial regulations and the impact on financial stability",
      "authors": [
        "Jon Danielsson",
        "Andreas Uthemann"
      ],
      "abstract": "Artificial intelligence (AI) can undermine financial stability because of\nmalicious use, misinformation, misalignment, and the AI analytics market\nstructure. The low frequency and uniqueness of financial crises, coupled with\nmutable and unclear objectives, frustrate machine learning. Even if the\nauthorities prefer a conservative approach to AI adoption, it will likely\nbecome widely used by stealth, taking over increasingly high-level functions\ndriven by significant cost efficiencies and superior performance. We propose\nsix criteria for judging the suitability of AI.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/59669c37371f0202a8cdd60020454bf655bf7aad",
      "published_date": "2023-10-17",
      "downloaded_date": "2025-02-01",
      "filename": "Danielsson-On the use of artificial intelligence in financial regulations and the impact on financial stability.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.11293v5",
      "categories": [
        "econ.GN",
        "q-fin.EC",
        "q-fin.RM"
      ]
    },
    "1811.03402v2": {
      "title": "A Survey on Data Collection for Machine Learning: a Big Data -- AI Integration Perspective",
      "authors": [
        "Yuji Roh",
        "Geon Heo",
        "Steven Euijong Whang"
      ],
      "abstract": "Data collection is a major bottleneck in machine learning and an active\nresearch topic in multiple communities. There are largely two reasons data\ncollection has recently become a critical issue. First, as machine learning is\nbecoming more widely-used, we are seeing new applications that do not\nnecessarily have enough labeled data. Second, unlike traditional machine\nlearning, deep learning techniques automatically generate features, which saves\nfeature engineering costs, but in return may require larger amounts of labeled\ndata. Interestingly, recent research in data collection comes not only from the\nmachine learning, natural language, and computer vision communities, but also\nfrom the data management community due to the importance of handling large\namounts of data. In this survey, we perform a comprehensive study of data\ncollection from a data management point of view. Data collection largely\nconsists of data acquisition, data labeling, and improvement of existing data\nor models. We provide a research landscape of these operations, provide\nguidelines on which technique to use when, and identify interesting research\nchallenges. The integration of machine learning and data management for data\ncollection is part of a larger trend of Big data and Artificial Intelligence\n(AI) integration and opens many opportunities for new research.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-11-08",
      "downloaded_date": "2025-02-01",
      "filename": "Roh-A Survey on Data Collection for Machine Learning a Big Data -- AI Integration Perspective.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1811.03402v2",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2212.11910v1": {
      "title": "Realizing Molecular Machine Learning through Communications for Biological AI: Future Directions and Challenges",
      "authors": [
        "Sasitharan Balasubramaniam",
        "Samitha Somathilaka",
        "Sehee Sun",
        "Adrian Ratwatte",
        "Massimiliano Pierobon"
      ],
      "abstract": "Artificial Intelligence (AI) and Machine Learning (ML) are weaving their way\ninto the fabric of society, where they are playing a crucial role in numerous\nfacets of our lives. As we witness the increased deployment of AI and ML in\nvarious types of devices, we benefit from their use into energy-efficient\nalgorithms for low powered devices. In this paper, we investigate a scale and\nmedium that is far smaller than conventional devices as we move towards\nmolecular systems that can be utilized to perform machine learning functions,\ni.e., Molecular Machine Learning (MML). Fundamental to the operation of MML is\nthe transport, processing, and interpretation of information propagated by\nmolecules through chemical reactions. We begin by reviewing the current\napproaches that have been developed for MML, before we move towards potential\nnew directions that rely on gene regulatory networks inside biological\norganisms as well as their population interactions to create neural networks.\nWe then investigate mechanisms for training machine learning structures in\nbiological cells based on calcium signaling and demonstrate their application\nto build an Analog to Digital Converter (ADC). Lastly, we look at potential\nfuture directions as well as challenges that this area could solve.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-12-22",
      "downloaded_date": "2025-02-01",
      "filename": "Balasubramaniam-Realizing Molecular Machine Learning through Communications for Biological AI Future Directions and ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.11910v1",
      "categories": [
        "cs.ET",
        "cs.LG"
      ]
    },
    "2407.12445v1": {
      "title": "A Comprehensive Sustainable Framework for Machine Learning and Artificial Intelligence",
      "authors": [
        "Roberto Pagliari",
        "Peter Hill",
        "Po-Yu Chen",
        "Maciej Dabrowny",
        "Tingsheng Tan",
        "Francois Buet-Golfouse"
      ],
      "abstract": "In financial applications, regulations or best practices often lead to\nspecific requirements in machine learning relating to four key pillars:\nfairness, privacy, interpretability and greenhouse gas emissions. These all sit\nin the broader context of sustainability in AI, an emerging practical AI topic.\nHowever, although these pillars have been individually addressed by past\nliterature, none of these works have considered all the pillars. There are\ninherent trade-offs between each of the pillars (for example, accuracy vs\nfairness or accuracy vs privacy), making it even more important to consider\nthem together. This paper outlines a new framework for Sustainable Machine\nLearning and proposes FPIG, a general AI pipeline that allows for these\ncritical topics to be considered simultaneously to learn the trade-offs between\nthe pillars better. Based on the FPIG framework, we propose a meta-learning\nalgorithm to estimate the four key pillars given a dataset summary, model\narchitecture, and hyperparameters before model training. This algorithm allows\nusers to select the optimal model architecture for a given dataset and a given\nset of user requirements on the pillars. We illustrate the trade-offs under the\nFPIG model on three classical datasets and demonstrate the meta-learning\napproach with an example of real-world datasets and models with different\ninterpretability, showcasing how it can aid model selection.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7e5f9b882ee852d98bb4019fbc025c0250647f4a",
      "published_date": "2024-07-17",
      "downloaded_date": "2025-02-01",
      "filename": "Pagliari-A Comprehensive Sustainable Framework for Machine Learning and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.12445v1",
      "categories": [
        "cs.LG",
        "cs.CY",
        "I.2.0"
      ]
    },
    "1902.06714v2": {
      "title": "A parallel Fortran framework for neural networks and deep learning",
      "authors": [
        "Milan Curcic"
      ],
      "abstract": "This paper describes neural-fortran, a parallel Fortran framework for neural\nnetworks and deep learning. It features a simple interface to construct\nfeed-forward neural networks of arbitrary structure and size, several\nactivation functions, and stochastic gradient descent as the default\noptimization algorithm. Neural-fortran also leverages the Fortran 2018 standard\ncollective subroutines to achieve data-based parallelism on shared- or\ndistributed-memory machines. First, I describe the implementation of neural\nnetworks with Fortran derived types, whole-array arithmetic, and collective sum\nand broadcast operations to achieve parallelism. Second, I demonstrate the use\nof neural-fortran in an example of recognizing hand-written digits from images.\nFinally, I evaluate the computational performance in both serial and parallel\nmodes. Ease of use and computational performance are similar to an existing\npopular machine learning framework, making neural-fortran a viable candidate\nfor further development and use in production.",
      "citation_count": 28,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ed5d4e3317115edf9aa15f0ba7bb3e06b43caaab",
      "published_date": "2019-02-18",
      "downloaded_date": "2025-02-01",
      "filename": "Curcic-A parallel Fortran framework for neural networks and deep learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1902.06714v2",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2105.00157v1": {
      "title": "A Deep Learning Framework for Lifelong Machine Learning",
      "authors": [
        "Charles X. Ling",
        "Tanner Bohn"
      ],
      "abstract": "Humans can learn a variety of concepts and skills incrementally over the\ncourse of their lives while exhibiting many desirable properties, such as\ncontinual learning without forgetting, forward transfer and backward transfer\nof knowledge, and learning a new concept or task with only a few examples.\nSeveral lines of machine learning research, such as lifelong machine learning,\nfew-shot learning, and transfer learning attempt to capture these properties.\nHowever, most previous approaches can only demonstrate subsets of these\nproperties, often by different complex mechanisms. In this work, we propose a\nsimple yet powerful unified deep learning framework that supports almost all of\nthese properties and approaches through one central mechanism. Experiments on\ntoy examples support our claims. We also draw connections between many\npeculiarities of human learning (such as memory loss and \"rain man\") and our\nframework.\n  As academics, we often lack resources required to build and train, deep\nneural networks with billions of parameters on hundreds of TPUs. Thus, while\nour framework is still conceptual, and our experiment results are surely not\nSOTA, we hope that this unified lifelong learning framework inspires new work\ntowards large-scale experiments and understanding human learning in general.\n  This paper is summarized in two short YouTube videos:\nhttps://youtu.be/gCuUyGETbTU (part 1) and https://youtu.be/XsaGI01b-1o (part\n2).",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a47fe34a90f66819039abcf58be944447460e744",
      "published_date": "2021-05-01",
      "downloaded_date": "2025-02-01",
      "filename": "Ling-A Deep Learning Framework for Lifelong Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.00157v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2407.17048v1": {
      "title": "Artificial intelligence and financial crises",
      "authors": [
        "Jon Danielsson",
        "Andreas Uthemann"
      ],
      "abstract": "The rapid adoption of artificial intelligence (AI) is transforming the\nfinancial industry. AI will either increase systemic financial risk or act to\nstabilise the system, depending on endogenous responses, strategic\ncomplementarities, the severity of events it faces and the objectives it is\ngiven. AI's ability to master complexity and respond rapidly to shocks means\nfuture crises will likely be more intense than those we have seen so far.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d1e51e3c8e7f86cb067479ffbe52a8bc0646acf4",
      "published_date": "2024-07-24",
      "downloaded_date": "2025-02-01",
      "filename": "Danielsson-Artificial intelligence and financial crises.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.17048v1",
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ]
    },
    "2209.11618v2": {
      "title": "Artificial Intelligence and Advanced Materials",
      "authors": [
        "Cefe LÃ³pez"
      ],
      "abstract": "Artificial intelligence is gaining strength and materials science can both\ncontribute to and profit from it. In a simultaneous progress race, new\nmaterials, systems and processes can be devised and optimized thanks to machine\nlearning techniques and such progress can be turned into in-novative computing\nplatforms. Future materials scientists will profit from understanding how\nmachine learning can boost the conception of advanced materials. This review\ncovers aspects of computation from the fundamentals to directions taken and\nrepercussions produced by compu-tation to account for the origins, procedures\nand applications of artificial intelligence. Machine learning and its methods\nare reviewed to provide basic knowledge on its implementation and its\npotential. The materials and systems used to implement artificial intelligence\nwith electric charges are finding serious competition from other information\ncarrying and processing agents. The impact these techniques are having on the\ninception of new advanced materials is so deep that a new paradigm is\ndeveloping where implicit knowledge is being mined to conceive materi-als and\nsystems for functions instead of finding applications to found materials. How\nfar this trend can be carried is hard to fathom as exemplified by the power to\ndiscover unheard of mate-rials or physical laws buried in data.",
      "citation_count": 32,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0fab7358eee320405f119bb9fa62f33eb5126aec",
      "published_date": "2022-09-23",
      "downloaded_date": "2025-02-01",
      "filename": "LÃ³pez-Artificial Intelligence and Advanced Materials.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.11618v2",
      "categories": [
        "cond-mat.mtrl-sci"
      ]
    },
    "2303.01679v2": {
      "title": "Automated Machine Learning for Deep Learning based Malware Detection",
      "authors": [
        "Austin Brown",
        "Maanak Gupta",
        "Mahmoud Abdelsalam"
      ],
      "abstract": "Deep learning (DL) has proven to be effective in detecting sophisticated\nmalware that is constantly evolving. Even though deep learning has alleviated\nthe feature engineering problem, finding the most optimal DL model, in terms of\nneural architecture search (NAS) and the model's optimal set of\nhyper-parameters, remains a challenge that requires domain expertise. In\naddition, many of the proposed state-of-the-art models are very complex and may\nnot be the best fit for different datasets. A promising approach, known as\nAutomated Machine Learning (AutoML), can reduce the domain expertise required\nto implement a custom DL model. AutoML reduces the amount of human\ntrial-and-error involved in designing DL models, and in more recent\nimplementations can find new model architectures with relatively low\ncomputational overhead.\n  This work provides a comprehensive analysis and insights on using AutoML for\nstatic and online malware detection. For static, our analysis is performed on\ntwo widely used malware datasets: SOREL-20M to demonstrate efficacy on large\ndatasets; and EMBER-2018, a smaller dataset specifically curated to hinder the\nperformance of machine learning models. In addition, we show the effects of\ntuning the NAS process parameters on finding a more optimal malware detection\nmodel on these static analysis datasets. Further, we also demonstrate that\nAutoML is performant in online malware detection scenarios using Convolutional\nNeural Networks (CNNs) for cloud IaaS. We compare an AutoML technique to six\nexisting state-of-the-art CNNs using a newly generated online malware dataset\nwith and without other applications running in the background during malware\nexecution.In general, our experimental results show that the performance of\nAutoML based static and online malware detection models are on par or even\nbetter than state-of-the-art models or hand-designed models presented in\nliterature.",
      "citation_count": 25,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b91bc8dd2fde57bb036a7f0f60dffeaffbf36044",
      "published_date": "2023-03-03",
      "downloaded_date": "2025-02-01",
      "filename": "Brown-Automated Machine Learning for Deep Learning based Malware Detection.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.01679v2",
      "categories": [
        "cs.CR"
      ]
    },
    "2102.03879v2": {
      "title": "Quantum computing models for artificial neural networks",
      "authors": [
        "Stefano Mangini",
        "Francesco Tacchino",
        "Dario Gerace",
        "Daniele Bajoni",
        "Chiara Macchiavello"
      ],
      "abstract": "Neural networks are computing models that have been leading progress in\nMachine Learning (ML) and Artificial Intelligence (AI) applications. In\nparallel, the first small scale quantum computing devices have become available\nin recent years, paving the way for the development of a new paradigm in\ninformation processing. Here we give an overview of the most recent proposals\naimed at bringing together these ongoing revolutions, and particularly at\nimplementing the key functionalities of artificial neural networks on quantum\narchitectures. We highlight the exciting perspectives in this context and\ndiscuss the potential role of near term quantum hardware in the quest for\nquantum machine learning advantage.",
      "citation_count": 81,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ec7f5dc077480df149bcd4358a3aa8441878ca59",
      "published_date": "2021-02-07",
      "downloaded_date": "2025-02-01",
      "filename": "Mangini-Quantum computing models for artificial neural networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.03879v2",
      "categories": [
        "quant-ph"
      ]
    },
    "1806.00148v1": {
      "title": "Interpreting Deep Learning: The Machine Learning Rorschach Test?",
      "authors": [
        "Adam S. Charles"
      ],
      "abstract": "Theoretical understanding of deep learning is one of the most important tasks\nfacing the statistics and machine learning communities. While deep neural\nnetworks (DNNs) originated as engineering methods and models of biological\nnetworks in neuroscience and psychology, they have quickly become a centerpiece\nof the machine learning toolbox. Unfortunately, DNN adoption powered by recent\nsuccesses combined with the open-source nature of the machine learning\ncommunity, has outpaced our theoretical understanding. We cannot reliably\nidentify when and why DNNs will make mistakes. In some applications like text\ntranslation these mistakes may be comical and provide for fun fodder in\nresearch talks, a single error can be very costly in tasks like medical\nimaging. As we utilize DNNs in increasingly sensitive applications, a better\nunderstanding of their properties is thus imperative. Recent advances in DNN\ntheory are numerous and include many different sources of intuition, such as\nlearning theory, sparse signal analysis, physics, chemistry, and psychology. An\ninteresting pattern begins to emerge in the breadth of possible\ninterpretations. The seemingly limitless approaches are mostly constrained by\nthe lens with which the mathematical operations are viewed. Ultimately, the\ninterpretation of DNNs appears to mimic a type of Rorschach test --- a\npsychological test wherein subjects interpret a series of seemingly ambiguous\nink-blots. Validation for DNN theory requires a convergence of the literature.\nWe must distinguish between universal results that are invariant to the\nanalysis perspective and those that are specific to a particular network\nconfiguration. Simultaneously we must deal with the fact that many standard\nstatistical tools for quantifying generalization or empirically assessing\nimportant network features are difficult to apply to DNNs.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b7488a0ac799a2c62882a5b40f4ea4b1c88f04c4",
      "published_date": "2018-06-01",
      "downloaded_date": "2025-02-01",
      "filename": "Charles-Interpreting Deep Learning The Machine Learning Rorschach Test.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1806.00148v1",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    "2012.03184v1": {
      "title": "dPOLY: Deep Learning of Polymer Phases and Phase Transition",
      "authors": [
        "Debjyoti Bhattacharya",
        "Tarak K Patra"
      ],
      "abstract": "Machine learning (ML) and artificial intelligence (AI) have the remarkable\nability to classify, recognize, and characterize complex patterns and trends in\nlarge data sets. Here, we adopt a subclass of machine learning methods viz.,\ndeep learnings and develop a general-purpose AI tool - dPOLY for analyzing\nmolecular dynamics trajectory and predicting phases and phase transitions in\npolymers. An unsupervised deep neural network is used within this framework to\nmap a molecular dynamics trajectory undergoing thermophysical treatment such as\ncooling, heating, drying, or compression to a lower dimension. A supervised\ndeep neural network is subsequently developed based on the lower dimensional\ndata to characterize the phases and phase transition. As a proof of concept, we\nemploy this framework to study coil to globule transition of a model polymer\nsystem. We conduct coarse-grained molecular dynamics simulations to collect\nmolecular dynamics trajectories of a single polymer chain over a wide range of\ntemperatures and use dPOLY framework to predict polymer phases. The dPOLY\nframework accurately predicts the critical temperatures for the coil to globule\ntransition for a wide range of polymer sizes. This method is generic and can be\nextended to capture various other phase transitions and dynamical crossovers in\npolymers and other soft materials.",
      "citation_count": 26,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3e570c8a2bde7f3e7f826e191d1c3c2c2166a275",
      "published_date": "2020-12-06",
      "downloaded_date": "2025-02-01",
      "filename": "Bhattacharya-dPOLY Deep Learning of Polymer Phases and Phase Transition.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.03184v1",
      "categories": [
        "cond-mat.soft",
        "cond-mat.mtrl-sci"
      ]
    },
    "1810.08653v1": {
      "title": "Deep Learning with the Random Neural Network and its Applications",
      "authors": [
        "Yonghua Yin"
      ],
      "abstract": "The random neural network (RNN) is a mathematical model for an \"integrate and\nfire\" spiking network that closely resembles the stochastic behaviour of\nneurons in mammalian brains. Since its proposal in 1989, there have been\nnumerous investigations into the RNN's applications and learning algorithms.\nDeep learning (DL) has achieved great success in machine learning. Recently,\nthe properties of the RNN for DL have been investigated, in order to combine\ntheir power. Recent results demonstrate that the gap between RNNs and DL can be\nbridged and the DL tools based on the RNN are faster and can potentially be\nused with less energy expenditure than existing methods.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/05e11636f521f463476b0cb4d47b048d41bba5b7",
      "published_date": "2018-10-08",
      "downloaded_date": "2025-02-01",
      "filename": "Yin-Deep Learning with the Random Neural Network and its Applications.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1810.08653v1",
      "categories": [
        "cs.NE",
        "cs.LG"
      ]
    },
    "1701.07769v1": {
      "title": "Ethical Considerations in Artificial Intelligence Courses",
      "authors": [
        "Emanuelle Burton",
        "Judy Goldsmith",
        "Sven Koenig",
        "Benjamin Kuipers",
        "Nicholas Mattei",
        "Toby Walsh"
      ],
      "abstract": "The recent surge in interest in ethics in artificial intelligence may leave\nmany educators wondering how to address moral, ethical, and philosophical\nissues in their AI courses. As instructors we want to develop curriculum that\nnot only prepares students to be artificial intelligence practitioners, but\nalso to understand the moral, ethical, and philosophical impacts that\nartificial intelligence will have on society. In this article we provide\npractical case studies and links to resources for use by AI educators. We also\nprovide concrete suggestions on how to integrate AI ethics into a general\nartificial intelligence course and how to teach a stand-alone artificial\nintelligence ethics course.",
      "citation_count": 120,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/57026b2d45fa59c6326b5a1d2e27626403f083ba",
      "published_date": "2017-01-26",
      "downloaded_date": "2025-02-01",
      "filename": "Burton-Ethical Considerations in Artificial Intelligence Courses.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1701.07769v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.GL",
        "K.3.2; K.4.1; K.7.m"
      ]
    },
    "2405.14556v1": {
      "title": "Deep Learning Classification of Photoplethysmogram Signal for Hypertension Levels",
      "authors": [
        "Nida Nasir",
        "Mustafa Sameer",
        "Feras Barneih",
        "Omar Alshaltone",
        "Muneeb Ahmed"
      ],
      "abstract": "Continuous photoplethysmography (PPG)-based blood pressure monitoring is\nnecessary for healthcare and fitness applications. In Artificial Intelligence\n(AI), signal classification levels with the machine and deep learning\narrangements need to be explored further. Techniques based on time-frequency\nspectra, such as Short-time Fourier Transform (STFT), have been used to address\nthe challenges of motion artifact correction. Therefore, the proposed study\nworks with PPG signals of more than 200 patients (650+ signal samples) with\nhypertension, using STFT with various Neural Networks (Convolution Neural\nNetwork (CNN), Long Short-Term Memory (LSTM), Bidirectional Long Short-Term\nMemory (Bi-LSTM), followed by machine learning classifiers, such as, Support\nVector Machine (SVM) and Random Forest (RF). The classification has been done\nfor two categories: Prehypertension (normal levels) and Hypertension (includes\nStage I and Stage II). Various performance metrics have been obtained with two\nbatch sizes of 3 and 16 for the fusion of the neural networks. With precision\nand specificity of 100% and recall of 82.1%, the LSTM model provides the best\nresults among all combinations of Neural Networks. However, the maximum\naccuracy of 71.9% is achieved by the LSTM-CNN model. Further stacked Ensemble\nmethod has been used to achieve 100% accuracy for Meta-LSTM-RF, Meta-\nLSTM-CNN-RF and Meta- STFT-CNN-SVM.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/58d67d68275b7aa7fa783f540dcbd6ad50b8c427",
      "published_date": "2024-05-23",
      "downloaded_date": "2025-02-01",
      "filename": "Nasir-Deep Learning Classification of Photoplethysmogram Signal for Hypertension Levels.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.14556v1",
      "categories": [
        "cs.CV",
        "cs.MM"
      ]
    },
    "2210.17331v1": {
      "title": "Trends in Energy Estimates for Computing in AI/Machine Learning Accelerators, Supercomputers, and Compute-Intensive Applications",
      "authors": [
        "Sadasivan Shankar",
        "Albert Reuther"
      ],
      "abstract": "We examine the computational energy requirements of different systems driven\nby the geometrical scaling law, and increasing use of Artificial Intelligence\nor Machine Learning (AI-ML) over the last decade. With more scientific and\ntechnology applications based on data-driven discovery, machine learning\nmethods, especially deep neural networks, have become widely used. In order to\nenable such applications, both hardware accelerators and advanced AI-ML methods\nhave led to the introduction of new architectures, system designs, algorithms,\nand software. Our analysis of energy trends indicates three important\nobservations: 1) Energy efficiency due to geometrical scaling is slowing down;\n2) The energy efficiency at the bit-level does not translate into efficiency at\nthe instruction-level, or at the system-level for a variety of systems,\nespecially for large-scale AI-ML accelerators or supercomputers; 3) At the\napplication level, general-purpose AI-ML methods can be computationally energy\nintensive, off-setting the gains in energy from geometrical scaling and special\npurpose accelerators. Further, our analysis provides specific pointers for\nintegrating energy efficiency with performance analysis for enabling\nhigh-performance and sustainable computing in the future.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cf7a41fedd0dfe0bb016c67e53317a5130c45d2a",
      "published_date": "2022-10-12",
      "downloaded_date": "2025-02-01",
      "filename": "Shankar-Trends in Energy Estimates for Computing in AIMachine Learning Accelerators Supercomputers and Compu....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.17331v1",
      "categories": [
        "cs.AR",
        "cs.CY",
        "68U01",
        "C.4; I.2"
      ]
    },
    "2406.18620v1": {
      "title": "Documentation Practices of Artificial Intelligence",
      "authors": [
        "Stefan Arnold",
        "Dilara Yesilbas",
        "Rene GrÃ¶bner",
        "Dominik Riedelbauch",
        "Maik Horn",
        "Sven Weinzierl"
      ],
      "abstract": "Artificial Intelligence (AI) faces persistent challenges in terms of\ntransparency and accountability, which requires rigorous documentation. Through\na literature review on documentation practices, we provide an overview of\nprevailing trends, persistent issues, and the multifaceted interplay of factors\ninfluencing the documentation. Our examination of key characteristics such as\nscope, target audiences, support for multimodality, and level of automation,\nhighlights a dynamic evolution in documentation practices, underscored by a\nshift towards a more holistic, engaging, and automated documentation.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/de90a14eef69639444d902ffe96f8ea70b211d94",
      "published_date": "2024-06-26",
      "downloaded_date": "2025-02-01",
      "filename": "Arnold-Documentation Practices of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.18620v1",
      "categories": [
        "cs.DL",
        "cs.AI"
      ]
    },
    "1608.08196v1": {
      "title": "Smart Policies for Artificial Intelligence",
      "authors": [
        "Miles Brundage",
        "Joanna Bryson"
      ],
      "abstract": "We argue that there already exists de facto artificial intelligence policy -\na patchwork of policies impacting the field of AI's development in myriad ways.\nThe key question related to AI policy, then, is not whether AI should be\ngoverned at all, but how it is currently being governed, and how that\ngovernance might become more informed, integrated, effective, and anticipatory.\nWe describe the main components of de facto AI policy and make some\nrecommendations for how AI policy can be improved, drawing on lessons from\nother scientific and technological domains.",
      "citation_count": 25,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/937d6d4c34ad41edc6fb68e477cad23657b949e2",
      "published_date": "2016-08-29",
      "downloaded_date": "2025-02-01",
      "filename": "Brundage-Smart Policies for Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1608.08196v1",
      "categories": [
        "cs.CY"
      ]
    },
    "1801.07130v2": {
      "title": "Computational Protein Design with Deep Learning Neural Networks",
      "authors": [
        "Jingxue Wang",
        "Huali Cao",
        "John Z. H. Zhang",
        "Yifei Qi"
      ],
      "abstract": "Computational protein design has a wide variety of applications. Despite its\nremarkable success, designing a protein for a given structure and function is\nstill a challenging task. On the other hand, the number of solved protein\nstructures is rapidly increasing while the number of unique protein folds has\nreached a steady number, suggesting more structural information is being\naccumulated on each fold. Deep learning neural network is a powerful method to\nlearn such big data set and has shown superior performance in many machine\nlearning fields. In this study, we applied the deep learning neural network\napproach to computational protein design for predicting the probability of 20\nnatural amino acids on each residue in a protein. A large set of protein\nstructures was collected and a multi-layer neural network was constructed. A\nnumber of structural properties were extracted as input features and the best\nnetwork achieved an accuracy of 38.3%. Using the network output as residue type\nrestraints was able to improve the average sequence identity in designing three\nnatural proteins using Rosetta. Moreover, the predictions from our network show\n~3% higher sequence identity than a previous method. Results from this study\nmay benefit further development of computational protein design methods.",
      "citation_count": 155,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/04fba8bbe4bb874fa6f4541b7cb9d4736527f1b5",
      "published_date": "2018-01-22",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Computational Protein Design with Deep Learning Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1801.07130v2",
      "categories": [
        "q-bio.QM",
        "q-bio.BM"
      ]
    },
    "1911.10500v2": {
      "title": "Causality for Machine Learning",
      "authors": [
        "Bernhard SchÃ¶lkopf"
      ],
      "abstract": "Graphical causal inference as pioneered by Judea Pearl arose from research on\nartificial intelligence (AI), and for a long time had little connection to the\nfield of machine learning.\n  This article discusses where links have been and should be established,\nintroducing key concepts along the way. It argues that the hard open problems\nof machine learning and AI are intrinsically related to causality, and explains\nhow the field is beginning to understand them.",
      "citation_count": 430,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b5461f9c5d65e87561e00848921ee797902dae14",
      "published_date": "2019-11-24",
      "downloaded_date": "2025-02-01",
      "filename": "SchÃ¶lkopf-Causality for Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.10500v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "I.2, I.5, K.4",
        "I.2; I.5; K.4"
      ]
    },
    "1902.03271v1": {
      "title": "Does the \"Artificial Intelligence Clinician\" learn optimal treatment strategies for sepsis in intensive care?",
      "authors": [
        "Russell Jeter",
        "Christopher Josef",
        "Supreeth Shashikumar",
        "Shamim Nemati"
      ],
      "abstract": "From 2017 to 2018 the number of scientific publications found via PubMed\nsearch using the keyword \"Machine Learning\" increased by 46% (4,317 to 6,307).\nThe results of studies involving machine learning, artificial intelligence\n(AI), and big data have captured the attention of healthcare practitioners,\nhealthcare managers, and the public at a time when Western medicine grapples\nwith unmitigated cost increases and public demands for accountability. The\ncomplexity involved in healthcare applications of machine learning and the size\nof the associated data sets has afforded many researchers an uncontested\nopportunity to satisfy these demands with relatively little oversight. In a\nrecent Nature Medicine article, \"The Artificial Intelligence Clinician learns\noptimal treatment strategies for sepsis in intensive care,\" Komorowski and his\ncoauthors propose methods to train an artificial intelligence clinician to\ntreat sepsis patients with vasopressors and IV fluids. In this post, we will\nclosely examine the claims laid out in this paper. In particular, we will study\nthe individual treatment profiles suggested by their AI Clinician to gain\ninsight into how their AI Clinician intends to treat patients on an individual\nlevel.",
      "citation_count": 21,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f1bc4538748efa3dc79a9ad829b9779658fae20c",
      "published_date": "2019-02-08",
      "downloaded_date": "2025-02-01",
      "filename": "Jeter-Does the Artificial Intelligence Clinician learn optimal treatment strategies for sepsis in intensiv....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1902.03271v1",
      "categories": [
        "cs.AI",
        "stat.AP"
      ]
    },
    "2305.18303v2": {
      "title": "New Era of Artificial Intelligence in Education: Towards a Sustainable Multifaceted Revolution",
      "authors": [
        "Firuz Kamalov",
        "David Santandreu Calong",
        "Ikhlaas Gurrib"
      ],
      "abstract": "The recent high performance of ChatGPT on several standardized academic tests\nhas thrust the topic of artificial intelligence (AI) into the mainstream\nconversation about the future of education. As deep learning is poised to shift\nthe teaching paradigm, it is essential to have a clear understanding of its\neffects on the current education system to ensure sustainable development and\ndeployment of AI-driven technologies at schools and universities. This research\naims to investigate the potential impact of AI on education through review and\nanalysis of the existing literature across three major axes: applications,\nadvantages, and challenges. Our review focuses on the use of artificial\nintelligence in collaborative teacher--student learning, intelligent tutoring\nsystems, automated assessment, and personalized learning. We also report on the\npotential negative aspects, ethical issues, and possible future routes for AI\nimplementation in education. Ultimately, we find that the only way forward is\nto embrace the new technology, while implementing guardrails to prevent its\nabuse.",
      "citation_count": 231,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/eac11727ef9c7c29711cb1ba82ef6f011e8ad78d",
      "published_date": "2023-05-12",
      "downloaded_date": "2025-02-01",
      "filename": "Kamalov-New Era of Artificial Intelligence in Education Towards a Sustainable Multifaceted Revolution.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.18303v2",
      "categories": [
        "cs.CY"
      ]
    },
    "2402.01720v2": {
      "title": "Deep Learning Based Amharic Chatbot for FAQs in Universities",
      "authors": [
        "Goitom Ybrah Hailu",
        "Hadush Hailu",
        "Shishay Welay"
      ],
      "abstract": "University students often spend a considerable amount of time seeking answers\nto common questions from administrators or teachers. This can become tedious\nfor both parties, leading to a need for a solution. In response, this paper\nproposes a chatbot model that utilizes natural language processing and deep\nlearning techniques to answer frequently asked questions (FAQs) in the Amharic\nlanguage. Chatbots are computer programs that simulate human conversation\nthrough the use of artificial intelligence (AI), acting as a virtual assistant\nto handle questions and other tasks. The proposed chatbot program employs\ntokenization, normalization, stop word removal, and stemming to analyze and\ncategorize Amharic input sentences. Three machine learning model algorithms\nwere used to classify tokens and retrieve appropriate responses: Support Vector\nMachine (SVM), Multinomial Na\\\"ive Bayes, and deep neural networks implemented\nthrough TensorFlow, Keras, and NLTK. The deep learning model achieved the best\nresults with 91.55% accuracy and a validation loss of 0.3548 using an Adam\noptimizer and SoftMax activation function. The chatbot model was integrated\nwith Facebook Messenger and deployed on a Heroku server for 24-hour\naccessibility. The experimental results demonstrate that the chatbot framework\nachieved its objectives and effectively addressed challenges such as Amharic\nFidel variation, morphological variation, and lexical gaps. Future research\ncould explore the integration of Amharic WordNet to narrow the lexical gap and\nsupport more complex questions.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/77baa6e28915afb3c0cdc1ee15f0d5f38f377f71",
      "published_date": "2024-01-26",
      "downloaded_date": "2025-02-01",
      "filename": "Hailu-Deep Learning Based Amharic Chatbot for FAQs in Universities.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.01720v2",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    "2101.10450v1": {
      "title": "LAIF: AI, Deep Learning for Germany Suetterlin Letter Recognition and Generation",
      "authors": [
        "Enkhtogtokh Togootogtokh",
        "Christian Klasen"
      ],
      "abstract": "One of the successful early implementation of deep learning AI technology was\non letter recognition. With the recent breakthrough of artificial intelligence\n(AI) brings more solid technology for complex problems like handwritten letter\nrecognition and even automatic generation of them. In this research, we\nproposed deep learning framework called Ludwig AI Framework(LAIF) for Germany\nSuetterlin letter recognition and generation. To recognize Suetterlin letter,\nwe proposed deep convolutional neural network. Since lack of big amount of data\nto train for the deep models and huge cost to label existing hard copy of\nhandwritten letters, we also introduce the methodology with deep generative\nadversarial network to generate handwritten letters as synthetic data. Main\nsource code is in https://github.com/enkhtogtokh/LAIF repository.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cc7ae9cbb04379675305b5d212421eb32469a51b",
      "published_date": "2020-12-30",
      "downloaded_date": "2025-02-01",
      "filename": "Togootogtokh-LAIF AI Deep Learning for Germany Suetterlin Letter Recognition and Generation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.10450v1",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    "2406.11272v1": {
      "title": "Development of an Adaptive Multi-Domain Artificial Intelligence System Built using Machine Learning and Expert Systems Technologies",
      "authors": [
        "Jeremy Straub"
      ],
      "abstract": "Producing an artificial general intelligence (AGI) has been an elusive goal\nin artificial intelligence (AI) research for some time. An AGI would have the\ncapability, like a human, to be exposed to a new problem domain, learn about it\nand then use reasoning processes to make decisions. While AI techniques have\nbeen used across a wide variety of problem domains, an AGI would require an AI\nthat could reason beyond its programming and training. This paper presents a\nsmall step towards producing an AGI. It describes a mechanism for an AI to\nlearn about and develop reasoning pathways to make decisions in an a priori\nunknown domain. It combines a classical AI technique, the expert system, with a\nits modern adaptation - the gradient descent trained expert system (GDTES) -\nand utilizes generative artificial intelligence (GAI) to create a network and\ntraining data set for this system. These can be created from available sources\nor may draw upon knowledge incorporated in a GAI's own pre-trained model. The\nlearning process in GDTES is used to optimize the AI's decision-making. While\nthis approach does not meet the standards that many have defined for an AGI, it\nprovides a somewhat similar capability, albeit one which requires a learning\nprocess before use.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/095114885bee45678f2299dca4660cccf1bf52bc",
      "published_date": "2024-06-17",
      "downloaded_date": "2025-02-01",
      "filename": "Straub-Development of an Adaptive Multi-Domain Artificial Intelligence System Built using Machine Learning ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.11272v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1707.08476v1": {
      "title": "Guidelines for Artificial Intelligence Containment",
      "authors": [
        "James Babcock",
        "Janos Kramar",
        "Roman V. Yampolskiy"
      ],
      "abstract": "With almost daily improvements in capabilities of artificial intelligence it\nis more important than ever to develop safety software for use by the AI\nresearch community. Building on our previous work on AI Containment Problem we\npropose a number of guidelines which should help AI safety researchers to\ndevelop reliable sandboxing software for intelligent programs of all levels.\nSuch safety container software will make it possible to study and analyze\nintelligent artificial agent while maintaining certain level of safety against\ninformation leakage, social engineering attacks and cyberattacks from within\nthe container.",
      "citation_count": 29,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b0c820f9d7fa4d8c56a7887548834b7ba65ddfa5",
      "published_date": "2017-07-24",
      "downloaded_date": "2025-02-01",
      "filename": "Babcock-Guidelines for Artificial Intelligence Containment.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1707.08476v1",
      "categories": [
        "cs.AI",
        "cs.CR"
      ]
    },
    "1806.04915v1": {
      "title": "The IQ of Artificial Intelligence",
      "authors": [
        "Dimiter Dobrev"
      ],
      "abstract": "All it takes to identify the computer programs which are Artificial\nIntelligence is to give them a test and award AI to those that pass the test.\nLet us say that the scores they earn at the test will be called IQ. We cannot\npinpoint a minimum IQ threshold that a program has to cover in order to be AI,\nhowever, we will choose a certain value. Thus, our definition for AI will be\nany program the IQ of which is above the chosen value. While this idea has\nalready been implemented in [3], here we will revisit this construct in order\nto introduce certain improvements.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/baa57480187c3ca6f16f9abdbc2ad2507bb0a40f",
      "published_date": "2018-06-13",
      "downloaded_date": "2025-02-01",
      "filename": "Dobrev-The IQ of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1806.04915v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2107.03912v1": {
      "title": "Artificial intelligence across company borders",
      "authors": [
        "Olga Fink",
        "TorbjÃ¸rn Netland",
        "Stefan Feuerriegel"
      ],
      "abstract": "Artificial intelligence (AI) has become a valued technology in many\ncompanies. At the same time, a substantial potential for utilizing AI\n\\emph{across} company borders has remained largely untapped. An inhibiting\nfactor concerns disclosure of data to external parties, which raises legitimate\nconcerns about intellectual property rights, privacy issues, and cybersecurity\nrisks. Combining federated learning with domain adaptation can provide a\nsolution to this problem by enabling effective cross-company AI without data\ndisclosure. In this Viewpoint, we discuss the use, value, and implications of\nthis approach in a cross-company setting.",
      "citation_count": 12,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d9315587da49a562b252481013893db9340ff4c6",
      "published_date": "2021-06-21",
      "downloaded_date": "2025-02-01",
      "filename": "Fink-Artificial intelligence across company borders.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.03912v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2405.19522v1": {
      "title": "Artificial Intelligence Index Report 2024",
      "authors": [
        "Nestor Maslej",
        "Loredana Fattorini",
        "Raymond Perrault",
        "Vanessa Parli",
        "Anka Reuel",
        "Erik Brynjolfsson",
        "John Etchemendy",
        "Katrina Ligett",
        "Terah Lyons",
        "James Manyika",
        "Juan Carlos Niebles",
        "Yoav Shoham",
        "Russell Wald",
        "Jack Clark"
      ],
      "abstract": "The 2024 Index is our most comprehensive to date and arrives at an important\nmoment when AI's influence on society has never been more pronounced. This\nyear, we have broadened our scope to more extensively cover essential trends\nsuch as technical advancements in AI, public perceptions of the technology, and\nthe geopolitical dynamics surrounding its development. Featuring more original\ndata than ever before, this edition introduces new estimates on AI training\ncosts, detailed analyses of the responsible AI landscape, and an entirely new\nchapter dedicated to AI's impact on science and medicine. The AI Index report\ntracks, collates, distills, and visualizes data related to artificial\nintelligence (AI). Our mission is to provide unbiased, rigorously vetted,\nbroadly sourced data in order for policymakers, researchers, executives,\njournalists, and the general public to develop a more thorough and nuanced\nunderstanding of the complex field of AI. The AI Index is recognized globally\nas one of the most credible and authoritative sources for data and insights on\nartificial intelligence. Previous editions have been cited in major newspapers,\nincluding the The New York Times, Bloomberg, and The Guardian, have amassed\nhundreds of academic citations, and been referenced by high-level policymakers\nin the United States, the United Kingdom, and the European Union, among other\nplaces. This year's edition surpasses all previous ones in size, scale, and\nscope, reflecting the growing significance that AI is coming to hold in all of\nour lives.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-05-29",
      "downloaded_date": "2025-02-01",
      "filename": "Maslej-Artificial Intelligence Index Report 2024.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.19522v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1812.02948v1": {
      "title": "A Survey on Artificial Intelligence Trends in Spacecraft Guidance Dynamics and Control",
      "authors": [
        "Dario Izzo",
        "Marcus MÃ¤rtens",
        "Binfeng Pan"
      ],
      "abstract": "The rapid developments of Artificial Intelligence in the last decade are\ninfluencing Aerospace Engineering to a great extent and research in this\ncontext is proliferating. We share our observations on the recent developments\nin the area of Spacecraft Guidance Dynamics and Control, giving selected\nexamples on success stories that have been motivated by mission designs. Our\nfocus is on evolutionary optimisation, tree searches and machine learning,\nincluding deep learning and reinforcement learning as the key technologies and\ndrivers for current and future research in the field. From a high-level\nperspective, we survey various scenarios for which these approaches have been\nsuccessfully applied or are under strong scientific investigation. Whenever\npossible, we highlight the relations and synergies that can be obtained by\ncombining different techniques and projects towards future domains for which\nnewly emerging artificial intelligence techniques are expected to become game\nchangers.",
      "citation_count": 196,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b6a3b0b6956e496f726ffe945dc5cdae8718ba43",
      "published_date": "2018-12-07",
      "downloaded_date": "2025-02-01",
      "filename": "Izzo-A Survey on Artificial Intelligence Trends in Spacecraft Guidance Dynamics and Control.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1812.02948v1",
      "categories": [
        "cs.NE"
      ]
    },
    "2104.04599v1": {
      "title": "A review of artificial intelligence methods combined with Raman spectroscopy to identify the composition of substances",
      "authors": [
        "Liangrui Pan",
        "Peng Zhang",
        "Chalongrat Daengngam",
        "Mitchai Chongcheawchamnan"
      ],
      "abstract": "In general, most of the substances in nature exist in mixtures, and the\nnoninvasive identification of mixture composition with high speed and accuracy\nremains a difficult task. However, the development of Raman spectroscopy,\nmachine learning, and deep learning techniques have paved the way for achieving\nefficient analytical tools capable of identifying mixture components, making an\napparent breakthrough in the identification of mixtures beyond the traditional\nchemical analysis methods. This article summarizes the work of Raman\nspectroscopy in identifying the composition of substances as well as provides\ndetailed reviews on the preprocessing process of Raman spectroscopy, the\nanalysis methods and applications of artificial intelligence. This review\nsummarizes the work of Raman spectroscopy in identifying the composition of\nsubstances and reviews the preprocessing process of Raman spectroscopy, the\nanalysis methods and applications of artificial intelligence. Finally, the\nadvantages and disadvantages and development prospects of Raman spectroscopy\nare discussed in detail.",
      "citation_count": 46,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6c3d6461ecf4bf9f2783e544f8015d5a1e548812",
      "published_date": "2021-04-05",
      "downloaded_date": "2025-02-01",
      "filename": "Pan-A review of artificial intelligence methods combined with Raman spectroscopy to identify the composi....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.04599v1",
      "categories": [
        "eess.SP",
        "cs.LG",
        "physics.chem-ph"
      ]
    },
    "2004.14942v1": {
      "title": "Memristors -- from In-memory computing, Deep Learning Acceleration, Spiking Neural Networks, to the Future of Neuromorphic and Bio-inspired Computing",
      "authors": [
        "Adnan Mehonic",
        "Abu Sebastian",
        "Bipin Rajendran",
        "Osvaldo Simeone",
        "Eleni Vasilaki",
        "Anthony J. Kenyon"
      ],
      "abstract": "Machine learning, particularly in the form of deep learning, has driven most\nof the recent fundamental developments in artificial intelligence. Deep\nlearning is based on computational models that are, to a certain extent,\nbio-inspired, as they rely on networks of connected simple computing units\noperating in parallel. Deep learning has been successfully applied in areas\nsuch as object/pattern recognition, speech and natural language processing,\nself-driving vehicles, intelligent self-diagnostics tools, autonomous robots,\nknowledgeable personal assistants, and monitoring. These successes have been\nmostly supported by three factors: availability of vast amounts of data,\ncontinuous growth in computing power, and algorithmic innovations. The\napproaching demise of Moore's law, and the consequent expected modest\nimprovements in computing power that can be achieved by scaling, raise the\nquestion of whether the described progress will be slowed or halted due to\nhardware limitations. This paper reviews the case for a novel beyond CMOS\nhardware technology, memristors, as a potential solution for the implementation\nof power-efficient in-memory computing, deep learning accelerators, and spiking\nneural networks. Central themes are the reliance on non-von-Neumann computing\narchitectures and the need for developing tailored learning and inference\nalgorithms. To argue that lessons from biology can be useful in providing\ndirections for further progress in artificial intelligence, we briefly discuss\nan example based reservoir computing. We conclude the review by speculating on\nthe big picture view of future neuromorphic and brain-inspired computing\nsystems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-04-30",
      "downloaded_date": "2025-02-01",
      "filename": "Mehonic-Memristors -- from In-memory computing Deep Learning Acceleration Spiking Neural Networks to the Fut....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.14942v1",
      "categories": [
        "cs.ET",
        "cs.NE"
      ]
    },
    "2310.05751v1": {
      "title": "A Review of the Ethics of Artificial Intelligence and its Applications in the United States",
      "authors": [
        "Esther Taiwo",
        "Ahmed Akinsola",
        "Edward Tella",
        "Kolade Makinde",
        "Mayowa Akinwande"
      ],
      "abstract": "This study is focused on the ethics of Artificial Intelligence and its\napplication in the United States, the paper highlights the impact AI has in\nevery sector of the US economy and multiple facets of the technological space\nand the resultant effect on entities spanning businesses, government, academia,\nand civil society. There is a need for ethical considerations as these entities\nare beginning to depend on AI for delivering various crucial tasks, which\nimmensely influence their operations, decision-making, and interactions with\neach other. The adoption of ethical principles, guidelines, and standards of\nwork is therefore required throughout the entire process of AI development,\ndeployment, and usage to ensure responsible and ethical AI practices. Our\ndiscussion explores eleven fundamental 'ethical principles' structured as\noverarching themes. These encompass Transparency, Justice, Fairness, Equity,\nNon- Maleficence, Responsibility, Accountability, Privacy, Beneficence,\nFreedom, Autonomy, Trust, Dignity, Sustainability, and Solidarity. These\nprinciples collectively serve as a guiding framework, directing the ethical\npath for the responsible development, deployment, and utilization of artificial\nintelligence (AI) technologies across diverse sectors and entities within the\nUnited States. The paper also discusses the revolutionary impact of AI\napplications, such as Machine Learning, and explores various approaches used to\nimplement AI ethics. This examination is crucial to address the growing\nconcerns surrounding the inherent risks associated with the widespread use of\nartificial intelligence.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a104ec4ab36c71c3eed9b31283ad562e35efd7a7",
      "published_date": "2023-10-09",
      "downloaded_date": "2025-02-01",
      "filename": "Taiwo-A Review of the Ethics of Artificial Intelligence and its Applications in the United States.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.05751v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1802.07782v1": {
      "title": "Artificial Intelligence and Legal Liability",
      "authors": [
        "John Kingston"
      ],
      "abstract": "A recent issue of a popular computing journal asked which laws would apply if\na self-driving car killed a pedestrian. This paper considers the question of\nlegal liability for artificially intelligent computer systems. It discusses\nwhether criminal liability could ever apply; to whom it might apply; and, under\ncivil law, whether an AI program is a product that is subject to product design\nlegislation or a service to which the tort of negligence applies. The issue of\nsales warranties is also considered. A discussion of some of the practical\nlimitations that AI systems are subject to is also included.",
      "citation_count": 73,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e08650b5df4e38065979f84362d0b442cb515b2f",
      "published_date": "2018-02-21",
      "downloaded_date": "2025-02-01",
      "filename": "Kingston-Artificial Intelligence and Legal Liability.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1802.07782v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "2201.05743v1": {
      "title": "Predicting Research Trends in Artificial Intelligence with Gradient Boosting Decision Trees and Time-aware Graph Neural Networks",
      "authors": [
        "Yichao Lu"
      ],
      "abstract": "The Science4cast 2021 competition focuses on predicting future edges in an\nevolving semantic network, where each vertex represents an artificial\nintelligence concept, and an edge between a pair of vertices denotes that the\ntwo concepts have been investigated together in a scientific paper. In this\npaper, we describe our solution to this competition. We present two distinct\napproaches: a tree-based gradient boosting approach and a deep learning\napproach, and demonstrate that both approaches achieve competitive performance.\nOur final solution, which is based on a blend of the two approaches, achieved\nthe 1st place among all the participating teams. The source code for this paper\nis available at https://github.com/YichaoLu/Science4cast2021.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/301dfedf0a54e0ead3b6d6d61dbb1d07ce8f00ca",
      "published_date": "2022-01-15",
      "downloaded_date": "2025-02-01",
      "filename": "Lu-Predicting Research Trends in Artificial Intelligence with Gradient Boosting Decision Trees and Time....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2201.05743v1",
      "categories": [
        "cs.SI"
      ]
    },
    "2107.13661v4": {
      "title": "Toward High-Throughput Artificial Intelligence-Based Segmentation in Oncological PET Imaging",
      "authors": [
        "Fereshteh Yousefirizi",
        "Abhinav K. Jha",
        "Julia Brosch-Lenz",
        "Babak Saboury",
        "Arman Rahmim"
      ],
      "abstract": "Artificial intelligence (AI) techniques for image-based segmentation have\ngarnered much attention in recent years. Convolutional neural networks (CNNs)\nhave shown impressive results and potential towards fully automated\nsegmentation in medical imaging, and particularly PET imaging. To cope with the\nlimited access to annotated data needed in supervised AI methods, given tedious\nand prone-to-error manual delineations, semi-supervised and unsupervised AI\ntechniques have also been explored for segmentation of tumors or normal organs\nin single and bi-modality scans. This work provides a review of existing AI\ntechniques for segmentation tasks and the evaluation criteria for translational\nAI-based segmentation efforts towards routine adoption in clinical workflows.",
      "citation_count": 31,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e022aaf96b2e6ed1c272e4fe6ec861f7c4698db1",
      "published_date": "2021-07-28",
      "downloaded_date": "2025-02-01",
      "filename": "Yousefirizi-Toward High-Throughput Artificial Intelligence-Based Segmentation in Oncological PET Imaging.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.13661v4",
      "categories": [
        "physics.med-ph"
      ]
    },
    "2103.03081v3": {
      "title": "An overview of artificial intelligence techniques for diagnosis of Schizophrenia based on magnetic resonance imaging modalities: Methods, challenges, and future works",
      "authors": [
        "Delaram Sadeghi",
        "Afshin Shoeibi",
        "Navid Ghassemi",
        "Parisa Moridian",
        "Ali Khadem",
        "Roohallah Alizadehsani",
        "Mohammad Teshnehlab",
        "Juan M. Gorriz",
        "Fahime Khozeimeh",
        "Yu-Dong Zhang",
        "Saeid Nahavandi",
        "U Rajendra Acharya"
      ],
      "abstract": "Schizophrenia (SZ) is a mental disorder that typically emerges in late\nadolescence or early adulthood. It reduces the life expectancy of patients by\n15 years. Abnormal behavior, perception of emotions, social relationships, and\nreality perception are among its most significant symptoms. Past studies have\nrevealed that SZ affects the temporal and anterior lobes of hippocampus regions\nof the brain. Also, increased volume of cerebrospinal fluid (CSF) and decreased\nvolume of white and gray matter can be observed due to this disease. Magnetic\nresonance imaging (MRI) is the popular neuroimaging technique used to explore\nstructural/functional brain abnormalities in SZ disorder, owing to its high\nspatial resolution. Various artificial intelligence (AI) techniques have been\nemployed with advanced image/signal processing methods to accurately diagnose\nSZ. This paper presents a comprehensive overview of studies conducted on the\nautomated diagnosis of SZ using MRI modalities. First, an AI-based computer\naided-diagnosis system (CADS) for SZ diagnosis and its relevant sections are\npresented. Then, this section introduces the most important conventional\nmachine learning (ML) and deep learning (DL) techniques in the diagnosis of\ndiagnosing SZ. A comprehensive comparison is also made between ML and DL\nstudies in the discussion section. In the following, the most important\nchallenges in diagnosing SZ are addressed. Future works in diagnosing SZ using\nAI techniques and MRI modalities are recommended in another section. Results,\nconclusion, and research findings are also presented at the end.",
      "citation_count": 101,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c10b9f1e0fc3e3ace083be0daa251d915ab82051",
      "published_date": "2021-02-24",
      "downloaded_date": "2025-02-01",
      "filename": "Sadeghi-An overview of artificial intelligence techniques for diagnosis of Schizophrenia based on magnetic r....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.03081v3",
      "categories": [
        "cs.LG",
        "eess.IV"
      ]
    },
    "1812.02953v1": {
      "title": "Building Ethics into Artificial Intelligence",
      "authors": [
        "Han Yu",
        "Zhiqi Shen",
        "Chunyan Miao",
        "Cyril Leung",
        "Victor R. Lesser",
        "Qiang Yang"
      ],
      "abstract": "As artificial intelligence (AI) systems become increasingly ubiquitous, the\ntopic of AI governance for ethical decision-making by AI has captured public\nimagination. Within the AI research community, this topic remains less familiar\nto many researchers. In this paper, we complement existing surveys, which\nlargely focused on the psychological, social and legal discussions of the\ntopic, with an analysis of recent advances in technical solutions for AI\ngovernance. By reviewing publications in leading AI conferences including AAAI,\nAAMAS, ECAI and IJCAI, we propose a taxonomy which divides the field into four\nareas: 1) exploring ethical dilemmas; 2) individual ethical decision\nframeworks; 3) collective ethical decision frameworks; and 4) ethics in\nhuman-AI interactions. We highlight the intuitions and key techniques used in\neach approach, and discuss promising future research directions towards\nsuccessful integration of ethical AI systems into human societies.",
      "citation_count": 178,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/80179a17eab0f9fb6e21840f3fed96c4d75c3442",
      "published_date": "2018-12-07",
      "downloaded_date": "2025-02-01",
      "filename": "Yu-Building Ethics into Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1812.02953v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2011.04105v1": {
      "title": "Evolution of Artificial Intelligent Plane",
      "authors": [
        "Puneet Kumar"
      ],
      "abstract": "With the growth of the internet, it is becoming hard to manage, configure and\nmonitor networks. Recent trends to control and operate them is artificial\nintelligence based automation to minimize human intervention. Albeit this\nconcept has been introduced since a decade with several different names, but\nthe underlying goal remains the same, which is to make network intelligent\nenough to assemble, reassemble if configuration changes, and detect a problem\non its own and fix it. As a result, in addition to Data Plane, Control Plane\nand Management Plane, a new plane called Artificial Intelligence (AI) Plane is\nintroduced. Our main objective is to analyze all major AI plane techniques,\nframeworks and algorithms proposed in various types of networks. We propose a\ncomprehensive and network independent framework to cover all aspects of AI\nplane, in particular we provide a systematically means of comparison. In\nconjunction to make AI plane understand simpler, this framework highlights\nrelevant challenges and design considerations for future research. To the best\nof our knowledge this is the first survey report which represents a complete\ncomparison of AI planes with their investigation issues in several types of\nnetworks.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3725aa4a2de5507d9d90b71ab4833f428edb70ea",
      "published_date": "2020-11-08",
      "downloaded_date": "2025-02-01",
      "filename": "Kumar-Evolution of Artificial Intelligent Plane.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2011.04105v1",
      "categories": [
        "cs.AI",
        "cs.NI"
      ]
    },
    "2202.12678v2": {
      "title": "Deep Learning, Natural Language Processing, and Explainable Artificial Intelligence in the Biomedical Domain",
      "authors": [
        "Milad Moradi",
        "Matthias Samwald"
      ],
      "abstract": "In this article, we first give an introduction to artificial intelligence and\nits applications in biology and medicine in Section 1. Deep learning methods\nare then described in Section 2. We narrow down the focus of the study on\ntextual data in Section 3, where natural language processing and its\napplications in the biomedical domain are described. In Section 4, we give an\nintroduction to explainable artificial intelligence and discuss the importance\nof explainability of artificial intelligence systems, especially in the\nbiomedical domain.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-02-25",
      "downloaded_date": "2025-02-01",
      "filename": "Moradi-Deep Learning Natural Language Processing and Explainable Artificial Intelligence in the Biomedical ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.12678v2",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    "2206.00225v1": {
      "title": "Can Artificial Intelligence Transform DevOps?",
      "authors": [
        "Mamdouh Alenezi",
        "Mohammad Zarour",
        "Mohammad Akour"
      ],
      "abstract": "DevOps and Artificial Intelligence (AI) are interconnected with each other.\nDevOps is a business-driven approach to providing quickly delivered quality\nsoftware, and AI is the technology that can be used in the system to enhance\nits functionality. So, DevOps teams can use AI to test, code, release, monitor,\nand improve the system. Through AI, the automation process delivered by DevOps\ncould be improved efficiently. This study aims to explore how AI can transform\nDevOps. The research is useful in terms of facilitating software developers and\nbusinesses to assess the importance of AI in DevOps. The study has practical\nimplications as it elaborates on how AI transforms DevOps and in what way it\ncan support businesses in their business.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c7c9f9a70f8d704a13813d6c678c0a1367332492",
      "published_date": "2022-06-01",
      "downloaded_date": "2025-02-01",
      "filename": "Alenezi-Can Artificial Intelligence Transform DevOps.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.00225v1",
      "categories": [
        "cs.SE"
      ]
    },
    "2310.03715v1": {
      "title": "Artificial Intelligence Index Report 2023",
      "authors": [
        "Nestor Maslej",
        "Loredana Fattorini",
        "Erik Brynjolfsson",
        "John Etchemendy",
        "Katrina Ligett",
        "Terah Lyons",
        "James Manyika",
        "Helen Ngo",
        "Juan Carlos Niebles",
        "Vanessa Parli",
        "Yoav Shoham",
        "Russell Wald",
        "Jack Clark",
        "Raymond Perrault"
      ],
      "abstract": "Welcome to the sixth edition of the AI Index Report. This year, the report\nintroduces more original data than any previous edition, including a new\nchapter on AI public opinion, a more thorough technical performance chapter,\noriginal analysis about large language and multimodal models, detailed trends\nin global AI legislation records, a study of the environmental impact of AI\nsystems, and more. The AI Index Report tracks, collates, distills, and\nvisualizes data related to artificial intelligence. Our mission is to provide\nunbiased, rigorously vetted, broadly sourced data in order for policymakers,\nresearchers, executives, journalists, and the general public to develop a more\nthorough and nuanced understanding of the complex field of AI. The report aims\nto be the world's most credible and authoritative source for data and insights\nabout AI.",
      "citation_count": 77,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/25e0bfda8b2d820a455a265d1f8238c61c10b418",
      "published_date": "2023-10-05",
      "downloaded_date": "2025-02-01",
      "filename": "Maslej-Artificial Intelligence Index Report 2023.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.03715v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "2411.13717v2": {
      "title": "Hardware Accelerators for Artificial Intelligence",
      "authors": [
        "S M Mojahidul Ahsan",
        "Anurag Dhungel",
        "Mrittika Chowdhury",
        "Md Sakib Hasan",
        "Tamzidul Hoque"
      ],
      "abstract": "In this chapter, we aim to explore an in-depth exploration of the specialized\nhardware accelerators designed to enhance Artificial Intelligence (AI)\napplications, focusing on their necessity, development, and impact on the field\nof AI. It covers the transition from traditional computing systems to advanced\nAI-specific hardware, addressing the growing demands of AI algorithms and the\ninefficiencies of conventional architectures. The discussion extends to various\ntypes of accelerators, including GPUs, FPGAs, and ASICs, and their roles in\noptimizing AI workloads. Additionally, it touches on the challenges and\nconsiderations in designing and implementing these accelerators, along with\nfuture prospects in the evolution of AI hardware. This comprehensive overview\naims to equip readers with a clear understanding of the current landscape and\nfuture directions in AI hardware development, making it accessible to both\nexperts and newcomers to the field.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/470462ed5ebed4c0f79769b4156484f861f61920",
      "published_date": "2024-11-20",
      "downloaded_date": "2025-02-01",
      "filename": "Ahsan-Hardware Accelerators for Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.13717v2",
      "categories": [
        "cs.AR",
        "cs.ET"
      ]
    },
    "2211.13069v1": {
      "title": "Cultural Incongruencies in Artificial Intelligence",
      "authors": [
        "Vinodkumar Prabhakaran",
        "Rida Qadri",
        "Ben Hutchinson"
      ],
      "abstract": "Artificial intelligence (AI) systems attempt to imitate human behavior. How\nwell they do this imitation is often used to assess their utility and to\nattribute human-like (or artificial) intelligence to them. However, most work\non AI refers to and relies on human intelligence without accounting for the\nfact that human behavior is inherently shaped by the cultural contexts they are\nembedded in, the values and beliefs they hold, and the social practices they\nfollow. Additionally, since AI technologies are mostly conceived and developed\nin just a handful of countries, they embed the cultural values and practices of\nthese countries. Similarly, the data that is used to train the models also\nfails to equitably represent global cultural diversity. Problems therefore\narise when these technologies interact with globally diverse societies and\ncultures, with different values and interpretive practices. In this position\npaper, we describe a set of cultural dependencies and incongruencies in the\ncontext of AI-based language and vision technologies, and reflect on the\npossibilities of and potential strategies towards addressing these\nincongruencies.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-11-19",
      "downloaded_date": "2025-02-01",
      "filename": "Prabhakaran-Cultural Incongruencies in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.13069v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2211.13230v1": {
      "title": "Generalization of Artificial Intelligence Models in Medical Imaging: A Case-Based Review",
      "authors": [
        "Rishi Gadepally",
        "Andrew Gomella",
        "Eric Gingold",
        "Paras Lakhani"
      ],
      "abstract": "The discussions around Artificial Intelligence (AI) and medical imaging are\ncentered around the success of deep learning algorithms. As new algorithms\nenter the market, it is important for practicing radiologists to understand the\npitfalls of various AI algorithms. This entails having a basic understanding of\nhow algorithms are developed, the kind of data they are trained on, and the\nsettings in which they will be deployed. As with all new technologies, use of\nAI should be preceded by a fundamental understanding of the risks and benefits\nto those it is intended to help. This case-based review is intended to point\nout specific factors practicing radiologists who intend to use AI should\nconsider.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3e1c9875198bfc93df5b2b0809a4652dd29d3a1e",
      "published_date": "2022-11-15",
      "downloaded_date": "2025-02-01",
      "filename": "Gadepally-Generalization of Artificial Intelligence Models in Medical Imaging A Case-Based Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.13230v1",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "1905.06088v1": {
      "title": "Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning",
      "authors": [
        "Artur d'Avila Garcez",
        "Marco Gori",
        "Luis C. Lamb",
        "Luciano Serafini",
        "Michael Spranger",
        "Son N. Tran"
      ],
      "abstract": "Current advances in Artificial Intelligence and machine learning in general,\nand deep learning in particular have reached unprecedented impact not only\nacross research communities, but also over popular media channels. However,\nconcerns about interpretability and accountability of AI have been raised by\ninfluential thinkers. In spite of the recent impact of AI, several works have\nidentified the need for principled knowledge representation and reasoning\nmechanisms integrated with deep learning-based systems to provide sound and\nexplainable models for such systems. Neural-symbolic computing aims at\nintegrating, as foreseen by Valiant, two most fundamental cognitive abilities:\nthe ability to learn from the environment, and the ability to reason from what\nhas been learned. Neural-symbolic computing has been an active topic of\nresearch for many years, reconciling the advantages of robust learning in\nneural networks and reasoning and interpretability of symbolic representation.\nIn this paper, we survey recent accomplishments of neural-symbolic computing as\na principled methodology for integrated machine learning and reasoning. We\nillustrate the effectiveness of the approach by outlining the main\ncharacteristics of the methodology: principled integration of neural learning\nwith symbolic knowledge representation and reasoning allowing for the\nconstruction of explainable AI systems. The insights provided by\nneural-symbolic computing shed new light on the increasingly prominent need for\ninterpretable and accountable AI systems.",
      "citation_count": 266,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/833c4ac0599f4b8c5f1ee6ea948ec675fbe56b15",
      "published_date": "2019-05-15",
      "downloaded_date": "2025-02-01",
      "filename": "Garcez-Neural-Symbolic Computing An Effective Methodology for Principled Integration of Machine Learning an....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1905.06088v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2111.12227v1": {
      "title": "Artificial intelligence enabled radio propagation for communications-Part I: Channel characterization and antenna-channel optimization",
      "authors": [
        "Chen Huang",
        "Ruisi He",
        "Bo Ai",
        "Andreas F. Molisch",
        "Buon Kiong Lau",
        "Katsuyuki Haneda",
        "Bo Liu",
        "Cheng-Xiang Wang",
        "Mi Yang",
        "Claude Oestges",
        "Zhangdui Zhong"
      ],
      "abstract": "To provide higher data rates, as well as better coverage, cost efficiency,\nsecurity, adaptability, and scalability, the 5G and beyond 5G networks are\ndeveloped with various artificial intelligence techniques. In this two-part\npaper, we investigate the application of artificial intelligence (AI) and in\nparticular machine learning (ML) to the study of wireless propagation channels.\nIt firstly provides a comprehensive overview of ML for channel characterization\nand ML-based antenna-channel optimization in this first part, and then it gives\na state-of-the-art literature review of channel scenario identification and\nchannel modeling in Part II. Fundamental results and key concepts of ML for\ncommunication networks are presented, and widely used ML methods for channel\ndata processing, propagation channel estimation, and characterization are\nanalyzed and compared. A discussion of challenges and future research\ndirections for ML-enabled next generation networks of the topics covered in\nthis part rounds off the paper.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-11-24",
      "downloaded_date": "2025-02-01",
      "filename": "Huang-Artificial intelligence enabled radio propagation for communications-Part I Channel characterization....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.12227v1",
      "categories": [
        "eess.SP"
      ]
    },
    "2303.09056v1": {
      "title": "Generating synthetic multi-dimensional molecular-mediator time series data for artificial intelligence-based disease trajectory forecasting and drug development digital twins: Considerations",
      "authors": [
        "Gary An",
        "Chase Cockrell"
      ],
      "abstract": "The use of synthetic data is recognized as a crucial step in the development\nof neural network-based Artificial Intelligence (AI) systems. While the methods\nfor generating synthetic data for AI applications in other domains have a role\nin certain biomedical AI systems, primarily related to image processing, there\nis a critical gap in the generation of time series data for AI tasks where it\nis necessary to know how the system works. This is most pronounced in the\nability to generate synthetic multi-dimensional molecular time series data\n(SMMTSD); this is the type of data that underpins research into biomarkers and\nmediator signatures for forecasting various diseases and is an essential\ncomponent of the drug development pipeline. We argue the insufficiency of\nstatistical and data-centric machine learning (ML) means of generating this\ntype of synthetic data is due to a combination of factors: perpetual data\nsparsity due to the Curse of Dimensionality, the inapplicability of the Central\nLimit Theorem, and the limits imposed by the Causal Hierarchy Theorem.\nAlternatively, we present a rationale for using complex multi-scale\nmechanism-based simulation models, constructed and operated on to account for\nepistemic incompleteness and the need to provide maximal expansiveness in\nconcordance with the Principle of Maximal Entropy. These procedures provide for\nthe generation of SMMTD that minimizes the known shortcomings associated with\nneural network AI systems, namely overfitting and lack of generalizability. The\ngeneration of synthetic data that accounts for the identified factors of\nmulti-dimensional time series data is an essential capability for the\ndevelopment of mediator-biomarker based AI forecasting systems, and therapeutic\ncontrol development and optimization through systems like Drug Development\nDigital Twins.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/91d17bb83cd54f88b887aac7707d376130612c04",
      "published_date": "2023-03-16",
      "downloaded_date": "2025-02-01",
      "filename": "An-Generating synthetic multi-dimensional molecular-mediator time series data for artificial intelligen....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.09056v1",
      "categories": [
        "cs.AI",
        "I.2.m; J.3"
      ]
    },
    "1907.04659v3": {
      "title": "Artificial Intelligence: A Child's Play",
      "authors": [
        "Ravi Kashyap"
      ],
      "abstract": "We discuss the objectives of any endeavor in creating artificial\nintelligence, AI, and provide a possible alternative. Intelligence might be an\nunintended consequence of curiosity left to roam free, best exemplified by a\nfrolicking infant. This suggests that our attempts at AI could have been\nmisguided. What we actually need to strive for can be termed artificial\ncuriosity, AC, and intelligence happens as a consequence of those efforts. For\nthis unintentional yet welcome aftereffect to set in a foundational list of\nguiding principles needs to be present. We start with the intuition for this\nline of reasoning and formalize it with a series of definitions, assumptions,\ningredients, models and iterative improvements that will be necessary to make\nthe incubation of intelligence a reality. Our discussion provides conceptual\nmodifications to the Turing Test and to Searle's Chinese room argument. We\ndiscuss the future implications for society as AI becomes an integral part of\nlife.\n  We provide a road-map for creating intelligence with the technical parts\nrelegated to the appendix so that the article is accessible to a wide audience.\nThe central techniques in our formal approach to creating intelligence draw\nupon tools and concepts widely used in physics, cognitive science, psychology,\nevolutionary biology, statistics, linguistics, communication systems, pattern\nrecognition, marketing, economics, finance, information science and\ncomputational theory highlighting that solutions for creating artificial\nintelligence have to transcend the artificial barriers between various fields\nand be highly multi-disciplinary.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d7b048603fac1abb52d85a826164226ae43141a7",
      "published_date": "2019-07-01",
      "downloaded_date": "2025-02-01",
      "filename": "Kashyap-Artificial Intelligence A Childs Play.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.04659v3",
      "categories": [
        "cs.AI",
        "68Q32 Computational learning theory, 68T05 Learning & adaptive\n  systems, 97R40 Artificial intelligence, 91E10 Cognitive psychology, 60J60\n  Diffusion processes",
        "I.2.0; I.2.6; I.2.8; F.4.3; G.3"
      ]
    },
    "2410.14767v1": {
      "title": "Machine Learning Aided Modeling of Granular Materials: A Review",
      "authors": [
        "Mengqi Wang",
        "Krishna Kumar",
        "Y. T. Feng",
        "Tongming Qu",
        "Min Wang"
      ],
      "abstract": "Artificial intelligence (AI) has become a buzz word since Google's AlphaGo\nbeat a world champion in 2017. In the past five years, machine learning as a\nsubset of the broader category of AI has obtained considerable attention in the\nresearch community of granular materials. This work offers a detailed review of\nthe recent advances in machine learning-aided studies of granular materials\nfrom the particle-particle interaction at the grain level to the macroscopic\nsimulations of granular flow. This work will start with the application of\nmachine learning in the microscopic particle-particle interaction and\nassociated contact models. Then, different neural networks for learning the\nconstitutive behaviour of granular materials will be reviewed and compared.\nFinally, the macroscopic simulations of practical engineering or boundary value\nproblems based on the combination of neural networks and numerical methods are\ndiscussed. We hope readers will have a clear idea of the development of machine\nlearning-aided modelling of granular materials via this comprehensive review\nwork.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ad373dd3a02da73ec1caf68524d73ea4418df2ca",
      "published_date": "2024-10-18",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Machine Learning Aided Modeling of Granular Materials A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.14767v1",
      "categories": [
        "physics.geo-ph",
        "cond-mat.soft",
        "cs.LG"
      ]
    },
    "2303.12350v2": {
      "title": "Artificial Intelligence and Dual Contract",
      "authors": [
        "Qian Qi"
      ],
      "abstract": "This paper explores the capacity of artificial intelligence (AI) algorithms\nto autonomously design incentive-compatible contracts in dual-principal-agent\nsettings, a relatively unexplored aspect of algorithmic mechanism design. We\ndevelop a dynamic model where two principals, each equipped with independent\nQ-learning algorithms, interact with a single agent. Our findings reveal that\nthe strategic behavior of AI principals (cooperation vs. competition) hinges\ncrucially on the alignment of their profits. Notably, greater profit alignment\nfosters collusive strategies, yielding higher principal profits at the expense\nof agent incentives. This emergent behavior persists across varying degrees of\nprincipal heterogeneity, multiple principals, and environments with\nuncertainty. Our study underscores the potential of AI for contract automation\nwhile raising critical concerns regarding strategic manipulation and the\nemergence of unintended collusion in AI-driven systems, particularly in the\ncontext of the broader AI alignment problem.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/717e8d432941d5297cd7dc7918f26e7fe73c8482",
      "published_date": "2023-03-22",
      "downloaded_date": "2025-02-01",
      "filename": "Qi-Artificial Intelligence and Dual Contract.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.12350v2",
      "categories": [
        "cs.AI",
        "cs.CY",
        "econ.GN",
        "q-fin.EC"
      ]
    },
    "2411.09131v1": {
      "title": "Artificial Intelligence for Quantum Computing",
      "authors": [
        "Yuri Alexeev",
        "Marwa H. Farag",
        "Taylor L. Patti",
        "Mark E. Wolf",
        "Natalia Ares",
        "AlÃ¡n Aspuru-Guzik",
        "Simon C. Benjamin",
        "Zhenyu Cai",
        "Zohim Chandani",
        "Federico Fedele",
        "Nicholas Harrigan",
        "Jin-Sung Kim",
        "Elica Kyoseva",
        "Justin G. Lietz",
        "Tom Lubowe",
        "Alexander McCaskey",
        "Roger G. Melko",
        "Kouhei Nakaji",
        "Alberto Peruzzo",
        "Sam Stanwyck",
        "Norm M. Tubman",
        "Hanrui Wang",
        "Timothy Costa"
      ],
      "abstract": "Artificial intelligence (AI) advancements over the past few years have had an\nunprecedented and revolutionary impact across everyday application areas. Its\nsignificance also extends to technical challenges within science and\nengineering, including the nascent field of quantum computing (QC). The\ncounterintuitive nature and high-dimensional mathematics of QC make it a prime\ncandidate for AI's data-driven learning capabilities, and in fact, many of QC's\nbiggest scaling challenges may ultimately rest on developments in AI. However,\nbringing leading techniques from AI to QC requires drawing on disparate\nexpertise from arguably two of the most advanced and esoteric areas of computer\nscience. Here we aim to encourage this cross-pollination by reviewing how\nstate-of-the-art AI techniques are already advancing challenges across the\nhardware and software stack needed to develop useful QC - from device design to\napplications. We then close by examining its future opportunities and obstacles\nin this space.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c86b1f4f4e82486fa7047dc57b89d2c3de212fab",
      "published_date": "2024-11-14",
      "downloaded_date": "2025-02-01",
      "filename": "Alexeev-Artificial Intelligence for Quantum Computing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.09131v1",
      "categories": [
        "quant-ph"
      ]
    },
    "2004.14035v1": {
      "title": "The Holy Grail of Quantum Artificial Intelligence: Major Challenges in Accelerating the Machine Learning Pipeline",
      "authors": [
        "Thomas Gabor",
        "Leo SÃ¼nkel",
        "Fabian Ritz",
        "Thomy Phan",
        "Lenz Belzner",
        "Christoph Roch",
        "Sebastian Feld",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "We discuss the synergetic connection between quantum computing and artificial\nintelligence. After surveying current approaches to quantum artificial\nintelligence and relating them to a formal model for machine learning\nprocesses, we deduce four major challenges for the future of quantum artificial\nintelligence: (i) Replace iterative training with faster quantum algorithms,\n(ii) distill the experience of larger amounts of data into the training\nprocess, (iii) allow quantum and classical components to be easily combined and\nexchanged, and (iv) build tools to thoroughly analyze whether observed benefits\nreally stem from quantum properties of the algorithm.",
      "citation_count": 24,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4aa6f7e0e063f6353829f97564d511096eb51591",
      "published_date": "2020-04-29",
      "downloaded_date": "2025-02-01",
      "filename": "Gabor-The Holy Grail of Quantum Artificial Intelligence Major Challenges in Accelerating the Machine Learn....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.14035v1",
      "categories": [
        "quant-ph",
        "cs.AI"
      ]
    },
    "1908.10714v1": {
      "title": "Automated Architecture Design for Deep Neural Networks",
      "authors": [
        "Steven Abreu"
      ],
      "abstract": "Machine learning has made tremendous progress in recent years and received\nlarge amounts of public attention. Though we are still far from designing a\nfull artificially intelligent agent, machine learning has brought us many\napplications in which computers solve human learning tasks remarkably well.\nMuch of this progress comes from a recent trend within machine learning, called\ndeep learning. Deep learning models are responsible for many state-of-the-art\napplications of machine learning. Despite their success, deep learning models\nare hard to train, very difficult to understand, and often times so complex\nthat training is only possible on very large GPU clusters. Lots of work has\nbeen done on enabling neural networks to learn efficiently. However, the design\nand architecture of such neural networks is often done manually through trial\nand error and expert knowledge. This thesis inspects different approaches,\nexisting and novel, to automate the design of deep feedforward neural networks\nin an attempt to create less complex models with good performance that take\naway the burden of deciding on an architecture and make it more efficient to\ndesign and train such deep networks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-08-22",
      "downloaded_date": "2025-02-01",
      "filename": "Abreu-Automated Architecture Design for Deep Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1908.10714v1",
      "categories": [
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ]
    },
    "2204.07519v1": {
      "title": "An Introductory Review of Spiking Neural Network and Artificial Neural Network: From Biological Intelligence to Artificial Intelligence",
      "authors": [
        "Shengjie Zheng",
        "Lang Qian",
        "Pingsheng Li",
        "Chenggang He",
        "Xiaoqin Qin",
        "Xiaojian Li"
      ],
      "abstract": "Recently, stemming from the rapid development of artificial intelligence,\nwhich has gained expansive success in pattern recognition, robotics, and\nbioinformatics, neuroscience is also gaining tremendous progress. A kind of\nspiking neural network with biological interpretability is gradually receiving\nwide attention, and this kind of neural network is also regarded as one of the\ndirections toward general artificial intelligence. This review introduces the\nfollowing sections, the biological background of spiking neurons and the\ntheoretical basis, different neuronal models, the connectivity of neural\ncircuits, the mainstream neural network learning mechanisms and network\narchitectures, etc. This review hopes to attract different researchers and\nadvance the development of brain-inspired intelligence and artificial\nintelligence.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/79741eb0a54972abde30c795a2571c37ebd2d147",
      "published_date": "2022-04-09",
      "downloaded_date": "2025-02-01",
      "filename": "Zheng-An Introductory Review of Spiking Neural Network and Artificial Neural Network From Biological Intel....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2204.07519v1",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    "2308.07457v1": {
      "title": "Artificial Intelligence for Smart Transportation",
      "authors": [
        "Michael Wilbur",
        "Amutheezan Sivagnanam",
        "Afiya Ayman",
        "Samitha Samaranayeke",
        "Abhishek Dubey",
        "Aron Laszka"
      ],
      "abstract": "There are more than 7,000 public transit agencies in the U.S. (and many more\nprivate agencies), and together, they are responsible for serving 60 billion\npassenger miles each year. A well-functioning transit system fosters the growth\nand expansion of businesses, distributes social and economic benefits, and\nlinks the capabilities of community members, thereby enhancing what they can\naccomplish as a society. Since affordable public transit services are the\nbackbones of many communities, this work investigates ways in which Artificial\nIntelligence (AI) can improve efficiency and increase utilization from the\nperspective of transit agencies. This book chapter discusses the primary\nrequirements, objectives, and challenges related to the design of AI-driven\nsmart transportation systems. We focus on three major topics. First, we discuss\ndata sources and data. Second, we provide an overview of how AI can aid\ndecision-making with a focus on transportation. Lastly, we discuss\ncomputational problems in the transportation domain and AI approaches to these\nproblems.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/10fb52f534595512a51598a5732066f07cd08958",
      "published_date": "2023-08-14",
      "downloaded_date": "2025-02-01",
      "filename": "Wilbur-Artificial Intelligence for Smart Transportation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.07457v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2404.10032v1": {
      "title": "Detecting AI Generated Text Based on NLP and Machine Learning Approaches",
      "authors": [
        "Nuzhat Prova"
      ],
      "abstract": "Recent advances in natural language processing (NLP) may enable artificial\nintelligence (AI) models to generate writing that is identical to human written\nform in the future. This might have profound ethical, legal, and social\nrepercussions. This study aims to address this problem by offering an accurate\nAI detector model that can differentiate between electronically produced text\nand human-written text. Our approach includes machine learning methods such as\nXGB Classifier, SVM, BERT architecture deep learning models. Furthermore, our\nresults show that the BERT performs better than previous models in identifying\ninformation generated by AI from information provided by humans. Provide a\ncomprehensive analysis of the current state of AI-generated text identification\nin our assessment of pertinent studies. Our testing yielded positive findings,\nshowing that our strategy is successful, with the BERT emerging as the most\nprobable answer. We analyze the research's societal implications, highlighting\nthe possible advantages for various industries while addressing sustainability\nissues pertaining to morality and the environment. The XGB classifier and SVM\ngive 0.84 and 0.81 accuracy in this article, respectively. The greatest\naccuracy in this research is provided by the BERT model, which provides 0.93%\naccuracy.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9d265cb66c488fbd9691d81b972e02a8155e4702",
      "published_date": "2024-04-15",
      "downloaded_date": "2025-02-01",
      "filename": "Prova-Detecting AI Generated Text Based on NLP and Machine Learning Approaches.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.10032v1",
      "categories": [
        "cs.LG",
        "cs.CL"
      ]
    },
    "2101.02991v1": {
      "title": "Artificial Intelligence enabled Smart Learning",
      "authors": [
        "Faisal Khan",
        "Debdeep Bose"
      ],
      "abstract": "Artificial Intelligence (AI) is a discipline of computer science that deals\nwith machine intelligence. It is essential to bring AI into the context of\nlearning because it helps in analysing the enormous amounts of data that is\ncollected from individual students, teachers and academic staff. The major\npriorities of implementing AI in education are making innovative use of\nexisting digital technologies for learning, and teaching practices that\nsignificantly improve traditional educational methods. The main problem with\ntraditional learning is that it cannot be suited to every student in class.\nSome students may grasp the concepts well, while some may have difficulties in\nunderstanding them and some may be more auditory or visual learners. The World\nBank report on education has indicated that the learning gap created by this\nproblem causes many students to drop out (World Development Report, 2018).\nPersonalised learning has been able to solve this grave problem.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8e57c407cdc7c5a957d9c422168270a05e0ed674",
      "published_date": "2021-01-08",
      "downloaded_date": "2025-02-01",
      "filename": "Khan-Artificial Intelligence enabled Smart Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.02991v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2306.06148v1": {
      "title": "Artificial intelligence and radiation protection. A game changer or an update?",
      "authors": [
        "Sylvain Andresz",
        "A ZÃ©phir",
        "Jeremy Bez",
        "Maxime Karst",
        "J. Danieli"
      ],
      "abstract": "Artificial intelligence (AI) is regarded as one of the most disruptive\ntechnology of the century and with countless applications. What does it mean\nfor radiation protection? This article describes the fundamentals of machine\nlearning (ML) based methods and presents the inaugural applications in\ndifferent fields of radiation protection. It is foreseen that the usage of AI\nwill increase in radiation protection. Consequently, this article explores some\nof the benefits and also the potential barriers and questions, including\nethical ones, that can come out. The article proposes that collaboration\nbetween radiation protection professionals and data scientist experts can\naccelerate and guide the development of the algorithms for effective scientific\nand technological outcomes.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-06-09",
      "downloaded_date": "2025-02-01",
      "filename": "Andresz-Artificial intelligence and radiation protection A game changer or an update.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.06148v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2010.05234v3": {
      "title": "A Practical Tutorial on Graph Neural Networks",
      "authors": [
        "Isaac Ronald Ward",
        "Jack Joyner",
        "Casey Lickfold",
        "Yulan Guo",
        "Mohammed Bennamoun"
      ],
      "abstract": "Graph neural networks (GNNs) have recently grown in popularity in the field\nof artificial intelligence (AI) due to their unique ability to ingest\nrelatively unstructured data types as input data. Although some elements of the\nGNN architecture are conceptually similar in operation to traditional neural\nnetworks (and neural network variants), other elements represent a departure\nfrom traditional deep learning techniques. This tutorial exposes the power and\nnovelty of GNNs to AI practitioners by collating and presenting details\nregarding the motivations, concepts, mathematics, and applications of the most\ncommon and performant variants of GNNs. Importantly, we present this tutorial\nconcisely, alongside practical examples, thus providing a practical and\naccessible tutorial on the topic of GNNs.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/28a22bea3d98b326715bcede9b0216d3f788e1b8",
      "published_date": "2020-10-11",
      "downloaded_date": "2025-02-01",
      "filename": "Ward-A Practical Tutorial on Graph Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2010.05234v3",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ]
    },
    "1804.01653v2": {
      "title": "Review of Deep Learning",
      "authors": [
        "Rong Zhang",
        "Weiping Li",
        "Tong Mo"
      ],
      "abstract": "In recent years, China, the United States and other countries, Google and\nother high-tech companies have increased investment in artificial intelligence.\nDeep learning is one of the current artificial intelligence research's key\nareas. This paper analyzes and summarizes the latest progress and future\nresearch directions of deep learning. Firstly, three basic models of deep\nlearning are outlined, including multilayer perceptrons, convolutional neural\nnetworks, and recurrent neural networks. On this basis, we further analyze the\nemerging new models of convolution neural networks and recurrent neural\nnetworks. This paper then summarizes deep learning's applications in many areas\nof artificial intelligence, including speech processing, computer vision,\nnatural language processing and so on. Finally, this paper discusses the\nexisting problems of deep learning and gives the corresponding possible\nsolutions.",
      "citation_count": 3827,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0084f3cb0a1754272151c5268a783f24bf5676a0",
      "published_date": "2018-04-05",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Review of Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1804.01653v2",
      "categories": [
        "cs.LG",
        "cs.CV",
        "cs.NE",
        "stat.ML"
      ]
    },
    "1803.03503v1": {
      "title": "Construction of neural networks for realization of localized deep learning",
      "authors": [
        "Charles K. Chui",
        "Shao-Bo Lin",
        "Ding-Xuan Zhou"
      ],
      "abstract": "The subject of deep learning has recently attracted users of machine learning\nfrom various disciplines, including: medical diagnosis and bioinformatics,\nfinancial market analysis and online advertisement, speech and handwriting\nrecognition, computer vision and natural language processing, time series\nforecasting, and search engines. However, theoretical development of deep\nlearning is still at its infancy. The objective of this paper is to introduce a\ndeep neural network (also called deep-net) approach to localized manifold\nlearning, with each hidden layer endowed with a specific learning task. For the\npurpose of illustrations, we only focus on deep-nets with three hidden layers,\nwith the first layer for dimensionality reduction, the second layer for bias\nreduction, and the third layer for variance reduction. A feedback component\nalso designed to eliminate outliers. The main theoretical result in this paper\nis the order $\\mathcal O\\left(m^{-2s/(2s+d)}\\right)$ of approximation of the\nregression function with regularity $s$, in terms of the number $m$ of sample\npoints, where the (unknown) manifold dimension $d$ replaces the dimension $D$\nof the sampling (Euclidean) space for shallow nets.",
      "citation_count": 34,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a376a1f5a27fb56873283dde0eabf290531c8310",
      "published_date": "2018-03-09",
      "downloaded_date": "2025-02-01",
      "filename": "Chui-Construction of neural networks for realization of localized deep learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1803.03503v1",
      "categories": [
        "cs.LG"
      ]
    },
    "1504.05696v2": {
      "title": "Ascribing Consciousness to Artificial Intelligence",
      "authors": [
        "Murray Shanahan"
      ],
      "abstract": "This paper critically assesses the anti-functionalist stance on consciousness\nadopted by certain advocates of integrated information theory (IIT), a\ncorollary of which is that human-level artificial intelligence implemented on\nconventional computing hardware is necessarily not conscious. The critique\ndraws on variations of a well-known gradual neuronal replacement thought\nexperiment, as well as bringing out tensions in IIT's treatment of\nself-knowledge. The aim, though, is neither to reject IIT outright nor to\nchampion functionalism in particular. Rather, it is suggested that both ideas\nhave something to offer a scientific understanding of consciousness, as long as\nthey are not dressed up as solutions to illusory metaphysical problems. As for\nhuman-level AI, we must await its development before we can decide whether or\nnot to ascribe consciousness to it.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4109ded67a94471dd01f02fa9cb3e65b09ecb344",
      "published_date": "2015-04-22",
      "downloaded_date": "2025-02-01",
      "filename": "Shanahan-Ascribing Consciousness to Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1504.05696v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2103.03608v3": {
      "title": "Eigen-spectrograms: An interpretable feature space for bearing fault diagnosis based on artificial intelligence and image processing",
      "authors": [
        "Eugenio Brusa",
        "Cristiana Delprete",
        "Luigi Gianpio Di Maggio"
      ],
      "abstract": "The Intelligent Fault Diagnosis of rotating machinery currently proposes some\ncaptivating challenges. Although results achieved by artificial intelligence\nand deep learning constantly improve, this field is characterized by several\nopen issues. Models' interpretation is still buried under the foundations of\ndata driven science, thus requiring attention to the development of new\nopportunities also for machine learning theories. This study proposes a machine\nlearning diagnosis model, based on intelligent spectrogram recognition, via\nimage processing. The approach is characterized by the employment of the\neigen-spectrograms and randomized linear algebra in fault diagnosis. Randomized\nalgebra and eigen-spectrograms enable the construction of a significant feature\nspace, which nonetheless emerges as a viable device to explore models'\ninterpretations. The computational efficiency of randomized approaches provides\nreading keys of well-established statistical learning theories such as the\nSupport Vector Machine (SVM). Machine learning applied to spectrogram\nrecognition shows to be extremely accurate and efficient as compared to state\nof the art results.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/478d7beff604027da28424f5fab80eb9c9419862",
      "published_date": "2021-03-05",
      "downloaded_date": "2025-02-01",
      "filename": "Brusa-Eigen-spectrograms An interpretable feature space for bearing fault diagnosis based on artificial in....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.03608v3",
      "categories": [
        "eess.SP"
      ]
    },
    "2306.07601v1": {
      "title": "Intrusion Detection: A Deep Learning Approach",
      "authors": [
        "Ishaan Shivhare",
        "Joy Purohit",
        "Vinay Jogani",
        "Samina Attari",
        "Madhav Chandane"
      ],
      "abstract": "Network intrusions are a significant problem in all industries today. A\ncritical part of the solution is being able to effectively detect intrusions.\nWith recent advances in artificial intelligence, current research has begun\nadopting deep learning approaches for intrusion detection. Current approaches\nfor multi-class intrusion detection include the use of a deep neural network.\nHowever, it fails to take into account spatial relationships between the data\nobjects and long term dependencies present in the dataset. The paper proposes a\nnovel architecture to combat intrusion detection that has a Convolutional\nNeural Network (CNN) module, along with a Long Short Term Memory(LSTM) module\nand with a Support Vector Machine (SVM) classification function. The analysis\nis followed by a comparison of both conventional machine learning techniques\nand deep learning methodologies, which highlights areas that could be further\nexplored.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5ea3ee9a72034d03da4768927837c249d924d975",
      "published_date": "2023-06-13",
      "downloaded_date": "2025-02-01",
      "filename": "Shivhare-Intrusion Detection A Deep Learning Approach.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.07601v1",
      "categories": [
        "cs.CR",
        "cs.CV"
      ]
    },
    "2302.07103v1": {
      "title": "Validation of artificial intelligence containing products across the regulated healthcare industries",
      "authors": [
        "David Higgins",
        "Christian Johner"
      ],
      "abstract": "Purpose: The introduction of artificial intelligence / machine learning\n(AI/ML) products to the regulated fields of pharmaceutical research and\ndevelopment (R&D) and drug manufacture, and medical devices (MD) and in-vitro\ndiagnostics (IVD), poses new regulatory problems: a lack of a common\nterminology and understanding leads to confusion, delays and product failures.\nValidation as a key step in product development, common to each of these\nsectors including computerized systems and AI/ML development, offers an\nopportune point of comparison for aligning people and processes for\ncross-sectoral product development.\n  Methods: A comparative approach, built upon workshops and a subsequent\nwritten sequence of exchanges, summarized in a look-up table suitable for\nmixed-teams work.\n  Results: 1. A bottom-up, definitions led, approach which leads to a\ndistinction between broad vs narrow validation, and their relationship to\nregulatory regimes. 2. Common basis introduction to the primary methodologies\nfor AI-containing software validation. 3. Pharmaceutical drug development and\nMD/IVD specific perspectives on compliant AI software development, as a basis\nfor collaboration.\n  Conclusions: Alignment of the terms and methodologies used in validation of\nsoftware products containing artificial intelligence / machine learning (AI/ML)\ncomponents across the regulated industries of human health is a vital first\nstep in streamlining processes and improving workflows.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4bf22969f89c91d4b215bacb15b731b707022834",
      "published_date": "2023-02-13",
      "downloaded_date": "2025-02-01",
      "filename": "Higgins-Validation of artificial intelligence containing products across the regulated healthcare industries.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.07103v1",
      "categories": [
        "cs.CY",
        "cs.SE",
        "I.2.1; J.3"
      ]
    },
    "2108.11954v2": {
      "title": "Cascading Neural Network Methodology for Artificial Intelligence-Assisted Radiographic Detection and Classification of Lead-Less Implanted Electronic Devices within the Chest",
      "authors": [
        "Mutlu Demirer",
        "Richard D. White",
        "Vikash Gupta",
        "Ronnie A. Sebro",
        "Barbaros S. Erdal"
      ],
      "abstract": "Background & Purpose: Chest X-Ray (CXR) use in pre-MRI safety screening for\nLead-Less Implanted Electronic Devices (LLIEDs), easily overlooked or\nmisidentified on a frontal view (often only acquired), is common. Although most\nLLIED types are \"MRI conditional\": 1. Some are stringently conditional; 2.\nDifferent conditional types have specific patient- or device- management\nrequirements; and 3. Particular types are \"MRI unsafe\". This work focused on\ndeveloping CXR interpretation-assisting Artificial Intelligence (AI)\nmethodology with: 1. 100% detection for LLIED presence/location; and 2. High\nclassification in LLIED typing. Materials & Methods: Data-mining\n(03/1993-02/2021) produced an AI Model Development Population (1,100\npatients/4,871 images) creating 4,924 LLIED Region-Of-Interests (ROIs) (with\nimage-quality grading) used in Training, Validation, and Testing. For\ndeveloping the cascading neural network (detection via Faster R-CNN and\nclassification via Inception V3), \"ground-truth\" CXR annotation (ROI labeling\nper LLIED), as well as inference display (as Generated Bounding Boxes (GBBs)),\nrelied on a GPU-based graphical user interface. Results: To achieve 100% LLIED\ndetection, probability threshold reduction to 0.00002 was required by Model 1,\nresulting in increasing GBBs per LLIED-related ROI. Targeting LLIED-type\nclassification following detection of all LLIEDs, Model 2 multi-classified to\nreach high-performance while decreasing falsely positive GBBs. Despite 24%\nsuboptimal ROI image quality, classification was correct in 98.9% and AUCs for\nthe 9 LLIED-types were 1.00 for 8 and 0.92 for 1. For all misclassification\ncases: 1. None involved stringently conditional or unsafe LLIEDs; and 2. Most\nwere attributable to suboptimal images. Conclusion: This project successfully\ndeveloped a LLIED-related AI methodology supporting: 1. 100% detection; and 2.\nTypically 100% type classification.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/617b6b09d29c7b5ea2d6c796421addf7f3f14ce0",
      "published_date": "2021-08-25",
      "downloaded_date": "2025-02-01",
      "filename": "Demirer-Cascading Neural Network Methodology for Artificial Intelligence-Assisted Radiographic Detection and....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.11954v2",
      "categories": [
        "eess.IV",
        "cs.AI"
      ]
    },
    "2012.06058v1": {
      "title": "Next Wave Artificial Intelligence: Robust, Explainable, Adaptable, Ethical, and Accountable",
      "authors": [
        "Odest Chadwicke Jenkins",
        "Daniel Lopresti",
        "Melanie Mitchell"
      ],
      "abstract": "The history of AI has included several \"waves\" of ideas. The first wave, from\nthe mid-1950s to the 1980s, focused on logic and symbolic hand-encoded\nrepresentations of knowledge, the foundations of so-called \"expert systems\".\nThe second wave, starting in the 1990s, focused on statistics and machine\nlearning, in which, instead of hand-programming rules for behavior, programmers\nconstructed \"statistical learning algorithms\" that could be trained on large\ndatasets. In the most recent wave research in AI has largely focused on deep\n(i.e., many-layered) neural networks, which are loosely inspired by the brain\nand trained by \"deep learning\" methods. However, while deep neural networks\nhave led to many successes and new capabilities in computer vision, speech\nrecognition, language processing, game-playing, and robotics, their potential\nfor broad application remains limited by several factors.\n  A concerning limitation is that even the most successful of today's AI\nsystems suffer from brittleness-they can fail in unexpected ways when faced\nwith situations that differ sufficiently from ones they have been trained on.\nThis lack of robustness also appears in the vulnerability of AI systems to\nadversarial attacks, in which an adversary can subtly manipulate data in a way\nto guarantee a specific wrong answer or action from an AI system. AI systems\nalso can absorb biases-based on gender, race, or other factors-from their\ntraining data and further magnify these biases in their subsequent\ndecision-making. Taken together, these various limitations have prevented AI\nsystems such as automatic medical diagnosis or autonomous vehicles from being\nsufficiently trustworthy for wide deployment. The massive proliferation of AI\nacross society will require radically new ideas to yield technology that will\nnot sacrifice our productivity, our quality of life, or our values.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d077a47f2ed077f294f50ec5e990939c2ea8fe6f",
      "published_date": "2020-12-11",
      "downloaded_date": "2025-02-01",
      "filename": "Jenkins-Next Wave Artificial Intelligence Robust Explainable Adaptable Ethical and Accountable.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.06058v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2202.09292v1": {
      "title": "System Safety and Artificial Intelligence",
      "authors": [
        "Roel I. J. Dobbe"
      ],
      "abstract": "This chapter formulates seven lessons for preventing harm in artificial\nintelligence (AI) systems based on insights from the field of system safety for\nsoftware-based automation in safety-critical domains. New applications of AI\nacross societal domains and public organizations and infrastructures come with\nnew hazards, which lead to new forms of harm, both grave and pernicious. The\ntext addresses the lack of consensus for diagnosing and eliminating new AI\nsystem hazards. For decades, the field of system safety has dealt with\naccidents and harm in safety-critical systems governed by varying degrees of\nsoftware-based automation and decision-making. This field embraces the core\nassumption of systems and control that AI systems cannot be safeguarded by\ntechnical design choices on the model or algorithm alone, instead requiring an\nend-to-end hazard analysis and design frame that includes the context of use,\nimpacted stakeholders and the formal and informal institutional environment in\nwhich the system operates. Safety and other values are then inherently\nsocio-technical and emergent system properties that require design and control\nmeasures to instantiate these across the technical, social and institutional\ncomponents of a system. This chapter honors system safety pioneer Nancy\nLeveson, by situating her core lessons for today's AI system safety challenges.\nFor every lesson, concrete tools are offered for rethinking and reorganizing\nthe safety management of AI systems, both in design and governance. This\nhistory tells us that effective AI safety management requires transdisciplinary\napproaches and a shared language that allows involvement of all levels of\nsociety.",
      "citation_count": 28,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/292d5fffe591d08702e8ddbe741d6f6e3b748cc2",
      "published_date": "2022-02-18",
      "downloaded_date": "2025-02-01",
      "filename": "Dobbe-System Safety and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.09292v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SE",
        "cs.SY"
      ]
    },
    "1905.10083v1": {
      "title": "Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing",
      "authors": [
        "Zhi Zhou",
        "Xu Chen",
        "En Li",
        "Liekang Zeng",
        "Ke Luo",
        "Junshan Zhang"
      ],
      "abstract": "With the breakthroughs in deep learning, the recent years have witnessed a\nbooming of artificial intelligence (AI) applications and services, spanning\nfrom personal assistant to recommendation systems to video/audio surveillance.\nMore recently, with the proliferation of mobile computing and\nInternet-of-Things (IoT), billions of mobile and IoT devices are connected to\nthe Internet, generating zillions Bytes of data at the network edge. Driving by\nthis trend, there is an urgent need to push the AI frontiers to the network\nedge so as to fully unleash the potential of the edge big data. To meet this\ndemand, edge computing, an emerging paradigm that pushes computing tasks and\nservices from the network core to the network edge, has been widely recognized\nas a promising solution. The resulted new inter-discipline, edge AI or edge\nintelligence, is beginning to receive a tremendous amount of interest. However,\nresearch on edge intelligence is still in its infancy stage, and a dedicated\nvenue for exchanging the recent advances of edge intelligence is highly desired\nby both the computer system and artificial intelligence communities. To this\nend, we conduct a comprehensive survey of the recent research efforts on edge\nintelligence. Specifically, we first review the background and motivation for\nartificial intelligence running at the network edge. We then provide an\noverview of the overarching architectures, frameworks and emerging key\ntechnologies for deep learning model towards training/inference at the network\nedge. Finally, we discuss future research opportunities on edge intelligence.\nWe believe that this survey will elicit escalating attentions, stimulate\nfruitful discussions and inspire further research ideas on edge intelligence.",
      "citation_count": 1331,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/928cd808aba140ec298508df87c5579811ff2f41",
      "published_date": "2019-05-24",
      "downloaded_date": "2025-02-01",
      "filename": "Zhou-Edge Intelligence Paving the Last Mile of Artificial Intelligence with Edge Computing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1905.10083v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI"
      ]
    },
    "2106.11022v1": {
      "title": "Hard Choices in Artificial Intelligence",
      "authors": [
        "Roel Dobbe",
        "Thomas Krendl Gilbert",
        "Yonatan Mintz"
      ],
      "abstract": "As AI systems are integrated into high stakes social domains, researchers now\nexamine how to design and operate them in a safe and ethical manner. However,\nthe criteria for identifying and diagnosing safety risks in complex social\ncontexts remain unclear and contested. In this paper, we examine the vagueness\nin debates about the safety and ethical behavior of AI systems. We show how\nthis vagueness cannot be resolved through mathematical formalism alone, instead\nrequiring deliberation about the politics of development as well as the context\nof deployment. Drawing from a new sociotechnical lexicon, we redefine vagueness\nin terms of distinct design challenges at key stages in AI system development.\nThe resulting framework of Hard Choices in Artificial Intelligence (HCAI)\nempowers developers by 1) identifying points of overlap between design\ndecisions and major sociotechnical challenges; 2) motivating the creation of\nstakeholder feedback channels so that safety issues can be exhaustively\naddressed. As such, HCAI contributes to a timely debate about the status of AI\ndevelopment in democratic societies, arguing that deliberation should be the\ngoal of AI Safety, not just the procedure by which it is ensured.",
      "citation_count": 46,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d11217e882e54fc3dfe948fa102555f75d0c80bc",
      "published_date": "2021-06-10",
      "downloaded_date": "2025-02-01",
      "filename": "Dobbe-Hard Choices in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2106.11022v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "I.2; K.4"
      ]
    },
    "2211.00065v1": {
      "title": "Artificial Intelligence and Arms Control",
      "authors": [
        "Paul Scharre",
        "Megan Lamberth"
      ],
      "abstract": "Potential advancements in artificial intelligence (AI) could have profound\nimplications for how countries research and develop weapons systems, and how\nmilitaries deploy those systems on the battlefield. The idea of AI-enabled\nmilitary systems has motivated some activists to call for restrictions or bans\non some weapon systems, while others have argued that AI may be too diffuse to\ncontrol. This paper argues that while a ban on all military applications of AI\nis likely infeasible, there may be specific cases where arms control is\npossible. Throughout history, the international community has attempted to ban\nor regulate weapons or military systems for a variety of reasons. This paper\nanalyzes both successes and failures and offers several criteria that seem to\ninfluence why arms control works in some cases and not others. We argue that\nsuccess or failure depends on the desirability (i.e., a weapon's military value\nversus its perceived horribleness) and feasibility (i.e., sociopolitical\nfactors that influence its success) of arms control. Based on these criteria,\nand the historical record of past attempts at arms control, we analyze the\npotential for AI arms control in the future and offer recommendations for what\npolicymakers can do today.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/610e21c06d9d8595c5db24b0e9a70cffce41076a",
      "published_date": "2022-10-22",
      "downloaded_date": "2025-02-01",
      "filename": "Scharre-Artificial Intelligence and Arms Control.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.00065v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2311.12816v1": {
      "title": "Evolution of Convolutional Neural Network (CNN): Compute vs Memory bandwidth for Edge AI",
      "authors": [
        "Dwith Chenna"
      ],
      "abstract": "Convolutional Neural Networks (CNNs) have greatly influenced the field of\nEmbedded Vision and Edge Artificial Intelligence (AI), enabling powerful\nmachine learning capabilities on resource-constrained devices. This article\nexplores the relationship between CNN compute requirements and memory bandwidth\nin the context of Edge AI. We delve into the historical progression of CNN\narchitectures, from the early pioneering models to the current state-of-the-art\ndesigns, highlighting the advancements in compute-intensive operations. We\nexamine the impact of increasing model complexity on both computational\nrequirements and memory access patterns. The paper presents a comparison\nanalysis of the evolving trade-off between compute demands and memory bandwidth\nrequirements in CNNs. This analysis provides insights into designing efficient\narchitectures and potential hardware accelerators in enhancing CNN performance\non edge devices.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b94ff9b907f6c66c5406c9523506268fcf8c6005",
      "published_date": "2023-09-24",
      "downloaded_date": "2025-02-01",
      "filename": "Chenna-Evolution of Convolutional Neural Network CNN Compute vs Memory bandwidth for Edge AI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.12816v1",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    "2107.01238v1": {
      "title": "Solving Machine Learning Problems",
      "authors": [
        "Sunny Tran",
        "Pranav Krishna",
        "Ishan Pakuwal",
        "Prabhakar Kafle",
        "Nikhil Singh",
        "Jayson Lynch",
        "Iddo Drori"
      ],
      "abstract": "Can a machine learn Machine Learning? This work trains a machine learning\nmodel to solve machine learning problems from a University undergraduate level\ncourse. We generate a new training set of questions and answers consisting of\ncourse exercises, homework, and quiz questions from MIT's 6.036 Introduction to\nMachine Learning course and train a machine learning model to answer these\nquestions. Our system demonstrates an overall accuracy of 96% for open-response\nquestions and 97% for multiple-choice questions, compared with MIT students'\naverage of 93%, achieving grade A performance in the course, all in real-time.\nQuestions cover all 12 topics taught in the course, excluding coding questions\nor questions with images. Topics include: (i) basic machine learning\nprinciples; (ii) perceptrons; (iii) feature extraction and selection; (iv)\nlogistic regression; (v) regression; (vi) neural networks; (vii) advanced\nneural networks; (viii) convolutional neural networks; (ix) recurrent neural\nnetworks; (x) state machines and MDPs; (xi) reinforcement learning; and (xii)\ndecision trees. Our system uses Transformer models within an encoder-decoder\narchitecture with graph and tree representations. An important aspect of our\napproach is a data-augmentation scheme for generating new example problems. We\nalso train a machine learning model to generate problem hints. Thus, our system\nautomatically generates new questions across topics, answers both open-response\nquestions and multiple-choice questions, classifies problems, and generates\nproblem hints, pushing the envelope of AI for STEM education.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f33961e2a4d608be89692478a4dbb89ce635cecb",
      "published_date": "2021-07-02",
      "downloaded_date": "2025-02-01",
      "filename": "Tran-Solving Machine Learning Problems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.01238v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2412.06820v1": {
      "title": "Artificial Intelligence without Restriction Surpassing Human Intelligence with Probability One: Theoretical Insight into Secrets of the Brain with AI Twins of the Brain",
      "authors": [
        "Guang-Bin Huang",
        "M. Brandon Westover",
        "Eng-King Tan",
        "Haibo Wang",
        "Dongshun Cui",
        "Wei-Ying Ma",
        "Tiantong Wang",
        "Qi He",
        "Haikun Wei",
        "Ning Wang",
        "Qiyuan Tian",
        "Kwok-Yan Lam",
        "Xin Yao",
        "Tien Yin Wong"
      ],
      "abstract": "Artificial Intelligence (AI) has apparently become one of the most important\ntechniques discovered by humans in history while the human brain is widely\nrecognized as one of the most complex systems in the universe. One fundamental\ncritical question which would affect human sustainability remains open: Will\nartificial intelligence (AI) evolve to surpass human intelligence in the\nfuture? This paper shows that in theory new AI twins with fresh cellular level\nof AI techniques for neuroscience could approximate the brain and its\nfunctioning systems (e.g. perception and cognition functions) with any expected\nsmall error and AI without restrictions could surpass human intelligence with\nprobability one in the end. This paper indirectly proves the validity of the\nconjecture made by Frank Rosenblatt 70 years ago about the potential\ncapabilities of AI, especially in the realm of artificial neural networks.\nIntelligence is just one of fortuitous but sophisticated creations of the\nnature which has not been fully discovered. Like mathematics and physics, with\nno restrictions artificial intelligence would lead to a new subject with its\nself-contained systems and principles. We anticipate that this paper opens new\ndoors for 1) AI twins and other AI techniques to be used in cellular level of\nefficient neuroscience dynamic analysis, functioning analysis of the brain and\nbrain illness solutions; 2) new worldwide collaborative scheme for\ninterdisciplinary teams concurrently working on and modelling different types\nof neurons and synapses and different level of functioning subsystems of the\nbrain with AI techniques; 3) development of low energy of AI techniques with\nthe aid of fundamental neuroscience properties; and 4) new controllable,\nexplainable and safe AI techniques with reasoning capabilities of discovering\nprinciples in nature.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/caa693d9a55244e761ce7c57da2f33a193577d65",
      "published_date": "2024-12-04",
      "downloaded_date": "2025-02-01",
      "filename": "Huang-Artificial Intelligence without Restriction Surpassing Human Intelligence with Probability One Theor....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.06820v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2104.06735v1": {
      "title": "Enabling Machine Learning Algorithms for Credit Scoring -- Explainable Artificial Intelligence (XAI) methods for clear understanding complex predictive models",
      "authors": [
        "PrzemysÅaw Biecek",
        "Marcin Chlebus",
        "Janusz Gajda",
        "Alicja Gosiewska",
        "Anna Kozak",
        "Dominik Ogonowski",
        "Jakub Sztachelski",
        "Piotr Wojewnik"
      ],
      "abstract": "Rapid development of advanced modelling techniques gives an opportunity to\ndevelop tools that are more and more accurate. However as usually, everything\ncomes with a price and in this case, the price to pay is to loose\ninterpretability of a model while gaining on its accuracy and precision. For\nmanagers to control and effectively manage credit risk and for regulators to be\nconvinced with model quality the price to pay is too high. In this paper, we\nshow how to take credit scoring analytics in to the next level, namely we\npresent comparison of various predictive models (logistic regression, logistic\nregression with weight of evidence transformations and modern artificial\nintelligence algorithms) and show that advanced tree based models give best\nresults in prediction of client default. What is even more important and\nvaluable we also show how to boost advanced models using techniques which allow\nto interpret them and made them more accessible for credit risk practitioners,\nresolving the crucial obstacle in widespread deployment of more complex, 'black\nbox' models like random forests, gradient boosted or extreme gradient boosted\ntrees. All this will be shown on the large dataset obtained from the Polish\nCredit Bureau to which all the banks and most of the lending companies in the\ncountry do report the credit files. In this paper the data from lending\ncompanies were used. The paper then compares state of the art best practices in\ncredit risk modelling with new advanced modern statistical tools boosted by the\nlatest developments in the field of interpretability and explainability of\nartificial intelligence algorithms. We believe that this is a valuable\ncontribution when it comes to presentation of different modelling tools but\nwhat is even more important it is showing which methods might be used to get\ninsight and understanding of AI methods in credit risk context.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-04-14",
      "downloaded_date": "2025-02-01",
      "filename": "Biecek-Enabling Machine Learning Algorithms for Credit Scoring -- Explainable Artificial Intelligence XAI m....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.06735v1",
      "categories": [
        "q-fin.RM",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2102.03406v2": {
      "title": "Symbolic Behaviour in Artificial Intelligence",
      "authors": [
        "Adam Santoro",
        "Andrew Lampinen",
        "Kory Mathewson",
        "Timothy Lillicrap",
        "David Raposo"
      ],
      "abstract": "The ability to use symbols is the pinnacle of human intelligence, but has yet\nto be fully replicated in machines. Here we argue that the path towards\nsymbolically fluent artificial intelligence (AI) begins with a reinterpretation\nof what symbols are, how they come to exist, and how a system behaves when it\nuses them. We begin by offering an interpretation of symbols as entities whose\nmeaning is established by convention. But crucially, something is a symbol only\nfor those who demonstrably and actively participate in this convention. We then\noutline how this interpretation thematically unifies the behavioural traits\nhumans exhibit when they use symbols. This motivates our proposal that the\nfield place a greater emphasis on symbolic behaviour rather than particular\ncomputational mechanisms inspired by more restrictive interpretations of\nsymbols. Finally, we suggest that AI research explore social and cultural\nengagement as a tool to develop the cognitive machinery necessary for symbolic\nbehaviour to emerge. This approach will allow for AI to interpret something as\nsymbolic on its own rather than simply manipulate things that are only symbols\nto human onlookers, and thus will ultimately lead to AI with more human-like\nsymbolic fluency.",
      "citation_count": 33,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/be09ed6cd73654a23f78416433a1b23ea623ea79",
      "published_date": "2021-02-05",
      "downloaded_date": "2025-02-01",
      "filename": "Santoro-Symbolic Behaviour in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.03406v2",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2108.02814v1": {
      "title": "Potential Applications of Artificial Intelligence and Machine Learning in Radiochemistry and Radiochemical Engineering",
      "authors": [
        "E. William Webb",
        "Peter J. H. Scott"
      ],
      "abstract": "Artificial intelligence and machine learning are poised to disrupt PET\nimaging from bench to clinic. In this perspective we offer insights into how\nthe technology could be applied to improve the design and synthesis of new\nradiopharmaceuticals for PET imaging, including identification of an optimal\nlabeling approach as well as strategies for radiolabeling reaction\noptimization.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-08-05",
      "downloaded_date": "2025-02-01",
      "filename": "Webb-Potential Applications of Artificial Intelligence and Machine Learning in Radiochemistry and Radioch....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.02814v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2309.12177v2": {
      "title": "Explainable Artificial Intelligence for Drug Discovery and Development -- A Comprehensive Survey",
      "authors": [
        "Roohallah Alizadehsani",
        "Solomon Sunday Oyelere",
        "Sadiq Hussain",
        "Rene Ripardo Calixto",
        "Victor Hugo C. de Albuquerque",
        "Mohamad Roshanzamir",
        "Mohamed Rahouti",
        "Senthil Kumar Jagatheesaperumal"
      ],
      "abstract": "The field of drug discovery has experienced a remarkable transformation with\nthe advent of artificial intelligence (AI) and machine learning (ML)\ntechnologies. However, as these AI and ML models are becoming more complex,\nthere is a growing need for transparency and interpretability of the models.\nExplainable Artificial Intelligence (XAI) is a novel approach that addresses\nthis issue and provides a more interpretable understanding of the predictions\nmade by machine learning models. In recent years, there has been an increasing\ninterest in the application of XAI techniques to drug discovery. This review\narticle provides a comprehensive overview of the current state-of-the-art in\nXAI for drug discovery, including various XAI methods, their application in\ndrug discovery, and the challenges and limitations of XAI techniques in drug\ndiscovery. The article also covers the application of XAI in drug discovery,\nincluding target identification, compound design, and toxicity prediction.\nFurthermore, the article suggests potential future research directions for the\napplication of XAI in drug discovery. The aim of this review article is to\nprovide a comprehensive understanding of the current state of XAI in drug\ndiscovery and its potential to transform the field.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-09-21",
      "downloaded_date": "2025-02-01",
      "filename": "Alizadehsani-Explainable Artificial Intelligence for Drug Discovery and Development -- A Comprehensive Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.12177v2",
      "categories": [
        "cs.AI",
        "I.2.0"
      ]
    },
    "2003.09744v1": {
      "title": "Towards an Enterprise-Ready Implementation of Artificial Intelligence-Enabled, Blockchain-Based Smart Contracts",
      "authors": [
        "Philipp Brune"
      ],
      "abstract": "Blockchain technology and artificial intelligence (AI) are current hot topics\nin research and practice. However, the potentials of their combination have\nbeen studied just recently to a larger extend. While different use cases for\ncombining AI and blockchain have been discussed, the idea of enabling\nblockchain-based smart contracts to perform \"smarter\" decisions by using AI or\nmachine learning (ML) models has only been considered on the conceptual level\nso far. It remained open, how such AI-enabled smart contracts could be\nimplemented in a robust way for real-world applications. Therefore, in this\npaper a new, enterprise-class implementation of AI-enabled smart contracts is\npresented and first insights regarding its feasibility are discussed.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-03-21",
      "downloaded_date": "2025-02-01",
      "filename": "Brune-Towards an Enterprise-Ready Implementation of Artificial Intelligence-Enabled Blockchain-Based Smart....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2003.09744v1",
      "categories": [
        "cs.DC",
        "cs.CR"
      ]
    },
    "2204.11405v1": {
      "title": "Adaptive cognitive fit: Artificial intelligence augmented management of information facets and representations",
      "authors": [
        "Jim Samuel",
        "Rajiv Kashyap",
        "Yana Samuel",
        "Alexander Pelaez"
      ],
      "abstract": "Explosive growth in big data technologies and artificial intelligence [AI]\napplications have led to increasing pervasiveness of information facets and a\nrapidly growing array of information representations. Information facets, such\nas equivocality and veracity, can dominate and significantly influence human\nperceptions of information and consequently affect human performance. Extant\nresearch in cognitive fit, which preceded the big data and AI era, focused on\nthe effects of aligning information representation and task on performance,\nwithout sufficient consideration to information facets and attendant cognitive\nchallenges. Therefore, there is a compelling need to understand the interplay\nof these dominant information facets with information representations and\ntasks, and their influence on human performance. We suggest that artificially\nintelligent technologies that can adapt information representations to overcome\ncognitive limitations are necessary for these complex information environments.\nTo this end, we propose and test a novel *Adaptive Cognitive Fit* [ACF]\nframework that explains the influence of information facets and AI-augmented\ninformation representations on human performance. We draw on information\nprocessing theory and cognitive dissonance theory to advance the ACF framework\nand a set of propositions. We empirically validate the ACF propositions with an\neconomic experiment that demonstrates the influence of information facets, and\na machine learning simulation that establishes the viability of using AI to\nimprove human performance.",
      "citation_count": 42,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/855005ed08b08e4d1c8521a8670c45870b5699f5",
      "published_date": "2022-04-25",
      "downloaded_date": "2025-02-01",
      "filename": "Samuel-Adaptive cognitive fit Artificial intelligence augmented management of information facets and repres....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2204.11405v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.IT",
        "cs.SI",
        "math.IT"
      ]
    },
    "2207.00091v1": {
      "title": "Threat Assessment in Machine Learning based Systems",
      "authors": [
        "Lionel Nganyewou Tidjon",
        "Foutse Khomh"
      ],
      "abstract": "Machine learning is a field of artificial intelligence (AI) that is becoming\nessential for several critical systems, making it a good target for threat\nactors. Threat actors exploit different Tactics, Techniques, and Procedures\n(TTPs) against the confidentiality, integrity, and availability of Machine\nLearning (ML) systems. During the ML cycle, they exploit adversarial TTPs to\npoison data and fool ML-based systems. In recent years, multiple security\npractices have been proposed for traditional systems but they are not enough to\ncope with the nature of ML-based systems. In this paper, we conduct an\nempirical study of threats reported against ML-based systems with the aim to\nunderstand and characterize the nature of ML threats and identify common\nmitigation strategies. The study is based on 89 real-world ML attack scenarios\nfrom the MITRE's ATLAS database, the AI Incident Database, and the literature;\n854 ML repositories from the GitHub search and the Python Packaging Advisory\ndatabase, selected based on their reputation. Attacks from the AI Incident\nDatabase and the literature are used to identify vulnerabilities and new types\nof threats that were not documented in ATLAS. Results show that convolutional\nneural networks were one of the most targeted models among the attack\nscenarios. ML repositories with the largest vulnerability prominence include\nTensorFlow, OpenCV, and Notebook. In this paper, we also report the most\nfrequent vulnerabilities in the studied ML repositories, the most targeted ML\nphases and models, the most used TTPs in ML phases and attack scenarios. This\ninformation is particularly important for red/blue teams to better conduct\nattacks/defenses, for practitioners to prevent threats during ML development,\nand for researchers to develop efficient defense mechanisms.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7b169cea0815daab069606e4a5f21fedf6ee35cf",
      "published_date": "2022-06-30",
      "downloaded_date": "2025-02-01",
      "filename": "Tidjon-Threat Assessment in Machine Learning based Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2207.00091v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2012.06310v1": {
      "title": "Artificial Intelligence for COVID-19 Detection -- A state-of-the-art review",
      "authors": [
        "Parsa Sarosh",
        "Shabir A. Parah",
        "Romany F Mansur",
        "G. M. Bhat"
      ],
      "abstract": "The emergence of COVID-19 has necessitated many efforts by the scientific\ncommunity for its proper management. An urgent clinical reaction is required in\nthe face of the unending devastation being caused by the pandemic. These\nefforts include technological innovations for improvement in screening,\ntreatment, vaccine development, contact tracing and, survival prediction. The\nuse of Deep Learning (DL) and Artificial Intelligence (AI) can be sought in all\nof the above-mentioned spheres. This paper aims to review the role of Deep\nLearning and Artificial intelligence in various aspects of the overall COVID-19\nmanagement and particularly for COVID-19 detection and classification. The DL\nmodels are developed to analyze clinical modalities like CT scans and X-Ray\nimages of patients and predict their pathological condition. A DL model aims to\ndetect the COVID-19 pneumonia, classify and distinguish between COVID-19,\nCommunity-Acquired Pneumonia (CAP), Viral and Bacterial pneumonia, and normal\nconditions. Furthermore, sophisticated models can be built to segment the\naffected area in the lungs and quantify the infection volume for a better\nunderstanding of the extent of damage. Many models have been developed either\nindependently or with the help of pre-trained models like VGG19, ResNet50, and\nAlexNet leveraging the concept of transfer learning. Apart from model\ndevelopment, data preprocessing and augmentation are also performed to cope\nwith the challenge of insufficient data samples often encountered in medical\napplications. It can be evaluated that DL and AI can be effectively implemented\nto withstand the challenges posed by the global emergency",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-11-25",
      "downloaded_date": "2025-02-01",
      "filename": "Sarosh-Artificial Intelligence for COVID-19 Detection -- A state-of-the-art review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.06310v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    "2403.18929v1": {
      "title": "A Review of Neuroscience-Inspired Machine Learning",
      "authors": [
        "Alexander Ororbia",
        "Ankur Mali",
        "Adam Kohan",
        "Beren Millidge",
        "Tommaso Salvatori"
      ],
      "abstract": "One major criticism of deep learning centers around the biological\nimplausibility of the credit assignment schema used for learning --\nbackpropagation of errors. This implausibility translates into practical\nlimitations, spanning scientific fields, including incompatibility with\nhardware and non-differentiable implementations, thus leading to expensive\nenergy requirements. In contrast, biologically plausible credit assignment is\ncompatible with practically any learning condition and is energy-efficient. As\na result, it accommodates hardware and scientific modeling, e.g. learning with\nphysical systems and non-differentiable behavior. Furthermore, it can lead to\nthe development of real-time, adaptive neuromorphic processing systems. In\naddressing this problem, an interdisciplinary branch of artificial intelligence\nresearch that lies at the intersection of neuroscience, cognitive science, and\nmachine learning has emerged. In this paper, we survey several vital algorithms\nthat model bio-plausible rules of credit assignment in artificial neural\nnetworks, discussing the solutions they provide for different scientific fields\nas well as their advantages on CPUs, GPUs, and novel implementations of\nneuromorphic hardware. We conclude by discussing the future challenges that\nwill need to be addressed in order to make such algorithms more useful in\npractical applications.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0586bffa0c06b3980713b9e249b8ff94e26c84f2",
      "published_date": "2024-02-16",
      "downloaded_date": "2025-02-01",
      "filename": "Ororbia-A Review of Neuroscience-Inspired Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.18929v1",
      "categories": [
        "cs.NE",
        "cs.LG"
      ]
    },
    "2004.06154v1": {
      "title": "An Efficient UAV-based Artificial Intelligence Framework for Real-Time Visual Tasks",
      "authors": [
        "Enkhtogtokh Togootogtokh",
        "Christian Micheloni",
        "Gian Luca Foresti",
        "Niki Martinel"
      ],
      "abstract": "Modern Unmanned Aerial Vehicles equipped with state of the art artificial\nintelligence (AI) technologies are opening to a wide plethora of novel and\ninteresting applications. While this field received a strong impact from the\nrecent AI breakthroughs, most of the provided solutions either entirely rely on\ncommercial software or provide a weak integration interface which denies the\ndevelopment of additional techniques. This leads us to propose a novel and\nefficient framework for the UAV-AI joint technology. Intelligent UAV systems\nencounter complex challenges to be tackled without human control. One of these\ncomplex challenges is to be able to carry out computer vision tasks in\nreal-time use cases. In this paper we focus on this challenge and introduce a\nmulti-layer AI (MLAI) framework to allow easy integration of ad-hoc\nvisual-based AI applications. To show its features and its advantages, we\nimplemented and evaluated different modern visual-based deep learning models\nfor object detection, target tracking and target handover.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/37ffc5d1699550fa7528fe08c75d5e6e3d3d81cd",
      "published_date": "2020-04-13",
      "downloaded_date": "2025-02-01",
      "filename": "Togootogtokh-An Efficient UAV-based Artificial Intelligence Framework for Real-Time Visual Tasks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.06154v1",
      "categories": [
        "cs.CV",
        "cs.RO"
      ]
    },
    "1912.09764v1": {
      "title": "An Artificial Intelligence approach to Shadow Rating",
      "authors": [
        "Angela Rita Provenzano",
        "Daniele TrifirÃ²",
        "Nicola Jean",
        "Giacomo Le Pera",
        "Maurizio Spadaccino",
        "Luca Massaron",
        "Claudio Nordio"
      ],
      "abstract": "We analyse the effectiveness of modern deep learning techniques in predicting\ncredit ratings over a universe of thousands of global corporate entities\nobligations when compared to most popular, traditional machine-learning\napproaches such as linear models and tree-based classifiers. Our results show a\nadequate accuracy over different rating classes when applying categorical\nembeddings to artificial neural networks (ANN) architectures.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d853dcdad518d6b98f8d3b8e4a8456bb6aa1111a",
      "published_date": "2019-12-20",
      "downloaded_date": "2025-02-01",
      "filename": "Provenzano-An Artificial Intelligence approach to Shadow Rating.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1912.09764v1",
      "categories": [
        "q-fin.RM",
        "cs.LG",
        "62M45, 91G40"
      ]
    },
    "2404.10296v5": {
      "title": "Interpolating neural network: A novel unification of machine learning and interpolation theory",
      "authors": [
        "Chanwook Park",
        "Sourav Saha",
        "Jiachen Guo",
        "Hantao Zhang",
        "Xiaoyu Xie",
        "Miguel A. Bessa",
        "Dong Qian",
        "Wei Chen",
        "Gregory J. Wagner",
        "Jian Cao",
        "Wing Kam Liu"
      ],
      "abstract": "Artificial intelligence (AI) has revolutionized software development,\nshifting from task-specific codes (Software 1.0) to neural network-based\napproaches (Software 2.0). However, applying this transition in engineering\nsoftware presents challenges, including low surrogate model accuracy, the curse\nof dimensionality in inverse design, and rising complexity in physical\nsimulations. We introduce an interpolating neural network (INN), grounded in\ninterpolation theory and tensor decomposition, to realize Engineering Software\n2.0 by advancing data training, partial differential equation solving, and\nparameter calibration. INN offers orders of magnitude fewer trainable/solvable\nparameters for comparable model accuracy than traditional multi-layer\nperceptron (MLP) or physics-informed neural networks (PINN). Demonstrated in\nmetal additive manufacturing, INN rapidly constructs an accurate surrogate\nmodel of Laser Powder Bed Fusion (L-PBF) heat transfer simulation, achieving\nsub-10-micrometer resolution for a 10 mm path in under 15 minutes on a single\nGPU. This makes a transformative step forward across all domains essential to\nengineering software.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/87435ff08442989df630610cd45fe37494d1de71",
      "published_date": "2024-04-16",
      "downloaded_date": "2025-02-01",
      "filename": "Park-Interpolating neural network A novel unification of machine learning and interpolation theory.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.10296v5",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ]
    },
    "2308.05315v1": {
      "title": "An Overview of the 3GPP Study on Artificial Intelligence for 5G New Radio",
      "authors": [
        "Xingqin Lin"
      ],
      "abstract": "Air interface is a fundamental component within any wireless communication\nsystem. In Release 18, the 3rd Generation Partnership Project (3GPP) delves\ninto the possibilities of leveraging artificial intelligence (AI)/machine\nlearning (ML) to improve the performance of the fifth-generation (5G) New Radio\n(NR) air interface. This endeavor marks a pioneering stride within 3GPP's\njourney in shaping wireless communication standards. This article offers a\ncomprehensive overview of the pivotal themes explored by 3GPP in this domain.\nEncompassing a general framework for AI/ML and specific use cases such as\nchannel state information feedback, beam management, and positioning, it\nprovides a holistic perspective. Moreover, we highlight the potential\ntrajectory of AI/ML for the NR air interface in 3GPP Release 19, a pathway that\npaves the journey towards the sixth generation (6G) wireless communication\nsystems that will feature integrated AI and communication as a key usage\nscenario.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b64d62103efa7380e2d93876892f77fa3aeb784b",
      "published_date": "2023-08-10",
      "downloaded_date": "2025-02-01",
      "filename": "Lin-An Overview of the 3GPP Study on Artificial Intelligence for 5G New Radio.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.05315v1",
      "categories": [
        "cs.NI",
        "eess.SP"
      ]
    },
    "2302.05266v1": {
      "title": "On the Applicability of Explainable Artificial Intelligence for Software Requirement Analysis",
      "authors": [
        "Behnaz Jamasb",
        "Reza Akbari",
        "Seyed Raouf Khayami"
      ],
      "abstract": "The applications of Artificial Intelligence (AI) methods especially machine\nlearning techniques have increased in recent years. Classification algorithms\nhave been successfully applied to different problems such as requirement\nclassification. Although these algorithms have good performance, most of them\ncannot explain how they make a decision. Explainable Artificial Intelligence\n(XAI) is a set of new techniques that explain the predictions of machine\nlearning algorithms. In this work, the applicability of XAI for software\nrequirement classification is studied. An explainable software requirement\nclassifier is presented using the LIME algorithm. The explainability of the\nproposed method is studied by applying it to the PROMISE software requirement\ndataset. The results show that XAI can help the analyst or requirement\nspecifier to better understand why a specific requirement is classified as\nfunctional or non-functional. The important keywords for such decisions are\nidentified and analyzed in detail. The experimental study shows that the XAI\ncan be used to help analysts and requirement specifiers to better understand\nthe predictions of the classifiers for categorizing software requirements.\nAlso, the effect of the XAI on feature reduction is analyzed. The results\nshowed that the XAI model has a positive role in feature analysis.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/46dd34ae1d59bd0efb2122dfa82d5e72b3985ad3",
      "published_date": "2023-02-10",
      "downloaded_date": "2025-02-01",
      "filename": "Jamasb-On the Applicability of Explainable Artificial Intelligence for Software Requirement Analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.05266v1",
      "categories": [
        "cs.SE"
      ]
    },
    "2407.12058v1": {
      "title": "Explainable artificial intelligence in breast cancer detection and risk prediction: A systematic scoping review",
      "authors": [
        "Amirehsan Ghasemi",
        "Soheil Hashtarkhani",
        "David L Schwartz",
        "Arash Shaban-Nejad"
      ],
      "abstract": "With the advances in artificial intelligence (AI), data-driven algorithms are\nbecoming increasingly popular in the medical domain. However, due to the\nnonlinear and complex behavior of many of these algorithms, decision-making by\nsuch algorithms is not trustworthy for clinicians and is considered a black-box\nprocess. Hence, the scientific community has introduced explainable artificial\nintelligence (XAI) to remedy the problem. This systematic scoping review\ninvestigates the application of XAI in breast cancer detection and risk\nprediction. We conducted a comprehensive search on Scopus, IEEE Explore,\nPubMed, and Google Scholar (first 50 citations) using a systematic search\nstrategy. The search spanned from January 2017 to July 2023, focusing on\npeer-reviewed studies implementing XAI methods in breast cancer datasets.\nThirty studies met our inclusion criteria and were included in the analysis.\nThe results revealed that SHapley Additive exPlanations (SHAP) is the top\nmodel-agnostic XAI technique in breast cancer research in terms of usage,\nexplaining the model prediction results, diagnosis and classification of\nbiomarkers, and prognosis and survival analysis. Additionally, the SHAP model\nprimarily explained tree-based ensemble machine learning models. The most\ncommon reason is that SHAP is model agnostic, which makes it both popular and\nuseful for explaining any model prediction. Additionally, it is relatively easy\nto implement effectively and completely suits performant models, such as\ntree-based models. Explainable AI improves the transparency, interpretability,\nfairness, and trustworthiness of AI-enabled health systems and medical devices\nand, ultimately, the quality of care and outcomes.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/305546cb41590a9566f8c812bb9a0537b598981b",
      "published_date": "2024-07-12",
      "downloaded_date": "2025-02-01",
      "filename": "Ghasemi-Explainable artificial intelligence in breast cancer detection and risk prediction A systematic scop....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.12058v1",
      "categories": [
        "q-bio.QM",
        "eess.IV",
        "68T01"
      ]
    },
    "2407.16062v1": {
      "title": "Artificial Intelligence-based Decision Support Systems for Precision and Digital Health",
      "authors": [
        "Nina Deliu",
        "Bibhas Chakraborty"
      ],
      "abstract": "Precision health, increasingly supported by digital technologies, is a domain\nof research that broadens the paradigm of precision medicine, advancing\neveryday healthcare. This vision goes hand in hand with the groundbreaking\nadvent of artificial intelligence (AI), which is reshaping the way we diagnose,\ntreat, and monitor both clinical subjects and the general population. AI tools\npowered by machine learning have shown considerable improvements in a variety\nof healthcare domains. In particular, reinforcement learning (RL) holds great\npromise for sequential and dynamic problems such as dynamic treatment regimes\nand just-in-time adaptive interventions in digital health. In this work, we\ndiscuss the opportunity offered by AI, more specifically RL, to current trends\nin healthcare, providing a methodological survey of RL methods in the context\nof precision and digital health. Focusing on the area of adaptive\ninterventions, we expand the methodological survey with illustrative case\nstudies that used RL in real practice.\n  This invited article has undergone anonymous review and is intended as a book\nchapter for the volume \"Frontiers of Statistics and Data Science\" edited by\nSubhashis Ghoshal and Anindya Roy for the International Indian Statistical\nAssociation Series on Statistics and Data Science, published by Springer. It\ncovers the material from a short course titled \"Artificial Intelligence in\nPrecision and Digital Health\" taught by the author Bibhas Chakraborty at the\nIISA 2022 Conference, December 26-30 2022, at the Indian Institute of Science,\nBengaluru.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1f4565902d0000648f60d83b36cf28d6b6e27fc0",
      "published_date": "2024-07-22",
      "downloaded_date": "2025-02-01",
      "filename": "Deliu-Artificial Intelligence-based Decision Support Systems for Precision and Digital Health.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.16062v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2410.17471v1": {
      "title": "First Photon Machine Learning",
      "authors": [
        "Lili Li",
        "Santosh Kumar",
        "Malvika Garikapati",
        "Yu-Ping Huang"
      ],
      "abstract": "Quantum techniques are expected to revolutionize how information is acquired,\nexchanged, and processed. Yet it has been a challenge to realize and measure\ntheir values in practical settings. We present first photon machine learning as\na new paradigm of neural networks and establish the first unambiguous advantage\nof quantum effects for artificial intelligence. By extending the physics behind\nthe double-slit experiment for quantum particles to a many-slit version, our\nexperiment finds that a single photon can perform image recognition at around\n$30\\%$ fidelity, which beats by a large margin the theoretical limit of what a\nsimilar classical system can possibly achieve (about 24\\%). In this experiment,\nthe entire neural network is implemented in sub-attojoule optics and the\nequivalent per-calculation energy cost is below $10^{-24}$ joule, highlighting\nthe prospects of quantum optical machine learning for unparalleled advantages\nin speed, capacity, and energy efficiency.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5d640f7774e0ffce3ad92863e92a33ed9b758db8",
      "published_date": "2024-10-22",
      "downloaded_date": "2025-02-01",
      "filename": "Li-First Photon Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.17471v1",
      "categories": [
        "quant-ph",
        "physics.optics"
      ]
    },
    "1911.02648v2": {
      "title": "Textual analysis of artificial intelligence manuscripts reveals features associated with peer review outcome",
      "authors": [
        "Philippe Vincent-Lamarre",
        "Vincent LariviÃ¨re"
      ],
      "abstract": "We analysed a dataset of scientific manuscripts that were submitted to\nvarious conferences in artificial intelligence. We performed a combination of\nsemantic, lexical and psycholinguistic analyses of the full text of the\nmanuscripts and compared them with the outcome of the peer review process. We\nfound that accepted manuscripts scored lower than rejected manuscripts on two\nindicators of readability, and that they also used more scientific and\nartificial intelligence jargon. We also found that accepted manuscripts were\nwritten with words that are less frequent, that are acquired at an older age,\nand that are more abstract than rejected manuscripts. The analysis of\nreferences included in the manuscripts revealed that the subset of accepted\nsubmissions were more likely to cite the same publications. This finding was\nechoed by pairwise comparisons of the word content of the manuscripts (i.e. an\nindicator or semantic similarity), which were more similar in the subset of\naccepted manuscripts. Finally, we predicted the peer review outcome of\nmanuscripts with their word content, with words related to machine learning and\nneural networks positively related with acceptance, whereas words related to\nlogic, symbolic processing and knowledge-based systems negatively related with\nacceptance.",
      "citation_count": 18,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a559b255cf070d3f4bdaaae561513ec94746698f",
      "published_date": "2019-10-21",
      "downloaded_date": "2025-02-01",
      "filename": "Vincent-Lamarre-Textual analysis of artificial intelligence manuscripts reveals features associated with peer review....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.02648v2",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL"
      ]
    },
    "2108.03793v1": {
      "title": "Toward Human-Level Artificial Intelligence",
      "authors": [
        "Deokgun Park"
      ],
      "abstract": "In this paper, we present our research on programming human-level artificial\nintelligence (HLAI), including 1) a definition of HLAI, 2) an environment to\ndevelop and test HLAI, and 3) a cognitive architecture for HLAI. The term AI is\nused in a broad meaning, and HLAI is not clearly defined. I claim that the\nessence of Human-Level Intelligence to be the capability to learn from others'\nexperiences via language. The key is that the event described by language has\nthe same effect as if the agent experiences it firsthand for the update of the\nbehavior policy. To develop and test models with such a capability, we are\ndeveloping a simulated environment called SEDRo. There is a 3D Home, and a\nmother character takes care of the baby (the learning agent) and teaches\nlanguages. The environment provides comparable experiences to that of a human\nbaby from birth to one year. Finally, I propose a cognitive architecture of\nHLAI called Modulated Heterarchical Prediction Memory (mHPM). In mHPM, there\nare three components: a universal module that learns to predict the next vector\ngiven the sequence of vector signals, a heterarchical network of those modules,\nand a reward-based modulation of learning. mHPM models the workings of the\nneocortex but the innate auxiliary units such hippocampus, reward system,\ninstincts, and amygdala play critical roles, too.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/be9f9c7bc2f5e3ac99231045a1dac6af24940521",
      "published_date": "2021-08-09",
      "downloaded_date": "2025-02-01",
      "filename": "Park-Toward Human-Level Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.03793v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2303.17249v4": {
      "title": "Model-agnostic explainable artificial intelligence for object detection in image data",
      "authors": [
        "Milad Moradi",
        "Ke Yan",
        "David Colwell",
        "Matthias Samwald",
        "Rhona Asgari"
      ],
      "abstract": "In recent years, deep neural networks have been widely used for building\nhigh-performance Artificial Intelligence (AI) systems for computer vision\napplications. Object detection is a fundamental task in computer vision, which\nhas been greatly progressed through developing large and intricate AI models.\nHowever, the lack of transparency is a big challenge that may not allow the\nwidespread adoption of these models. Explainable artificial intelligence is a\nfield of research where methods are developed to help users understand the\nbehavior, decision logics, and vulnerabilities of AI systems. Previously, few\nexplanation methods were developed for object detection based on random\nmasking. However, random masks may raise some issues regarding the actual\nimportance of pixels within an image. In this paper, we design and implement a\nblack-box explanation method named Black-box Object Detection Explanation by\nMasking (BODEM) through adopting a hierarchical random masking approach for\nobject detection systems. We propose a hierarchical random masking framework in\nwhich coarse-grained masks are used in lower levels to find salient regions\nwithin an image, and fine-grained mask are used to refine the salient regions\nin higher levels. Experimentations on various object detection datasets and\nmodels showed that BODEM can effectively explain the behavior of object\ndetectors. Moreover, our method outperformed Detector Randomized Input Sampling\nfor Explanation (D-RISE) and Local Interpretable Model-agnostic Explanations\n(LIME) with respect to different quantitative measures of explanation\neffectiveness. The experimental results demonstrate that BODEM can be an\neffective method for explaining and validating object detection systems in\nblack-box testing scenarios.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/eef71d5db03c357220ccf4165de3e37951f74a12",
      "published_date": "2023-03-30",
      "downloaded_date": "2025-02-01",
      "filename": "Moradi-Model-agnostic explainable artificial intelligence for object detection in image data.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.17249v4",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "2302.10908v1": {
      "title": "Human-Centric Multimodal Machine Learning: Recent Advances and Testbed on AI-based Recruitment",
      "authors": [
        "Alejandro PeÃ±a",
        "Ignacio Serna",
        "Aythami Morales",
        "Julian Fierrez",
        "Alfonso Ortega",
        "Ainhoa Herrarte",
        "Manuel Alcantara",
        "Javier Ortega-Garcia"
      ],
      "abstract": "The presence of decision-making algorithms in society is rapidly increasing\nnowadays, while concerns about their transparency and the possibility of these\nalgorithms becoming new sources of discrimination are arising. There is a\ncertain consensus about the need to develop AI applications with a\nHuman-Centric approach. Human-Centric Machine Learning needs to be developed\nbased on four main requirements: (i) utility and social good; (ii) privacy and\ndata ownership; (iii) transparency and accountability; and (iv) fairness in\nAI-driven decision-making processes. All these four Human-Centric requirements\nare closely related to each other. With the aim of studying how current\nmultimodal algorithms based on heterogeneous sources of information are\naffected by sensitive elements and inner biases in the data, we propose a\nfictitious case study focused on automated recruitment: FairCVtest. We train\nautomatic recruitment algorithms using a set of multimodal synthetic profiles\nincluding image, text, and structured data, which are consciously scored with\ngender and racial biases. FairCVtest shows the capacity of the Artificial\nIntelligence (AI) behind automatic recruitment tools built this way (a common\npractice in many other application scenarios beyond recruitment) to extract\nsensitive information from unstructured data and exploit it in combination to\ndata biases in undesirable (unfair) ways. We present an overview of recent\nworks developing techniques capable of removing sensitive information and\nbiases from the decision-making process of deep learning architectures, as well\nas commonly used databases for fairness research in AI. We demonstrate how\nlearning approaches developed to guarantee privacy in latent spaces can lead to\nunbiased and fair automatic decision-making process.",
      "citation_count": 30,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/75658c78ecbeb8173761f57750c757c5c85d0bd8",
      "published_date": "2023-02-13",
      "downloaded_date": "2025-02-01",
      "filename": "PeÃ±a-Human-Centric Multimodal Machine Learning Recent Advances and Testbed on AI-based Recruitment.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.10908v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2407.08902v1": {
      "title": "Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Treatment of Autistic Children",
      "authors": [
        "Hossein Mohammadi Rouzbahani",
        "Hadis Karimipour"
      ],
      "abstract": "Autism Spectrum Disorder (ASD) represents a multifaceted neurodevelopmental\ncondition marked by difficulties in social interaction, communication\nimpediments, and repetitive behaviors. Despite progress in understanding ASD,\nits diagnosis and treatment continue to pose significant challenges due to the\nvariability in symptomatology and the necessity for multidisciplinary care\napproaches. This paper investigates the potential of Artificial Intelligence\n(AI) to augment the capabilities of healthcare professionals and caregivers in\nmanaging ASD. We have developed a sophisticated algorithm designed to analyze\nfacial and bodily expressions during daily activities of both autistic and\nnon-autistic children, leading to the development of a powerful deep\nlearning-based autism detection system. Our study demonstrated that AI models,\nspecifically the Xception and ResNet50V2 architectures, achieved high accuracy\nin diagnosing Autism Spectrum Disorder (ASD). This research highlights the\ntransformative potential of AI in improving the diagnosis, treatment, and\ncomprehensive management of ASD. Our study revealed that AI models, notably the\nXception and ResNet50V2 architectures, demonstrated high accuracy in diagnosing\nASD.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-07-12",
      "downloaded_date": "2025-02-01",
      "filename": "Rouzbahani-Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Trea....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.08902v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2012.10961v4": {
      "title": "Recent Developments in Detection of Central Serous Retinopathy through Imaging and Artificial Intelligence Techniques A Review",
      "authors": [
        "Syed Ale Hassan",
        "Shahzad Akbar",
        "Amjad Rehman",
        "Tanzila Saba",
        "Hoshang Kolivand",
        "Saeed Ali Bahaj"
      ],
      "abstract": "Central Serous Retinopathy (CSR) or Central Serous Chorioretinopathy (CSC) is\na significant disease that causes blindness and vision loss among millions of\npeople worldwide. It transpires as a result of accumulation of watery fluids\nbehind the retina. Therefore, detection of CSR at early stages allows\npreventive measures to avert any impairment to the human eye. Traditionally,\nseveral manual methods for detecting CSR have been developed in the past;\nhowever, they have shown to be imprecise and unreliable. Consequently,\nArtificial Intelligence (AI) services in the medical field, including automated\nCSR detection, are now possible to detect and cure this disease. This review\nassessed a variety of innovative technologies and researches that contribute to\nthe automatic detection of CSR. In this review, various CSR disease detection\ntechniques, broadly classified into two categories: a) CSR detection based on\nclassical imaging technologies, and b) CSR detection based on Machine/Deep\nLearning methods, have been reviewed after an elaborated evaluation of 29\ndifferent relevant articles. Additionally, it also goes over the advantages,\ndrawbacks and limitations of a variety of traditional imaging techniques, such\nas Optical Coherence Tomography Angiography (OCTA), Fundus Imaging and more\nrecent approaches that utilize Artificial Intelligence techniques. Finally, it\nis concluded that the most recent Deep Learning (DL) classifiers deliver\naccurate, fast, and reliable CSR detection. However, more research needs to be\nconducted on publicly available datasets to improve computation complexity for\nthe reliable detection and diagnosis of CSR disease.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-12-20",
      "downloaded_date": "2025-02-01",
      "filename": "Hassan-Recent Developments in Detection of Central Serous Retinopathy through Imaging and Artificial Intell....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.10961v4",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    "1911.07509v2": {
      "title": "AI-based Pilgrim Detection using Convolutional Neural Networks",
      "authors": [
        "Marwa Ben Jabra",
        "Adel Ammar",
        "Anis Koubaa",
        "Omar Cheikhrouhou",
        "Habib Hamam"
      ],
      "abstract": "Pilgrimage represents the most important Islamic religious gathering in the\nworld where millions of pilgrims visit the holy places of Makkah and Madinah to\nperform their rituals. The safety and security of pilgrims is the highest\npriority for the authorities. In Makkah, 5000 cameras are spread around the\nholy for monitoring pilgrims, but it is almost impossible to track all events\nby humans considering the huge number of images collected every second. To\naddress this issue, we propose to use artificial intelligence technique based\non deep learning and convolution neural networks to detect and identify\nPilgrims and their features. For this purpose, we built a comprehensive dataset\nfor the detection of pilgrims and their genders. Then, we develop two\nconvolutional neural networks based on YOLOv3 and Faster-RCNN for the detection\nof Pilgrims. Experiments results show that Faster RCNN with Inception v2\nfeature extractor provides the best mean average precision over all classes of\n51%.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/34d6c1af1d852fc0dd566109bc0ca9dce6cf3e2d",
      "published_date": "2019-11-18",
      "downloaded_date": "2025-02-01",
      "filename": "Jabra-AI-based Pilgrim Detection using Convolutional Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.07509v2",
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2309.15936v1": {
      "title": "Genomic Analysis and Artificial Intelligence: Predicting Viral Mutations and Future Pandemics",
      "authors": [
        "Fadhil G. Al-Amran",
        "Abbas M. Hezam",
        "Salman Rawaf",
        "Maitham G. Yousif"
      ],
      "abstract": "This study presents a novel approach at the intersection of genomic analysis\nand artificial intelligence (AI) to predict viral mutations and assess the\nrisks of future pandemics. Through comprehensive genomic analysis, genetic\nmarkers associated with increased virulence and transmissibility are\nidentified. Advanced machine learning algorithms are employed to analyze\ngenetic data and forecast viral mutations, taking into account factors such as\nreplication rates, host-pathogen interactions, and environmental influences.\nThe research also evaluates the risk of future pandemics by examining zoonotic\nreservoirs, human-animal interfaces, and climate change impacts. AI-powered\nrisk assessment models provide insights into potential outbreak hotspots,\nfacilitating targeted surveillance and preventive measures. This research\noffers a proactive approach to pandemic preparedness, enabling early\nintervention and the development of effective containment strategies and\nvaccines. The fusion of genomic analysis and AI enhances our ability to\nmitigate the impact of infectious diseases on a global scale, emphasizing the\nimportance of proactive measures in safeguarding public health.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c38f7fbc7f45b07e28011511aad996b50c709efd",
      "published_date": "2023-09-26",
      "downloaded_date": "2025-02-01",
      "filename": "Al-Amran-Genomic Analysis and Artificial Intelligence Predicting Viral Mutations and Future Pandemics.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.15936v1",
      "categories": [
        "q-bio.OT"
      ]
    },
    "2111.12228v1": {
      "title": "Artificial intelligence enabled radio propagation for communications-Part II: Scenario identification and channel modeling",
      "authors": [
        "Chen Huang",
        "Ruisi He",
        "Bo Ai",
        "Andreas F. Molisch",
        "Buon Kiong Lau",
        "Katsuyuki Haneda",
        "Bo Liu",
        "Cheng-Xiang Wang",
        "Mi Yang",
        "Claude Oestges",
        "Zhangdui Zhong"
      ],
      "abstract": "This two-part paper investigates the application of artificial intelligence\n(AI) and in particular machine learning (ML) to the study of wireless\npropagation channels. In Part I, we introduced AI and ML as well as provided a\ncomprehensive survey on ML enabled channel characterization and antenna-channel\noptimization, and in this part (Part II) we review state-of-the-art literature\non scenario identification and channel modeling here. In particular, the key\nideas of ML for scenario identification and channel modeling/prediction are\npresented, and the widely used ML methods for propagation scenario\nidentification and channel modeling and prediction are analyzed and compared.\nBased on the state-of-art, the future challenges of AI/ML-based channel data\nprocessing techniques are given as well.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-11-24",
      "downloaded_date": "2025-02-01",
      "filename": "Huang-Artificial intelligence enabled radio propagation for communications-Part II Scenario identification....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.12228v1",
      "categories": [
        "eess.SP"
      ]
    },
    "2204.09579v2": {
      "title": "A Survey and Perspective on Artificial Intelligence for Security-Aware Electronic Design Automation",
      "authors": [
        "David Selasi Koblah",
        "Rabin Yu Acharya",
        "Daniel Capecci",
        "Olivia P. Dizon-Paradis",
        "Shahin Tajik",
        "Fatemeh Ganji",
        "Damon L. Woodard",
        "Domenic Forte"
      ],
      "abstract": "Artificial intelligence (AI) and machine learning (ML) techniques have been\nincreasingly used in several fields to improve performance and the level of\nautomation. In recent years, this use has exponentially increased due to the\nadvancement of high-performance computing and the ever increasing size of data.\nOne of such fields is that of hardware design; specifically the design of\ndigital and analog integrated circuits~(ICs), where AI/ ML techniques have been\nextensively used to address ever-increasing design complexity, aggressive\ntime-to-market, and the growing number of ubiquitous interconnected devices\n(IoT). However, the security concerns and issues related to IC design have been\nhighly overlooked. In this paper, we summarize the state-of-the-art in AL/ML\nfor circuit design/optimization, security and engineering challenges, research\nin security-aware CAD/EDA, and future research directions and needs for using\nAI/ML for security-aware circuit design.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7b4f1eea24a17b180af90e6d3581bfb7c52fa3f4",
      "published_date": "2022-04-19",
      "downloaded_date": "2025-02-01",
      "filename": "Koblah-A Survey and Perspective on Artificial Intelligence for Security-Aware Electronic Design Automation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2204.09579v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ]
    },
    "2408.10788v1": {
      "title": "Understanding the Skills Gap between Higher Education and Industry in the UK in Artificial Intelligence Sector",
      "authors": [
        "Khushi Jaiswal",
        "Ievgeniia Kuzminykh",
        "Sanjay Modgil"
      ],
      "abstract": "As Artificial Intelligence (AI) changes how businesses work, there is a\ngrowing need for people who can work in this sector. This paper investigates\nhow well universities in United Kingdom offering courses in AI, prepare\nstudents for jobs in the real world. To gain insight into the differences\nbetween university curricula and industry demands we review the contents of\ntaught courses and job advertisement portals. By using custom data scraping\ntools to gather information from job advertisements and university curricula,\nand frequency and Naive Bayes classifier analysis, this study will show exactly\nwhat skills industry is looking for. In this study we identified 12 skill\ncategories that were used for mapping. The study showed that the university\ncurriculum in the AI domain is well balanced in most technical skills,\nincluding Programming and Machine learning subjects, but have a gap in Data\nScience and Maths and Statistics skill categories.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0250efcb5e25a55b074cc85f777521222c65e11d",
      "published_date": "2024-08-20",
      "downloaded_date": "2025-02-01",
      "filename": "Jaiswal-Understanding the Skills Gap between Higher Education and Industry in the UK in Artificial Intellige....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.10788v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1901.05639v4": {
      "title": "Machine learning with neural networks",
      "authors": [
        "B. Mehlig"
      ],
      "abstract": "These are lecture notes for a course on machine learning with neural networks\nfor scientists and engineers that I have given at Gothenburg University and\nChalmers Technical University in Gothenburg, Sweden. The material is organised\ninto three parts: Hopfield networks, supervised learning of labeled data, and\nlearning algorithms for unlabeled data sets. Part I introduces stochastic\nrecurrent networks: Hopfield networks and Boltzmann machines. The analysis of\ntheir learning rules sets the scene for the later parts. Part II describes\nsupervised learning with multilayer perceptrons and convolutional neural\nnetworks. This part starts with a simple geometrical interpretation of the\nlearning rule and leads to the recent successes of convolutional networks in\nobject recognition, recurrent networks in language processing, and reservoir\ncomputers in time-series analysis. Part III explains what neural networks can\nlearn about data that is not labeled. This part begins with a description of\nunsupervised learning techniques for clustering of data, non-linear\nprojections, and embeddings. A section on autoencoders explains how to learn\nwithout labels using convolutional networks, and the last chapter is dedicated\nto reinforcement learning. The overall goal of the course is to explain the\nfundamental principles that allow neural networks to learn, emphasising ideas\nand concepts that are common to all three parts.\n  The present version does not contain exercises (copyright owned by Cambridge\nUniversity Press). The complete book is available at\nhttps://www.cambridge.org/gb/academic/subjects/physics/statistical-physics/machine-learning-neural-networks-introduction-scientists-and-engineers?format=HB.",
      "citation_count": 33,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d58cec43af3d618c4ae5664461472dae5e715018",
      "published_date": "2019-01-17",
      "downloaded_date": "2025-02-01",
      "filename": "Mehlig-Machine learning with neural networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.05639v4",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "stat.ML"
      ]
    },
    "2305.05321v1": {
      "title": "Application of Artificial Intelligence in the Classification of Microscopical Starch Images for Drug Formulation",
      "authors": [
        "Marvellous Ajala",
        "Blessing Oko",
        "David Oba-Fidelis",
        "Joycelyn Iyasele",
        "Joy I. Odimegwu"
      ],
      "abstract": "Starches are important energy sources found in plants with many uses in the\npharmaceutical industry such as binders, disintegrants, bulking agents in drugs\nand thus require very careful physicochemical analysis for proper\nidentification and verification which includes microscopy. In this work, we\napplied artificial intelligence techniques (using transfer learning and deep\nconvolution neural network CNNs to microscopical images obtained from 9 starch\nsamples of different botanical sources. Our approach obtained an accuracy of\n61% when the machine learning model was pretrained on microscopic images from\nMicroNet dataset. However the accuracy jumped to 81% for model pretrained on\nrandom day to day images obtained from Imagenet dataset. The model pretrained\non the imagenet dataset also showed a better precision, recall and f1 score\nthan that pretrained on the imagenet dataset.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/07c5405326ec82e56c59248d654bbd03cb9264c7",
      "published_date": "2023-05-09",
      "downloaded_date": "2025-02-01",
      "filename": "Ajala-Application of Artificial Intelligence in the Classification of Microscopical Starch Images for Drug....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.05321v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "2211.08430v1": {
      "title": "Power-law Scaling to Assist with Key Challenges in Artificial Intelligence",
      "authors": [
        "Yuval Meir",
        "Shira Sardi",
        "Shiri Hodassman",
        "Karin Kisos",
        "Itamar Ben-Noam",
        "Amir Goldental",
        "Ido Kanter"
      ],
      "abstract": "Power-law scaling, a central concept in critical phenomena, is found to be\nuseful in deep learning, where optimized test errors on handwritten digit\nexamples converge as a power-law to zero with database size. For rapid decision\nmaking with one training epoch, each example is presented only once to the\ntrained network, the power-law exponent increased with the number of hidden\nlayers. For the largest dataset, the obtained test error was estimated to be in\nthe proximity of state-of-the-art algorithms for large epoch numbers. Power-law\nscaling assists with key challenges found in current artificial intelligence\napplications and facilitates an a priori dataset size estimation to achieve a\ndesired test accuracy. It establishes a benchmark for measuring training\ncomplexity and a quantitative hierarchy of machine learning tasks and\nalgorithms.",
      "citation_count": 16,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4f55f6fbbd53679a71bd943da0c79d6b9e64fc28",
      "published_date": "2022-11-15",
      "downloaded_date": "2025-02-01",
      "filename": "Meir-Power-law Scaling to Assist with Key Challenges in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.08430v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    "2306.00314v1": {
      "title": "Adversarial-Aware Deep Learning System based on a Secondary Classical Machine Learning Verification Approach",
      "authors": [
        "Mohammed Alkhowaiter",
        "Hisham Kholidy",
        "Mnassar Alyami",
        "Abdulmajeed Alghamdi",
        "Cliff Zou"
      ],
      "abstract": "Deep learning models have been used in creating various effective image\nclassification applications. However, they are vulnerable to adversarial\nattacks that seek to misguide the models into predicting incorrect classes. Our\nstudy of major adversarial attack models shows that they all specifically\ntarget and exploit the neural networking structures in their designs. This\nunderstanding makes us develop a hypothesis that most classical machine\nlearning models, such as Random Forest (RF), are immune to adversarial attack\nmodels because they do not rely on neural network design at all. Our\nexperimental study of classical machine learning models against popular\nadversarial attacks supports this hypothesis. Based on this hypothesis, we\npropose a new adversarial-aware deep learning system by using a classical\nmachine learning model as the secondary verification system to complement the\nprimary deep learning model in image classification. Although the secondary\nclassical machine learning model has less accurate output, it is only used for\nverification purposes, which does not impact the output accuracy of the primary\ndeep learning model, and at the same time, can effectively detect an\nadversarial attack when a clear mismatch occurs. Our experiments based on\nCIFAR-100 dataset show that our proposed approach outperforms current\nstate-of-the-art adversarial defense systems.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4c4dcfb1c77685210167178f58a3e60c65c48527",
      "published_date": "2023-06-01",
      "downloaded_date": "2025-02-01",
      "filename": "Alkhowaiter-Adversarial-Aware Deep Learning System based on a Secondary Classical Machine Learning Verification ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.00314v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    "2302.06852v1": {
      "title": "Using Artificial Intelligence to aid Scientific Discovery of Climate Tipping Points",
      "authors": [
        "Jennifer Sleeman",
        "David Chung",
        "Chace Ashcraft",
        "Jay Brett",
        "Anand Gnanadesikan",
        "Yannis Kevrekidis",
        "Marisa Hughes",
        "Thomas Haine",
        "Marie-Aude Pradal",
        "Renske Gelderloos",
        "Caroline Tang",
        "Anshu Saksena",
        "Larry White"
      ],
      "abstract": "We propose a hybrid Artificial Intelligence (AI) climate modeling approach\nthat enables climate modelers in scientific discovery using a climate-targeted\nsimulation methodology based on a novel combination of deep neural networks and\nmathematical methods for modeling dynamical systems. The simulations are\ngrounded by a neuro-symbolic language that both enables question answering of\nwhat is learned by the AI methods and provides a means of explainability. We\ndescribe how this methodology can be applied to the discovery of climate\ntipping points and, in particular, the collapse of the Atlantic Meridional\nOverturning Circulation (AMOC). We show how this methodology is able to predict\nAMOC collapse with a high degree of accuracy using a surrogate climate model\nfor ocean interaction. We also show preliminary results of neuro-symbolic\nmethod performance when translating between natural language questions and\nsymbolically learned representations. Our AI methodology shows promising early\nresults, potentially enabling faster climate tipping point related research\nthat would otherwise be computationally infeasible.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a9bbbb80f44038770cbd56f6f0e38e915cbeae27",
      "published_date": "2023-02-14",
      "downloaded_date": "2025-02-01",
      "filename": "Sleeman-Using Artificial Intelligence to aid Scientific Discovery of Climate Tipping Points.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.06852v1",
      "categories": [
        "cs.AI",
        "cs.CE"
      ]
    },
    "2309.07589v1": {
      "title": "MPAI-EEV: Standardization Efforts of Artificial Intelligence based End-to-End Video Coding",
      "authors": [
        "Chuanmin Jia",
        "Feng Ye",
        "Fanke Dong",
        "Kai Lin",
        "Leonardo Chiariglione",
        "Siwei Ma",
        "Huifang Sun",
        "Wen Gao"
      ],
      "abstract": "The rapid advancement of artificial intelligence (AI) technology has led to\nthe prioritization of standardizing the processing, coding, and transmission of\nvideo using neural networks. To address this priority area, the Moving Picture,\nAudio, and Data Coding by Artificial Intelligence (MPAI) group is developing a\nsuite of standards called MPAI-EEV for \"end-to-end optimized neural video\ncoding.\" The aim of this AI-based video standard project is to compress the\nnumber of bits required to represent high-fidelity video data by utilizing\ndata-trained neural coding technologies. This approach is not constrained by\nhow data coding has traditionally been applied in the context of a hybrid\nframework. This paper presents an overview of recent and ongoing\nstandardization efforts in this area and highlights the key technologies and\ndesign philosophy of EEV. It also provides a comparison and report on some\nprimary efforts such as the coding efficiency of the reference model.\nAdditionally, it discusses emerging activities such as learned\nUnmanned-Aerial-Vehicles (UAVs) video coding which are currently planned, under\ndevelopment, or in the exploration phase. With a focus on UAV video signals,\nthis paper addresses the current status of these preliminary efforts. It also\nindicates development timelines, summarizes the main technical details, and\nprovides pointers to further points of reference. The exploration experiment\nshows that the EEV model performs better than the state-of-the-art video coding\nstandard H.266/VVC in terms of perceptual evaluation metric.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4d4b63765a5f38bb7d66c48b63f0138e6d6f2ec1",
      "published_date": "2023-09-14",
      "downloaded_date": "2025-02-01",
      "filename": "Jia-MPAI-EEV Standardization Efforts of Artificial Intelligence based End-to-End Video Coding.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.07589v1",
      "categories": [
        "cs.MM",
        "eess.IV"
      ]
    },
    "2101.08904v2": {
      "title": "Applications of artificial intelligence in drug development using real-world data",
      "authors": [
        "Zhaoyi Chen",
        "Xiong Liu",
        "William Hogan",
        "Elizabeth Shenkman",
        "Jiang Bian"
      ],
      "abstract": "The US Food and Drug Administration (FDA) has been actively promoting the use\nof real-world data (RWD) in drug development. RWD can generate important\nreal-world evidence reflecting the real-world clinical environment where the\ntreatments are used. Meanwhile, artificial intelligence (AI), especially\nmachine- and deep-learning (ML/DL) methods, have been increasingly used across\nmany stages of the drug development process. Advancements in AI have also\nprovided new strategies to analyze large, multidimensional RWD. Thus, we\nconducted a rapid review of articles from the past 20 years, to provide an\noverview of the drug development studies that use both AI and RWD. We found\nthat the most popular applications were adverse event detection, trial\nrecruitment, and drug repurposing. Here, we also discuss current research gaps\nand future opportunities.",
      "citation_count": 42,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e8c4a48b1cf6d8a3826fa2ade872e989923781ea",
      "published_date": "2021-01-22",
      "downloaded_date": "2025-02-01",
      "filename": "Chen-Applications of artificial intelligence in drug development using real-world data.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.08904v2",
      "categories": [
        "cs.CY",
        "cs.CL",
        "cs.LG",
        "q-bio.QM"
      ]
    },
    "1909.06040v1": {
      "title": "DL2: A Deep Learning-driven Scheduler for Deep Learning Clusters",
      "authors": [
        "Yanghua Peng",
        "Yixin Bao",
        "Yangrui Chen",
        "Chuan Wu",
        "Chen Meng",
        "Wei Lin"
      ],
      "abstract": "More and more companies have deployed machine learning (ML) clusters, where\ndeep learning (DL) models are trained for providing various AI-driven services.\nEfficient resource scheduling is essential for maximal utilization of expensive\nDL clusters. Existing cluster schedulers either are agnostic to ML workload\ncharacteristics, or use scheduling heuristics based on operators' understanding\nof particular ML framework and workload, which are less efficient or not\ngeneral enough. In this paper, we show that DL techniques can be adopted to\ndesign a generic and efficient scheduler. DL2 is a DL-driven scheduler for DL\nclusters, targeting global training job expedition by dynamically resizing\nresources allocated to jobs. DL2 advocates a joint supervised learning and\nreinforcement learning approach: a neural network is warmed up via offline\nsupervised learning based on job traces produced by the existing cluster\nscheduler; then the neural network is plugged into the live DL cluster,\nfine-tuned by reinforcement learning carried out throughout the training\nprogress of the DL jobs, and used for deciding job resource allocation in an\nonline fashion. By applying past decisions made by the existing cluster\nscheduler in the preparatory supervised learning phase, our approach enables a\nsmooth transition from existing scheduler, and renders a high-quality scheduler\nin minimizing average training completion time. We implement DL2 on Kubernetes\nand enable dynamic resource scaling in DL jobs on MXNet. Extensive evaluation\nshows that DL2 outperforms fairness scheduler (i.e., DRF) by 44.1% and expert\nheuristic scheduler (i.e., Optimus) by 17.5% in terms of average job completion\ntime.",
      "citation_count": 68,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2f2ab063761101e5af69aad864d0b0d66e8b0a0a",
      "published_date": "2019-09-13",
      "downloaded_date": "2025-02-01",
      "filename": "Peng-DL2 A Deep Learning-driven Scheduler for Deep Learning Clusters.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1909.06040v1",
      "categories": [
        "cs.LG",
        "cs.DC",
        "stat.ML"
      ]
    },
    "2008.09072v1": {
      "title": "Utilizing Explainable AI for Quantization and Pruning of Deep Neural Networks",
      "authors": [
        "Muhammad Sabih",
        "Frank Hannig",
        "Juergen Teich"
      ],
      "abstract": "For many applications, utilizing DNNs (Deep Neural Networks) requires their\nimplementation on a target architecture in an optimized manner concerning\nenergy consumption, memory requirement, throughput, etc. DNN compression is\nused to reduce the memory footprint and complexity of a DNN before its\ndeployment on hardware. Recent efforts to understand and explain AI (Artificial\nIntelligence) methods have led to a new research area, termed as explainable\nAI. Explainable AI methods allow us to understand better the inner working of\nDNNs, such as the importance of different neurons and features. The concepts\nfrom explainable AI provide an opportunity to improve DNN compression methods\nsuch as quantization and pruning in several ways that have not been\nsufficiently explored so far. In this paper, we utilize explainable AI methods:\nmainly DeepLIFT method. We use these methods for (1) pruning of DNNs; this\nincludes structured and unstructured pruning of \\ac{CNN} filters pruning as\nwell as pruning weights of fully connected layers, (2) non-uniform quantization\nof DNN weights using clustering algorithm; this is also referred to as Weight\nSharing, and (3) integer-based mixed-precision quantization; this is where each\nlayer of a DNN may use a different number of integer bits. We use typical image\nclassification datasets with common deep learning image classification models\nfor evaluation. In all these three cases, we demonstrate significant\nimprovements as well as new insights and opportunities from the use of\nexplainable AI in DNN compression.",
      "citation_count": 18,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/20a07ce44e0b766c334ed16f6e3f33611d7a84ee",
      "published_date": "2020-08-20",
      "downloaded_date": "2025-02-01",
      "filename": "Sabih-Utilizing Explainable AI for Quantization and Pruning of Deep Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.09072v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2404.03892v3": {
      "title": "Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI",
      "authors": [
        "Maryam Ahmed",
        "Tooba Bibi",
        "Rizwan Ahmed Khan",
        "Sidra Nasir"
      ],
      "abstract": "The Deep learning (DL) models for diagnosing breast cancer from mammographic\nimages often operate as \"black boxes\", making it difficult for healthcare\nprofessionals to trust and understand their decision-making processes. The\nstudy presents an integrated framework combining Convolutional Neural Networks\n(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis\nof breast cancer using the CBIS-DDSM dataset. The methodology encompasses an\nelaborate data preprocessing pipeline and advanced data augmentation techniques\nto counteract dataset limitations and transfer learning using pre-trained\nnetworks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of\nour study is the evaluation of XAI's effectiveness in interpreting model\npredictions, highlighted by utilizing the Hausdorff measure to assess the\nalignment between AI-generated explanations and expert annotations\nquantitatively. This approach is critical for XAI in promoting trustworthiness\nand ethical fairness in AI-assisted diagnostics. The findings from our research\nillustrate the effective collaboration between CNNs and XAI in advancing\ndiagnostic methods for breast cancer, thereby facilitating a more seamless\nintegration of advanced AI technologies within clinical settings. By enhancing\nthe interpretability of AI driven decisions, this work lays the groundwork for\nimproved collaboration between AI systems and medical practitioners, ultimately\nenriching patient care. Furthermore, the implications of our research extended\nwell beyond the current methodologies. It encourages further research into how\nto combine multimodal data and improve AI explanations to meet the needs of\nclinical practice.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/16f04860d22f925ce90ef50d6daa5833db157c73",
      "published_date": "2024-04-05",
      "downloaded_date": "2025-02-01",
      "filename": "Ahmed-Enhancing Breast Cancer Diagnosis in Mammography Evaluation and Integration of Convolutional Neural ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.03892v3",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ]
    },
    "2407.18264v1": {
      "title": "Latency optimized Deep Neural Networks (DNNs): An Artificial Intelligence approach at the Edge using Multiprocessor System on Chip (MPSoC)",
      "authors": [
        "Seyed Nima Omidsajedi",
        "Rekha Reddy",
        "Jianming Yi",
        "Jan Herbst",
        "Christoph Lipps",
        "Hans Dieter Schotten"
      ],
      "abstract": "Almost in every heavily computation-dependent application, from 6G\ncommunication systems to autonomous driving platforms, a large portion of\ncomputing should be near to the client side. Edge computing (AI at Edge) in\nmobile devices is one of the optimized approaches for addressing this\nrequirement. Therefore, in this work, the possibilities and challenges of\nimplementing a low-latency and power-optimized smart mobile system are\nexamined. Utilizing Field Programmable Gate Array (FPGA) based solutions at the\nedge will lead to bandwidth-optimized designs and as a consequence can boost\nthe computational effectiveness at a system-level deadline. Moreover, various\nperformance aspects and implementation feasibilities of Neural Networks (NNs)\non both embedded FPGA edge devices (using Xilinx Multiprocessor System on Chip\n(MPSoC)) and Cloud are discussed throughout this research. The main goal of\nthis work is to demonstrate a hybrid system that uses the deep learning\nprogrammable engine developed by Xilinx Inc. as the main component of the\nhardware accelerator. Then based on this design, an efficient system for mobile\nedge computing is represented by utilizing an embedded solution.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2d65a3cfe86960be0120b85e991ea267c1e10cdc",
      "published_date": "2024-07-16",
      "downloaded_date": "2025-02-01",
      "filename": "Omidsajedi-Latency optimized Deep Neural Networks DNNs An Artificial Intelligence approach at the Edge using Mu....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.18264v1",
      "categories": [
        "cs.AR",
        "cs.AI"
      ]
    },
    "2007.15843v1": {
      "title": "Artificial Intelligence in Music and Performance: A Subjective Art-Research Inquiry",
      "authors": [
        "Baptiste Caramiaux",
        "Marco Donnarumma"
      ],
      "abstract": "This article presents a five-year collaboration situated at the intersection\nof Art practice and Scientific research in Human-Computer Interaction (HCI). At\nthe core of our collaborative work is a hybrid, Art and Science methodology\nthat combines computational learning technology -- Machine Learning (ML) and\nArtificial Intelligence (AI) -- with interactive music performance and\nchoreography. This article first exposes our thoughts on combining art,\nscience, movement and sound research. We then describe two of our artistic\nworks \\textit{Corpus Nil} and \\textit{Humane Methods} -- created five years\napart from each other -- that crystallize our collaborative research process.\nWe present the scientific and artistic motivations, framed through our research\ninterests and cultural environment of the time. We conclude by reflecting on\nthe methodology we developed during the collaboration and on the conceptual\nshift of computational learning technologies, from ML to AI, and its impact on\nMusic performance.",
      "citation_count": 15,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7dc5b56344ebae5cb165df94ae00f40057729917",
      "published_date": "2020-07-31",
      "downloaded_date": "2025-02-01",
      "filename": "Caramiaux-Artificial Intelligence in Music and Performance A Subjective Art-Research Inquiry.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.15843v1",
      "categories": [
        "cs.HC",
        "H.5.5; I.2.m"
      ]
    },
    "2302.11573v1": {
      "title": "Analyzing Astronomical Data with Machine Learning Techniques",
      "authors": [
        "Mohammad H. Zhoolideh Haghighi"
      ],
      "abstract": "Classification is a popular task in the field of Machine Learning (ML) and\nArtificial Intelligence (AI), and it happens when outputs are categorical\nvariables. There are a wide variety of models that attempts to draw some\nconclusions from observed values, so classification algorithms predict\ncategorical class labels and use them in classifying new data. Popular\nclassification models including logistic regression, decision tree, random\nforest, Support Vector Machine (SVM), multilayer perceptron, Naive Bayes, and\nneural networks have proven to be efficient and accurate applied to many\nindustrial and scientific problems. Particularly, the application of ML to\nastronomy has shown to be very useful for classification, clustering, and data\ncleaning. It is because after learning computers, these tasks can be done\nautomatically by them in a more precise and more rapid way than human\noperators. In view of this, in this paper, we will review some of these popular\nclassification algorithms, and then we apply some of them to the observational\ndata of nonvariable and the RR Lyrae variable stars that come from the SDSS\nsurvey. For the sake of comparison, we calculate the accuracy and F1-score of\nthe applied models.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/012d0b97e624bd96803de246384e394bb68381fa",
      "published_date": "2023-02-22",
      "downloaded_date": "2025-02-01",
      "filename": "Haghighi-Analyzing Astronomical Data with Machine Learning Techniques.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.11573v1",
      "categories": [
        "astro-ph.IM",
        "astro-ph.SR",
        "physics.comp-ph",
        "physics.data-an"
      ]
    },
    "1410.1054v1": {
      "title": "Experimental Realization of Quantum Artificial Intelligence",
      "authors": [
        "Li Zhaokai",
        "Liu Xiaomei",
        "Xu Nanyang",
        "Du jiangfeng"
      ],
      "abstract": "Machines are possible to have some artificial intelligence like human beings\nowing to particular algorithms or software. Such machines could learn knowledge\nfrom what people taught them and do works according to the knowledge. In\npractical learning cases, the data is often extremely complicated and large,\nthus classical learning machines often need huge computational resources.\nQuantum machine learning algorithm, on the other hand, could be exponentially\nfaster than classical machines using quantum parallelism. Here, we demonstrate\na quantum machine learning algorithm on a four-qubit NMR test bench to solve an\noptical character recognition problem, also known as the handwriting\nrecognition. The quantum machine learns standard character fonts and then\nrecognize handwritten characters from a set with two candidates. To our best\nknowledge, this is the first artificial intelligence realized on a quantum\nprocessor. Due to the widespreading importance of artificial intelligence and\nits tremendous consuming of computational resources, quantum speedup would be\nextremely attractive against the challenges from the Big Data.",
      "citation_count": 25,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5c23cf78a979ecd2a9d4e1c62dfc8e01362811b3",
      "published_date": "2014-10-04",
      "downloaded_date": "2025-02-01",
      "filename": "Zhaokai-Experimental Realization of Quantum Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1410.1054v1",
      "categories": [
        "quant-ph"
      ]
    },
    "1910.09031v1": {
      "title": "CAI4CAI: The Rise of Contextual Artificial Intelligence in Computer Assisted Interventions",
      "authors": [
        "Tom Vercauteren",
        "Mathias Unberath",
        "Nicolas Padoy",
        "Nassir Navab"
      ],
      "abstract": "Data-driven computational approaches have evolved to enable extraction of\ninformation from medical images with a reliability, accuracy and speed which is\nalready transforming their interpretation and exploitation in clinical\npractice. While similar benefits are longed for in the field of interventional\nimaging, this ambition is challenged by a much higher heterogeneity. Clinical\nworkflows within interventional suites and operating theatres are extremely\ncomplex and typically rely on poorly integrated intra-operative devices,\nsensors, and support infrastructures. Taking stock of some of the most exciting\ndevelopments in machine learning and artificial intelligence for computer\nassisted interventions, we highlight the crucial need to take context and human\nfactors into account in order to address these challenges. Contextual\nartificial intelligence for computer assisted intervention, or CAI4CAI, arises\nas an emerging opportunity feeding into the broader field of surgical data\nscience. Central challenges being addressed in CAI4CAI include how to integrate\nthe ensemble of prior knowledge and instantaneous sensory information from\nexperts, sensors and actuators; how to create and communicate a faithful and\nactionable shared representation of the surgery among a mixed human-AI actor\nteam; how to design interventional systems and associated cognitive shared\ncontrol schemes for online uncertainty-aware collaborative decision making\nultimately producing more precise and reliable interventions.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-10-20",
      "downloaded_date": "2025-02-01",
      "filename": "Vercauteren-CAI4CAI The Rise of Contextual Artificial Intelligence in Computer Assisted Interventions.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1910.09031v1",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "1511.02420v1": {
      "title": "Design of an Alarm System for Isfahan Ozone Level based on Artificial Intelligence Predictor Models",
      "authors": [
        "Ehsan Lotfi"
      ],
      "abstract": "The ozone level prediction is an important task of air quality agencies of\nmodern cities. In this paper, we design an ozone level alarm system (OLP) for\nIsfahan city and test it through the real word data from 1-1-2000 to 7-6-2011.\nWe propose a computer based system with three inputs and single output. The\ninputs include three sensors of solar ultraviolet (UV), total solar radiation\n(TSR) and total ozone (O3). And the output of the system is the predicted O3 of\nthe next day and the alarm massages. A developed artificial intelligence (AI)\nalgorithm is applied to determine the output, based on the inputs variables.\nFor this issue, AI models, including supervised brain emotional learning (BEL),\nadaptive neuro-fuzzy inference system (ANFIS) and artificial neural networks\n(ANNs), are compared in order to find the best model. The simulation of the\nproposed system shows that it can be used successfully in prediction of major\ncities ozone level.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d401fd19614f9d75aea4820964aea786a0ad83a0",
      "published_date": "2015-11-08",
      "downloaded_date": "2025-02-01",
      "filename": "Lotfi-Design of an Alarm System for Isfahan Ozone Level based on Artificial Intelligence Predictor Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1511.02420v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2009.12437v1": {
      "title": "Democratizing Artificial Intelligence in Healthcare: A Study of Model Development Across Two Institutions Incorporating Transfer Learning",
      "authors": [
        "Vikash Gupta1",
        "Holger Roth",
        "Varun Buch3",
        "Marcio A. B. C. Rockenbach",
        "Richard D White",
        "Dong Yang",
        "Olga Laur",
        "Brian Ghoshhajra",
        "Ittai Dayan",
        "Daguang Xu",
        "Mona G. Flores",
        "Barbaros Selnur Erdal"
      ],
      "abstract": "The training of deep learning models typically requires extensive data, which\nare not readily available as large well-curated medical-image datasets for\ndevelopment of artificial intelligence (AI) models applied in Radiology.\nRecognizing the potential for transfer learning (TL) to allow a fully trained\nmodel from one institution to be fine-tuned by another institution using a much\nsmall local dataset, this report describes the challenges, methodology, and\nbenefits of TL within the context of developing an AI model for a basic\nuse-case, segmentation of Left Ventricular Myocardium (LVM) on images from\n4-dimensional coronary computed tomography angiography. Ultimately, our results\nfrom comparisons of LVM segmentation predicted by a model locally trained using\nrandom initialization, versus one training-enhanced by TL, showed that a\nuse-case model initiated by TL can be developed with sparse labels with\nacceptable performance. This process reduces the time required to build a new\nmodel in the clinical environment at a different institution.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bf2308c377636cdd14f3deb296dbf346aeebc71f",
      "published_date": "2020-09-25",
      "downloaded_date": "2025-02-01",
      "filename": "Gupta1-Democratizing Artificial Intelligence in Healthcare A Study of Model Development Across Two Institut....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.12437v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "I.2.10"
      ]
    },
    "2202.04847v1": {
      "title": "A Survey on Artificial Intelligence for Source Code: A Dialogue Systems Perspective",
      "authors": [
        "Erfan Al-Hossami",
        "Samira Shaikh"
      ],
      "abstract": "In this survey paper, we overview major deep learning methods used in Natural\nLanguage Processing (NLP) and source code over the last 35 years. Next, we\npresent a survey of the applications of Artificial Intelligence (AI) for source\ncode, also known as Code Intelligence (CI) and Programming Language Processing\n(PLP). We survey over 287 publications and present a software-engineering\ncentered taxonomy for CI placing each of the works into one category describing\nhow it best assists the software development cycle. Then, we overview the field\nof conversational assistants and their applications in software engineering and\neducation. Lastly, we highlight research opportunities at the intersection of\nAI for code and conversational assistants and provide future directions for\nresearching conversational assistants with CI capabilities.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7b46b9da287429d19a00ca3f9219c1020f7c9df8",
      "published_date": "2022-02-10",
      "downloaded_date": "2025-02-01",
      "filename": "Al-Hossami-A Survey on Artificial Intelligence for Source Code A Dialogue Systems Perspective.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.04847v1",
      "categories": [
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "cs.SE",
        "I.2.2; I.2.7; K.3.1"
      ]
    },
    "2103.04244v2": {
      "title": "Counterfactuals and Causability in Explainable Artificial Intelligence: Theory, Algorithms, and Applications",
      "authors": [
        "Yu-Liang Chou",
        "Catarina Moreira",
        "Peter Bruza",
        "Chun Ouyang",
        "Joaquim Jorge"
      ],
      "abstract": "There has been a growing interest in model-agnostic methods that can make\ndeep learning models more transparent and explainable to a user. Some\nresearchers recently argued that for a machine to achieve a certain degree of\nhuman-level explainability, this machine needs to provide human causally\nunderstandable explanations, also known as causability. A specific class of\nalgorithms that have the potential to provide causability are counterfactuals.\nThis paper presents an in-depth systematic review of the diverse existing body\nof literature on counterfactuals and causability for explainable artificial\nintelligence. We performed an LDA topic modelling analysis under a PRISMA\nframework to find the most relevant literature articles. This analysis resulted\nin a novel taxonomy that considers the grounding theories of the surveyed\nalgorithms, together with their underlying properties and applications in\nreal-world data. This research suggests that current model-agnostic\ncounterfactual algorithms for explainable AI are not grounded on a causal\ntheoretical formalism and, consequently, cannot promote causability to a human\ndecision-maker. Our findings suggest that the explanations derived from major\nalgorithms in the literature provide spurious correlations rather than\ncause/effects relationships, leading to sub-optimal, erroneous or even biased\nexplanations. This paper also advances the literature with new directions and\nchallenges on promoting causability in model-agnostic approaches for\nexplainable artificial intelligence.",
      "citation_count": 162,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d6c94081e1f331d97d23a2cd0d3927bb2591b2c8",
      "published_date": "2021-03-07",
      "downloaded_date": "2025-02-01",
      "filename": "Chou-Counterfactuals and Causability in Explainable Artificial Intelligence Theory Algorithms and Applica....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.04244v2",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2208.01674v1": {
      "title": "Diagnosis of Paratuberculosis in Histopathological Images Based on Explainable Artificial Intelligence and Deep Learning",
      "authors": [
        "Tuncay YiÄit",
        "NilgÃ¼n ÅengÃ¶z",
        "Ãzlem Ãzmen",
        "Jude Hemanth",
        "Ali Hakan IÅÄ±k"
      ],
      "abstract": "Artificial intelligence holds great promise in medical imaging, especially\nhistopathological imaging. However, artificial intelligence algorithms cannot\nfully explain the thought processes during decision-making. This situation has\nbrought the problem of explainability, i.e., the black box problem, of\nartificial intelligence applications to the agenda: an algorithm simply\nresponds without stating the reasons for the given images. To overcome the\nproblem and improve the explainability, explainable artificial intelligence\n(XAI) has come to the fore, and piqued the interest of many researchers.\nAgainst this backdrop, this study examines a new and original dataset using the\ndeep learning algorithm, and visualizes the output with gradient-weighted class\nactivation mapping (Grad-CAM), one of the XAI applications. Afterwards, a\ndetailed questionnaire survey was conducted with the pathologists on these\nimages. Both the decision-making processes and the explanations were verified,\nand the accuracy of the output was tested. The research results greatly help\npathologists in the diagnosis of paratuberculosis.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/261a45bc9a81c2a534dfbfaf32cfdc700ec654c1",
      "published_date": "2022-08-02",
      "downloaded_date": "2025-02-01",
      "filename": "YiÄit-Diagnosis of Paratuberculosis in Histopathological Images Based on Explainable Artificial Intelligen....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2208.01674v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG",
        "68T07",
        "I.4.0"
      ]
    },
    "1907.12363v2": {
      "title": "A comparison of Deep Learning performances with other machine learning algorithms on credit scoring unbalanced data",
      "authors": [
        "Louis Marceau",
        "Lingling Qiu",
        "Nick Vandewiele",
        "Eric Charton"
      ],
      "abstract": "Training models on highly unbalanced data is admitted to be a challenging\ntask for machine learning algorithms. Current studies on deep learning mainly\nfocus on data sets with balanced class labels or unbalanced data, but with\nmassive amount of samples available, like in speech recognition. However, the\ncapacities of deep learning on imbalanced data with little samples is not\ndeeply investigated in literature, while it is a very common application\ncontext in numerous industries. To contribute to fill this gap, this paper\ncompares the performances of several popular machine learning algorithms\npreviously applied with success to unbalanced data set with deep learning\nalgorithms. We conduct those experiments on a highly unbalanced data set, used\nfor credit scoring. We evaluate various configuration including neural network\noptimization techniques and try to determine their capacities when they operate\nwith imbalanced corpora.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-07-25",
      "downloaded_date": "2025-02-01",
      "filename": "Marceau-A comparison of Deep Learning performances with other machine learning algorithms on credit scoring ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.12363v2",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2003.00880v1": {
      "title": "Introducing Fuzzy Layers for Deep Learning",
      "authors": [
        "Stanton R. Price",
        "Steven R. Price",
        "Derek T. Anderson"
      ],
      "abstract": "Many state-of-the-art technologies developed in recent years have been\ninfluenced by machine learning to some extent. Most popular at the time of this\nwriting are artificial intelligence methodologies that fall under the umbrella\nof deep learning. Deep learning has been shown across many applications to be\nextremely powerful and capable of handling problems that possess great\ncomplexity and difficulty. In this work, we introduce a new layer to deep\nlearning: the fuzzy layer. Traditionally, the network architecture of neural\nnetworks is composed of an input layer, some combination of hidden layers, and\nan output layer. We propose the introduction of fuzzy layers into the deep\nlearning architecture to exploit the powerful aggregation properties expressed\nthrough fuzzy methodologies, such as the Choquet and Sugueno fuzzy integrals.\nTo date, fuzzy approaches taken to deep learning have been through the\napplication of various fusion strategies at the decision level to aggregate\noutputs from state-of-the-art pre-trained models, e.g., AlexNet, VGG16,\nGoogLeNet, Inception-v3, ResNet-18, etc. While these strategies have been shown\nto improve accuracy performance for image classification tasks, none have\nexplored the use of fuzzified intermediate, or hidden, layers. Herein, we\npresent a new deep learning strategy that incorporates fuzzy strategies into\nthe deep learning architecture focused on the application of semantic\nsegmentation using per-pixel classification. Experiments are conducted on a\nbenchmark data set as well as a data set collected via an unmanned aerial\nsystem at a U.S. Army test site for the task of automatic road segmentation,\nand preliminary results are promising.",
      "citation_count": 29,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4162d25d28eb1ac0b2c45b545df7b193a54a50d6",
      "published_date": "2020-02-21",
      "downloaded_date": "2025-02-01",
      "filename": "Price-Introducing Fuzzy Layers for Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2003.00880v1",
      "categories": [
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2409.03112v1": {
      "title": "AI-Machine Learning-Enabled Tokamak Digital Twin",
      "authors": [
        "William Tang",
        "Eliot Feibush",
        "Ge Dong",
        "Noah Borthwick",
        "Apollo Lee",
        "Juan-Felipe Gomez",
        "Tom Gibbs",
        "John Stone",
        "Peter Messmer",
        "Jack Wells",
        "Xishuo Wei",
        "Zhihong Lin"
      ],
      "abstract": "In addressing the Department of Energy's April, 2022 announcement of a Bold\nDecadal Vision for delivering a Fusion Pilot Plant by 2035, associated software\ntools need to be developed for the integration of real world engineering and\nsupply chain data with advanced science models that are accelerated with\nMachine Learning. An associated research and development effort has been\nintroduced here with promising early progress on the delivery of a realistic\nDigital Twin Tokamak that has benefited from accelerated advances by the\nPrinceton University AI Deep Learning innovative near-real-time simulators\naccompanied by technological capabilities from the NVIDIA Omniverse, an open\ncomputing platform for building and operating applications that connect with\nleading scientific computing visualization software. Working with the CAD files\nfor the GA/DIII-D tokamak including equilibrium evolution as an exemplar\ntokamak application using Omniverse, the Princeton-NVIDIA collaboration has\nintegrated modern AI/HPC-enabled near-real-time kinetic dynamics to connect and\naccelerate state-of-the-art, synthetic, HPC simulators to model fusion devices\nand control systems. The overarching goal is to deliver an interactive\nscientific digital twin of an advanced MFE tokamak that enables near-real-time\nsimulation workflows built with Omniverse to eventually help open doors to new\ncapabilities for generating clean power for a better future.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/eb7ab2f17f53ca788b288eb19c5ecb532cce39c5",
      "published_date": "2024-09-04",
      "downloaded_date": "2025-02-01",
      "filename": "Tang-AI-Machine Learning-Enabled Tokamak Digital Twin.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.03112v1",
      "categories": [
        "physics.comp-ph",
        "physics.plasm-ph"
      ]
    },
    "1906.11282v1": {
      "title": "Developing an App to interpret Chest X-rays to support the diagnosis of respiratory pathology with Artificial Intelligence",
      "authors": [
        "Andrew Elkins",
        "Felipe F. Freitas",
        "Veronica Sanz"
      ],
      "abstract": "In this paper we present our work to improve access to diagnosis in remote\nareas where good quality medical services may be lacking. We develop new\nMachine Learning methodologies for deployment onto mobile devices to help the\nearly diagnosis of a number of life-threatening conditions using X-ray images.\nBy using the latest developments in fast and portable Artificial Intelligence\nenvironments, we develop a smartphone app using an Artificial Neural Network to\nassist physicians in their diagnostic.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d62d03fdf8cf6f603bb2966397f41657de613bfe",
      "published_date": "2019-06-26",
      "downloaded_date": "2025-02-01",
      "filename": "Elkins-Developing an App to interpret Chest X-rays to support the diagnosis of respiratory pathology with A....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1906.11282v1",
      "categories": [
        "cs.CV",
        "physics.med-ph"
      ]
    },
    "2203.00469v1": {
      "title": "Compliance Challenges in Forensic Image Analysis Under the Artificial Intelligence Act",
      "authors": [
        "Benedikt Lorch",
        "Nicole Scheler",
        "Christian Riess"
      ],
      "abstract": "In many applications of forensic image analysis, state-of-the-art results are\nnowadays achieved with machine learning methods. However, concerns about their\nreliability and opaqueness raise the question whether such methods can be used\nin criminal investigations. So far, this question of legal compliance has\nhardly been discussed, also because legal regulations for machine learning\nmethods were not defined explicitly. To this end, the European Commission\nrecently proposed the artificial intelligence (AI) act, a regulatory framework\nfor the trustworthy use of AI. Under the draft AI act, high-risk AI systems for\nuse in law enforcement are permitted but subject to compliance with mandatory\nrequirements. In this paper, we review why the use of machine learning in\nforensic image analysis is classified as high-risk. We then summarize the\nmandatory requirements for high-risk AI systems and discuss these requirements\nin light of two forensic applications, license plate recognition and deep fake\ndetection. The goal of this paper is to raise awareness of the upcoming legal\nrequirements and to point out avenues for future research.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4e5b63d4667f09e16547e58f08bc96245f0079f7",
      "published_date": "2022-03-01",
      "downloaded_date": "2025-02-01",
      "filename": "Lorch-Compliance Challenges in Forensic Image Analysis Under the Artificial Intelligence Act.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.00469v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ]
    },
    "2208.01918v4": {
      "title": "DeepProphet2 -- A Deep Learning Gene Recommendation Engine",
      "authors": [
        "Daniele Brambilla",
        "Davide Maria Giacomini",
        "Luca Muscarnera",
        "Andrea Mazzoleni"
      ],
      "abstract": "New powerful tools for tackling life science problems have been created by\nrecent advances in machine learning. The purpose of the paper is to discuss the\npotential advantages of gene recommendation performed by artificial\nintelligence (AI). Indeed, gene recommendation engines try to solve this\nproblem: if the user is interested in a set of genes, which other genes are\nlikely to be related to the starting set and should be investigated? This task\nwas solved with a custom deep learning recommendation engine, DeepProphet2\n(DP2), which is freely available to researchers worldwide via\nhttps://www.generecommender.com?utm_source=DeepProphet2_paper&utm_medium=pdf.\nHereafter, insights behind the algorithm and its practical applications are\nillustrated.\n  The gene recommendation problem can be addressed by mapping the genes to a\nmetric space where a distance can be defined to represent the real semantic\ndistance between them. To achieve this objective a transformer-based model has\nbeen trained on a well-curated freely available paper corpus, PubMed. The paper\ndescribes multiple optimization procedures that were employed to obtain the\nbest bias-variance trade-off, focusing on embedding size and network depth. In\nthis context, the model's ability to discover sets of genes implicated in\ndiseases and pathways was assessed through cross-validation. A simple\nassumption guided the procedure: the network had no direct knowledge of\npathways and diseases but learned genes' similarities and the interactions\namong them. Moreover, to further investigate the space where the neural network\nrepresents genes, the dimensionality of the embedding was reduced, and the\nresults were projected onto a human-comprehensible space. In conclusion, a set\nof use cases illustrates the algorithm's potential applications in a real word\nsetting.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-08-03",
      "downloaded_date": "2025-02-01",
      "filename": "Brambilla-DeepProphet2 -- A Deep Learning Gene Recommendation Engine.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2208.01918v4",
      "categories": [
        "q-bio.QM",
        "cs.IR",
        "cs.LG"
      ]
    },
    "2007.04068v1": {
      "title": "Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence",
      "authors": [
        "Shakir Mohamed",
        "Marie-Therese Png",
        "William Isaac"
      ],
      "abstract": "This paper explores the important role of critical science, and in particular\nof post-colonial and decolonial theories, in understanding and shaping the\nongoing advances in artificial intelligence. Artificial Intelligence (AI) is\nviewed as amongst the technological advances that will reshape modern societies\nand their relations. Whilst the design and deployment of systems that\ncontinually adapt holds the promise of far-reaching positive change, they\nsimultaneously pose significant risks, especially to already vulnerable\npeoples. Values and power are central to this discussion. Decolonial theories\nuse historical hindsight to explain patterns of power that shape our\nintellectual, political, economic, and social world. By embedding a decolonial\ncritical approach within its technical practice, AI communities can develop\nforesight and tactics that can better align research and technology development\nwith established ethical principles, centring vulnerable peoples who continue\nto bear the brunt of negative impacts of innovation and scientific progress. We\nhighlight problematic applications that are instances of coloniality, and using\na decolonial lens, submit three tactics that can form a decolonial field of\nartificial intelligence: creating a critical technical practice of AI, seeking\nreverse tutelage and reverse pedagogies, and the renewal of affective and\npolitical communities. The years ahead will usher in a wave of new scientific\nbreakthroughs and technologies driven by AI research, making it incumbent upon\nAI communities to strengthen the social contract through ethical foresight and\nthe multiplicity of intellectual perspectives available to us; ultimately\nsupporting future technologies that enable greater well-being, with the goal of\nbeneficence and justice for all.",
      "citation_count": 359,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d3e8b100038c2bf3983ffae96a56c6af0793a62f",
      "published_date": "2020-07-08",
      "downloaded_date": "2025-02-01",
      "filename": "Mohamed-Decolonial AI Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.04068v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2012.00885v1": {
      "title": "Artificial intelligence techniques for integrative structural biology of intrinsically disordered proteins",
      "authors": [
        "Arvind Ramanathan",
        "Heng Ma",
        "Akash Parvatikar",
        "Chakra S. Chennubhotla"
      ],
      "abstract": "We outline recent developments in artificial intelligence (AI) and machine\nlearning (ML) techniques for integrative structural biology of intrinsically\ndisordered proteins (IDP) ensembles. IDPs challenge the traditional protein\nstructure-function paradigm by adapting their conformations in response to\nspecific binding partners leading them to mediate diverse, and often complex\ncellular functions such as biological signaling, self organization and\ncompartmentalization. Obtaining mechanistic insights into their function can\ntherefore be challenging for traditional structural determination techniques.\nOften, scientists have to rely on piecemeal evidence drawn from diverse\nexperimental techniques to characterize their functional mechanisms. Multiscale\nsimulations can help bridge critical knowledge gaps about IDP structure\nfunction relationships - however, these techniques also face challenges in\nresolving emergent phenomena within IDP conformational ensembles. We posit that\nscalable statistical inference techniques can effectively integrate information\ngleaned from multiple experimental techniques as well as from simulations, thus\nproviding access to atomistic details of these emergent phenomena.",
      "citation_count": 36,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2b3414ad0297f451f0f5628f606b371586ee7dd1",
      "published_date": "2020-12-01",
      "downloaded_date": "2025-02-01",
      "filename": "Ramanathan-Artificial intelligence techniques for integrative structural biology of intrinsically disordered pr....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.00885v1",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ]
    },
    "1912.06723v3": {
      "title": "AutoAIViz: Opening the Blackbox of Automated Artificial Intelligence with Conditional Parallel Coordinates",
      "authors": [
        "Daniel Karl I. Weidele",
        "Justin D. Weisz",
        "Eno Oduor",
        "Michael Muller",
        "Josh Andres",
        "Alexander Gray",
        "Dakuo Wang"
      ],
      "abstract": "Artificial Intelligence (AI) can now automate the algorithm selection,\nfeature engineering, and hyperparameter tuning steps in a machine learning\nworkflow. Commonly known as AutoML or AutoAI, these technologies aim to relieve\ndata scientists from the tedious manual work. However, today's AutoAI systems\noften present only limited to no information about the process of how they\nselect and generate model results. Thus, users often do not understand the\nprocess, neither do they trust the outputs. In this short paper, we provide a\nfirst user evaluation by 10 data scientists of an experimental system,\nAutoAIViz, that aims to visualize AutoAI's model generation process. We find\nthat the proposed system helps users to complete the data science tasks, and\nincreases their understanding, toward the goal of increasing trust in the\nAutoAI system.",
      "citation_count": 53,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b22ddde457fb9439d02b16761af572830b25c985",
      "published_date": "2019-12-13",
      "downloaded_date": "2025-02-01",
      "filename": "Weidele-AutoAIViz Opening the Blackbox of Automated Artificial Intelligence with Conditional Parallel Coordi....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1912.06723v3",
      "categories": [
        "cs.LG",
        "cs.HC",
        "stat.ML"
      ]
    },
    "2012.10390v2": {
      "title": "Deep Learning and the Global Workspace Theory",
      "authors": [
        "Rufin VanRullen",
        "Ryota Kanai"
      ],
      "abstract": "Recent advances in deep learning have allowed Artificial Intelligence (AI) to\nreach near human-level performance in many sensory, perceptual, linguistic or\ncognitive tasks. There is a growing need, however, for novel, brain-inspired\ncognitive architectures. The Global Workspace theory refers to a large-scale\nsystem integrating and distributing information among networks of specialized\nmodules to create higher-level forms of cognition and awareness. We argue that\nthe time is ripe to consider explicit implementations of this theory using deep\nlearning techniques. We propose a roadmap based on unsupervised neural\ntranslation between multiple latent spaces (neural networks trained for\ndistinct tasks, on distinct sensory inputs and/or modalities) to create a\nunique, amodal global latent workspace (GLW). Potential functional advantages\nof GLW are reviewed, along with neuroscientific implications.",
      "citation_count": 60,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/69135a269b8d2536bc4f3caa03b465ceb9356192",
      "published_date": "2020-12-04",
      "downloaded_date": "2025-02-01",
      "filename": "VanRullen-Deep Learning and the Global Workspace Theory.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.10390v2",
      "categories": [
        "cs.AI",
        "cs.NE",
        "q-bio.NC"
      ]
    },
    "1904.12419v2": {
      "title": "Detecting Exoplanet Transits through Machine Learning Techniques with Convolutional Neural Networks",
      "authors": [
        "Pattana Chintarungruangchai",
        "Ing-Guey Jiang"
      ],
      "abstract": "A machine learning technique with two-dimension convolutional neural network\nis proposed for detecting exoplanet transits. To test this new method, five\ndifferent types of deep learning models with or without folding are constructed\nand studied. The light curves of the Kepler Data Release 25 are employed as the\ninput of these models. The accuracy, reliability, and completeness are\ndetermined and their performances are compared. These results indicate that a\ncombination of two-dimension convolutional neural network with folding would be\nan excellent choice for the future transit analysis.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-04-29",
      "downloaded_date": "2025-02-01",
      "filename": "Chintarungruangchai-Detecting Exoplanet Transits through Machine Learning Techniques with Convolutional Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1904.12419v2",
      "categories": [
        "astro-ph.EP",
        "astro-ph.IM",
        "physics.comp-ph"
      ]
    },
    "2501.09967v1": {
      "title": "Explainable artificial intelligence (XAI): from inherent explainability to large language models",
      "authors": [
        "Fuseini Mumuni",
        "Alhassan Mumuni"
      ],
      "abstract": "Artificial Intelligence (AI) has continued to achieve tremendous success in\nrecent times. However, the decision logic of these frameworks is often not\ntransparent, making it difficult for stakeholders to understand, interpret or\nexplain their behavior. This limitation hinders trust in machine learning\nsystems and causes a general reluctance towards their adoption in practical\napplications, particularly in mission-critical domains like healthcare and\nautonomous driving. Explainable AI (XAI) techniques facilitate the\nexplainability or interpretability of machine learning models, enabling users\nto discern the basis of the decision and possibly avert undesirable behavior.\nThis comprehensive survey details the advancements of explainable AI methods,\nfrom inherently interpretable models to modern approaches for achieving\ninterpretability of various black box models, including large language models\n(LLMs). Additionally, we review explainable AI techniques that leverage LLM and\nvision-language model (VLM) frameworks to automate or improve the\nexplainability of other machine learning models. The use of LLM and VLM as\ninterpretability methods particularly enables high-level, semantically\nmeaningful explanations of model decisions and behavior. Throughout the paper,\nwe highlight the scientific principles, strengths and weaknesses of\nstate-of-the-art methods and outline different areas of improvement. Where\nappropriate, we also present qualitative and quantitative comparison results of\nvarious methods to show how they compare. Finally, we discuss the key\nchallenges of XAI and directions for future research.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a4b0744a93fee40f1e16904af16e06294eff0dcd",
      "published_date": "2025-01-17",
      "downloaded_date": "2025-02-01",
      "filename": "Mumuni-Explainable artificial intelligence XAI from inherent explainability to large language models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.09967v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    "2306.08323v2": {
      "title": "How to estimate carbon footprint when training deep learning models? A guide and review",
      "authors": [
        "Lucia Bouza Heguerte",
        "AurÃ©lie Bugeau",
        "LoÃ¯c Lannelongue"
      ],
      "abstract": "Machine learning and deep learning models have become essential in the recent\nfast development of artificial intelligence in many sectors of the society. It\nis now widely acknowledge that the development of these models has an\nenvironmental cost that has been analyzed in many studies. Several online and\nsoftware tools have been developed to track energy consumption while training\nmachine learning models. In this paper, we propose a comprehensive introduction\nand comparison of these tools for AI practitioners wishing to start estimating\nthe environmental impact of their work. We review the specific vocabulary, the\ntechnical requirements for each tool. We compare the energy consumption\nestimated by each tool on two deep neural networks for image processing and on\ndifferent types of servers. From these experiments, we provide some advice for\nbetter choosing the right tool and infrastructure.",
      "citation_count": 42,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/58a50fe82225a530b14ebe03ee66f4c167c58450",
      "published_date": "2023-06-14",
      "downloaded_date": "2025-02-01",
      "filename": "Heguerte-How to estimate carbon footprint when training deep learning models A guide and review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.08323v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2110.05478v1": {
      "title": "An In-depth Summary of Recent Artificial Intelligence Applications in Drug Design",
      "authors": [
        "Yi Zhang"
      ],
      "abstract": "As a promising tool to navigate in the vast chemical space, artificial\nintelligence (AI) is leveraged for drug design. From the year 2017 to 2021, the\nnumber of applications of several recent AI models (i.e. graph neural network\n(GNN), recurrent neural network (RNN), variation autoencoder (VAE), generative\nadversarial network (GAN), flow and reinforcement learning (RL)) in drug design\nincreases significantly. Many relevant literature reviews exist. However, none\nof them provides an in-depth summary of many applications of the recent AI\nmodels in drug design. To complement the existing literature, this survey\nincludes the theoretical development of the previously mentioned AI models and\ndetailed summaries of 42 recent applications of AI in drug design. Concretely,\n13 of them leverage GNN for molecular property prediction and 29 of them use RL\nand/or deep generative models for molecule generation and optimization. In most\ncases, the focus of the summary is the models, their variants, and\nmodifications for specific tasks in drug design. Moreover, 60 additional\napplications of AI in molecule generation and optimization are briefly\nsummarized in a table. Finally, this survey provides a holistic discussion of\nthe abundant applications so that the tasks, potential solutions, and\nchallenges in AI-based drug design become evident.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/30fb5f7109b79d49706e8046c59865ffdf67c3ff",
      "published_date": "2021-10-10",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-An In-depth Summary of Recent Artificial Intelligence Applications in Drug Design.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.05478v1",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "J.3; I.2"
      ]
    },
    "2304.12241v4": {
      "title": "Positive AI: Key Challenges in Designing Artificial Intelligence for Wellbeing",
      "authors": [
        "Willem van der Maden",
        "Derek Lomas",
        "Malak Sadek",
        "Paul Hekkert"
      ],
      "abstract": "Artificial Intelligence (AI) is a double-edged sword: on one hand, AI\npromises to provide great advances that could benefit humanity, but on the\nother hand, AI poses substantial (even existential) risks. With advancements\nhappening daily, many people are increasingly worried about AI's impact on\ntheir lives. To ensure AI progresses beneficially, some researchers have\nproposed \"wellbeing\" as a key objective to govern AI. This article addresses\nkey challenges in designing AI for wellbeing. We group these challenges into\nissues of modeling wellbeing in context, assessing wellbeing in context,\ndesigning interventions to improve wellbeing, and maintaining AI alignment with\nwellbeing over time. The identification of these challenges provides a scope\nfor efforts to help ensure that AI developments are aligned with human\nwellbeing.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a4f180d2bd945bc326409dc5f9cdd2e9d4f647d6",
      "published_date": "2023-04-12",
      "downloaded_date": "2025-02-01",
      "filename": "Maden-Positive AI Key Challenges in Designing Artificial Intelligence for Wellbeing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.12241v4",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2"
      ]
    },
    "1301.2158v1": {
      "title": "Artificial Intelligence Framework for Simulating Clinical Decision-Making: A Markov Decision Process Approach",
      "authors": [
        "Casey C. Bennett",
        "Kris Hauser"
      ],
      "abstract": "In the modern healthcare system, rapidly expanding costs/complexity, the\ngrowing myriad of treatment options, and exploding information streams that\noften do not effectively reach the front lines hinder the ability to choose\noptimal treatment decisions over time. The goal in this paper is to develop a\ngeneral purpose (non-disease-specific) computational/artificial intelligence\n(AI) framework to address these challenges. This serves two potential\nfunctions: 1) a simulation environment for exploring various healthcare\npolicies, payment methodologies, etc., and 2) the basis for clinical artificial\nintelligence - an AI that can think like a doctor. This approach combines\nMarkov decision processes and dynamic decision networks to learn from clinical\ndata and develop complex plans via simulation of alternative sequential\ndecision paths while capturing the sometimes conflicting, sometimes synergistic\ninteractions of various components in the healthcare system. It can operate in\npartially observable environments (in the case of missing observations or data)\nby maintaining belief states about patient health status and functions as an\nonline agent that plans and re-plans. This framework was evaluated using real\npatient data from an electronic health record. Such an AI framework easily\noutperforms the current treatment-as-usual (TAU) case-rate/fee-for-service\nmodels of healthcare (Cost per Unit Change: $189 vs. $497) while obtaining a\n30-35% increase in patient outcomes. Tweaking certain model parameters further\nenhances this advantage, obtaining roughly 50% more improvement for roughly\nhalf the costs. Given careful design and problem formulation, an AI simulation\nframework can approximate optimal decisions even in complex and uncertain\nenvironments. Future work is described that outlines potential lines of\nresearch and integration of machine learning algorithms for personalized\nmedicine.",
      "citation_count": 88,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cacfb6df4937059a166c0c59b2ad152c9b67c42c",
      "published_date": "2013-01-10",
      "downloaded_date": "2025-02-01",
      "filename": "Bennett-Artificial Intelligence Framework for Simulating Clinical Decision-Making A Markov Decision Process ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1301.2158v1",
      "categories": [
        "cs.AI",
        "stat.ML"
      ]
    },
    "1903.04766v2": {
      "title": "Artificial Intelligence-aided Receiver for A CP-Free OFDM System: Design, Simulation, and Experimental Test",
      "authors": [
        "Jing Zhang",
        "Chao-Kai Wen",
        "Shi Jin",
        "Geoffrey Ye Li"
      ],
      "abstract": "Orthogonal frequency division multiplexing (OFDM), usually with sufficient\ncyclic prefix (CP), has been widely applied in various communication systems.\nThe CP in OFDM consumes additional resource and reduces spectrum and energy\nefficiency. However, channel estimation and signal detection are very\nchallenging for CP-free OFDM systems. In this paper, we propose a novel\nartificial intelligence (AI)-aided receiver (AI receiver) for a CP-free OFDM\nsystem. The AI receiver includes a channel estimation neural network (CE-NET)\nand a signal detection neural network based on orthogonal approximate message\npassing (OAMP), called OAMP-NET. The CE-NET is initialized by the least-square\nchannel estimation algorithm and refined by a linear minimum mean-squared error\nneural network. The OAMP-NET is established by unfolding the iterative OAMP\nalgorithm and adding several trainable parameters to improve the detection\nperformance. We first investigate their performance under different channel\nmodels through extensive simulation and then establish a real transmission\nsystem using a 5G rapid prototyping system for an over-the-air (OTA) test.\nBased on our study, the AI receiver can estimate time-varying channels with a\nsingle training phase. It also has great robustness to various imperfections\nand has better performance than those competitive algorithms, especially for\nhigh-order modulation. The OTA test further verifies its feasibility to real\nenvironments and indicates its potential for future communications systems.",
      "citation_count": 33,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7716cc74ce261006d3b6cc4c41955f3a6333d90e",
      "published_date": "2019-03-12",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Artificial Intelligence-aided Receiver for A CP-Free OFDM System Design Simulation and Experimental ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1903.04766v2",
      "categories": [
        "cs.IT",
        "math.IT"
      ]
    },
    "2203.04308v1": {
      "title": "Breast cancer detection using artificial intelligence techniques: A systematic literature review",
      "authors": [
        "Ali Bou Nassif",
        "Manar Abu Talib",
        "Qassim Nasir",
        "Yaman Afadar",
        "Omar Elgendy"
      ],
      "abstract": "Cancer is one of the most dangerous diseases to humans, and yet no permanent\ncure has been developed for it. Breast cancer is one of the most common cancer\ntypes. According to the National Breast Cancer foundation, in 2020 alone, more\nthan 276,000 new cases of invasive breast cancer and more than 48,000\nnon-invasive cases were diagnosed in the US. To put these figures in\nperspective, 64% of these cases are diagnosed early in the disease's cycle,\ngiving patients a 99% chance of survival. Artificial intelligence and machine\nlearning have been used effectively in detection and treatment of several\ndangerous diseases, helping in early diagnosis and treatment, and thus\nincreasing the patient's chance of survival. Deep learning has been designed to\nanalyze the most important features affecting detection and treatment of\nserious diseases. For example, breast cancer can be detected using genes or\nhistopathological imaging. Analysis at the genetic level is very expensive, so\nhistopathological imaging is the most common approach used to detect breast\ncancer. In this research work, we systematically reviewed previous work done on\ndetection and treatment of breast cancer using genetic sequencing or\nhistopathological imaging with the help of deep learning and machine learning.\nWe also provide recommendations to researchers who will work in this field",
      "citation_count": 161,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e0d49bfb2c61e78299b16e78e5da3a9aa41b4097",
      "published_date": "2022-03-08",
      "downloaded_date": "2025-02-01",
      "filename": "Nassif-Breast cancer detection using artificial intelligence techniques A systematic literature review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.04308v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "q-bio.QM"
      ]
    },
    "2111.02874v1": {
      "title": "Deep Artificial Intelligence for Fantasy Football Language Understanding",
      "authors": [
        "Aaron Baughman",
        "Micah Forester",
        "Jeff Powell",
        "Eduardo Morales",
        "Shaun McPartlin",
        "Daniel Bohm"
      ],
      "abstract": "Fantasy sports allow fans to manage a team of their favorite athletes and\ncompete with friends. The fantasy platform aligns the real-world statistical\nperformance of athletes to fantasy scoring and has steadily risen in popularity\nto an estimated 9.1 million players per month with 4.4 billion player card\nviews on the ESPN Fantasy Football platform from 2018-2019. In parallel, the\nsports media community produces news stories, blogs, forum posts, tweets,\nvideos, podcasts and opinion pieces that are both within and outside the\ncontext of fantasy sports. However, human fantasy football players can only\nanalyze an average of 3.9 sources of information. Our work discusses the\nresults of a machine learning pipeline to manage an ESPN Fantasy Football team.\nThe use of trained statistical entity detectors and document2vector models\napplied to over 100,000 news sources and 2.3 million articles, videos and\npodcasts each day enables the system to comprehend natural language with an\nanalogy test accuracy of 100% and keyword test accuracy of 80%. Deep learning\nfeedforward neural networks provide player classifications such as if a player\nwill be a bust, boom, play with a hidden injury or play meaningful touches with\na cumulative 72% accuracy. Finally, a multiple regression ensemble uses the\ndeep learning output and ESPN projection data to provide a point projection for\neach of the top 500+ fantasy football players in 2018. The point projection\nmaintained a RMSE of 6.78 points. The best fit probability density function\nfrom a set of 24 is selected to visualize score spreads. Within the first 6\nweeks of the product launch, the total number of users spent a cumulative time\nof over 4.6 years viewing our AI insights. The training data for our models was\nprovided by a 2015 to 2016 web archive from Webhose, ESPN statistics, and\nRotowire injury reports. We used 2017 fantasy football data as a test set.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f68a45a8055571f6373de945751aa2009d482b98",
      "published_date": "2021-11-04",
      "downloaded_date": "2025-02-01",
      "filename": "Baughman-Deep Artificial Intelligence for Fantasy Football Language Understanding.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.02874v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2305.02327v1": {
      "title": "The Future of Artificial Intelligence (AI) and Machine Learning (ML) in Landscape Design: A Case Study in Coastal Virginia, USA",
      "authors": [
        "Zihao Zhang",
        "Ben Bowes"
      ],
      "abstract": "There have been theory-based endeavours that directly engage with AI and ML\nin the landscape discipline. By presenting a case that uses machine learning\ntechniques to predict variables in a coastal environment, this paper provides\nempirical evidence of the forthcoming cybernetic environment, in which\ndesigners are conceptualized not as authors but as choreographers, catalyst\nagents, and conductors among many other intelligent agents. Drawing ideas from\nposthumanism, this paper argues that, to truly understand the cybernetic\nenvironment, we have to take on posthumanist ethics and overcome human\nexceptionalism.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7efbc07a21d3d94cd61b6cf44fab53621a26baea",
      "published_date": "2023-05-03",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-The Future of Artificial Intelligence AI and Machine Learning ML in Landscape Design A Case Study in....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.02327v1",
      "categories": [
        "cs.AI",
        "cs.IT",
        "cs.SY",
        "eess.SY",
        "math.IT"
      ]
    },
    "2212.13289v1": {
      "title": "Artificial Intelligence to Enhance Mission Science Output for In-situ Observations: Dealing with the Sparse Data Challenge",
      "authors": [
        "M. I. Sitnov",
        "G. K. Stephens",
        "V. G. Merkin",
        "C. -P. Wang",
        "D. Turner",
        "K. Genestreti",
        "M. Argall",
        "T. Y. Chen",
        "A. Y. Ukhorskiy",
        "S. Wing",
        "Y. -H. Liu"
      ],
      "abstract": "In the Earth's magnetosphere, there are fewer than a dozen dedicated probes\nbeyond low-Earth orbit making in-situ observations at any given time. As a\nresult, we poorly understand its global structure and evolution, the mechanisms\nof its main activity processes, magnetic storms, and substorms. New Artificial\nIntelligence (AI) methods, including machine learning, data mining, and data\nassimilation, as well as new AI-enabled missions will need to be developed to\nmeet this Sparse Data challenge.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/69e905fdfbd3eb4bc9a65ce032e10876cac6708b",
      "published_date": "2022-12-26",
      "downloaded_date": "2025-02-01",
      "filename": "Sitnov-Artificial Intelligence to Enhance Mission Science Output for In-situ Observations Dealing with the ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.13289v1",
      "categories": [
        "astro-ph.IM",
        "astro-ph.EP",
        "cs.LG"
      ]
    },
    "2411.15243v1": {
      "title": "Bio-inspired AI: Integrating Biological Complexity into Artificial Intelligence",
      "authors": [
        "Nima Dehghani",
        "Michael Levin"
      ],
      "abstract": "The pursuit of creating artificial intelligence (AI) mirrors our longstanding\nfascination with understanding our own intelligence. From the myths of Talos to\nAristotelian logic and Heron's inventions, we have sought to replicate the\nmarvels of the mind. While recent advances in AI hold promise, singular\napproaches often fall short in capturing the essence of intelligence. This\npaper explores how fundamental principles from biological\ncomputation--particularly context-dependent, hierarchical information\nprocessing, trial-and-error heuristics, and multi-scale organization--can guide\nthe design of truly intelligent systems. By examining the nuanced mechanisms of\nbiological intelligence, such as top-down causality and adaptive interaction\nwith the environment, we aim to illuminate potential limitations in artificial\nconstructs. Our goal is to provide a framework inspired by biological systems\nfor designing more adaptable and robust artificial intelligent systems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-11-22",
      "downloaded_date": "2025-02-01",
      "filename": "Dehghani-Bio-inspired AI Integrating Biological Complexity into Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.15243v1",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.NE",
        "cs.SC"
      ]
    },
    "2208.04508v2": {
      "title": "Training Overparametrized Neural Networks in Sublinear Time",
      "authors": [
        "Yichuan Deng",
        "Hang Hu",
        "Zhao Song",
        "Omri Weinstein",
        "Danyang Zhuo"
      ],
      "abstract": "The success of deep learning comes at a tremendous computational and energy\ncost, and the scalability of training massively overparametrized neural\nnetworks is becoming a real barrier to the progress of artificial intelligence\n(AI). Despite the popularity and low cost-per-iteration of traditional\nbackpropagation via gradient decent, stochastic gradient descent (SGD) has\nprohibitive convergence rate in non-convex settings, both in theory and\npractice.\n  To mitigate this cost, recent works have proposed to employ alternative\n(Newton-type) training methods with much faster convergence rate, albeit with\nhigher cost-per-iteration. For a typical neural network with\n$m=\\mathrm{poly}(n)$ parameters and input batch of $n$ datapoints in\n$\\mathbb{R}^d$, the previous work of [Brand, Peng, Song, and Weinstein,\nITCS'2021] requires $\\sim mnd + n^3$ time per iteration. In this paper, we\npresent a novel training method that requires only $m^{1-\\alpha} n d + n^3$\namortized time in the same overparametrized regime, where $\\alpha \\in (0.01,1)$\nis some fixed constant. This method relies on a new and alternative view of\nneural networks, as a set of binary search trees, where each iteration\ncorresponds to modifying a small subset of the nodes in the tree. We believe\nthis view would have further applications in the design and analysis of deep\nneural networks (DNNs).",
      "citation_count": 25,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/15acdb9c0fd1224a5a7c44c2e36e0630600e090d",
      "published_date": "2022-08-09",
      "downloaded_date": "2025-02-01",
      "filename": "Deng-Training Overparametrized Neural Networks in Sublinear Time.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2208.04508v2",
      "categories": [
        "cs.LG",
        "cs.DS",
        "stat.ML"
      ]
    },
    "2211.08244v2": {
      "title": "Artificial Intelligence for Automatic Detection and Classification Disease on the X-Ray Images",
      "authors": [
        "Liora Mayats-Alpay"
      ],
      "abstract": "Detecting and classifying diseases using X-ray images is one of the more\nchallenging core tasks in the medical and research world. Due to the recent\nhigh interest in radiological images and AI, early detection of diseases in\nX-ray images has become notably more essential to prevent further spreading and\nflatten the curve. Innovations and revolutions of Computer Vision with Deep\nlearning methods offer great promise for fast and accurate diagnosis of\nscreening and detection from chest X-ray images (CXR). This work presents rapid\ndetection of diseases in the lung using the efficient Deep learning pre-trained\nRepVGG algorithm for deep feature extraction and classification. We used X-ray\nimages as an example to show the model's efficiency. To perform this task, we\nclassify X-Ray images into Covid-19, Pneumonia, and Normal X-Ray images. Employ\nROI object to improve the detection accuracy for lung extraction, followed by\ndata pre-processing and augmentation. We are applying Artificial Intelligence\ntechnology for automatic highlighted detection of affected areas of people's\nlungs. Based on the X-Ray images, an algorithm was developed that classifies\nX-Ray images with height accuracy and power faster thanks to the architecture\ntransformation of the model. We compared deep learning frameworks' accuracy and\ndetection of disease. The study shows the high power of deep learning methods\nfor X-ray images based on COVID-19 detection utilizing chest X-rays. The\nproposed framework offers better diagnostic accuracy by comparing popular deep\nlearning models, i.e., VGG, ResNet50, inceptionV3, DenseNet, and\nInceptionResnetV2.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/53889370afcf4c590c7c3d44394ef78ee76875e4",
      "published_date": "2022-11-14",
      "downloaded_date": "2025-02-01",
      "filename": "Mayats-Alpay-Artificial Intelligence for Automatic Detection and Classification Disease on the X-Ray Images.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.08244v2",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2102.00179v1": {
      "title": "Matching Representations of Explainable Artificial Intelligence and Eye Gaze for Human-Machine Interaction",
      "authors": [
        "Tiffany Hwu",
        "Mia Levy",
        "Steven Skorheim",
        "David Huber"
      ],
      "abstract": "Rapid non-verbal communication of task-based stimuli is a challenge in\nhuman-machine teaming, particularly in closed-loop interactions such as\ndriving. To achieve this, we must understand the representations of information\nfor both the human and machine, and determine a basis for bridging these\nrepresentations. Techniques of explainable artificial intelligence (XAI) such\nas layer-wise relevance propagation (LRP) provide visual heatmap explanations\nfor high-dimensional machine learning techniques such as deep neural networks.\nOn the side of human cognition, visual attention is driven by the bottom-up and\ntop-down processing of sensory input related to the current task. Since both\nXAI and human cognition should focus on task-related stimuli, there may be\noverlaps between their representations of visual attention, potentially\nproviding a means of nonverbal communication between the human and machine. In\nthis work, we examine the correlations between LRP heatmap explanations of a\nneural network trained to predict driving behavior and eye gaze heatmaps of\nhuman drivers. The analysis is used to determine the feasibility of using such\na technique for enhancing driving performance. We find that LRP heatmaps show\nincreasing levels of similarity with eye gaze according to the task specificity\nof the neural network. We then propose how these findings may assist humans by\nvisually directing attention towards relevant areas. To our knowledge, our work\nprovides the first known analysis of LRP and eye gaze for driving tasks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-01-30",
      "downloaded_date": "2025-02-01",
      "filename": "Hwu-Matching Representations of Explainable Artificial Intelligence and Eye Gaze for Human-Machine Inter....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.00179v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    "2404.06031v1": {
      "title": "FuSeBMC AI: Acceleration of Hybrid Approach through Machine Learning",
      "authors": [
        "Kaled M. Alshmrany",
        "Mohannad Aldughaim",
        "Chenfeng Wei",
        "Tom Sweet",
        "Richard Allmendinger",
        "Lucas C. Cordeiro"
      ],
      "abstract": "We present FuSeBMC-AI, a test generation tool grounded in machine learning\ntechniques. FuSeBMC-AI extracts various features from the program and employs\nsupport vector machine and neural network models to predict a hybrid approach\noptimal configuration. FuSeBMC-AI utilizes Bounded Model Checking and Fuzzing\nas back-end verification engines. FuSeBMC-AI outperforms the default\nconfiguration of the underlying verification engine in certain cases while\nconcurrently diminishing resource consumption.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b99595420790988fa58c8449a0f8457a1b6ba6c3",
      "published_date": "2024-04-09",
      "downloaded_date": "2025-02-01",
      "filename": "Alshmrany-FuSeBMC AI Acceleration of Hybrid Approach through Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.06031v1",
      "categories": [
        "cs.CR"
      ]
    },
    "2105.05330v2": {
      "title": "Neuro-Symbolic Artificial Intelligence: Current Trends",
      "authors": [
        "Md Kamruzzaman Sarker",
        "Lu Zhou",
        "Aaron Eberhart",
        "Pascal Hitzler"
      ],
      "abstract": "Neuro-Symbolic Artificial Intelligence -- the combination of symbolic methods\nwith methods that are based on artificial neural networks -- has a\nlong-standing history. In this article, we provide a structured overview of\ncurrent trends, by means of categorizing recent publications from key\nconferences. The article is meant to serve as a convenient starting point for\nresearch on the general topic.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-05-11",
      "downloaded_date": "2025-02-01",
      "filename": "Sarker-Neuro-Symbolic Artificial Intelligence Current Trends.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.05330v2",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2409.12922v1": {
      "title": "AI Thinking: A framework for rethinking artificial intelligence in practice",
      "authors": [
        "Denis Newman-Griffis"
      ],
      "abstract": "Artificial intelligence is transforming the way we work with information\nacross disciplines and practical contexts. A growing range of disciplines are\nnow involved in studying, developing, and assessing the use of AI in practice,\nbut these disciplines often employ conflicting understandings of what AI is and\nwhat is involved in its use. New, interdisciplinary approaches are needed to\nbridge competing conceptualisations of AI in practice and help shape the future\nof AI use. I propose a novel conceptual framework called AI Thinking, which\nmodels key decisions and considerations involved in AI use across disciplinary\nperspectives. The AI Thinking model addresses five practice-based competencies\ninvolved in applying AI in context: motivating AI use in information processes,\nformulating AI methods, assessing available tools and technologies, selecting\nappropriate data, and situating AI in the sociotechnical contexts it is used\nin. A hypothetical case study is provided to illustrate the application of AI\nThinking in practice. This article situates AI Thinking in broader\ncross-disciplinary discourses of AI, including its connections to ongoing\ndiscussions around AI literacy and AI-driven innovation. AI Thinking can help\nto bridge divides between academic disciplines and diverse contexts of AI use,\nand to reshape the future of AI in practice.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-08-26",
      "downloaded_date": "2025-02-01",
      "filename": "Newman-Griffis-AI Thinking A framework for rethinking artificial intelligence in practice.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.12922v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ]
    },
    "2410.10929v6": {
      "title": "ASTM :Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM",
      "authors": [
        "Christofel Rio Goenawan"
      ],
      "abstract": "In the modern world, the development of Artificial Intelligence (AI) has\ncontributed to improvements in various areas, including automation, computer\nvision, fraud detection, and more. AI can be leveraged to enhance the\nefficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce\ntraffic congestion rates. This paper presents an Autonomous Smart Traffic\nManagement (STM) system that uses AI to improve traffic flow rates. The system\nemploys the YOLO V5 Convolutional Neural Network to detect vehicles in traffic\nmanagement images. Additionally, it predicts the number of vehicles for the\nnext 12 hours using a Recurrent Neural Network with Long Short-Term Memory\n(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the\ntraffic cycle length based on these vehicle predictions, aided by AI. From the\nresults of the RNN-LSTM model for predicting vehicle numbers over the next 12\nhours, we observe that the model predicts traffic with a Mean Squared Error\n(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.\nAfter simulating the STM system in the CARLA simulation environment, we found\nthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per\nminute) is 50\\% higher than the rate without STM (around 15 vehicles per\nminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5\nseconds per vehicle) is 70\\% lower than without STM (around 12 seconds per\nvehicle). These results demonstrate that the STM system using AI can increase\ntraffic flow by 50\\% and reduce vehicle pass delays by 70\\%.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/448e7bd9d691981d4921772e768fabb8356259f0",
      "published_date": "2024-10-14",
      "downloaded_date": "2025-02-01",
      "filename": "Goenawan-ASTM Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.10929v6",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    "2108.03383v2": {
      "title": "Artificial Intelligence-Driven Customized Manufacturing Factory: Key Technologies, Applications, and Challenges",
      "authors": [
        "Jiafu Wan",
        "Xiaomin Li",
        "Hong-Ning Dai",
        "Andrew Kusiak",
        "Miguel MartÃ­nez-GarcÃ­a",
        "Di Li"
      ],
      "abstract": "The traditional production paradigm of large batch production does not offer\nflexibility towards satisfying the requirements of individual customers. A new\ngeneration of smart factories is expected to support new multi-variety and\nsmall-batch customized production modes. For that, Artificial Intelligence (AI)\nis enabling higher value-added manufacturing by accelerating the integration of\nmanufacturing and information communication technologies, including computing,\ncommunication, and control. The characteristics of a customized smart factory\nare to include self-perception, operations optimization, dynamic\nreconfiguration, and intelligent decision-making. The AI technologies will\nallow manufacturing systems to perceive the environment, adapt to external\nneeds, and extract the processed knowledge, including business models, such as\nintelligent production, networked collaboration, and extended service models.\n  This paper focuses on the implementation of AI in customized manufacturing\n(CM). The architecture of an AI-driven customized smart factory is presented.\nDetails of intelligent manufacturing devices, intelligent information\ninteraction, and the construction of a flexible manufacturing line are\nshowcased. The state-of-the-art AI technologies of potential use in CM, i.e.,\nmachine learning, multi-agent systems, Internet of Things, big data, and\ncloud-edge computing are surveyed. The AI-enabled technologies in a customized\nsmart factory are validated with a case study of customized packaging. The\nexperimental results have demonstrated that the AI-assisted CM offers the\npossibility of higher production flexibility and efficiency. Challenges and\nsolutions related to AI in CM are also discussed.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-08-07",
      "downloaded_date": "2025-02-01",
      "filename": "Wan-Artificial Intelligence-Driven Customized Manufacturing Factory Key Technologies Applications and Ch....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.03383v2",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO",
        "68T40, 68T42, 68T05",
        "I.2.1; I.2.11; I.2.9"
      ]
    },
    "2112.08453v1": {
      "title": "The Need for Ethical, Responsible, and Trustworthy Artificial Intelligence for Environmental Sciences",
      "authors": [
        "Amy McGovern",
        "Imme Ebert-Uphoff",
        "David John Gagne II",
        "Ann Bostrom"
      ],
      "abstract": "Given the growing use of Artificial Intelligence (AI) and machine learning\n(ML) methods across all aspects of environmental sciences, it is imperative\nthat we initiate a discussion about the ethical and responsible use of AI. In\nfact, much can be learned from other domains where AI was introduced, often\nwith the best of intentions, yet often led to unintended societal consequences,\nsuch as hard coding racial bias in the criminal justice system or increasing\neconomic inequality through the financial system. A common misconception is\nthat the environmental sciences are immune to such unintended consequences when\nAI is being used, as most data come from observations, and AI algorithms are\nbased on mathematical formulas, which are often seen as objective. In this\narticle, we argue the opposite can be the case. Using specific examples, we\ndemonstrate many ways in which the use of AI can introduce similar consequences\nin the environmental sciences. This article will stimulate discussion and\nresearch efforts in this direction. As a community, we should avoid repeating\nany foreseeable mistakes made in other domains through the introduction of AI.\nIn fact, with proper precautions, AI can be a great tool to help {\\it reduce}\nclimate and environmental injustice. We primarily focus on weather and climate\nexamples but the conclusions apply broadly across the environmental sciences.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-12-15",
      "downloaded_date": "2025-02-01",
      "filename": "McGovern-The Need for Ethical Responsible and Trustworthy Artificial Intelligence for Environmental Sciences.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2112.08453v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "K.4.0; I.2.0"
      ]
    },
    "2211.03157v4": {
      "title": "Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control",
      "authors": [
        "Kyle A. Kilian",
        "Christopher J. Ventura",
        "Mark M. Bailey"
      ],
      "abstract": "Artificial Intelligence (AI) is one of the most transformative technologies\nof the 21st century. The extent and scope of future AI capabilities remain a\nkey uncertainty, with widespread disagreement on timelines and potential\nimpacts. As nations and technology companies race toward greater complexity and\nautonomy in AI systems, there are concerns over the extent of integration and\noversight of opaque AI decision processes. This is especially true in the\nsubfield of machine learning (ML), where systems learn to optimize objectives\nwithout human assistance. Objectives can be imperfectly specified or executed\nin an unexpected or potentially harmful way. This becomes more concerning as\nsystems increase in power and autonomy, where an abrupt capability jump could\nresult in unexpected shifts in power dynamics or even catastrophic failures.\nThis study presents a hierarchical complex systems framework to model AI risk\nand provide a template for alternative futures analysis. Survey data were\ncollected from domain experts in the public and private sectors to classify AI\nimpact and likelihood. The results show increased uncertainty over the powerful\nAI agent scenario, confidence in multiagent environments, and increased concern\nover AI alignment failures and influence-seeking behavior.",
      "citation_count": 12,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3607dd3cbe7bf8f82df92fbb1e80849b0f1b4297",
      "published_date": "2022-11-06",
      "downloaded_date": "2025-02-01",
      "filename": "Kilian-Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.03157v4",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ]
    },
    "2501.10374v1": {
      "title": "Artificial Intelligence in Mental Health and Well-Being: Evolution, Current Applications, Future Challenges, and Emerging Evidence",
      "authors": [
        "Hari Mohan Pandey"
      ],
      "abstract": "Artificial Intelligence (AI) is a broad field that is upturning mental health\ncare in many ways, from addressing anxiety, depression, and stress to\nincreasing access, personalization of treatment, and real-time monitoring that\nenhances patient outcomes. The current paper discusses the evolution, present\napplication, and future challenges in the field of AI for mental health and\nwell-being. From the early chatbot models, such as ELIZA, to modern machine\nlearning systems, the integration of AI in mental health has grown rapidly to\naugment traditional treatment and open innovative solutions. AI-driven tools\nprovide continuous support, offering personalized interventions and addressing\nissues such as treatment access and patient stigma. AI also enables early\ndiagnosis through the analysis of complex datasets, including speech patterns\nand social media behavior, to detect early signs of conditions like depression\nand Post-Traumatic Stress Disorder (PTSD). Ethical challenges persist, however,\nmost notably around privacy, data security, and algorithmic bias. With AI at\nthe core of mental health care, there is a dire need to develop strong ethical\nframeworks that ensure patient rights are protected, access is equitable, and\ntransparency is maintained in AI applications. Going forward, the role of AI in\nmental health will continue to evolve, and continued research and policy\ndevelopment will be needed to meet the diverse needs of patients while\nmitigating associated risks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-12-13",
      "downloaded_date": "2025-02-01",
      "filename": "Pandey-Artificial Intelligence in Mental Health and Well-Being Evolution Current Applications Future Challe....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.10374v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2307.00364v2": {
      "title": "The future of human-centric eXplainable Artificial Intelligence (XAI) is not post-hoc explanations",
      "authors": [
        "Vinitra Swamy",
        "Jibril Frej",
        "Tanja KÃ¤ser"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) plays a crucial role in enabling\nhuman understanding and trust in deep learning systems. As models get larger,\nmore ubiquitous, and pervasive in aspects of daily life, explainability is\nnecessary to minimize adverse effects of model mistakes. Unfortunately, current\napproaches in human-centric XAI (e.g. predictive tasks in healthcare,\neducation, or personalized ads) tend to rely on a single post-hoc explainer,\nwhereas recent work has identified systematic disagreement between post-hoc\nexplainers when applied to the same instances of underlying black-box models.\nIn this paper, we therefore present a call for action to address the\nlimitations of current state-of-the-art explainers. We propose a shift from\npost-hoc explainability to designing interpretable neural network\narchitectures. We identify five needs of human-centric XAI (real-time,\naccurate, actionable, human-interpretable, and consistent) and propose two\nschemes for interpretable-by-design neural network workflows (adaptive routing\nwith InterpretCC and temporal diagnostics with I2MD). We postulate that the\nfuture of human-centric XAI is neither in explaining black-boxes nor in\nreverting to traditional, interpretable models, but in neural networks that are\nintrinsically interpretable.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/20b8ad15dbce756a3f20cf6bb0233386eac4f89d",
      "published_date": "2023-07-01",
      "downloaded_date": "2025-02-01",
      "filename": "Swamy-The future of human-centric eXplainable Artificial Intelligence XAI is not post-hoc explanations.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.00364v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ]
    },
    "1906.01478v1": {
      "title": "What do AI algorithms actually learn? - On false structures in deep learning",
      "authors": [
        "Laura Thesing",
        "Vegard Antun",
        "Anders C. Hansen"
      ],
      "abstract": "There are two big unsolved mathematical questions in artificial intelligence\n(AI): (1) Why is deep learning so successful in classification problems and (2)\nwhy are neural nets based on deep learning at the same time universally\nunstable, where the instabilities make the networks vulnerable to adversarial\nattacks. We present a solution to these questions that can be summed up in two\nwords; false structures. Indeed, deep learning does not learn the original\nstructures that humans use when recognising images (cats have whiskers, paws,\nfur, pointy ears, etc), but rather different false structures that correlate\nwith the original structure and hence yield the success. However, the false\nstructure, unlike the original structure, is unstable. The false structure is\nsimpler than the original structure, hence easier to learn with less data and\nthe numerical algorithm used in the training will more easily converge to the\nneural network that captures the false structure. We formally define the\nconcept of false structures and formulate the solution as a conjecture. Given\nthat trained neural networks always are computed with approximations, this\nconjecture can only be established through a combination of theoretical and\ncomputational results similar to how one establishes a postulate in theoretical\nphysics (e.g. the speed of light is constant). Establishing the conjecture\nfully will require a vast research program characterising the false structures.\nWe provide the foundations for such a program establishing the existence of the\nfalse structures in practice. Finally, we discuss the far reaching consequences\nthe existence of the false structures has on state-of-the-art AI and Smale's\n18th problem.",
      "citation_count": 21,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f530c7d41d73831809f521b94c8766fb3733a2da",
      "published_date": "2019-06-04",
      "downloaded_date": "2025-02-01",
      "filename": "Thesing-What do AI algorithms actually learn - On false structures in deep learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1906.01478v1",
      "categories": [
        "stat.ML",
        "cs.CR",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2105.12700v2": {
      "title": "Towards Transparent Application of Machine Learning in Video Processing",
      "authors": [
        "Luka Murn",
        "Marc Gorriz Blanch",
        "Maria Santamaria",
        "Fiona Rivera",
        "Marta Mrak"
      ],
      "abstract": "Machine learning techniques for more efficient video compression and video\nenhancement have been developed thanks to breakthroughs in deep learning. The\nnew techniques, considered as an advanced form of Artificial Intelligence (AI),\nbring previously unforeseen capabilities. However, they typically come in the\nform of resource-hungry black-boxes (overly complex with little transparency\nregarding the inner workings). Their application can therefore be unpredictable\nand generally unreliable for large-scale use (e.g. in live broadcast). The aim\nof this work is to understand and optimise learned models in video processing\napplications so systems that incorporate them can be used in a more trustworthy\nmanner. In this context, the presented work introduces principles for\nsimplification of learned models targeting improved transparency in\nimplementing machine learning for video production and distribution\napplications. These principles are demonstrated on video compression examples,\nshowing how bitrate savings and reduced complexity can be achieved by\nsimplifying relevant deep learning models.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-05-26",
      "downloaded_date": "2025-02-01",
      "filename": "Murn-Towards Transparent Application of Machine Learning in Video Processing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.12700v2",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ]
    },
    "2501.14306v1": {
      "title": "Additive Manufacturing Processes Protocol Prediction by Artificial Intelligence using X-ray Computed Tomography data",
      "authors": [
        "Sunita Khod",
        "Akshay Dvivedi",
        "Mayank Goswami"
      ],
      "abstract": "The quality of the part fabricated from the Additive Manufacturing (AM)\nprocess depends upon the process parameters used, and therefore, optimization\nis required for apt quality. A methodology is proposed to set these parameters\nnon-iteratively without human intervention. It utilizes Artificial Intelligence\n(AI) to fully automate the process, with the capability to self-train any apt\nAI model by further assimilating the training data.This study includes three\ncommercially available 3D printers for soft material printing based on the\nMaterial Extrusion (MEX) AM process. The samples are 3D printed for six\ndifferent AM process parameters obtained by varying layer height and nozzle\nspeed. The novelty part of the methodology is incorporating an AI-based image\nsegmentation step in the decision-making stage that uses quality inspected\ntraining data from the Non-Destructive Testing (NDT) method. The performance of\nthe trained AI model is compared with the two software tools based on the\nclassical thresholding method. The AI-based Artificial Neural Network (ANN)\nmodel is trained from NDT-assessed and AI-segmented data to automate the\nselection of optimized process parameters. The AI-based model is 99.3 %\naccurate, while the best available commercial classical image method is 83.44 %\naccurate. The best value of overall R for training ANN is 0.82. The MEX process\ngives a 22.06 % porosity error relative to the design. The NDT-data trained two\nAI models integrated into a series pipeline for optimal process parameters are\nproposed and verified by classical optimization and mechanical testing methods.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/61f960afbca6f124e1c8713850a141cf4a8df2d9",
      "published_date": "2025-01-24",
      "downloaded_date": "2025-02-01",
      "filename": "Khod-Additive Manufacturing Processes Protocol Prediction by Artificial Intelligence using X-ray Computed....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.14306v1",
      "categories": [
        "cs.CV",
        "physics.app-ph"
      ]
    },
    "2209.15104v1": {
      "title": "OAK4XAI: Model towards Out-Of-Box eXplainable Artificial Intelligence for Digital Agriculture",
      "authors": [
        "Quoc Hung Ngo",
        "Tahar Kechadi",
        "Nhien-An Le-Khac"
      ],
      "abstract": "Recent machine learning approaches have been effective in Artificial\nIntelligence (AI) applications. They produce robust results with a high level\nof accuracy. However, most of these techniques do not provide\nhuman-understandable explanations for supporting their results and decisions.\nThey usually act as black boxes, and it is not easy to understand how decisions\nhave been made. Explainable Artificial Intelligence (XAI), which has received\nmuch interest recently, tries to provide human-understandable explanations for\ndecision-making and trained AI models. For instance, in digital agriculture,\nrelated domains often present peculiar or input features with no link to\nbackground knowledge. The application of the data mining process on\nagricultural data leads to results (knowledge), which are difficult to explain.\nIn this paper, we propose a knowledge map model and an ontology design as an\nXAI framework (OAK4XAI) to deal with this issue. The framework does not only\nconsider the data analysis part of the process, but it takes into account the\nsemantics aspect of the domain knowledge via an ontology and a knowledge map\nmodel, provided as modules of the framework. Many ongoing XAI studies aim to\nprovide accurate and verbalizable accounts for how given feature values\ncontribute to model decisions. The proposed approach, however, focuses on\nproviding consistent information and definitions of concepts, algorithms, and\nvalues involved in the data mining models. We built an Agriculture Computing\nOntology (AgriComO) to explain the knowledge mined in agriculture. AgriComO has\na well-designed structure and includes a wide range of concepts and\ntransformations suitable for agriculture and computing domains.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-09-29",
      "downloaded_date": "2025-02-01",
      "filename": "Ngo-OAK4XAI Model towards Out-Of-Box eXplainable Artificial Intelligence for Digital Agriculture.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.15104v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2002.04500v1": {
      "title": "Artificial Intelligence Assistance Significantly Improves Gleason Grading of Prostate Biopsies by Pathologists",
      "authors": [
        "Wouter Bulten",
        "Maschenka Balkenhol",
        "Jean-JoÃ«l Awoumou Belinga",
        "AmÃ©rico Brilhante",
        "AslÄ± ÃakÄ±r",
        "Xavier FarrÃ©",
        "Katerina Geronatsiou",
        "Vincent MoliniÃ©",
        "Guilherme Pereira",
        "Paromita Roy",
        "GÃ¼nter Saile",
        "Paulo Salles",
        "Ewout Schaafsma",
        "JoÃ«lle Tschui",
        "Anne-Marie Vos",
        "Hester van Boven",
        "Robert Vink",
        "Jeroen van der Laak",
        "Christina Hulsbergen-van de Kaa",
        "Geert Litjens"
      ],
      "abstract": "While the Gleason score is the most important prognostic marker for prostate\ncancer patients, it suffers from significant observer variability. Artificial\nIntelligence (AI) systems, based on deep learning, have proven to achieve\npathologist-level performance at Gleason grading. However, the performance of\nsuch systems can degrade in the presence of artifacts, foreign tissue, or other\nanomalies. Pathologists integrating their expertise with feedback from an AI\nsystem could result in a synergy that outperforms both the individual\npathologist and the system. Despite the hype around AI assistance, existing\nliterature on this topic within the pathology domain is limited. We\ninvestigated the value of AI assistance for grading prostate biopsies. A panel\nof fourteen observers graded 160 biopsies with and without AI assistance. Using\nAI, the agreement of the panel with an expert reference standard significantly\nincreased (quadratically weighted Cohen's kappa, 0.799 vs 0.872; p=0.018). Our\nresults show the added value of AI systems for Gleason grading, but more\nimportantly, show the benefits of pathologist-AI synergy.",
      "citation_count": 120,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/06bcda243a29be0892422c60b663f80cff21978a",
      "published_date": "2020-02-11",
      "downloaded_date": "2025-02-01",
      "filename": "Bulten-Artificial Intelligence Assistance Significantly Improves Gleason Grading of Prostate Biopsies by Pa....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2002.04500v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "q-bio.QM"
      ]
    },
    "2308.02030v1": {
      "title": "Perceptions of the Fourth Industrial Revolution and Artificial Intelligence Impact on Society",
      "authors": [
        "Daniel Agbaji",
        "Brady Lund",
        "Nishith Reddy Mannuru"
      ],
      "abstract": "The Fourth Industrial Revolution, particularly Artificial Intelligence (AI),\nhas had a profound impact on society, raising concerns about its implications\nand ethical considerations. The emergence of text generative AI tools like\nChatGPT has further intensified concerns regarding ethics, security, privacy,\nand copyright. This study aims to examine the perceptions of individuals in\ndifferent information flow categorizations toward AI. The results reveal key\nthemes in participant-supplied definitions of AI and the fourth industrial\nrevolution, emphasizing the replication of human intelligence, machine\nlearning, automation, and the integration of digital technologies. Participants\nexpressed concerns about job replacement, privacy invasion, and inaccurate\ninformation provided by AI. However, they also recognized the benefits of AI,\nsuch as solving complex problems and increasing convenience. Views on\ngovernment involvement in shaping the fourth industrial revolution varied, with\nsome advocating for strict regulations and others favoring support and\ndevelopment. The anticipated changes brought by the fourth industrial\nrevolution include automation, potential job impacts, increased social\ndisconnect, and reliance on technology. Understanding these perceptions is\ncrucial for effectively managing the challenges and opportunities associated\nwith AI in the evolving digital landscape.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f2bbf3d1e4f681b45ddaff8776531165d542db70",
      "published_date": "2023-07-31",
      "downloaded_date": "2025-02-01",
      "filename": "Agbaji-Perceptions of the Fourth Industrial Revolution and Artificial Intelligence Impact on Society.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.02030v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "68-XX(Primary) 68TXX, 68T42 (Secondary)",
        "I.2.1; H.4"
      ]
    },
    "2406.18900v1": {
      "title": "The Rise of Artificial Intelligence in Educational Measurement: Opportunities and Ethical Challenges",
      "authors": [
        "Okan Bulut",
        "Maggie Beiting-Parrish",
        "Jodi M. Casabianca",
        "Sharon C. Slater",
        "Hong Jiao",
        "Dan Song",
        "Christopher M. Ormerod",
        "Deborah Gbemisola Fabiyi",
        "Rodica Ivan",
        "Cole Walsh",
        "Oscar Rios",
        "Joshua Wilson",
        "Seyma N. Yildirim-Erbasli",
        "Tarid Wongvorachan",
        "Joyce Xinle Liu",
        "Bin Tan",
        "Polina Morilova"
      ],
      "abstract": "The integration of artificial intelligence (AI) in educational measurement\nhas revolutionized assessment methods, enabling automated scoring, rapid\ncontent analysis, and personalized feedback through machine learning and\nnatural language processing. These advancements provide timely, consistent\nfeedback and valuable insights into student performance, thereby enhancing the\nassessment experience. However, the deployment of AI in education also raises\nsignificant ethical concerns regarding validity, reliability, transparency,\nfairness, and equity. Issues such as algorithmic bias and the opacity of AI\ndecision-making processes pose risks of perpetuating inequalities and affecting\nassessment outcomes. Responding to these concerns, various stakeholders,\nincluding educators, policymakers, and organizations, have developed guidelines\nto ensure ethical AI use in education. The National Council of Measurement in\nEducation's Special Interest Group on AI in Measurement and Education (AIME)\nalso focuses on establishing ethical standards and advancing research in this\narea. In this paper, a diverse group of AIME members examines the ethical\nimplications of AI-powered tools in educational measurement, explores\nsignificant challenges such as automation bias and environmental impact, and\nproposes solutions to ensure AI's responsible and effective use in education.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/26c2794ed945a595c556e4c15ce3a64f175cb31b",
      "published_date": "2024-06-27",
      "downloaded_date": "2025-02-01",
      "filename": "Bulut-The Rise of Artificial Intelligence in Educational Measurement Opportunities and Ethical Challenges.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.18900v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "1812.07040v2": {
      "title": "Deep learning incorporating biologically-inspired neural dynamics",
      "authors": [
        "StanisÅaw WoÅºniak",
        "Angeliki Pantazi",
        "Thomas Bohnstingl",
        "Evangelos Eleftheriou"
      ],
      "abstract": "Neural networks have become the key technology of artificial intelligence and\nhave contributed to breakthroughs in several machine learning tasks, primarily\nowing to advances in deep learning applied to Artificial Neural Networks\n(ANNs). Simultaneously, Spiking Neural Networks (SNNs) incorporating\nbiologically-feasible spiking neurons have held great promise because of their\nrich temporal dynamics and high-power efficiency. However, the developments in\nSNNs were proceeding separately from those in ANNs, effectively limiting the\nadoption of deep learning research insights. Here we show an alternative\nperspective on the spiking neuron that casts it as a particular ANN construct\ncalled Spiking Neural Unit (SNU), and a soft SNU (sSNU) variant that\ngeneralizes its dynamics to a novel recurrent ANN unit. SNUs bridge the\nbiologically-inspired SNNs with ANNs and provide a methodology for seamless\ninclusion of spiking neurons in deep learning architectures. Furthermore, SNU\nenables highly-efficient in-memory acceleration of SNNs trained with\nbackpropagation through time, implemented with the hardware in-the-loop. We\napply SNUs to tasks ranging from hand-written digit recognition, language\nmodelling, to music prediction. We obtain accuracy comparable to, or better\nthan, that of state-of-the-art ANNs, and we experimentally verify the efficacy\nof the in-memory-based SNN realization for the music-prediction task using\n52,800 phase-change memory devices. The new generation of neural units\nintroduced in this paper incorporate biologically-inspired neural dynamics in\ndeep learning. In addition, they provide a systematic methodology for training\nneuromorphic computing hardware. Thus, they open a new avenue for a widespread\nadoption of SNNs in practical applications.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/eb45afbe0def02554811fb83a3d1becb382bdc03",
      "published_date": "2018-12-17",
      "downloaded_date": "2025-02-01",
      "filename": "WoÅºniak-Deep learning incorporating biologically-inspired neural dynamics.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1812.07040v2",
      "categories": [
        "cs.NE"
      ]
    },
    "2009.01812v1": {
      "title": "The Pace of Artificial Intelligence Innovations: Speed, Talent, and Trial-and-Error",
      "authors": [
        "Xuli Tang",
        "Xin Li",
        "Ying Ding",
        "Min Song",
        "Yi Bu"
      ],
      "abstract": "Innovations in artificial intelligence (AI) are occurring at speeds faster\nthan ever witnessed before. However, few studies have managed to measure or\ndepict this increasing velocity of innovations in the field of AI. In this\npaper, we combine data on AI from arXiv and Semantic Scholar to explore the\npace of AI innovations from three perspectives: AI publications, AI players,\nand AI updates (trial and error). A research framework and three novel\nindicators, Average Time Interval (ATI), Innovation Speed (IS) and Update Speed\n(US), are proposed to measure the pace of innovations in the field of AI. The\nresults show that: (1) in 2019, more than 3 AI preprints were submitted to\narXiv per hour, over 148 times faster than in 1994. Furthermore, there was one\ndeep learning-related preprint submitted to arXiv every 0.87 hours in 2019,\nover 1,064 times faster than in 1994. (2) For AI players, 5.26 new researchers\nentered into the field of AI each hour in 2019, more than 175 times faster than\nin the 1990s. (3) As for AI updates (trial and error), one updated AI preprint\nwas submitted to arXiv every 41 days, with around 33% of AI preprints having\nbeen updated at least twice in 2019. In addition, as reported in 2019, it took,\non average, only around 0.2 year for AI preprints to receive their first\ncitations, which is 5 times faster than 2000-2007. This swift pace in AI\nillustrates the increase in popularity of AI innovation. The systematic and\nfine-grained analysis of the AI field enabled to portrait the pace of AI\ninnovation and demonstrated that the proposed approach can be adopted to\nunderstand other fast-growing fields such as cancer research and nano science.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-09-03",
      "downloaded_date": "2025-02-01",
      "filename": "Tang-The Pace of Artificial Intelligence Innovations Speed Talent and Trial-and-Error.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.01812v1",
      "categories": [
        "cs.DL",
        "physics.soc-ph"
      ]
    },
    "2412.14085v1": {
      "title": "Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report",
      "authors": [
        "Markus Dablander"
      ],
      "abstract": "Video games are a natural and synergistic application domain for artificial\nintelligence (AI) systems, offering both the potential to enhance player\nexperience and immersion, as well as providing valuable benchmarks and virtual\nenvironments to advance AI technologies in general. This report presents a\nhigh-level overview of five promising research pathways for applying\nstate-of-the-art AI methods, particularly deep learning, to digital gaming\nwithin the context of the current research landscape. The objective of this\nwork is to outline a curated, non-exhaustive list of encouraging research\ndirections at the intersection of AI and video games that may serve to inspire\nmore rigorous and comprehensive research efforts in the future. We discuss (i)\ninvestigating large language models as core engines for game agent modelling,\n(ii) using neural cellular automata for procedural game content generation,\n(iii) accelerating computationally expensive in-game simulations via deep\nsurrogate modelling, (iv) leveraging self-supervised learning to obtain useful\nvideo game state embeddings, and (v) training generative models of interactive\nworlds using unlabelled video data. We also briefly address current technical\nchallenges associated with the integration of advanced deep learning systems\ninto video game development, and indicate key areas where further progress is\nlikely to be beneficial.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-12-18",
      "downloaded_date": "2025-02-01",
      "filename": "Dablander-Future Research Avenues for Artificial Intelligence in Digital Gaming An Exploratory Report.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.14085v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ]
    },
    "1911.11872v3": {
      "title": "Artificial Intelligence-Based Image Classification for Diagnosis of Skin Cancer: Challenges and Opportunities",
      "authors": [
        "Manu Goyal",
        "Thomas Knackstedt",
        "Shaofeng Yan",
        "Saeed Hassanpour"
      ],
      "abstract": "Recently, there has been great interest in developing Artificial Intelligence\n(AI) enabled computer-aided diagnostics solutions for the diagnosis of skin\ncancer. With the increasing incidence of skin cancers, low awareness among a\ngrowing population, and a lack of adequate clinical expertise and services,\nthere is an immediate need for AI systems to assist clinicians in this domain.\nA large number of skin lesion datasets are available publicly, and researchers\nhave developed AI-based image classification solutions, particularly deep\nlearning algorithms, to distinguish malignant skin lesions from benign lesions\nin different image modalities such as dermoscopic, clinical, and histopathology\nimages. Despite the various claims of AI systems achieving higher accuracy than\ndermatologists in the classification of different skin lesions, these AI\nsystems are still in the very early stages of clinical application in terms of\nbeing ready to aid clinicians in the diagnosis of skin cancers. In this review,\nwe discuss advancements in the digital image-based AI solutions for the\ndiagnosis of skin cancer, along with some challenges and future opportunities\nto improve these AI systems to support dermatologists and enhance their ability\nto diagnose skin cancer.",
      "citation_count": 109,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/dcfab95dc878c1fa9217495c72085406ed2b6b72",
      "published_date": "2019-11-26",
      "downloaded_date": "2025-02-01",
      "filename": "Goyal-Artificial Intelligence-Based Image Classification for Diagnosis of Skin Cancer Challenges and Oppor....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.11872v3",
      "categories": [
        "eess.IV",
        "cs.CV",
        "q-bio.QM"
      ]
    },
    "2109.08880v1": {
      "title": "Computational Imaging and Artificial Intelligence: The Next Revolution of Mobile Vision",
      "authors": [
        "Jinli Suo",
        "Weihang Zhang",
        "Jin Gong",
        "Xin Yuan",
        "David J. Brady",
        "Qionghai Dai"
      ],
      "abstract": "Signal capture stands in the forefront to perceive and understand the\nenvironment and thus imaging plays the pivotal role in mobile vision. Recent\nexplosive progresses in Artificial Intelligence (AI) have shown great potential\nto develop advanced mobile platforms with new imaging devices. Traditional\nimaging systems based on the \"capturing images first and processing afterwards\"\nmechanism cannot meet this unprecedented demand. Differently, Computational\nImaging (CI) systems are designed to capture high-dimensional data in an\nencoded manner to provide more information for mobile vision systems.Thanks to\nAI, CI can now be used in real systems by integrating deep learning algorithms\ninto the mobile vision platform to achieve the closed loop of intelligent\nacquisition, processing and decision making, thus leading to the next\nrevolution of mobile vision.Starting from the history of mobile vision using\ndigital cameras, this work first introduces the advances of CI in diverse\napplications and then conducts a comprehensive review of current research\ntopics combining CI and AI. Motivated by the fact that most existing studies\nonly loosely connect CI and AI (usually using AI to improve the performance of\nCI and only limited works have deeply connected them), in this work, we propose\na framework to deeply integrate CI and AI by using the example of self-driving\nvehicles with high-speed communication, edge computing and traffic planning.\nFinally, we outlook the future of CI plus AI by investigating new materials,\nbrain science and new computing techniques to shed light on new directions of\nmobile vision systems.",
      "citation_count": 19,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/23964a91d992f67f7d3df9dbd5c32e7650cad357",
      "published_date": "2021-09-18",
      "downloaded_date": "2025-02-01",
      "filename": "Suo-Computational Imaging and Artificial Intelligence The Next Revolution of Mobile Vision.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2109.08880v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ]
    },
    "2410.05686v2": {
      "title": "Deep Learning and Machine Learning with GPGPU and CUDA: Unlocking the Power of Parallel Computing",
      "authors": [
        "Ming Li",
        "Ziqian Bi",
        "Tianyang Wang",
        "Yizhu Wen",
        "Qian Niu",
        "Junyu Liu",
        "Benji Peng",
        "Sen Zhang",
        "Xuanhe Pan",
        "Jiawei Xu",
        "Jinlang Wang",
        "Keyu Chen",
        "Caitlyn Heqi Yin",
        "Pohsun Feng",
        "Ming Liu"
      ],
      "abstract": "General Purpose Graphics Processing Unit (GPGPU) computing plays a\ntransformative role in deep learning and machine learning by leveraging the\ncomputational advantages of parallel processing. Through the power of Compute\nUnified Device Architecture (CUDA), GPUs enable the efficient execution of\ncomplex tasks via massive parallelism. This work explores CPU and GPU\narchitectures, data flow in deep learning, and advanced GPU features, including\nstreams, concurrency, and dynamic parallelism. The applications of GPGPU span\nscientific computing, machine learning acceleration, real-time rendering, and\ncryptocurrency mining. This study emphasizes the importance of selecting\nappropriate parallel architectures, such as GPUs, FPGAs, TPUs, and ASICs,\ntailored to specific computational tasks and optimizing algorithms for these\nplatforms. Practical examples using popular frameworks such as PyTorch,\nTensorFlow, and XGBoost demonstrate how to maximize GPU efficiency for training\nand inference tasks. This resource serves as a comprehensive guide for both\nbeginners and experienced practitioners, offering insights into GPU-based\nparallel computing and its critical role in advancing machine learning and\nartificial intelligence.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e29f7fad8452074b3857a1b56269e859824c5c64",
      "published_date": "2024-10-08",
      "downloaded_date": "2025-02-01",
      "filename": "Li-Deep Learning and Machine Learning with GPGPU and CUDA Unlocking the Power of Parallel Computing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.05686v2",
      "categories": [
        "cs.DC",
        "cs.AR"
      ]
    },
    "2111.00826v4": {
      "title": "Reproducibility as a Mechanism for Teaching Fairness, Accountability, Confidentiality, and Transparency in Artificial Intelligence",
      "authors": [
        "Ana Lucic",
        "Maurits Bleeker",
        "Sami Jullien",
        "Samarth Bhargav",
        "Maarten de Rijke"
      ],
      "abstract": "In this work, we explain the setup for a technical, graduate-level course on\nFairness, Accountability, Confidentiality, and Transparency in Artificial\nIntelligence (FACT-AI) at the University of Amsterdam, which teaches FACT-AI\nconcepts through the lens of reproducibility. The focal point of the course is\na group project based on reproducing existing FACT-AI algorithms from top AI\nconferences and writing a corresponding report. In the first iteration of the\ncourse, we created an open source repository with the code implementations from\nthe group projects. In the second iteration, we encouraged students to submit\ntheir group projects to the Machine Learning Reproducibility Challenge,\nresulting in 9 reports from our course being accepted for publication in the\nReScience journal. We reflect on our experience teaching the course over two\nyears, where one year coincided with a global pandemic, and propose guidelines\nfor teaching FACT-AI through reproducibility in graduate-level AI study\nprograms. We hope this can be a useful resource for instructors who want to set\nup similar courses in the future.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-11-01",
      "downloaded_date": "2025-02-01",
      "filename": "Lucic-Reproducibility as a Mechanism for Teaching Fairness Accountability Confidentiality and Transparency....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.00826v4",
      "categories": [
        "cs.AI"
      ]
    },
    "2205.15686v2": {
      "title": "The NOMAD Artificial-Intelligence Toolkit: Turning materials-science data into knowledge and understanding",
      "authors": [
        "Luigi SbailÃ²",
        "ÃdÃ¡m Fekete",
        "Luca M. Ghiringhelli",
        "Matthias Scheffler"
      ],
      "abstract": "We present the Novel-Materials-Discovery (NOMAD) Artificial-Intelligence (AI)\nToolkit, a web-browser-based infrastructure for the interactive AI-based\nanalysis of materials-science findable, accessible, interoperable, and reusable\n(FAIR) data. The AI Toolkit readily operates on the FAIR data stored in the\ncentral server of the NOMAD Archive, the largest database of materials-science\ndata worldwide, as well as locally stored, users' owned data. The NOMAD Oasis,\na local, stand alone server can be also used to run the AI Toolkit. By using\nJupyter notebooks that run in a web-browser, the NOMAD data can be queried and\naccessed; data mining, machine learning, and other AI techniques can be then\napplied to analyse them. This infrastructure brings the concept of\nreproducibility in materials science to the next level, by allowing researchers\nto share not only the data contributing to their scientific publications, but\nalso all the developed methods and analytics tools. Besides reproducing\npublished results, users of the NOMAD AI toolkit can modify the Jupyter\nnotebooks towards their own research work.",
      "citation_count": 28,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bd9106d6f0c4964512a3393187c378c8f247b405",
      "published_date": "2022-05-31",
      "downloaded_date": "2025-02-01",
      "filename": "SbailÃ²-The NOMAD Artificial-Intelligence Toolkit Turning materials-science data into knowledge and understa....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.15686v2",
      "categories": [
        "cond-mat.mtrl-sci"
      ]
    },
    "2409.05918v1": {
      "title": "Developing an Explainable Artificial Intelligent (XAI) Model for Predicting Pile Driving Vibrations in Bangkok's Subsoil",
      "authors": [
        "Sompote Youwai",
        "Anuwat Pamungmoon"
      ],
      "abstract": "This study presents an explainable artificial intelligent (XAI) model for\npredicting pile driving vibrations in Bangkok's soft clay subsoil. A deep\nneural network was developed using a dataset of 1,018 real-world pile driving\nmeasurements, encompassing variations in pile dimensions, hammer\ncharacteristics, sensor locations, and vibration measurement axes. The model\nachieved a mean absolute error (MAE) of 0.276, outperforming traditional\nempirical methods and other machine learning approaches such as XGBoost and\nCatBoost. SHapley Additive exPlanations (SHAP) analysis was employed to\ninterpret the model's predictions, revealing complex relationships between\ninput features and peak particle velocity (PPV). Distance from the pile driving\nlocation emerged as the most influential factor, followed by hammer weight and\npile size. Non-linear relationships and threshold effects were observed,\nproviding new insights into vibration propagation in soft clay. A web-based\napplication was developed to facilitate adoption by practicing engineers,\nbridging the gap between advanced machine learning techniques and practical\nengineering applications. This research contributes to the field of\ngeotechnical engineering by offering a more accurate and nuanced approach to\npredicting pile driving vibrations, with implications for optimizing\nconstruction practices and mitigating environmental impacts in urban areas. The\nmodel and its source code are publicly available, promoting transparency and\nreproducibility in geotechnical research.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e17a16f988c79a6c9c66100d08ec5d1016b86089",
      "published_date": "2024-09-08",
      "downloaded_date": "2025-02-01",
      "filename": "Youwai-Developing an Explainable Artificial Intelligent XAI Model for Predicting Pile Driving Vibrations in....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.05918v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2310.19231v1": {
      "title": "There Are No Data Like More Data- Datasets for Deep Learning in Earth Observation",
      "authors": [
        "Michael Schmitt",
        "Seyed Ali Ahmadi",
        "Yonghao Xu",
        "Gulsen Taskin",
        "Ujjwal Verma",
        "Francescopaolo Sica",
        "Ronny Hansch"
      ],
      "abstract": "Carefully curated and annotated datasets are the foundation of machine\nlearning, with particularly data-hungry deep neural networks forming the core\nof what is often called Artificial Intelligence (AI). Due to the massive\nsuccess of deep learning applied to Earth Observation (EO) problems, the focus\nof the community has been largely on the development of ever-more sophisticated\ndeep neural network architectures and training strategies largely ignoring the\noverall importance of datasets. For that purpose, numerous task-specific\ndatasets have been created that were largely ignored by previously published\nreview articles on AI for Earth observation. With this article, we want to\nchange the perspective and put machine learning datasets dedicated to Earth\nobservation data and applications into the spotlight. Based on a review of the\nhistorical developments, currently available resources are described and a\nperspective for future developments is formed. We hope to contribute to an\nunderstanding that the nature of our data is what distinguishes the Earth\nobservation community from many other communities that apply deep learning\ntechniques to image data, and that a detailed understanding of EO data\npeculiarities is among the core competencies of our discipline.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-10-30",
      "downloaded_date": "2025-02-01",
      "filename": "Schmitt-There Are No Data Like More Data- Datasets for Deep Learning in Earth Observation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.19231v1",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    "2009.14596v1": {
      "title": "Machine Learning and Computational Mathematics",
      "authors": [
        "Weinan E"
      ],
      "abstract": "Neural network-based machine learning is capable of approximating functions\nin very high dimension with unprecedented efficiency and accuracy. This has\nopened up many exciting new possibilities, not just in traditional areas of\nartificial intelligence, but also in scientific computing and computational\nscience. At the same time, machine learning has also acquired the reputation of\nbeing a set of \"black box\" type of tricks, without fundamental principles. This\nhas been a real obstacle for making further progress in machine learning. In\nthis article, we try to address the following two very important questions: (1)\nHow machine learning has already impacted and will further impact computational\nmathematics, scientific computing and computational science? (2) How\ncomputational mathematics, particularly numerical analysis, {can} impact\nmachine learning? We describe some of the most important progress that has been\nmade on these issues. Our hope is to put things into a perspective that will\nhelp to integrate machine learning with computational mathematics.",
      "citation_count": 60,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3cc4823ce339ba27299241c8a7d639e8722f81c1",
      "published_date": "2020-09-23",
      "downloaded_date": "2025-02-01",
      "filename": "E-Machine Learning and Computational Mathematics.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.14596v1",
      "categories": [
        "math.NA",
        "cs.LG",
        "cs.NA",
        "stat.ML",
        "68T07, 46E15, 26B35, 26B40"
      ]
    },
    "2203.08648v1": {
      "title": "Artificial Intelligence Enables Real-Time and Intuitive Control of Prostheses via Nerve Interface",
      "authors": [
        "Diu Khue Luu",
        "Anh Tuan Nguyen",
        "Ming Jiang",
        "Markus W. Drealan",
        "Jian Xu",
        "Tong Wu",
        "Wing-kin Tam",
        "Wenfeng Zhao",
        "Brian Z. H. Lim",
        "Cynthia K. Overstreet",
        "Qi Zhao",
        "Jonathan Cheng",
        "Edward W. Keefer",
        "Zhi Yang"
      ],
      "abstract": "Objective: The next generation prosthetic hand that moves and feels like a\nreal hand requires a robust neural interconnection between the human minds and\nmachines. Methods: Here we present a neuroprosthetic system to demonstrate that\nprinciple by employing an artificial intelligence (AI) agent to translate the\namputee's movement intent through a peripheral nerve interface. The AI agent is\ndesigned based on the recurrent neural network (RNN) and could simultaneously\ndecode six degree-of-freedom (DOF) from multichannel nerve data in real-time.\nThe decoder's performance is characterized in motor decoding experiments with\nthree human amputees. Results: First, we show the AI agent enables amputees to\nintuitively control a prosthetic hand with individual finger and wrist\nmovements up to 97-98% accuracy. Second, we demonstrate the AI agent's\nreal-time performance by measuring the reaction time and information throughput\nin a hand gesture matching task. Third, we investigate the AI agent's long-term\nuses and show the decoder's robust predictive performance over a 16-month\nimplant duration. Conclusion & significance: Our study demonstrates the\npotential of AI-enabled nerve technology, underling the next generation of\ndexterous and intuitive prosthetic hands.",
      "citation_count": 13,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a6b195860c11067336a98bf29ff85c1bd71e1216",
      "published_date": "2022-03-16",
      "downloaded_date": "2025-02-01",
      "filename": "Luu-Artificial Intelligence Enables Real-Time and Intuitive Control of Prostheses via Nerve Interface.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.08648v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "q-bio.NC"
      ]
    },
    "1710.08191v1": {
      "title": "Human-in-the-loop Artificial Intelligence",
      "authors": [
        "Fabio Massimo Zanzotto"
      ],
      "abstract": "Little by little, newspapers are revealing the bright future that Artificial\nIntelligence (AI) is building. Intelligent machines will help everywhere.\nHowever, this bright future has a dark side: a dramatic job market contraction\nbefore its unpredictable transformation. Hence, in a near future, large numbers\nof job seekers will need financial support while catching up with these novel\nunpredictable jobs. This possible job market crisis has an antidote inside. In\nfact, the rise of AI is sustained by the biggest knowledge theft of the recent\nyears. Learning AI machines are extracting knowledge from unaware skilled or\nunskilled workers by analyzing their interactions. By passionately doing their\njobs, these workers are digging their own graves.\n  In this paper, we propose Human-in-the-loop Artificial Intelligence (HIT-AI)\nas a fairer paradigm for Artificial Intelligence systems. HIT-AI will reward\naware and unaware knowledge producers with a different scheme: decisions of AI\nsystems generating revenues will repay the legitimate owners of the knowledge\nused for taking those decisions. As modern Robin Hoods, HIT-AI researchers\nshould fight for a fairer Artificial Intelligence that gives back what it\nsteals.",
      "citation_count": 247,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b2277775e67ad13a5ab22d86a055e1f49a4cc8f5",
      "published_date": "2017-10-23",
      "downloaded_date": "2025-02-01",
      "filename": "Zanzotto-Human-in-the-loop Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1710.08191v1",
      "categories": [
        "cs.AI",
        "I.2; I.2.6"
      ]
    },
    "1610.07997v1": {
      "title": "Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures",
      "authors": [
        "Roman V. Yampolskiy",
        "M. S. Spellchecker"
      ],
      "abstract": "In this work, we present and analyze reported failures of artificially\nintelligent systems and extrapolate our analysis to future AIs. We suggest that\nboth the frequency and the seriousness of future AI failures will steadily\nincrease. AI Safety can be improved based on ideas developed by cybersecurity\nexperts. For narrow AIs safety failures are at the same, moderate, level of\ncriticality as in cybersecurity, however for general AI, failures have a\nfundamentally different impact. A single failure of a superintelligent system\nmay cause a catastrophic event without a chance for recovery. The goal of\ncybersecurity is to reduce the number of successful attacks on the system; the\ngoal of AI Safety is to make sure zero attacks succeed in bypassing the safety\nmechanisms. Unfortunately, such a level of performance is unachievable. Every\nsecurity system will eventually fail; there is no such thing as a 100% secure\nsystem.",
      "citation_count": 83,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/dc36a9454691c95a8e7c17f1529cadde125805a3",
      "published_date": "2016-10-25",
      "downloaded_date": "2025-02-01",
      "filename": "Yampolskiy-Artificial Intelligence Safety and Cybersecurity a Timeline of AI Failures.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1610.07997v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "2202.04977v3": {
      "title": "Needs-aware Artificial Intelligence: AI that 'serves [human] needs'",
      "authors": [
        "Ryan Watkins",
        "Soheil Human"
      ],
      "abstract": "By defining the current limits (and thereby the frontiers), many boundaries\nare shaping, and will continue to shape, the future of Artificial Intelligence\n(AI). We push on these boundaries in order to make further progress into what\nwere yesterday's frontiers. They are both pliable and resilient - always\ncreating new boundaries of what AI can (or should) achieve. Among these are\ntechnical boundaries (such as processing capacity), psychological boundaries\n(such as human trust in AI systems), ethical boundaries (such as with AI\nweapons), and conceptual boundaries (such as the AI people can imagine). It is\nwithin this final category while it can play a fundamental role in all other\nboundaries} that we find the construct of needs and the limitations that our\ncurrent concept of need places on the future AI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-02-10",
      "downloaded_date": "2025-02-01",
      "filename": "Watkins-Needs-aware Artificial Intelligence AI that serves human needs.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.04977v3",
      "categories": [
        "cs.AI"
      ]
    },
    "2001.08159v1": {
      "title": "Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenges",
      "authors": [
        "Cheng-Xiang Wang",
        "Marco Di Renzo",
        "Slawomir StaÅczak",
        "Sen Wang",
        "Erik G. Larsson"
      ],
      "abstract": "The fifth generation (5G) wireless communication networks are currently being\ndeployed, and beyond 5G (B5G) networks are expected to be developed over the\nnext decade. Artificial intelligence (AI) technologies and, in particular,\nmachine learning (ML) have the potential to efficiently solve the unstructured\nand seemingly intractable problems by involving large amounts of data that need\nto be dealt with in B5G. This article studies how AI and ML can be leveraged\nfor the design and operation of B5G networks. We first provide a comprehensive\nsurvey of recent advances and future challenges that result from bringing AI/ML\ntechnologies into B5G wireless networks. Our survey touches different aspects\nof wireless network design and optimization, including channel measurements,\nmodeling, and estimation, physical-layer research, and network management and\noptimization. Then, ML algorithms and applications to B5G networks are\nreviewed, followed by an overview of standard developments of applying AI/ML\nalgorithms to B5G networks. We conclude this study by the future challenges on\napplying AI/ML to B5G networks.",
      "citation_count": 153,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2adf3e102f80b4513a909c86317220b914f13209",
      "published_date": "2020-01-02",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Artificial Intelligence Enabled Wireless Networking for 5G and Beyond Recent Advances and Future Cha....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2001.08159v1",
      "categories": [
        "cs.NI",
        "eess.SP"
      ]
    },
    "2103.03610v1": {
      "title": "A framework for fostering transparency in shared artificial intelligence models by increasing visibility of contributions",
      "authors": [
        "Iain Barclay",
        "Harrison Taylor",
        "Alun Preece",
        "Ian Taylor",
        "Dinesh Verma",
        "Geeth de Mel"
      ],
      "abstract": "Increased adoption of artificial intelligence (AI) systems into scientific\nworkflows will result in an increasing technical debt as the distance between\nthe data scientists and engineers who develop AI system components and\nscientists, researchers and other users grows. This could quickly become\nproblematic, particularly where guidance or regulations change and\nonce-acceptable best practice becomes outdated, or where data sources are later\ndiscredited as biased or inaccurate. This paper presents a novel method for\nderiving a quantifiable metric capable of ranking the overall transparency of\nthe process pipelines used to generate AI systems, such that users, auditors\nand other stakeholders can gain confidence that they will be able to validate\nand trust the data sources and contributors in the AI systems that they rely\non. The methodology for calculating the metric, and the type of criteria that\ncould be used to make judgements on the visibility of contributions to systems\nare evaluated through models published at ModelHub and PyTorch Hub, popular\narchives for sharing science resources, and is found to be helpful in driving\nconsideration of the contributions made to generating AI systems and approaches\ntowards effective documentation and improving transparency in machine learning\nassets shared within scientific communities.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/83fb3eb9177b03116fe0c9e51ffed90c0aa2db01",
      "published_date": "2021-03-05",
      "downloaded_date": "2025-02-01",
      "filename": "Barclay-A framework for fostering transparency in shared artificial intelligence models by increasing visibi....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.03610v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2312.10077v1": {
      "title": "Artificial intelligence in social science: A study based on bibliometrics analysis",
      "authors": [
        "Juan-Jose Prieto-Gutierrez",
        "Francisco Segado-Boj",
        "Fabiana Da Silva FranÃ§a"
      ],
      "abstract": "Artificial intelligence (AI) is gradually changing the planet. Data\ndigitisation, computing infrastructure and machine learning are helping AI\ntools to spread across all sectors of society. This article presents the\nresults of a bibliometric analysis of AI-related publications in the social\nsciences over the last ten years (2013-2022). Most of the historical\npublications are taken into consideration with the aim of identifying research\nrelevance and trends in this field. The results indicate that more than 19,408\narticles have been published, 85% from 2008 to 2022, showing that research in\nthis field is increasing significantly year on year. Clear domains or\ndisciplines of research related to AI within the social sciences can be grouped\ninto sub-areas such as law and legal reasoning, education, economics, and\nethics. The United States is the country that publishes the most (20%),\nfollowed by China (13%). The influence of AI on society is inevitable and the\nadvances can generate great opportunities for innovation and new jobs, but in\nthe medium term it is necessary to adequately face this transition, setting\nregulations and reviewing the challenges of ethics and responsibility.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/27bcb586768b4e3c3e01ff095a40dbd50af6d394",
      "published_date": "2023-12-09",
      "downloaded_date": "2025-02-01",
      "filename": "Prieto-Gutierrez-Artificial intelligence in social science A study based on bibliometrics analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.10077v1",
      "categories": [
        "cs.CY",
        "cs.DL"
      ]
    },
    "1901.00246v2": {
      "title": "Natively Interpretable Machine Learning and Artificial Intelligence: Preliminary Results and Future Directions",
      "authors": [
        "Christopher J. Hazard",
        "Christopher Fusting",
        "Michael Resnick",
        "Michael Auerbach",
        "Michael Meehan",
        "Valeri Korobov"
      ],
      "abstract": "Machine learning models have become more and more complex in order to better\napproximate complex functions. Although fruitful in many domains, the added\ncomplexity has come at the cost of model interpretability. The once popular\nk-nearest neighbors (kNN) approach, which finds and uses the most similar data\nfor reasoning, has received much less attention in recent decades due to\nnumerous problems when compared to other techniques. We show that many of these\nhistorical problems with kNN can be overcome, and our contribution has\napplications not only in machine learning but also in online learning, data\nsynthesis, anomaly detection, model compression, and reinforcement learning,\nwithout sacrificing interpretability. We introduce a synthesis between kNN and\ninformation theory that we hope will provide a clear path towards models that\nare innately interpretable and auditable. Through this work we hope to gather\ninterest in combining kNN with information theory as a promising path to fully\nauditable machine learning and artificial intelligence.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/80a2d10454087b09f19db0e88720afa3e8a85a9b",
      "published_date": "2019-01-02",
      "downloaded_date": "2025-02-01",
      "filename": "Hazard-Natively Interpretable Machine Learning and Artificial Intelligence Preliminary Results and Future D....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.00246v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    "1907.10424v1": {
      "title": "Less (Data) Is More: Why Small Data Holds the Key to the Future of Artificial Intelligence",
      "authors": [
        "Ciro Greco",
        "Andrea Polonioli",
        "Jacopo Tagliabue"
      ],
      "abstract": "The claims that big data holds the key to enterprise successes and that\nArtificial Intelligence is going to replace humanity have become increasingly\nmore popular over the past few years, both in academia and in the industry.\nHowever, while these claims may indeed capture some truth, they have also been\nmassively oversold, or so we contend here. The goal of this paper is two-fold.\nFirst, we provide a qualified defence of the value of less data within the\ncontext of AI. This is done by carefully reviewing two distinct problems for\nbig data driven AI, namely a) the limited track record of Deep Learning in key\nareas such as Natural Language Processing, b) the regulatory and business\nsignificance of being able to learn from few data points. Second, we briefly\nsketch what we refer to as a case of AI with humans and for humans, namely an\nAI paradigm whereby the systems we build are privacy-oriented and focused on\nhuman-machine collaboration, not competition. Combining our claims above, we\nconclude that when seen through the lens of cognitively inspired AI, the bright\nfuture of the discipline is about less data, not more, and more humans, not\nfewer.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/44670a05f6cb7285e80d82b799f4c2d4f3088885",
      "published_date": "2019-07-22",
      "downloaded_date": "2025-02-01",
      "filename": "Greco-Less Data Is More Why Small Data Holds the Key to the Future of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.10424v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2304.11733v1": {
      "title": "COVID-19 Spreading Prediction and Impact Analysis by Using Artificial Intelligence for Sustainable Global Health Assessment",
      "authors": [
        "Subhrangshu Adhikary",
        "Sonam Chaturvedi",
        "Sudhir Kumar Chaturvedi",
        "Saikat Banerjee"
      ],
      "abstract": "The COVID-19 pandemic is considered as the most alarming global health\ncalamity of this century. COVID-19 has been confirmed to be mutated from\ncoronavirus family. As stated by the records of The World Health Organization\n(WHO at April 18 2020), the present epidemic of COVID-19, has influenced more\nthan 2,164,111 persons and killed more than 146,198 folks in over 200 countries\nacross the globe and billions had confronted impacts in lifestyle because of\nthis virus outbreak. The ongoing overall outbreak of the COVID-19 opened up new\ndifficulties to the research sectors. Artificial intelligence (AI) driven\nstrategies can be valuable to predict the parameters, hazards, and impacts of\nsuch an epidemic in a cost-efficient manner. The fundamental difficulties of AI\nin this situation is the limited availability of information and the uncertain\nnature of the disease. Here in this article, we have tried to integrate AI to\npredict the infection outbreak and along with this, we have also tried to test\nwhether AI with help deep learning can recognize COVID-19 infected chest X-Rays\nor not. The global outbreak of the virus posed enormous economic, ecological\nand societal challenges into the human population and with help of this paper,\nwe have tried to give a message that AI can help us to identify certain\nfeatures of the disease outbreak that could prove to be essential to protect\nthe humanity from this deadly disease.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1b3e2bde6902c0dd1df9f967588a5fffbd6dc60b",
      "published_date": "2023-04-23",
      "downloaded_date": "2025-02-01",
      "filename": "Adhikary-COVID-19 Spreading Prediction and Impact Analysis by Using Artificial Intelligence for Sustainable G....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.11733v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2305.01899v2": {
      "title": "Empowering Agrifood System with Artificial Intelligence: A Survey of the Progress, Challenges and Opportunities",
      "authors": [
        "Tao Chen",
        "Liang Lv",
        "Di Wang",
        "Jing Zhang",
        "Yue Yang",
        "Zeyang Zhao",
        "Chen Wang",
        "Xiaowei Guo",
        "Hao Chen",
        "Qingye Wang",
        "Yufei Xu",
        "Qiming Zhang",
        "Bo Du",
        "Liangpei Zhang",
        "Dacheng Tao"
      ],
      "abstract": "With the world population rapidly increasing, transforming our agrifood\nsystems to be more productive, efficient, safe, and sustainable is crucial to\nmitigate potential food shortages. Recently, artificial intelligence (AI)\ntechniques such as deep learning (DL) have demonstrated their strong abilities\nin various areas, including language, vision, remote sensing (RS), and agrifood\nsystems applications. However, the overall impact of AI on agrifood systems\nremains unclear. In this paper, we thoroughly review how AI techniques can\ntransform agrifood systems and contribute to the modern agrifood industry.\nFirstly, we summarize the data acquisition methods in agrifood systems,\nincluding acquisition, storage, and processing techniques. Secondly, we present\na progress review of AI methods in agrifood systems, specifically in\nagriculture, animal husbandry, and fishery, covering topics such as agrifood\nclassification, growth monitoring, yield prediction, and quality assessment.\nFurthermore, we highlight potential challenges and promising research\nopportunities for transforming modern agrifood systems with AI. We hope this\nsurvey could offer an overall picture to newcomers in the field and serve as a\nstarting point for their further research. The project website is\nhttps://github.com/Frenkie14/Agrifood-Survey.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/14993bd3da06d77d4f9cc109764700dec43b25a3",
      "published_date": "2023-05-03",
      "downloaded_date": "2025-02-01",
      "filename": "Chen-Empowering Agrifood System with Artificial Intelligence A Survey of the Progress Challenges and Oppo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.01899v2",
      "categories": [
        "cs.AI",
        "cs.CY",
        "eess.IV"
      ]
    },
    "2404.18183v1": {
      "title": "Innovative Application of Artificial Intelligence Technology in Bank Credit Risk Management",
      "authors": [
        "Shuochen Bi",
        "Wenqing Bao"
      ],
      "abstract": "With the rapid growth of technology, especially the widespread application of\nartificial intelligence (AI) technology, the risk management level of\ncommercial banks is constantly reaching new heights. In the current wave of\ndigitalization, AI has become a key driving force for the strategic\ntransformation of financial institutions, especially the banking industry. For\ncommercial banks, the stability and safety of asset quality are crucial, which\ndirectly relates to the long-term stable growth of the bank. Among them, credit\nrisk management is particularly core because it involves the flow of a large\namount of funds and the accuracy of credit decisions. Therefore, establishing a\nscientific and effective credit risk decision-making mechanism is of great\nstrategic significance for commercial banks. In this context, the innovative\napplication of AI technology has brought revolutionary changes to bank credit\nrisk management. Through deep learning and big data analysis, AI can accurately\nevaluate the credit status of borrowers, timely identify potential risks, and\nprovide banks with more accurate and comprehensive credit decision support. At\nthe same time, AI can also achieve realtime monitoring and early warning,\nhelping banks intervene before risks occur and reduce losses.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f3321a12f61f0167d689e859ec6e70d0b059a443",
      "published_date": "2024-04-28",
      "downloaded_date": "2025-02-01",
      "filename": "Bi-Innovative Application of Artificial Intelligence Technology in Bank Credit Risk Management.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.18183v1",
      "categories": [
        "q-fin.RM",
        "cs.AI"
      ]
    },
    "2411.09874v1": {
      "title": "A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation",
      "authors": [
        "Chin-Sung Tung",
        "Sheng-Fu Liang",
        "Shu-Feng Chang",
        "Chung-Ping Young"
      ],
      "abstract": "Electroencephalography (EEG) plays a crucial role in the diagnosis of various\nneurological disorders. However, small hospitals and clinics often lack\nadvanced EEG signal analysis systems and are prone to misinterpretation in\nmanual EEG reading. This study proposes an innovative hybrid artificial\nintelligence (AI) system for automatic interpretation of EEG background\nactivity and report generation. The system combines deep learning models for\nposterior dominant rhythm (PDR) prediction, unsupervised artifact removal, and\nexpert-designed algorithms for abnormality detection. For PDR prediction, 1530\nlabeled EEGs were used, and the best ensemble model achieved a mean absolute\nerror (MAE) of 0.237, a root mean square error (RMSE) of 0.359, an accuracy of\n91.8% within a 0.6Hz error, and an accuracy of 99% within a 1.2Hz error. The AI\nsystem significantly outperformed neurologists in detecting generalized\nbackground slowing (p = 0.02; F1: AI 0.93, neurologists 0.82) and demonstrated\nimproved focal abnormality detection, although not statistically significant (p\n= 0.79; F1: AI 0.71, neurologists 0.55). Validation on both an internal dataset\nand the Temple University Abnormal EEG Corpus showed consistent performance\n(F1: 0.884 and 0.835, respectively; p = 0.66), demonstrating generalizability.\nThe use of large language models (LLMs) for report generation demonstrated 100%\naccuracy, verified by three other independent LLMs. This hybrid AI system\nprovides an easily scalable and accurate solution for EEG interpretation in\nresource-limited settings, assisting neurologists in improving diagnostic\naccuracy and reducing misdiagnosis rates.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-11-15",
      "downloaded_date": "2025-02-01",
      "filename": "Tung-A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.09874v1",
      "categories": [
        "cs.AI",
        "eess.SP"
      ]
    },
    "2111.12963v1": {
      "title": "Error Bounds for a Matrix-Vector Product Approximation with Deep ReLU Neural Networks",
      "authors": [
        "Tilahun M. Getu"
      ],
      "abstract": "Among the several paradigms of artificial intelligence (AI) or machine\nlearning (ML), a remarkably successful paradigm is deep learning. Deep\nlearning's phenomenal success has been hoped to be interpreted via fundamental\nresearch on the theory of deep learning. Accordingly, applied research on deep\nlearning has spurred the theory of deep learning-oriented depth and breadth of\ndevelopments. Inspired by such developments, we pose these fundamental\nquestions: can we accurately approximate an arbitrary matrix-vector product\nusing deep rectified linear unit (ReLU) feedforward neural networks (FNNs)? If\nso, can we bound the resulting approximation error? In light of these\nquestions, we derive error bounds in Lebesgue and Sobolev norms that comprise\nour developed deep approximation theory. Guided by this theory, we have\nsuccessfully trained deep ReLU FNNs whose test results justify our developed\ntheory. The developed theory is also applicable for guiding and easing the\ntraining of teacher deep ReLU FNNs in view of the emerging teacher-student AI\nor ML paradigms that are essential for solving several AI or ML problems in\nwireless communications and signal processing; network science and graph signal\nprocessing; and network neuroscience and brain physics.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0567f5f5f460a969eef994e5ee7b0fc77d47e491",
      "published_date": "2021-11-25",
      "downloaded_date": "2025-02-01",
      "filename": "Getu-Error Bounds for a Matrix-Vector Product Approximation with Deep ReLU Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.12963v1",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2107.10912v1": {
      "title": "Explainable artificial intelligence (XAI) in deep learning-based medical image analysis",
      "authors": [
        "Bas H. M. van der Velden",
        "Hugo J. Kuijf",
        "Kenneth G. A. Gilhuijs",
        "Max A. Viergever"
      ],
      "abstract": "With an increase in deep learning-based methods, the call for explainability\nof such methods grows, especially in high-stakes decision making areas such as\nmedical image analysis. This survey presents an overview of eXplainable\nArtificial Intelligence (XAI) used in deep learning-based medical image\nanalysis. A framework of XAI criteria is introduced to classify deep\nlearning-based medical image analysis methods. Papers on XAI techniques in\nmedical image analysis are then surveyed and categorized according to the\nframework and according to anatomical location. The paper concludes with an\noutlook of future opportunities for XAI in medical image analysis.",
      "citation_count": 537,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/27209d185ffe3c70d9a6a7562c7eb5176750eab7",
      "published_date": "2021-07-22",
      "downloaded_date": "2025-02-01",
      "filename": "Velden-Explainable artificial intelligence XAI in deep learning-based medical image analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.10912v1",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "2405.11008v2": {
      "title": "A Systematic Review on Sleep Stage Classification and Sleep Disorder Detection Using Artificial Intelligence",
      "authors": [
        "Tayab Uddin Wara",
        "Ababil Hossain Fahad",
        "Adri Shankar Das",
        "Md. Mehedi Hasan Shawon"
      ],
      "abstract": "Sleep is vital for people's physical and mental health, and sound sleep can\nhelp them focus on daily activities. Therefore, a sleep study that includes\nsleep patterns and sleep disorders is crucial to enhancing our knowledge about\nindividuals' health status. This study aims to provide a comprehensive,\nsystematic review of the recent literature to analyze the different approaches\nand their outcomes in sleep studies, which includes works on \"sleep stages\nclassification\" and \"sleep disorder detection\" using AI. In this review, 183\narticles were initially selected from different journals, among which 80\nrecords were enlisted for explicit review, ranging from 2016 to 2023. Brain\nwaves were the most commonly employed body parameters for sleep staging and\ndisorder studies (almost 29% of the research used brain activity signals\nexclusively, and 77% combined with the other signals). The convolutional neural\nnetwork (CNN), the most widely used of the 34 distinct artificial intelligence\nmodels, comprised 27%. The other models included the long short-term memory\n(LSTM), support vector machine (SVM), random forest (RF), and recurrent neural\nnetwork (RNN), which consisted of 11%, 6%, 6%, and 5% sequentially. For\nperformance metrics, accuracy was widely used for a maximum of 83.75% of the\ncases, the F1 score of 45%, Kappa of 36.25%, Sensitivity of 31.25%, and\nSpecificity of 30% of cases, along with the other metrics. This article would\nhelp physicians and researchers get the gist of AI's contribution to sleep\nstudies and the feasibility of their intended work.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/62ad8db85a56c712a1873973548c37e1a5f7f940",
      "published_date": "2024-05-17",
      "downloaded_date": "2025-02-01",
      "filename": "Wara-A Systematic Review on Sleep Stage Classification and Sleep Disorder Detection Using Artificial Inte....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.11008v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1604.04660v2": {
      "title": "Why Artificial Intelligence Needs a Task Theory --- And What It Might Look Like",
      "authors": [
        "Kristinn R. ThÃ³risson",
        "Jordi Bieger",
        "ThrÃ¶stur Thorarensen",
        "JÃ³na S. SigurÃ°ardÃ³ttir",
        "Bas R. Steunebrink"
      ],
      "abstract": "The concept of \"task\" is at the core of artificial intelligence (AI): Tasks\nare used for training and evaluating AI systems, which are built in order to\nperform and automatize tasks we deem useful. In other fields of engineering\ntheoretical foundations allow thorough evaluation of designs by methodical\nmanipulation of well understood parameters with a known role and importance;\nthis allows an aeronautics engineer, for instance, to systematically assess the\neffects of wind speed on an airplane's performance and stability. No framework\nexists in AI that allows this kind of methodical manipulation: Performance\nresults on the few tasks in current use (cf. board games, question-answering)\ncannot be easily compared, however similar or different. The issue is even more\nacute with respect to artificial *general* intelligence systems, which must\nhandle unanticipated tasks whose specifics cannot be known beforehand. A *task\ntheory* would enable addressing tasks at the *class* level, bypassing their\nspecifics, providing the appropriate formalization and classification of tasks,\nenvironments, and their parameters, resulting in more rigorous ways of\nmeasuring, comparing, and evaluating intelligent behavior. Even modest\nimprovements in this direction would surpass the current ad-hoc nature of\nmachine learning and AI evaluation. Here we discuss the main elements of the\nargument for a task theory and present an outline of what it might look like\nfor physical tasks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2016-04-15",
      "downloaded_date": "2025-02-01",
      "filename": "ThÃ³risson-Why Artificial Intelligence Needs a Task Theory --- And What It Might Look Like.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1604.04660v2",
      "categories": [
        "cs.AI",
        "I.2.0; I.2.m"
      ]
    },
    "2207.01490v1": {
      "title": "Experts' View on Challenges and Needs for Fairness in Artificial Intelligence for Education",
      "authors": [
        "Gianni Fenu",
        "Roberta Galici",
        "Mirko Marras"
      ],
      "abstract": "In recent years, there has been a stimulating discussion on how artificial\nintelligence (AI) can support the science and engineering of intelligent\neducational applications. Many studies in the field are proposing actionable\ndata mining pipelines and machine-learning models driven by learning-related\ndata. The potential of these pipelines and models to amplify unfairness for\ncertain categories of students is however receiving increasing attention. If AI\napplications are to have a positive impact on education, it is crucial that\ntheir design considers fairness at every step. Through anonymous surveys and\ninterviews with experts (researchers and practitioners) who have published\ntheir research at top-tier educational conferences in the last year, we\nconducted the first expert-driven systematic investigation on the challenges\nand needs for addressing fairness throughout the development of educational\nsystems based on AI. We identified common and diverging views about the\nchallenges and the needs faced by educational technologies experts in practice,\nthat lead the community to have a clear understanding on the main questions\nraising doubts in this topic. Based on these findings, we highlighted\ndirections that will facilitate the ongoing research towards fairer AI for\neducation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-06-23",
      "downloaded_date": "2025-02-01",
      "filename": "Fenu-Experts View on Challenges and Needs for Fairness in Artificial Intelligence for Education.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2207.01490v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2303.03511v1": {
      "title": "Applying Artificial Intelligence to Clinical Decision Support in Mental Health: What Have We Learned?",
      "authors": [
        "Grace Golden",
        "Christina Popescu",
        "Sonia Israel",
        "Kelly Perlman",
        "Caitrin Armstrong",
        "Robert Fratila",
        "Myriam Tanguay-Sela",
        "David Benrimoh"
      ],
      "abstract": "Clinical decision support systems (CDSS) augmented with artificial\nintelligence (AI) models are emerging as potentially valuable tools in\nhealthcare. Despite their promise, the development and implementation of these\nsystems typically encounter several barriers, hindering the potential for\nwidespread adoption. Here we present a case study of a recently developed\nAI-CDSS, Aifred Health, aimed at supporting the selection and management of\ntreatment in major depressive disorder. We consider both the principles\nespoused during development and testing of this AI-CDSS, as well as the\npractical solutions developed to facilitate implementation. We also propose\nrecommendations to consider throughout the building, validation, training, and\nimplementation process of an AI-CDSS. These recommendations include:\nidentifying the key problem, selecting the type of machine learning approach\nbased on this problem, determining the type of data required, determining the\nformat required for a CDSS to provide clinical utility, gathering physician and\npatient feedback, and validating the tool across multiple settings. Finally, we\nexplore the potential benefits of widespread adoption of these systems, while\nbalancing these against implementation challenges such as ensuring systems do\nnot disrupt the clinical workflow, and designing systems in a manner that\nengenders trust on the part of end users.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/03b9e6b752a4865e2edd5d85734cdcd0dfb9befa",
      "published_date": "2023-03-06",
      "downloaded_date": "2025-02-01",
      "filename": "Golden-Applying Artificial Intelligence to Clinical Decision Support in Mental Health What Have We Learned.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.03511v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    "2306.00227v2": {
      "title": "From human-centered to social-centered artificial intelligence: Assessing ChatGPT's impact through disruptive events",
      "authors": [
        "Skyler Wang",
        "Ned Cooper",
        "Margaret Eby"
      ],
      "abstract": "Large language models (LLMs) and dialogue agents represent a significant\nshift in artificial intelligence (AI) research, particularly with the recent\nrelease of the GPT family of models. ChatGPT's generative capabilities and\nversatility across technical and creative domains led to its widespread\nadoption, marking a departure from more limited deployments of previous AI\nsystems. While society grapples with the emerging cultural impacts of this new\nsocietal-scale technology, critiques of ChatGPT's impact within machine\nlearning research communities have coalesced around its performance or other\nconventional safety evaluations relating to bias, toxicity, and\n\"hallucination.\" We argue that these critiques draw heavily on a particular\nconceptualization of the \"human-centered\" framework, which tends to cast\natomized individuals as the key recipients of technology's benefits and\ndetriments. In this article, we direct attention to another dimension of LLMs\nand dialogue agents' impact: their effects on social groups, institutions, and\naccompanying norms and practices. By analyzing ChatGPT's social impact through\na social-centered framework, we challenge individualistic approaches in AI\ndevelopment and contribute to ongoing debates around the ethical and\nresponsible deployment of AI systems. We hope this effort will call attention\nto more comprehensive and longitudinal evaluation tools (e.g., including more\nethnographic analyses and participatory approaches) and compel technologists to\ncomplement human-centered thinking with social-centered approaches.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/098c5080501af2d4918b8867c0ec27652dd195c1",
      "published_date": "2023-05-31",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-From human-centered to social-centered artificial intelligence Assessing ChatGPTs impact through dis....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.00227v2",
      "categories": [
        "cs.CY"
      ]
    },
    "2403.13784v6": {
      "title": "The Model Openness Framework: Promoting Completeness and Openness for Reproducibility, Transparency, and Usability in Artificial Intelligence",
      "authors": [
        "Matt White",
        "Ibrahim Haddad",
        "Cailean Osborne",
        "Xiao-Yang Yanglet Liu",
        "Ahmed Abdelmonsef",
        "Sachin Varghese",
        "Arnaud Le Hors"
      ],
      "abstract": "Generative artificial intelligence (AI) offers numerous opportunities for\nresearch and innovation, but its commercialization has raised concerns about\nthe transparency and safety of frontier AI models. Most models lack the\nnecessary components for full understanding, auditing, and reproducibility, and\nsome model producers use restrictive licenses whilst claiming that their models\nare \"open source\". To address these concerns, we introduce the Model Openness\nFramework (MOF), a three-tiered ranked classification system that rates machine\nlearning models based on their completeness and openness, following open\nscience principles. For each MOF class, we specify code, data, and\ndocumentation components of the model development lifecycle that must be\nreleased and under which open licenses. In addition, the Model Openness Tool\n(MOT) provides a user-friendly reference implementation to evaluate the\nopenness and completeness of models against the MOF classification system.\nTogether, the MOF and MOT provide timely practical guidance for (i) model\nproducers to enhance the openness and completeness of their publicly-released\nmodels, and (ii) model consumers to identify open models and their constituent\ncomponents that can be permissively used, studied, modified, and redistributed.\nThrough the MOF, we seek to establish completeness and openness as core tenets\nof responsible AI research and development, and to promote best practices in\nthe burgeoning open AI ecosystem.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2e2ca71b9fe364380d6fa25a6492bf827185a632",
      "published_date": "2024-03-20",
      "downloaded_date": "2025-02-01",
      "filename": "White-The Model Openness Framework Promoting Completeness and Openness for Reproducibility Transparency an....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.13784v6",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.SE"
      ]
    },
    "2111.09437v1": {
      "title": "Sustainable Artificial Intelligence through Continual Learning",
      "authors": [
        "Andrea Cossu",
        "Marta Ziosi",
        "Vincenzo Lomonaco"
      ],
      "abstract": "The increasing attention on Artificial Intelligence (AI) regulation has led\nto the definition of a set of ethical principles grouped into the Sustainable\nAI framework. In this article, we identify Continual Learning, an active area\nof AI research, as a promising approach towards the design of systems compliant\nwith the Sustainable AI principles. While Sustainable AI outlines general\ndesiderata for ethical applications, Continual Learning provides means to put\nsuch desiderata into practice.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f0c7d8317fffce4820ebf34322bade0d40e996fa",
      "published_date": "2021-11-17",
      "downloaded_date": "2025-02-01",
      "filename": "Cossu-Sustainable Artificial Intelligence through Continual Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.09437v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2210.09850v2": {
      "title": "Near Real-time CO$_2$ Emissions Based on Carbon Satellite and Artificial Intelligence",
      "authors": [
        "Zhengwen Zhang",
        "Jinjin Gu",
        "Junhua Zhao",
        "Jianwei Huang",
        "Haifeng Wu"
      ],
      "abstract": "To limit global warming to pre-industrial levels, global governments,\nindustry and academia are taking aggressive efforts to reduce carbon emissions.\nThe evaluation of anthropogenic carbon dioxide (CO$_2$) emissions, however,\ndepends on the self-reporting information that is not always reliable. Society\nneed to develop an objective, independent, and generalized system to meter\nCO$_2$ emissions. Satellite CO$_2$ observation from space that reports\ncolumn-average regional CO$_2$ dry-air mole fractions has gradually indicated\nits potential to build such a system. Nevertheless, estimating anthropogenic\nCO$_2$ emissions from CO$_2$ observing satellite is bottlenecked by the\ninfluence of the highly complicated physical characteristics of atmospheric\nactivities. Here we provide the first method that combines the advanced\nartificial intelligence (AI) techniques and the carbon satellite monitor to\nquantify anthropogenic CO$_2$ emissions. We propose an integral AI based\npipeline that contains both a data retrieval algorithm and a two-step\ndata-driven solution. First, the data retrieval algorithm can generate\neffective datasets from multi-modal data including carbon satellite, the\ninformation of carbon sources, and several environmental factors. Second, the\ntwo-step data-driven solution that applies the powerful representation of deep\nlearning techniques to learn to quantify anthropogenic CO$_2$ emissions from\nsatellite CO$_2$ observation with other factors. Our work unmasks the potential\nof quantifying CO$_2$ emissions based on the combination of deep learning\nalgorithms and the carbon satellite monitor.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cdf050bbd51a50f6039140bc30215a5c05c19bcf",
      "published_date": "2022-10-11",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Near Real-time CO_2 Emissions Based on Carbon Satellite and Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.09850v2",
      "categories": [
        "physics.ao-ph",
        "cs.LG"
      ]
    },
    "2412.05583v2": {
      "title": "Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms",
      "authors": [
        "Atit Pokharel",
        "Shashank Dahal",
        "Pratik Sapkota",
        "Bhupendra Bimal Chhetri"
      ],
      "abstract": "The rapid advancements in Artificial Intelligence, specifically Machine\nLearning (ML) and Deep Learning (DL), have opened new prospects in medical\nsciences for improved diagnosis, prognosis, and treatment of severe health\nconditions. This paper focuses on the development of an ML model with high\npredictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The\nECG signals datasets utilized in this study were sourced from the PhysioNet and\nMIT-BIH databases. The research commenced with binary classification, where an\noptimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded\nexcellent results in differentiating normal and atrial fibrillation signals. A\npivotal aspect of this research was a survey among medical professionals, which\nnot only validated the practicality of AI-based ECG classifiers but also\nidentified areas for improvement, including accuracy and the inclusion of more\narrhythmia types. These insights drove the development of an advanced\nConvolutional Neural Network (CNN) system capable of classifying five different\ntypes of ECG signals with better accuracy and precision. The CNN model's robust\nperformance was ensured through rigorous stratified 5-fold cross validation. A\nweb portal was also developed to demonstrate real-world utility, offering\naccess to the trained model for real-time classification. This study highlights\nthe potential applications of such models in remote health monitoring,\npredictive healthcare, assistive diagnostic tools, and simulated environments\nfor educational training and interdisciplinary collaboration between data\nscientists and medical personnel.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/64cfbff6298fb57a2da1c1e109de7b018c72f45c",
      "published_date": "2024-12-07",
      "downloaded_date": "2025-02-01",
      "filename": "Pokharel-Electrocardiogram ECG Based Cardiac Arrhythmia Detection and Classification using Machine Learning A....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.05583v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV"
      ]
    },
    "2410.14760v1": {
      "title": "Advancing Physics Data Analysis through Machine Learning and Physics-Informed Neural Networks",
      "authors": [
        "Vasileios Vatellis"
      ],
      "abstract": "In an era increasingly focused on green computing and explainable AI,\nrevisiting traditional approaches in theoretical and phenomenological particle\nphysics is paramount. This project evaluates various machine learning (ML)\nalgorithms-including Nearest Neighbors, Decision Trees, Random Forest,\nAdaBoost, Naive Bayes, Quadratic Discriminant Analysis (QDA), and\nXGBoost-alongside standard neural networks and a novel Physics-Informed Neural\nNetwork (PINN) for physics data analysis. We apply these techniques to a binary\nclassification task that distinguishes the experimental viability of simulated\nscenarios based on Higgs observables and essential parameters. Through this\ncomprehensive analysis, we aim to showcase the capabilities and computational\nefficiency of each model in binary classification tasks, thereby contributing\nto the ongoing discourse on integrating ML and Deep Neural Networks (DNNs) into\nphysics research. In this study, XGBoost emerged as the preferred choice among\nthe evaluated machine learning algorithms for its speed and effectiveness,\nespecially in the initial stages of computation with limited datasets. However,\nwhile standard Neural Networks and Physics-Informed Neural Networks (PINNs)\ndemonstrated superior performance in terms of accuracy and adherence to\nphysical laws, they require more computational time. These findings underscore\nthe trade-offs between computational efficiency and model sophistication.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/06af98658835e1203dcfdecad84e5ad1e7c4fbcf",
      "published_date": "2024-10-18",
      "downloaded_date": "2025-02-01",
      "filename": "Vatellis-Advancing Physics Data Analysis through Machine Learning and Physics-Informed Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.14760v1",
      "categories": [
        "hep-ph",
        "cs.LG"
      ]
    },
    "2209.07335v1": {
      "title": "Artificial Intelligence Models and Employee Lifecycle Management: A Systematic Literature Review",
      "authors": [
        "Saeed Nosratabadi",
        "Roya Khayer Zahed",
        "Vadim Vitalievich Ponkratov",
        "Evgeniy Vyacheslavovich Kostyrin"
      ],
      "abstract": "Background/Purpose: The use of artificial intelligence (AI) models for\ndata-driven decision-making in different stages of employee lifecycle (EL)\nmanagement is increasing. However, there is no comprehensive study that\naddresses contributions of AI in EL management. Therefore, the main goal of\nthis study was to address this theoretical gap and determine the contribution\nof AI models to EL. Methods: This study applied the PRISMA method, a systematic\nliterature review model, to ensure that the maximum number of publications\nrelated to the subject can be accessed. The output of the PRISMA model led to\nthe identification of 23 related articles, and the findings of this study were\npresented based on the analysis of these articles. Results: The findings\nrevealed that AL algorithms were used in all stages of EL management (i.e.,\nrecruitment, on-boarding, employability and benefits, retention, and\noff-boarding). It was also disclosed that Random Forest, Support Vector\nMachines, Adaptive Boosting, Decision Tree, and Artificial Neural Network\nalgorithms outperform other algorithms and were the most used in the\nliterature. Conclusion: Although the use of AI models in solving EL problems is\nincreasing, research on this topic is still in its infancy stage, and more\nresearch on this topic is necessary.",
      "citation_count": 13,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/10191ff5a06e9abb7674eb95aa08b8c7227dfc31",
      "published_date": "2022-09-15",
      "downloaded_date": "2025-02-01",
      "filename": "Nosratabadi-Artificial Intelligence Models and Employee Lifecycle Management A Systematic Literature Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.07335v1",
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ]
    },
    "2412.00508v1": {
      "title": "Graph-to-SFILES: Control structure prediction from process topologies using generative artificial intelligence",
      "authors": [
        "Lukas Schulze Balhorn",
        "Kevin Degens",
        "Artur M. Schweidtmann"
      ],
      "abstract": "Control structure design is an important but tedious step in P&ID\ndevelopment. Generative artificial intelligence (AI) promises to reduce P&ID\ndevelopment time by supporting engineers. Previous research on generative AI in\nchemical process design mainly represented processes by sequences. However,\ngraphs offer a promising alternative because of their permutation invariance.\nWe propose the Graph-to-SFILES model, a generative AI method to predict control\nstructures from flowsheet topologies. The Graph-to-SFILES model takes the\nflowsheet topology as a graph input and returns a control-extended flowsheet as\na sequence in the SFILES 2.0 notation. We compare four different graph encoder\narchitectures, one of them being a graph neural network (GNN) proposed in this\nwork. The Graph-to-SFILES model achieves a top-5 accuracy of 73.2% when trained\non 10,000 flowsheet topologies. In addition, the proposed GNN performs best\namong the encoder architectures. Compared to a purely sequence-based approach,\nthe Graph-to-SFILES model improves the top-5 accuracy for a relatively small\ntraining dataset of 1,000 flowsheets from 0.9% to 28.4%. However, the\nsequence-based approach performs better on a large-scale dataset of 100,000\nflowsheets. These results highlight the potential of graph-based AI models to\naccelerate P&ID development in small-data regimes but their effectiveness on\nindustry relevant case studies still needs to be investigated.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a6bc605f32cb33cb302e2d6a2b8311ded86c9763",
      "published_date": "2024-11-30",
      "downloaded_date": "2025-02-01",
      "filename": "Balhorn-Graph-to-SFILES Control structure prediction from process topologies using generative artificial int....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.00508v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ]
    },
    "1901.09133v1": {
      "title": "VQNet: Library for a Quantum-Classical Hybrid Neural Network",
      "authors": [
        "Zhao-Yun Chen",
        "Cheng Xue",
        "Si-Ming Chen",
        "Guo-Ping Guo"
      ],
      "abstract": "Deep learning is a modern approach to realize artificial intelligence. Many\nframeworks exist to implement the machine learning task; however, performance\nis limited by computing resources. Using a quantum computer to accelerate\ntraining is a promising approach. The variational quantum circuit (VQC) has\ngained a great deal of attention because it can be run on near-term quantum\ncomputers. In this paper, we establish a new framework that merges traditional\nmachine learning tasks with the VQC. Users can implement a trainable quantum\noperation into a neural network. This framework enables the training of a\nquantum-classical hybrid task and may lead to a new area of quantum machine\nlearning.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-01-26",
      "downloaded_date": "2025-02-01",
      "filename": "Chen-VQNet Library for a Quantum-Classical Hybrid Neural Network.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.09133v1",
      "categories": [
        "quant-ph"
      ]
    },
    "1802.08925v1": {
      "title": "Generating retinal flow maps from structural optical coherence tomography with artificial intelligence",
      "authors": [
        "Cecilia S. Lee",
        "Ariel J. Tyring",
        "Yue Wu",
        "Sa Xiao",
        "Ariel S. Rokem",
        "Nicolaas P. Deruyter",
        "Qinqin Zhang",
        "Adnan Tufail",
        "Ruikang K. Wang",
        "Aaron Y. Lee"
      ],
      "abstract": "Despite significant advances in artificial intelligence (AI) for computer\nvision, its application in medical imaging has been limited by the burden and\nlimits of expert-generated labels. We used images from optical coherence\ntomography angiography (OCTA), a relatively new imaging modality that measures\nperfusion of the retinal vasculature, to train an AI algorithm to generate\nvasculature maps from standard structural optical coherence tomography (OCT)\nimages of the same retinae, both exceeding the ability and bypassing the need\nfor expert labeling. Deep learning was able to infer perfusion of\nmicrovasculature from structural OCT images with similar fidelity to OCTA and\nsignificantly better than expert clinicians (P < 0.00001). OCTA suffers from\nneed of specialized hardware, laborious acquisition protocols, and motion\nartifacts; whereas our model works directly from standard OCT which are\nubiquitous and quick to obtain, and allows unlocking of large volumes of\npreviously collected standard OCT data both in existing clinical trials and\nclinical practice. This finding demonstrates a novel application of AI to\nmedical imaging, whereby subtle regularities between different modalities are\nused to image the same body part and AI is used to generate detailed and\naccurate inferences of tissue function from structure imaging.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-02-24",
      "downloaded_date": "2025-02-01",
      "filename": "Lee-Generating retinal flow maps from structural optical coherence tomography with artificial intelligen....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1802.08925v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "stat.ML"
      ]
    },
    "2310.01944v1": {
      "title": "Artificial Intelligence for Prediction of Climate Extremes: State of the art, challenges and future perspectives",
      "authors": [
        "Stefano Materia",
        "LluÃ­s Palma GarcÃ­a",
        "Chiem van Straaten",
        "Sungmin O",
        "Antonios Mamalakis",
        "Leone Cavicchia",
        "Dim Coumou",
        "Paolo De Luca",
        "Marlene Kretschmer",
        "Markus G. Donat"
      ],
      "abstract": "Scientific and technological advances in numerical modelling have improved\nthe quality of climate predictions over recent decades, but predictive skill\nremains limited in many aspects. Extreme events such as heat and cold waves,\ndroughts, heavy rain and storms are particularly challenging to predict\naccurately due to their rarity and non-linear chaotic nature, and because of\nmodel limitations. However, recent studies have shown that predictive skill of\nextremes can be increased when using more sophisticated approaches, indicating\nthat there might be systemic predictability that is not being leveraged.\nRecently, numerous studies have been devoted to the exploitation of Artificial\nIntelligence (AI) to study the predictability and make predictions of weather\nand climate. AI techniques have shown great potential to improve the prediction\nof extreme events and uncover their links to large-scale and local drivers.\nMachine and deep learning, causal discovery, explainable AI, are only some of\nthe approaches that have been tested to both improve our understanding of the\nprocesses underlying predictability and enhance prediction skill of extreme\nevents. Results are promising, especially for hybrid predictions that combine\nthe AI, which can reveal and exploit unknown spatio-temporal connections from\ndata, and climate models, that provide the theoretical foundation and\ninterpretability of the physical world. On the other hand, challenges are\nmultiple in many aspects, from data curation to model uncertainty and\ngeneralizability, to the reproducibility of methods and workflows. A few best\npractices are identified to increase trust in these novel techniques, and\nfuture perspectives are envisaged for further scientific development.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-10-03",
      "downloaded_date": "2025-02-01",
      "filename": "Materia-Artificial Intelligence for Prediction of Climate Extremes State of the art challenges and future pe....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.01944v1",
      "categories": [
        "physics.ao-ph"
      ]
    },
    "2408.10414v1": {
      "title": "Towards Automation of Human Stage of Decay Identification: An Artificial Intelligence Approach",
      "authors": [
        "Anna-Maria Nau",
        "Phillip Ditto",
        "Dawnie Wolfe Steadman",
        "Audris Mockus"
      ],
      "abstract": "Determining the stage of decomposition (SOD) is crucial for estimating the\npostmortem interval and identifying human remains. Currently, labor-intensive\nmanual scoring methods are used for this purpose, but they are subjective and\ndo not scale for the emerging large-scale archival collections of human\ndecomposition photos. This study explores the feasibility of automating two\ncommon human decomposition scoring methods proposed by Megyesi and Gelderman\nusing artificial intelligence (AI). We evaluated two popular deep learning\nmodels, Inception V3 and Xception, by training them on a large dataset of human\ndecomposition images to classify the SOD for different anatomical regions,\nincluding the head, torso, and limbs. Additionally, an interrater study was\nconducted to assess the reliability of the AI models compared to human forensic\nexaminers for SOD identification. The Xception model achieved the best\nclassification performance, with macro-averaged F1 scores of .878, .881, and\n.702 for the head, torso, and limbs when predicting Megyesi's SODs, and .872,\n.875, and .76 for the head, torso, and limbs when predicting Gelderman's SODs.\nThe interrater study results supported AI's ability to determine the SOD at a\nreliability level comparable to a human expert. This work demonstrates the\npotential of AI models trained on a large dataset of human decomposition images\nto automate SOD identification.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/773e12af01e02788dc7e72eaa8af3b5d4dc462e4",
      "published_date": "2024-08-19",
      "downloaded_date": "2025-02-01",
      "filename": "Nau-Towards Automation of Human Stage of Decay Identification An Artificial Intelligence Approach.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.10414v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "2412.21022v1": {
      "title": "Text Classification: Neural Networks VS Machine Learning Models VS Pre-trained Models",
      "authors": [
        "Christos Petridis"
      ],
      "abstract": "Text classification is a very common task nowadays and there are many\nefficient methods and algorithms that we can employ to accomplish it.\nTransformers have revolutionized the field of deep learning, particularly in\nNatural Language Processing (NLP) and have rapidly expanded to other domains\nsuch as computer vision, time-series analysis and more. The transformer model\nwas firstly introduced in the context of machine translation and its\narchitecture relies on self-attention mechanisms to capture complex\nrelationships within data sequences. It is able to handle long-range\ndependencies more effectively than traditional neural networks (such as\nRecurrent Neural Networks and Multilayer Perceptrons). In this work, we present\na comparison between different techniques to perform text classification. We\ntake into consideration seven pre-trained models, three standard neural\nnetworks and three machine learning models. For standard neural networks and\nmachine learning models we also compare two embedding techniques: TF-IDF and\nGloVe, with the latter consistently outperforming the former. Finally, we\ndemonstrate the results from our experiments where pre-trained models such as\nBERT and DistilBERT always perform better than standard models/algorithms.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7d67c77680b0833315f69ed40d12d43ffab14b87",
      "published_date": "2024-12-30",
      "downloaded_date": "2025-02-01",
      "filename": "Petridis-Text Classification Neural Networks VS Machine Learning Models VS Pre-trained Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.21022v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2311.02400v1": {
      "title": "From Plate to Production: Artificial Intelligence in Modern Consumer-Driven Food Systems",
      "authors": [
        "Weiqing Min",
        "Pengfei Zhou",
        "Leyi Xu",
        "Tao Liu",
        "Tianhao Li",
        "Mingyu Huang",
        "Ying Jin",
        "Yifan Yi",
        "Min Wen",
        "Shuqiang Jiang",
        "Ramesh Jain"
      ],
      "abstract": "Global food systems confront the urgent challenge of supplying sustainable,\nnutritious diets in the face of escalating demands. The advent of Artificial\nIntelligence (AI) is bringing in a personal choice revolution, wherein\nAI-driven individual decisions transform food systems from dinner tables, to\nthe farms, and back to our plates. In this context, AI algorithms refine\npersonal dietary choices, subsequently shaping agricultural outputs, and\npromoting an optimized feedback loop from consumption to cultivation.\nInitially, we delve into AI tools and techniques spanning the food supply\nchain, and subsequently assess how AI subfields$\\unicode{x2013}$encompassing\nmachine learning, computer vision, and speech recognition$\\unicode{x2013}$are\nharnessed within the AI-enabled Food System (AIFS) framework, which\nincreasingly leverages Internet of Things, multimodal sensors and real-time\ndata exchange. We spotlight the AIFS framework, emphasizing its fusion of AI\nwith technologies such as digitalization, big data analytics, biotechnology,\nand IoT extensively used in modern food systems in every component. This\nparadigm shifts the conventional \"farm to fork\" narrative to a cyclical\n\"consumer-driven farm to fork\" model for better achieving sustainable,\nnutritious diets. This paper explores AI's promise and the intrinsic challenges\nit poses within the food domain. By championing stringent AI governance,\nuniform data architectures, and cross-disciplinary partnerships, we argue that\nAI, when synergized with consumer-centric strategies, holds the potential to\nsteer food systems toward a sustainable trajectory. We furnish a comprehensive\nsurvey for the state-of-the-art in diverse facets of food systems, subsequently\npinpointing gaps and advocating for the judicious and efficacious deployment of\nemergent AI methodologies.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/41986b0f6e61652be1f71aa568e207a123954d85",
      "published_date": "2023-11-04",
      "downloaded_date": "2025-02-01",
      "filename": "Min-From Plate to Production Artificial Intelligence in Modern Consumer-Driven Food Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.02400v1",
      "categories": [
        "cs.CY"
      ]
    },
    "1809.05762v1": {
      "title": "Using Artificial Intelligence to Support Compliance with the General Data Protection Regulation",
      "authors": [
        "John KC Kingston"
      ],
      "abstract": "The General Data Protection Regulation (GDPR) is a European Union regulation\nthat will replace the existing Data Protection Directive on 25 May 2018. The\nmost significant change is a huge increase in the maximum fine that can be\nlevied for breaches of the regulation. Yet fewer than half of UK companies are\nfully aware of GDPR - and a number of those who were preparing for it stopped\ndoing so when the Brexit vote was announced. A last-minute rush to become\ncompliant is therefore expected, and numerous companies are starting to offer\nadvice, checklists and consultancy on how to comply with GDPR. In such an\nenvironment, artificial intelligence technologies ought to be able to assist by\nproviding best advice; asking all and only the relevant questions; monitoring\nactivities; and carrying out assessments. The paper considers four areas of\nGDPR compliance where rule based technologies and/or machine learning\ntechniques may be relevant: * Following compliance checklists and codes of\nconduct; * Supporting risk assessments; * Complying with the new regulations\nregarding technologies that perform automatic profiling; * Complying with the\nnew regulations concerning recognising and reporting breaches of security. It\nconcludes that AI technology can support each of these four areas. The\nrequirements that GDPR (or organisations that need to comply with GDPR) state\nfor explanation and justification of reasoning imply that rule-based approaches\nare likely to be more helpful than machine learning approaches. However, there\nmay be good business reasons to take a different approach in some\ncircumstances.",
      "citation_count": 42,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fda214d53c185098bb7227a7970faad6facf3148",
      "published_date": "2018-09-15",
      "downloaded_date": "2025-02-01",
      "filename": "Kingston-Using Artificial Intelligence to Support Compliance with the General Data Protection Regulation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1809.05762v1",
      "categories": [
        "cs.AI",
        "I.2.1"
      ]
    },
    "2407.12620v2": {
      "title": "Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences",
      "authors": [
        "Claudio Pinhanez",
        "Paulo Cavalin",
        "Luciana Storto",
        "Thomas Finbow",
        "Alexander Cobbinah",
        "Julio Nogima",
        "Marisa Vasconcelos",
        "Pedro Domingues",
        "Priscila de Souza Mizukami",
        "Nicole Grell",
        "MajoÃ­ Gongora",
        "Isabel GonÃ§alves"
      ],
      "abstract": "Since 2022 we have been exploring application areas and technologies in which\nArtificial Intelligence (AI) and modern Natural Language Processing (NLP), such\nas Large Language Models (LLMs), can be employed to foster the usage and\nfacilitate the documentation of Indigenous languages which are in danger of\ndisappearing. We start by discussing the decreasing diversity of languages in\nthe world and how working with Indigenous languages poses unique ethical\nchallenges for AI and NLP. To address those challenges, we propose an\nalternative development AI cycle based on community engagement and usage. Then,\nwe report encouraging results in the development of high-quality machine\nlearning translators for Indigenous languages by fine-tuning state-of-the-art\n(SOTA) translators with tiny amounts of data and discuss how to avoid some\ncommon pitfalls in the process. We also present prototypes we have built in\nprojects done in 2023 and 2024 with Indigenous communities in Brazil, aimed at\nfacilitating writing, and discuss the development of Indigenous Language Models\n(ILMs) as a replicable and scalable way to create spell-checkers, next-word\npredictors, and similar tools. Finally, we discuss how we envision a future for\nlanguage documentation where dying languages are preserved as interactive\nlanguage models.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a5e21d05c666ce7b9b38450b9ee3703a6017a07a",
      "published_date": "2024-07-17",
      "downloaded_date": "2025-02-01",
      "filename": "Pinhanez-Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages Technolo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.12620v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    "2410.14230v1": {
      "title": "Global Inequalities in the Production of Artificial Intelligence: A Four-Country Study on Data Work",
      "authors": [
        "Antonio A. Casilli",
        "Paola Tubaro",
        "Maxime Cornet",
        "ClÃ©ment Le Ludec",
        "Juana Torres-Cierpe",
        "Matheus Viana Braz"
      ],
      "abstract": "Labor plays a major, albeit largely unrecognized role in the development of\nartificial intelligence. Machine learning algorithms are predicated on\ndata-intensive processes that rely on humans to execute repetitive and\ndifficult-to-automate, but no less essential, tasks such as labeling images,\nsorting items in lists, recording voice samples, and transcribing audio files.\nOnline platforms and networks of subcontractors recruit data workers to execute\nsuch tasks in the shadow of AI production, often in lower-income countries with\nlong-standing traditions of informality and lessregulated labor markets. This\nstudy unveils the resulting complexities by comparing the working conditions\nand the profiles of data workers in Venezuela, Brazil, Madagascar, and as an\nexample of a richer country, France. By leveraging original data collected over\nthe years 2018-2023 via a mixed-method design, we highlight how the\ncross-country supply chains that link data workers to core AI production sites\nare reminiscent of colonial relationships, maintain historical economic\ndependencies, and generate inequalities that compound with those inherited from\nthe past. The results also point to the importance of less-researched,\nnon-English speaking countries to understand key features of the production of\nAI solutions at planetary scale.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/59dce3d82073b14833f6aee18e3e0b5b3715a069",
      "published_date": "2024-10-18",
      "downloaded_date": "2025-02-01",
      "filename": "Casilli-Global Inequalities in the Production of Artificial Intelligence A Four-Country Study on Data Work.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.14230v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2501.05165v1": {
      "title": "Bringing Order Amidst Chaos: On the Role of Artificial Intelligence in Secure Software Engineering",
      "authors": [
        "Matteo Esposito"
      ],
      "abstract": "Context. Developing secure and reliable software remains a key challenge in\nsoftware engineering (SE). The ever-evolving technological landscape offers\nboth opportunities and threats, creating a dynamic space where chaos and order\ncompete. Secure software engineering (SSE) must continuously address\nvulnerabilities that endanger software systems and carry broader socio-economic\nrisks, such as compromising critical national infrastructure and causing\nsignificant financial losses. Researchers and practitioners have explored\nmethodologies like Static Application Security Testing Tools (SASTTs) and\nartificial intelligence (AI) approaches, including machine learning (ML) and\nlarge language models (LLMs), to detect and mitigate these vulnerabilities.\nEach method has unique strengths and limitations.\n  Aim. This thesis seeks to bring order to the chaos in SSE by addressing\ndomain-specific differences that impact AI accuracy.\n  Methodology. The research employs a mix of empirical strategies, such as\nevaluating effort-aware metrics, analyzing SASTTs, conducting method-level\nanalysis, and leveraging evidence-based techniques like systematic dataset\nreviews. These approaches help characterize vulnerability prediction datasets.\n  Results. Key findings include limitations in static analysis tools for\nidentifying vulnerabilities, gaps in SASTT coverage of vulnerability types,\nweak relationships among vulnerability severity scores, improved defect\nprediction accuracy using just-in-time modeling, and threats posed by untouched\nmethods.\n  Conclusions. This thesis highlights the complexity of SSE and the importance\nof contextual knowledge in improving AI-driven vulnerability and defect\nprediction. The comprehensive analysis advances effective prediction models,\nbenefiting both researchers and practitioners.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7304ce3a6b16093ddfc4cd12da2a7fe6720e497c",
      "published_date": "2025-01-09",
      "downloaded_date": "2025-02-01",
      "filename": "Esposito-Bringing Order Amidst Chaos On the Role of Artificial Intelligence in Secure Software Engineering.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.05165v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.ET"
      ]
    },
    "2501.07317v3": {
      "title": "Evaluation of Artificial Intelligence Methods for Lead Time Prediction in Non-Cycled Areas of Automotive Production",
      "authors": [
        "Cornelius Hake",
        "Jonas Weigele",
        "Frederik Reichert",
        "Christian Friedrich"
      ],
      "abstract": "The present study examines the effectiveness of applying Artificial\nIntelligence methods in an automotive production environment to predict unknown\nlead times in a non-cycle-controlled production area. Data structures are\nanalyzed to identify contextual features and then preprocessed using one-hot\nencoding. Methods selection focuses on supervised machine learning techniques.\nIn supervised learning methods, regression and classification methods are\nevaluated. Continuous regression based on target size distribution is not\nfeasible. Classification methods analysis shows that Ensemble Learning and\nSupport Vector Machines are the most suitable. Preliminary study results\nindicate that gradient boosting algorithms LightGBM, XGBoost, and CatBoost\nyield the best results. After further testing and extensive hyperparameter\noptimization, the final method choice is the LightGBM algorithm. Depending on\nfeature availability and prediction interval granularity, relative prediction\naccuracies of up to 90% can be achieved. Further tests highlight the importance\nof periodic retraining of AI models to accurately represent complex production\nprocesses using the database. The research demonstrates that AI methods can be\neffectively applied to highly variable production data, adding business value\nby providing an additional metric for various control tasks while outperforming\ncurrent non AI-based systems.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/35c21f6279ee96ff39e9dae14229d149d1cd729b",
      "published_date": "2025-01-13",
      "downloaded_date": "2025-02-01",
      "filename": "Hake-Evaluation of Artificial Intelligence Methods for Lead Time Prediction in Non-Cycled Areas of Automo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.07317v3",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    "2111.02001v1": {
      "title": "Certifiable Artificial Intelligence Through Data Fusion",
      "authors": [
        "Erik Blasch",
        "Junchi Bin",
        "Zheng Liu"
      ],
      "abstract": "This paper reviews and proposes concerns in adopting, fielding, and\nmaintaining artificial intelligence (AI) systems. While the AI community has\nmade rapid progress, there are challenges in certifying AI systems. Using\nprocedures from design and operational test and evaluation, there are\nopportunities towards determining performance bounds to manage expectations of\nintended use. A notional use case is presented with image data fusion to\nsupport AI object recognition certifiability considering precision versus\ndistance.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d5c4166fd8d9b318d9f41f5449bb2d6822d92e5a",
      "published_date": "2021-11-03",
      "downloaded_date": "2025-02-01",
      "filename": "Blasch-Certifiable Artificial Intelligence Through Data Fusion.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.02001v1",
      "categories": [
        "cs.AI",
        "eess.IV"
      ]
    },
    "2305.12728v1": {
      "title": "Diversity and Inclusion in Artificial Intelligence",
      "authors": [
        "Didar Zowghi",
        "Francesca da Rimini"
      ],
      "abstract": "To date, there has been little concrete practical advice about how to ensure\nthat diversity and inclusion considerations should be embedded within both\nspecific Artificial Intelligence (AI) systems and the larger global AI\necosystem. In this chapter, we present a clear definition of diversity and\ninclusion in AI, one which positions this concept within an evolving and\nholistic ecosystem. We use this definition and conceptual framing to present a\nset of practical guidelines primarily aimed at AI technologists, data\nscientists and project leaders.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-05-22",
      "downloaded_date": "2025-02-01",
      "filename": "Zowghi-Diversity and Inclusion in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.12728v1",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    },
    "2203.02927v1": {
      "title": "Enabling Automated Machine Learning for Model-Driven AI Engineering",
      "authors": [
        "Armin Moin",
        "Ukrit Wattanavaekin",
        "Alexandra Lungu",
        "Moharram Challenger",
        "Atta Badii",
        "Stephan GÃ¼nnemann"
      ],
      "abstract": "Developing smart software services requires both Software Engineering and\nArtificial Intelligence (AI) skills. AI practitioners, such as data scientists\noften focus on the AI side, for example, creating and training Machine Learning\n(ML) models given a specific use case and data. They are typically not\nconcerned with the entire software development life-cycle, architectural\ndecisions for the system and performance issues beyond the predictive ML models\n(e.g., regarding the security, privacy, throughput, scalability, availability,\nas well as ethical, legal and regulatory compliance). In this manuscript, we\npropose a novel approach to enable Model-Driven Software Engineering and\nModel-Driven AI Engineering. In particular, we support Automated ML, thus\nassisting software engineers without deep AI knowledge in developing\nAI-intensive systems by choosing the most appropriate ML model, algorithm and\ntechniques with suitable hyper-parameters for the task at hand. To validate our\nwork, we carry out a case study in the smart energy domain.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a25338007d621df488130f3278a2a7c5f77c6676",
      "published_date": "2022-03-06",
      "downloaded_date": "2025-02-01",
      "filename": "Moin-Enabling Automated Machine Learning for Model-Driven AI Engineering.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.02927v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2102.06929v1": {
      "title": "Hybrid Artificial Intelligence Methods for Predicting Air Demand in Dam Bottom Outlet",
      "authors": [
        "Aliakbar Narimani",
        "Mahdi Moghimi",
        "Amir Mosavi"
      ],
      "abstract": "In large infrastructures such as dams, which have a relatively high economic\nvalue, ensuring the proper operation of the associated hydraulic facilities in\ndifferent operating conditions is of utmost importance. To ensure the correct\nand successful operation of the dam's hydraulic equipment and prevent possible\ndamages, including gates and downstream tunnel, to build laboratory models and\nperform some tests are essential (the advancement of the smart sensors based on\nartificial intelligence is essential). One of the causes of damage to dam\nbottom outlets is cavitation in downstream and between the gates, which can\nimpact on dam facilities, and air aeration can be a solution to improve it. In\nthe present study, six dams in different provinces in Iran has been chosen to\nevaluate the air entrainment in the downstream tunnel experimentally. Three\nartificial neural networks (ANN) based machine learning (ML) algorithms are\nused to model and predict the air aeration in the bottom outlet. The proposed\nmodels are trained with genetic algorithms (GA), particle swarm optimization\n(PSO), i.e., ANN-GA, ANN-PSO, and ANFIS-PSO. Two hydrodynamic variables, namely\nvolume rate and opening percentage of the gate, are used as inputs into all\nbottom outlet models. The results showed that the most optimal model is\nANFIS-PSO to predict the dependent value compared with ANN-GA and ANN-PSO. The\nimportance of the volume rate and opening percentage of the dams' gate\nparameters is more effective for suitable air aeration.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5cb5aa6c78d9623a2a7760b74306a592178f2772",
      "published_date": "2021-02-13",
      "downloaded_date": "2025-02-01",
      "filename": "Narimani-Hybrid Artificial Intelligence Methods for Predicting Air Demand in Dam Bottom Outlet.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.06929v1",
      "categories": [
        "cs.LG",
        "cs.NE",
        "68T07"
      ]
    },
    "2311.07609v2": {
      "title": "Artificial Intelligence in Assessing Cardiovascular Diseases and Risk Factors via Retinal Fundus Images: A Review of the Last Decade",
      "authors": [
        "Mirsaeed Abdollahi",
        "Ali Jafarizadeh",
        "Amirhosein Ghafouri Asbagh",
        "Navid Sobhi",
        "Keysan Pourmoghtader",
        "Siamak Pedrammehr",
        "Houshyar Asadi",
        "Roohallah Alizadehsani",
        "Ru-San Tan",
        "U. Rajendra Acharya"
      ],
      "abstract": "Background: Cardiovascular diseases (CVDs) are the leading cause of death\nglobally. The use of artificial intelligence (AI) methods - in particular, deep\nlearning (DL) - has been on the rise lately for the analysis of different\nCVD-related topics. The use of fundus images and optical coherence tomography\nangiography (OCTA) in the diagnosis of retinal diseases has also been\nextensively studied. To better understand heart function and anticipate changes\nbased on microvascular characteristics and function, researchers are currently\nexploring the integration of AI with non-invasive retinal scanning. There is\ngreat potential to reduce the number of cardiovascular events and the financial\nstrain on healthcare systems by utilizing AI-assisted early detection and\nprediction of cardiovascular diseases on a large scale. Method: A comprehensive\nsearch was conducted across various databases, including PubMed, Medline,\nGoogle Scholar, Scopus, Web of Sciences, IEEE Xplore, and ACM Digital Library,\nusing specific keywords related to cardiovascular diseases and artificial\nintelligence. Results: The study included 87 English-language publications\nselected for relevance, and additional references were considered. This paper\nprovides an overview of the recent developments and difficulties in using\nartificial intelligence and retinal imaging to diagnose cardiovascular\ndiseases. It provides insights for further exploration in this field.\nConclusion: Researchers are trying to develop precise disease prognosis\npatterns in response to the aging population and the growing global burden of\nCVD. AI and deep learning are revolutionizing healthcare by potentially\ndiagnosing multiple CVDs from a single retinal image. However, swifter adoption\nof these technologies in healthcare systems is required.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-11-11",
      "downloaded_date": "2025-02-01",
      "filename": "Abdollahi-Artificial Intelligence in Assessing Cardiovascular Diseases and Risk Factors via Retinal Fundus Ima....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.07609v2",
      "categories": [
        "q-bio.QM",
        "cs.CV",
        "eess.IV",
        "physics.med-ph",
        "J.3.2; J.3.3"
      ]
    },
    "2312.05640v1": {
      "title": "Keyword spotting -- Detecting commands in speech using deep learning",
      "authors": [
        "Sumedha Rai",
        "Tong Li",
        "Bella Lyu"
      ],
      "abstract": "Speech recognition has become an important task in the development of machine\nlearning and artificial intelligence. In this study, we explore the important\ntask of keyword spotting using speech recognition machine learning and deep\nlearning techniques. We implement feature engineering by converting raw\nwaveforms to Mel Frequency Cepstral Coefficients (MFCCs), which we use as\ninputs to our models. We experiment with several different algorithms such as\nHidden Markov Model with Gaussian Mixture, Convolutional Neural Networks and\nvariants of Recurrent Neural Networks including Long Short-Term Memory and the\nAttention mechanism. In our experiments, RNN with BiLSTM and Attention achieves\nthe best performance with an accuracy of 93.9 %",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-12-09",
      "downloaded_date": "2025-02-01",
      "filename": "Rai-Keyword spotting -- Detecting commands in speech using deep learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.05640v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "eess.AS"
      ]
    },
    "2001.10056v1": {
      "title": "Explainable Machine Learning Control -- robust control and stability analysis",
      "authors": [
        "Markus Quade",
        "Thomas Isele",
        "Markus Abel"
      ],
      "abstract": "Recently, the term explainable AI became known as an approach to produce\nmodels from artificial intelligence which allow interpretation. Since a long\ntime, there are models of symbolic regression in use that are perfectly\nexplainable and mathematically tractable: in this contribution we demonstrate\nhow to use symbolic regression methods to infer the optimal control of a\ndynamical system given one or several optimization criteria, or cost functions.\nIn previous publications, network control was achieved by automatized machine\nlearning control using genetic programming. Here, we focus on the subsequent\nanalysis of the analytical expressions which result from the machine learning.\nIn particular, we use AUTO to analyze the stability properties of the\ncontrolled oscillator system which served as our model. As a result, we show\nthat there is a considerable advantage of explainable models over less\naccessible neural networks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-01-23",
      "downloaded_date": "2025-02-01",
      "filename": "Quade-Explainable Machine Learning Control -- robust control and stability analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2001.10056v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "nlin.AO",
        "physics.data-an"
      ]
    },
    "2210.15889v5": {
      "title": "Towards Data-and Knowledge-Driven Artificial Intelligence: A Survey on Neuro-Symbolic Computing",
      "authors": [
        "Wenguan Wang",
        "Yi Yang",
        "Fei Wu"
      ],
      "abstract": "Neural-symbolic computing (NeSy), which pursues the integration of the\nsymbolic and statistical paradigms of cognition, has been an active research\narea of Artificial Intelligence (AI) for many years. As NeSy shows promise of\nreconciling the advantages of reasoning and interpretability of symbolic\nrepresentation and robust learning in neural networks, it may serve as a\ncatalyst for the next generation of AI. In the present paper, we provide a\nsystematic overview of the recent developments and important contributions of\nNeSy research. Firstly, we introduce study history of this area, covering early\nwork and foundations. We further discuss background concepts and identify key\ndriving factors behind the development of NeSy. Afterward, we categorize recent\nlandmark approaches along several main characteristics that underline this\nresearch paradigm, including neural-symbolic integration, knowledge\nrepresentation, knowledge embedding, and functionality. Next, we briefly\ndiscuss the successful application of modern NeSy approaches in several\ndomains. Then, we benchmark several NeSy methods on three representative\napplication tasks. Finally, we identify the open problems together with\npotential future research directions. This survey is expected to help new\nresearchers enter this rapidly evolving field and accelerate the progress\ntowards data-and knowledge-driven AI.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d8dcb7d090d4c11758023f19f38f80e8e7f05b2b",
      "published_date": "2022-10-28",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Towards Data-and Knowledge-Driven Artificial Intelligence A Survey on Neuro-Symbolic Computing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.15889v5",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2310.04992v1": {
      "title": "VisionFM: a Multi-Modal Multi-Task Vision Foundation Model for Generalist Ophthalmic Artificial Intelligence",
      "authors": [
        "Jianing Qiu",
        "Jian Wu",
        "Hao Wei",
        "Peilun Shi",
        "Minqing Zhang",
        "Yunyun Sun",
        "Lin Li",
        "Hanruo Liu",
        "Hongyi Liu",
        "Simeng Hou",
        "Yuyang Zhao",
        "Xuehui Shi",
        "Junfang Xian",
        "Xiaoxia Qu",
        "Sirui Zhu",
        "Lijie Pan",
        "Xiaoniao Chen",
        "Xiaojia Zhang",
        "Shuai Jiang",
        "Kebing Wang",
        "Chenlong Yang",
        "Mingqiang Chen",
        "Sujie Fan",
        "Jianhua Hu",
        "Aiguo Lv",
        "Hui Miao",
        "Li Guo",
        "Shujun Zhang",
        "Cheng Pei",
        "Xiaojuan Fan",
        "Jianqin Lei",
        "Ting Wei",
        "Junguo Duan",
        "Chun Liu",
        "Xiaobo Xia",
        "Siqi Xiong",
        "Junhong Li",
        "Benny Lo",
        "Yih Chung Tham",
        "Tien Yin Wong",
        "Ningli Wang",
        "Wu Yuan"
      ],
      "abstract": "We present VisionFM, a foundation model pre-trained with 3.4 million\nophthalmic images from 560,457 individuals, covering a broad range of\nophthalmic diseases, modalities, imaging devices, and demography. After\npre-training, VisionFM provides a foundation to foster multiple ophthalmic\nartificial intelligence (AI) applications, such as disease screening and\ndiagnosis, disease prognosis, subclassification of disease phenotype, and\nsystemic biomarker and disease prediction, with each application enhanced with\nexpert-level intelligence and accuracy. The generalist intelligence of VisionFM\noutperformed ophthalmologists with basic and intermediate levels in jointly\ndiagnosing 12 common ophthalmic diseases. Evaluated on a new large-scale\nophthalmic disease diagnosis benchmark database, as well as a new large-scale\nsegmentation and detection benchmark database, VisionFM outperformed strong\nbaseline deep neural networks. The ophthalmic image representations learned by\nVisionFM exhibited noteworthy explainability, and demonstrated strong\ngeneralizability to new ophthalmic modalities, disease spectrum, and imaging\ndevices. As a foundation model, VisionFM has a large capacity to learn from\ndiverse ophthalmic imaging data and disparate datasets. To be commensurate with\nthis capacity, in addition to the real data used for pre-training, we also\ngenerated and leveraged synthetic ophthalmic imaging data. Experimental results\nrevealed that synthetic data that passed visual Turing tests, can also enhance\nthe representation learning capability of VisionFM, leading to substantial\nperformance gains on downstream ophthalmic AI tasks. Beyond the ophthalmic AI\napplications developed, validated, and demonstrated in this work, substantial\nfurther applications can be achieved in an efficient and cost-effective manner\nusing VisionFM as the foundation.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bba297cb1e35cb357273df56b495a60933157af4",
      "published_date": "2023-10-08",
      "downloaded_date": "2025-02-01",
      "filename": "Qiu-VisionFM a Multi-Modal Multi-Task Vision Foundation Model for Generalist Ophthalmic Artificial Intel....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.04992v1",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "2401.15022v4": {
      "title": "Applications of artificial intelligence in the analysis of histopathology images of gliomas: a review",
      "authors": [
        "Jan-Philipp Redlich",
        "Friedrich Feuerhake",
        "Joachim Weis",
        "Nadine S. Schaadt",
        "Sarah Teuber-Hanselmann",
        "Christoph Buck",
        "Sabine Luttmann",
        "Andrea Eberle",
        "Stefan Nikolin",
        "Arno Appenzeller",
        "Andreas Portmann",
        "AndrÃ© Homeyer"
      ],
      "abstract": "In recent years, the diagnosis of gliomas has become increasingly complex.\nAnalysis of glioma histopathology images using artificial intelligence (AI)\noffers new opportunities to support diagnosis and outcome prediction. To give\nan overview of the current state of research, this review examines 83 publicly\navailable research studies that have proposed AI-based methods for whole-slide\nhistopathology images of human gliomas, covering the diagnostic tasks of\nsubtyping (23/83), grading (27/83), molecular marker prediction (20/83), and\nsurvival prediction (29/83). All studies were reviewed with regard to\nmethodological aspects as well as clinical applicability. It was found that the\nfocus of current research is the assessment of hematoxylin and eosin-stained\ntissue sections of adult-type diffuse gliomas. The majority of studies (52/83)\nare based on the publicly available glioblastoma and low-grade glioma datasets\nfrom The Cancer Genome Atlas (TCGA) and only a few studies employed other\ndatasets in isolation (16/83) or in addition to the TCGA datasets (15/83).\nCurrent approaches mostly rely on convolutional neural networks (63/83) for\nanalyzing tissue at 20x magnification (35/83). A new field of research is the\nintegration of clinical data, omics data, or magnetic resonance imaging\n(29/83). So far, AI-based methods have achieved promising results, but are not\nyet used in real clinical settings. Future work should focus on the independent\nvalidation of methods on larger, multi-site datasets with high-quality and\nup-to-date clinical and molecular pathology annotations to demonstrate routine\napplicability.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-01-26",
      "downloaded_date": "2025-02-01",
      "filename": "Redlich-Applications of artificial intelligence in the analysis of histopathology images of gliomas a review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.15022v4",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2405.00066v1": {
      "title": "Research and application of artificial intelligence based webshell detection model: A literature review",
      "authors": [
        "Mingrui Ma",
        "Lansheng Han",
        "Chunjie Zhou"
      ],
      "abstract": "Webshell, as the \"culprit\" behind numerous network attacks, is one of the\nresearch hotspots in the field of cybersecurity. However, the complexity,\nstealthiness, and confusing nature of webshells pose significant challenges to\nthe corresponding detection schemes. With the rise of Artificial Intelligence\n(AI) technology, researchers have started to apply different intelligent\nalgorithms and neural network architectures to the task of webshell detection.\nHowever, the related research still lacks a systematic and standardized\nmethodological process, which is confusing and redundant. Therefore, following\nthe development timeline, we carefully summarize the progress of relevant\nresearch in this field, dividing it into three stages: Start Stage, Initial\nDevelopment Stage, and In-depth Development Stage. We further elaborate on the\nmain characteristics and core algorithms of each stage. In addition, we analyze\nthe pain points and challenges that still exist in this field and predict the\nfuture development trend of this field from our point of view. To the best of\nour knowledge, this is the first review that details the research related to\nAI-based webshell detection. It is also hoped that this paper can provide\ndetailed technical information for more researchers interested in AI-based\nwebshell detection tasks.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b9364236d8d81b33f9ab23cf62b210526725d12f",
      "published_date": "2024-04-28",
      "downloaded_date": "2025-02-01",
      "filename": "Ma-Research and application of artificial intelligence based webshell detection model A literature revi....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.00066v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    "2412.11837v1": {
      "title": "The Eclipsing Binaries via Artificial Intelligence. II. Need for Speed in PHOEBE Forward Models",
      "authors": [
        "Marcin Wrona",
        "Andrej PrÅ¡a"
      ],
      "abstract": "In modern astronomy, the quantity of data collected has vastly exceeded the\ncapacity for manual analysis, necessitating the use of advanced artificial\nintelligence (AI) techniques to assist scientists with the most labor-intensive\ntasks. AI can optimize simulation codes where computational bottlenecks arise\nfrom the time required to generate forward models. One such example is PHOEBE,\na modeling code for eclipsing binaries (EBs), where simulating individual\nsystems is feasible, but analyzing observables for extensive parameter\ncombinations is highly time-consuming.\n  To address this, we present a fully connected feedforward artificial neural\nnetwork (ANN) trained on a dataset of over one million synthetic light curves\ngenerated with PHOEBE. Optimization of the ANN architecture yielded a model\nwith six hidden layers, each containing 512 nodes, provides an optimized\nbalance between accuracy and computational complexity. Extensive testing\nenabled us to establish ANN's applicability limits and to quantify the\nsystematic and statistical errors associated with using such networks for EB\nanalysis. Our findings demonstrate the critical role of dilution effects in\nparameter estimation for EBs, and we outline methods to incorporate these\neffects in AI-based models.\n  This proposed ANN framework enables a speedup of over four orders of\nmagnitude compared to traditional methods, with systematic errors not exceeding\n1\\%, and often as low as 0.01\\%, across the entire parameter space.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2f0ceb8105fdf8400cb2a35e3c871bedf10ea099",
      "published_date": "2024-12-16",
      "downloaded_date": "2025-02-01",
      "filename": "Wrona-The Eclipsing Binaries via Artificial Intelligence II Need for Speed in PHOEBE Forward Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.11837v1",
      "categories": [
        "astro-ph.SR",
        "astro-ph.EP",
        "astro-ph.GA",
        "cs.LG"
      ]
    },
    "2103.03048v1": {
      "title": "Detecting Spurious Correlations with Sanity Tests for Artificial Intelligence Guided Radiology Systems",
      "authors": [
        "Usman Mahmood",
        "Robik Shrestha",
        "David D. B. Bates",
        "Lorenzo Mannelli",
        "Giuseppe Corrias",
        "Yusuf Erdi",
        "Christopher Kanan"
      ],
      "abstract": "Artificial intelligence (AI) has been successful at solving numerous problems\nin machine perception. In radiology, AI systems are rapidly evolving and show\nprogress in guiding treatment decisions, diagnosing, localizing disease on\nmedical images, and improving radiologists' efficiency. A critical component to\ndeploying AI in radiology is to gain confidence in a developed system's\nefficacy and safety. The current gold standard approach is to conduct an\nanalytical validation of performance on a generalization dataset from one or\nmore institutions, followed by a clinical validation study of the system's\nefficacy during deployment. Clinical validation studies are time-consuming, and\nbest practices dictate limited re-use of analytical validation data, so it is\nideal to know ahead of time if a system is likely to fail analytical or\nclinical validation. In this paper, we describe a series of sanity tests to\nidentify when a system performs well on development data for the wrong reasons.\nWe illustrate the sanity tests' value by designing a deep learning system to\nclassify pancreatic cancer seen in computed tomography scans.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-03-04",
      "downloaded_date": "2025-02-01",
      "filename": "Mahmood-Detecting Spurious Correlations with Sanity Tests for Artificial Intelligence Guided Radiology Syste....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.03048v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2204.02360v1": {
      "title": "Scientometric Review of Artificial Intelligence for Operations & Maintenance of Wind Turbines: The Past, Present and Future",
      "authors": [
        "Joyjit Chatterjee",
        "Nina Dethlefs"
      ],
      "abstract": "Wind energy has emerged as a highly promising source of renewable energy in\nrecent times. However, wind turbines regularly suffer from operational\ninconsistencies, leading to significant costs and challenges in operations and\nmaintenance (O&M). Condition-based monitoring (CBM) and performance\nassessment/analysis of turbines are vital aspects for ensuring efficient O&M\nplanning and cost minimisation. Data-driven decision making techniques have\nwitnessed rapid evolution in the wind industry for such O&M tasks during the\nlast decade, from applying signal processing methods in early 2010 to\nartificial intelligence (AI) techniques, especially deep learning in 2020. In\nthis article, we utilise statistical computing to present a scientometric\nreview of the conceptual and thematic evolution of AI in the wind energy\nsector, providing evidence-based insights into present strengths and\nlimitations of data-driven decision making in the wind industry. We provide a\nperspective into the future and on current key challenges in data availability\nand quality, lack of transparency in black box-natured AI models, and\nprevailing issues in deploying models for real-time decision support, along\nwith possible strategies to overcome these problems. We hope that a systematic\nanalysis of the past, present and future of CBM and performance assessment can\nencourage more organisations to adopt data-driven decision making techniques in\nO&M towards making wind energy sources more reliable, contributing to the\nglobal efforts of tackling climate change.",
      "citation_count": 78,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a97e41e880dc3ffcbeb1c2c35b98faa3d69559b1",
      "published_date": "2022-03-30",
      "downloaded_date": "2025-02-01",
      "filename": "Chatterjee-Scientometric Review of Artificial Intelligence for Operations  Maintenance of Wind Turbines The Pas....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2204.02360v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2405.12785v1": {
      "title": "Artificial Intelligence Approaches for Predictive Maintenance in the Steel Industry: A Survey",
      "authors": [
        "Jakub Jakubowski",
        "Natalia Wojak-Strzelecka",
        "Rita P. Ribeiro",
        "Sepideh Pashami",
        "Szymon Bobek",
        "Joao Gama",
        "Grzegorz J Nalepa"
      ],
      "abstract": "Predictive Maintenance (PdM) emerged as one of the pillars of Industry 4.0,\nand became crucial for enhancing operational efficiency, allowing to minimize\ndowntime, extend lifespan of equipment, and prevent failures. A wide range of\nPdM tasks can be performed using Artificial Intelligence (AI) methods, which\noften use data generated from industrial sensors. The steel industry, which is\nan important branch of the global economy, is one of the potential\nbeneficiaries of this trend, given its large environmental footprint, the\nglobalized nature of the market, and the demanding working conditions. This\nsurvey synthesizes the current state of knowledge in the field of AI-based PdM\nwithin the steel industry and is addressed to researchers and practitioners. We\nidentified 219 articles related to this topic and formulated five research\nquestions, allowing us to gain a global perspective on current trends and the\nmain research gaps. We examined equipment and facilities subjected to PdM,\ndetermined common PdM approaches, and identified trends in the AI methods used\nto develop these solutions. We explored the characteristics of the data used in\nthe surveyed articles and assessed the practical implications of the research\npresented there. Most of the research focuses on the blast furnace or hot\nrolling, using data from industrial sensors. Current trends show increasing\ninterest in the domain, especially in the use of deep learning. The main\nchallenges include implementing the proposed methods in a production\nenvironment, incorporating them into maintenance plans, and enhancing the\naccessibility and reproducibility of the research.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-05-21",
      "downloaded_date": "2025-02-01",
      "filename": "Jakubowski-Artificial Intelligence Approaches for Predictive Maintenance in the Steel Industry A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.12785v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2501.14684v1": {
      "title": "Artificial Intelligence Could Have Predicted All Space Weather Events Associated with the May 2024 Superstorm",
      "authors": [
        "Sabrina Guastavino",
        "Edoardo Legnaro",
        "Anna Maria Massone",
        "Michele Piana"
      ],
      "abstract": "Space weather, driven by solar flares and Coronal Mass Ejections (CMEs),\nposes significant risks to technological systems. Accurately forecasting these\nevents and their impact on Earth's magnetosphere remains a challenge because of\nthe complexity of solar-terrestrial interactions. This study applied artificial\nintelligence (AI) to predict the chain of events associated with the May $2024$\nsuperstorm, including solar flares from NOAA active region 13644,\nEarth-directed CMEs, and a violent geomagnetic storm. Using magnetogram\ncut-outs, a Vision Transformer was able to classify the evolution of the active\nregion morphologies, and a video-based deep learning method predicted the\noccurrence of solar flares; a physics-driven model improved the precision of\nCME travel-time prediction using coronal observations and solar wind\nmeasurements; and a data-driven method exploited these in situ measurements to\nsound alerts of the geomagnetic storm unrolled over time. The results showed\nunprecedented accuracy in predicting CME arrival with uncertainty as small as\none minute. Moreover, these AI models outperformed traditional methods in\npredicting solar flares occurrences, onset, and recovery phases of the\ngeomagnetic storm. These findings highlight the impressive potential of AI for\nspace weather forecasting and as a tool to mitigate the impact of extreme solar\nevents on critical infrastructure.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2025-01-24",
      "downloaded_date": "2025-02-01",
      "filename": "Guastavino-Artificial Intelligence Could Have Predicted All Space Weather Events Associated with the May 2024 S....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.14684v1",
      "categories": [
        "astro-ph.SR",
        "physics.space-ph",
        "68T07"
      ]
    },
    "2103.04132v1": {
      "title": "A Real-time Low-cost Artificial Intelligence System for Autonomous Spraying in Palm Plantations",
      "authors": [
        "Zhenwang Qin",
        "Wensheng Wang",
        "Karl-Heinz Dammer",
        "Leifeng Guo",
        "Zhen Cao"
      ],
      "abstract": "In precision crop protection, (target-orientated) object detection in image\nprocessing can help navigate Unmanned Aerial Vehicles (UAV, crop protection\ndrones) to the right place to apply the pesticide. Unnecessary application of\nnon-target areas could be avoided. Deep learning algorithms dominantly use in\nmodern computer vision tasks which require high computing time, memory\nfootprint, and power consumption. Based on the Edge Artificial Intelligence, we\ninvestigate the main three paths that lead to dealing with this problem,\nincluding hardware accelerators, efficient algorithms, and model compression.\nFinally, we integrate them and propose a solution based on a light deep neural\nnetwork (DNN), called Ag-YOLO, which can make the crop protection UAV have the\nability to target detection and autonomous operation. This solution is\nrestricted in size, cost, flexible, fast, and energy-effective. The hardware is\nonly 18 grams in weight and 1.5 watts in energy consumption, and the developed\nDNN model needs only 838 kilobytes of disc space. We tested the developed\nhardware and software in comparison to the tiny version of the state-of-art\nYOLOv3 framework, known as YOLOv3-Tiny to detect individual palm in a\nplantation. An average F1 score of 0.9205 at the speed of 36.5 frames per\nsecond (in comparison to similar accuracy at 18 frames per second and 8.66\nmegabytes of the YOLOv3-Tiny algorithm) was reached. This developed detection\nsystem is easily plugged into any machines already purchased as long as the\nmachines have USB ports and run Linux Operating System.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0f49e08f5ec54c190a80f7911bdf5defeecebe7d",
      "published_date": "2021-03-06",
      "downloaded_date": "2025-02-01",
      "filename": "Qin-A Real-time Low-cost Artificial Intelligence System for Autonomous Spraying in Palm Plantations.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.04132v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "1911.04542v2": {
      "title": "Explainable Artificial Intelligence (XAI) for 6G: Improving Trust between Human and Machine",
      "authors": [
        "Weisi Guo"
      ],
      "abstract": "As the 5th Generation (5G) mobile networks are bringing about global societal\nbenefits, the design phase for the 6th Generation (6G) has started. 6G will\nneed to enable greater levels of autonomy, improve human machine interfacing,\nand achieve deep connectivity in more diverse environments. The need for\nincreased explainability to enable trust is critical for 6G as it manages a\nwide range of mission critical services (e.g. autonomous driving) to safety\ncritical tasks (e.g. remote surgery). As we migrate from traditional\nmodel-based optimisation to deep learning, the trust we have in our\noptimisation modules decrease. This loss of trust means we cannot understand\nthe impact of: 1) poor/bias/malicious data, and 2) neural network design on\ndecisions; nor can we explain to the engineer or the public the network's\nactions. In this review, we outline the core concepts of Explainable Artificial\nIntelligence (XAI) for 6G, including: public and legal motivations, definitions\nof explainability, performance vs. explainability trade-offs, methods to\nimprove explainability, and frameworks to incorporate XAI into future wireless\nsystems. Our review is grounded in cases studies for both PHY and MAC layer\noptimisation, and provide the community with an important research area to\nembark upon.",
      "citation_count": 40,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/23bf87c26c9a072ade7b10a0dddf118397c54088",
      "published_date": "2019-11-11",
      "downloaded_date": "2025-02-01",
      "filename": "Guo-Explainable Artificial Intelligence XAI for 6G Improving Trust between Human and Machine.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.04542v2",
      "categories": [
        "eess.SP",
        "cs.LG",
        "cs.NI"
      ]
    },
    "2408.16395v2": {
      "title": "IBO: Inpainting-Based Occlusion to Enhance Explainable Artificial Intelligence Evaluation in Histopathology",
      "authors": [
        "Pardis Afshar",
        "Sajjad Hashembeiki",
        "Pouya Khani",
        "Emad Fatemizadeh",
        "Mohammad Hossein Rohban"
      ],
      "abstract": "Histopathological image analysis is crucial for accurate cancer diagnosis and\ntreatment planning. While deep learning models, especially convolutional neural\nnetworks, have advanced this field, their \"black-box\" nature raises concerns\nabout interpretability and trustworthiness. Explainable Artificial Intelligence\n(XAI) techniques aim to address these concerns, but evaluating their\neffectiveness remains challenging. A significant issue with current\nocclusion-based XAI methods is that they often generate Out-of-Distribution\n(OoD) samples, leading to inaccurate evaluations. In this paper, we introduce\nInpainting-Based Occlusion (IBO), a novel occlusion strategy that utilizes a\nDenoising Diffusion Probabilistic Model to inpaint occluded regions in\nhistopathological images. By replacing cancerous areas with realistic,\nnon-cancerous tissue, IBO minimizes OoD artifacts and preserves data integrity.\nWe evaluate our method on the CAMELYON16 dataset through two phases: first, by\nassessing perceptual similarity using the Learned Perceptual Image Patch\nSimilarity (LPIPS) metric, and second, by quantifying the impact on model\npredictions through Area Under the Curve (AUC) analysis. Our results\ndemonstrate that IBO significantly improves perceptual fidelity, achieving\nnearly twice the improvement in LPIPS scores compared to the best existing\nocclusion strategy. Additionally, IBO increased the precision of XAI\nperformance prediction from 42% to 71% compared to traditional methods. These\nresults demonstrate IBO's potential to provide more reliable evaluations of XAI\ntechniques, benefiting histopathology and other applications. The source code\nfor this study is available at https://github.com/a-fsh-r/IBO.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/72ad177ff0964c6c7192098b08083bef527aceb4",
      "published_date": "2024-08-29",
      "downloaded_date": "2025-02-01",
      "filename": "Afshar-IBO Inpainting-Based Occlusion to Enhance Explainable Artificial Intelligence Evaluation in Histopat....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.16395v2",
      "categories": [
        "cs.CV"
      ]
    },
    "1801.01704v2": {
      "title": "Artificial Intelligence (AI) Methods in Optical Networks: A Comprehensive Survey",
      "authors": [
        "Javier Mata",
        "Ignacio de Miguel",
        "RamÃ³ n J. DurÃ¡ n",
        "NoemÃ­ Merayo",
        "Sandeep Kumar Singh",
        "Admela Jukan",
        "Mohit Chamania"
      ],
      "abstract": "Artificial intelligence (AI) is an extensive scientific discipline which\nenables computer systems to solve problems by emulating complex biological\nprocesses such as learning, reasoning and self-correction. This paper presents\na comprehensive review of the application of AI techniques for improving\nperformance of optical communication systems and networks. The use of AI-based\ntechniques is first studied in applications related to optical transmission,\nranging from the characterization and operation of network components to\nperformance monitoring, mitigation of nonlinearities, and quality of\ntransmission estimation. Then, applications related to optical network control\nand management are also reviewed, including topics like optical network\nplanning and operation in both transport and access networks. Finally, the\npaper also presents a summary of opportunities and challenges in optical\nnetworking where AI is expected to play a key role in the near future.",
      "citation_count": 318,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7477379ab2b7d854620daa487cdf639761185a01",
      "published_date": "2018-01-05",
      "downloaded_date": "2025-02-01",
      "filename": "Mata-Artificial Intelligence AI Methods in Optical Networks A Comprehensive Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1801.01704v2",
      "categories": [
        "cs.AI",
        "cs.NI"
      ]
    },
    "cs/0601129v1": {
      "title": "Instantaneously Trained Neural Networks",
      "authors": [
        "Abhilash Ponnath"
      ],
      "abstract": "This paper presents a review of instantaneously trained neural networks\n(ITNNs). These networks trade learning time for size and, in the basic model, a\nnew hidden node is created for each training sample. Various versions of the\ncorner-classification family of ITNNs, which have found applications in\nartificial intelligence (AI), are described. Implementation issues are also\nconsidered.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2006-01-30",
      "downloaded_date": "2025-02-01",
      "filename": "Ponnath-Instantaneously Trained Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/cs/0601129v1",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    "2102.03061v1": {
      "title": "Applications of Artificial Intelligence in Particle Radiotherapy",
      "authors": [
        "Chao Wu",
        "Dan Nguyen",
        "Jan Schuemann",
        "Andrea Mairani",
        "Yuehu Pu",
        "Steve Jiang"
      ],
      "abstract": "Radiotherapy, due to its technology-intensive nature and reliance on digital\ndata and human-machine interactions, is particularly suited to benefit from\nartificial intelligence (AI) to improve the accuracy and efficiency of its\nclinical workflow. Recently, various artificial intelligence (AI) methods have\nbeen successfully developed to exploit the benefit of the inherent physical\nproperties of particle therapy. Many reviews about AI applications in\nradiotherapy have already been published, but none were specifically dedicated\nto particle therapy. In this article, we present a comprehensive review of the\nrecent published works on AI applications in particle therapy, which can be\nclassified into particle therapy treatment planning, adaptive particle therapy,\nrange and dose verification and other applications in particle therapy.\nAlthough promising results reported in these works demonstrate how AI-based\nmethods can help exploit the intrinsic physic advantages of particle therapy,\nchallenges remained to be address before AI applications in particle therapy\nenjoy widespread implementation in clinical practice.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a97cefbef6edd60615568aa6773268ced12bc813",
      "published_date": "2021-02-05",
      "downloaded_date": "2025-02-01",
      "filename": "Wu-Applications of Artificial Intelligence in Particle Radiotherapy.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.03061v1",
      "categories": [
        "physics.med-ph"
      ]
    },
    "2006.12439v1": {
      "title": "Fully-parallel Convolutional Neural Network Hardware",
      "authors": [
        "Christiam F. Frasser",
        "Pablo Linares-Serrano",
        "V. Canals",
        "Miquel Roca",
        "T. Serrano-Gotarredona",
        "Josep L. Rossello"
      ],
      "abstract": "A new trans-disciplinary knowledge area, Edge Artificial Intelligence or Edge\nIntelligence, is beginning to receive a tremendous amount of interest from the\nmachine learning community due to the ever increasing popularization of the\nInternet of Things (IoT). Unfortunately, the incorporation of AI\ncharacteristics to edge computing devices presents the drawbacks of being power\nand area hungry for typical machine learning techniques such as Convolutional\nNeural Networks (CNN). In this work, we propose a new power-and-area-efficient\narchitecture for implementing Articial Neural Networks (ANNs) in hardware,\nbased on the exploitation of correlation phenomenon in Stochastic Computing\n(SC) systems. The architecture purposed can solve the difficult implementation\nchallenges that SC presents for CNN applications, such as the high resources\nused in binary-tostochastic conversion, the inaccuracy produced by undesired\ncorrelation between signals, and the stochastic maximum function\nimplementation. Compared with traditional binary logic implementations,\nexperimental results showed an improvement of 19.6x and 6.3x in terms of speed\nperformance and energy efficiency, for the FPGA implementation. We have also\nrealized a full VLSI implementation of the proposed SC-CNN architecture\ndemonstrating that our optimization achieve a 18x area reduction over previous\nSC-DNN architecture VLSI implementation in a comparable technological node. For\nthe first time, a fully-parallel CNN as LENET-5 is embedded and tested in a\nsingle FPGA, showing the benefits of using stochastic computing for embedded\napplications, in contrast to traditional binary logic implementations.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8da14102e9d4d16fa18cf146391502da2dff8ef9",
      "published_date": "2020-06-22",
      "downloaded_date": "2025-02-01",
      "filename": "Frasser-Fully-parallel Convolutional Neural Network Hardware.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2006.12439v1",
      "categories": [
        "cs.NE",
        "I.2.m, B.7.1"
      ]
    },
    "2104.02532v3": {
      "title": "End-To-End Bias Mitigation: Removing Gender Bias in Deep Learning",
      "authors": [
        "Tal Feldman",
        "Ashley Peake"
      ],
      "abstract": "Machine Learning models have been deployed across many different aspects of\nsociety, often in situations that affect social welfare. Although these models\noffer streamlined solutions to large problems, they may contain biases and\ntreat groups or individuals unfairly based on protected attributes such as\ngender. In this paper, we introduce several examples of machine learning gender\nbias in practice followed by formalizations of fairness. We provide a survey of\nfairness research by detailing influential pre-processing, in-processing, and\npost-processing bias mitigation algorithms. We then propose an end-to-end bias\nmitigation framework, which employs a fusion of pre-, in-, and post-processing\nmethods to leverage the strengths of each individual technique. We test this\nmethod, along with the standard techniques we review, on a deep neural network\nto analyze bias mitigation in a deep learning setting. We find that our\nend-to-end bias mitigation framework outperforms the baselines with respect to\nseveral fairness metrics, suggesting its promise as a method for improving\nfairness. As society increasingly relies on artificial intelligence to help in\ndecision-making, addressing gender biases present in deep learning models is\nimperative. To provide readers with the tools to assess the fairness of machine\nlearning models and mitigate the biases present in them, we discuss multiple\nopen source packages for fairness in AI.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b73dc1678b7b70861afe5b6f2364fcdfe3c5e176",
      "published_date": "2021-04-06",
      "downloaded_date": "2025-02-01",
      "filename": "Feldman-End-To-End Bias Mitigation Removing Gender Bias in Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.02532v3",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2404.03499v1": {
      "title": "Comprehensible Artificial Intelligence on Knowledge Graphs: A survey",
      "authors": [
        "Simon Schramm",
        "Christoph Wehner",
        "Ute Schmid"
      ],
      "abstract": "Artificial Intelligence applications gradually move outside the safe walls of\nresearch labs and invade our daily lives. This is also true for Machine\nLearning methods on Knowledge Graphs, which has led to a steady increase in\ntheir application since the beginning of the 21st century. However, in many\napplications, users require an explanation of the Artificial Intelligences\ndecision. This led to increased demand for Comprehensible Artificial\nIntelligence. Knowledge Graphs epitomize fertile soil for Comprehensible\nArtificial Intelligence, due to their ability to display connected data, i.e.\nknowledge, in a human- as well as machine-readable way. This survey gives a\nshort history to Comprehensible Artificial Intelligence on Knowledge Graphs.\nFurthermore, we contribute by arguing that the concept Explainable Artificial\nIntelligence is overloaded and overlapping with Interpretable Machine Learning.\nBy introducing the parent concept Comprehensible Artificial Intelligence, we\nprovide a clear-cut distinction of both concepts while accounting for their\nsimilarities. Thus, we provide in this survey a case for Comprehensible\nArtificial Intelligence on Knowledge Graphs consisting of Interpretable Machine\nLearning on Knowledge Graphs and Explainable Artificial Intelligence on\nKnowledge Graphs. This leads to the introduction of a novel taxonomy for\nComprehensible Artificial Intelligence on Knowledge Graphs. In addition, a\ncomprehensive overview of the research on Comprehensible Artificial\nIntelligence on Knowledge Graphs is presented and put into the context of the\ntaxonomy. Finally, research gaps in the field of Comprehensible Artificial\nIntelligence on Knowledge Graphs are identified for future research.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-04-04",
      "downloaded_date": "2025-02-01",
      "filename": "Schramm-Comprehensible Artificial Intelligence on Knowledge Graphs A survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.03499v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2007.12998v1": {
      "title": "A Novel Approach to the Diagnosis of Heart Disease using Machine Learning and Deep Neural Networks",
      "authors": [
        "Sahithi Ankireddy"
      ],
      "abstract": "Heart disease is the leading cause of death worldwide. Currently, 33% of\ncases are misdiagnosed, and approximately half of myocardial infarctions occur\nin people who are not predicted to be at risk. The use of Artificial\nIntelligence could reduce the chance of error, leading to possible earlier\ndiagnoses, which could be the difference between life and death for some. The\nobjective of this project was to develop an application for assisted heart\ndisease diagnosis using Machine Learning (ML) and Deep Neural Network (DNN)\nalgorithms. The dataset was provided from the Cleveland Clinic Foundation, and\nthe models were built based on various optimization and hyper parametrization\ntechniques including a Grid Search algorithm. The application, running on\nFlask, and utilizing Bootstrap was developed using the DNN, as it performed\nhigher than the Random Forest ML model with a total accuracy rate of 92%.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-07-25",
      "downloaded_date": "2025-02-01",
      "filename": "Ankireddy-A Novel Approach to the Diagnosis of Heart Disease using Machine Learning and Deep Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.12998v1",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "1710.06910v2": {
      "title": "Characterization of Gradient Dominance and Regularity Conditions for Neural Networks",
      "authors": [
        "Yi Zhou",
        "Yingbin Liang"
      ],
      "abstract": "The past decade has witnessed a successful application of deep learning to\nsolving many challenging problems in machine learning and artificial\nintelligence. However, the loss functions of deep neural networks (especially\nnonlinear networks) are still far from being well understood from a theoretical\naspect. In this paper, we enrich the current understanding of the landscape of\nthe square loss functions for three types of neural networks. Specifically,\nwhen the parameter matrices are square, we provide an explicit characterization\nof the global minimizers for linear networks, linear residual networks, and\nnonlinear networks with one hidden layer. Then, we establish two quadratic\ntypes of landscape properties for the square loss of these neural networks,\ni.e., the gradient dominance condition within the neighborhood of their full\nrank global minimizers, and the regularity condition along certain directions\nand within the neighborhood of their global minimizers. These two landscape\nproperties are desirable for the optimization around the global minimizers of\nthe loss function for these neural networks.",
      "citation_count": 33,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5fef384d40543761c537e0111de37a3ed94db388",
      "published_date": "2017-10-18",
      "downloaded_date": "2025-02-01",
      "filename": "Zhou-Characterization of Gradient Dominance and Regularity Conditions for Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1710.06910v2",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.OC"
      ]
    },
    "1811.03392v1": {
      "title": "Transformative Machine Learning",
      "authors": [
        "Ivan Olier",
        "Oghenejokpeme I. Orhobor",
        "Joaquin Vanschoren",
        "Ross D. King"
      ],
      "abstract": "The key to success in machine learning (ML) is the use of effective data\nrepresentations. Traditionally, data representations were hand-crafted.\nRecently it has been demonstrated that, given sufficient data, deep neural\nnetworks can learn effective implicit representations from simple input\nrepresentations. However, for most scientific problems, the use of deep\nlearning is not appropriate as the amount of available data is limited, and/or\nthe output models must be explainable. Nevertheless, many scientific problems\ndo have significant amounts of data available on related tasks, which makes\nthem amenable to multi-task learning, i.e. learning many related problems\nsimultaneously. Here we propose a novel and general representation learning\napproach for multi-task learning that works successfully with small amounts of\ndata. The fundamental new idea is to transform an input intrinsic data\nrepresentation (i.e., handcrafted features), to an extrinsic representation\nbased on what a pre-trained set of models predict about the examples. This\ntransformation has the dual advantages of producing significantly more accurate\npredictions, and providing explainable models. To demonstrate the utility of\nthis transformative learning approach, we have applied it to three real-world\nscientific problems: drug-design (quantitative structure activity relationship\nlearning), predicting human gene expression (across different tissue types and\ndrug treatments), and meta-learning for machine learning (predicting which\nmachine learning methods work best for a given problem). In all three problems,\ntransformative machine learning significantly outperforms the best intrinsic\nrepresentation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-11-08",
      "downloaded_date": "2025-02-01",
      "filename": "Olier-Transformative Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1811.03392v1",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "1911.05755v1": {
      "title": "An Introduction to Artificial Intelligence and Solutions to the Problems of Algorithmic Discrimination",
      "authors": [
        "Nicholas Schmidt",
        "Bryce Stephens"
      ],
      "abstract": "There is substantial evidence that Artificial Intelligence (AI) and Machine\nLearning (ML) algorithms can generate bias against minorities, women, and other\nprotected classes. Federal and state laws have been enacted to protect\nconsumers from discrimination in credit, housing, and employment, where\nregulators and agencies are tasked with enforcing these laws. Additionally,\nthere are laws in place to ensure that consumers understand why they are denied\naccess to services and products, such as consumer loans. In this article, we\nprovide an overview of the potential benefits and risks associated with the use\nof algorithms and data, and focus specifically on fairness. While our\nobservations generalize to many contexts, we focus on the fairness concerns\nraised in consumer credit and the legal requirements of the Equal Credit and\nOpportunity Act. We propose a methodology for evaluating algorithmic fairness\nand minimizing algorithmic bias that aligns with the provisions of federal and\nstate anti-discrimination statutes that outlaw overt, disparate treatment, and,\nspecifically, disparate impact discrimination. We argue that while the use of\nAI and ML algorithms heighten potential discrimination risks, these risks can\nbe evaluated and mitigated, but doing so requires a deep understanding of these\nalgorithms and the contexts and domains in which they are being used.",
      "citation_count": 12,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a4d97258abf832d8614b38c2433583a88d873de7",
      "published_date": "2019-11-08",
      "downloaded_date": "2025-02-01",
      "filename": "Schmidt-An Introduction to Artificial Intelligence and Solutions to the Problems of Algorithmic Discriminati....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.05755v1",
      "categories": [
        "cs.CY",
        "cs.LG",
        "68T01",
        "K.5.2; K.4.1; K.4.2"
      ]
    },
    "2005.01908v1": {
      "title": "A multi-component framework for the analysis and design of explainable artificial intelligence",
      "authors": [
        "S. Atakishiyev",
        "H. Babiker",
        "N. Farruque",
        "R. Goebel1",
        "M-Y. Kima",
        "M. H. Motallebi",
        "J. Rabelo",
        "T. Syed",
        "O. R. ZaÃ¯ane"
      ],
      "abstract": "The rapid growth of research in explainable artificial intelligence (XAI)\nfollows on two substantial developments. First, the enormous application\nsuccess of modern machine learning methods, especially deep and reinforcement\nlearning, which have created high expectations for industrial, commercial and\nsocial value. Second, the emergence of concern for creating trusted AI systems,\nincluding the creation of regulatory principles to ensure transparency and\ntrust of AI systems.These two threads have created a kind of \"perfect storm\" of\nresearch activity, all eager to create and deliver it any set of tools and\ntechniques to address the XAI demand. As some surveys of current XAI suggest,\nthere is yet to appear a principled framework that respects the literature of\nexplainability in the history of science, and which provides a basis for the\ndevelopment of a framework for transparent XAI. Here we intend to provide a\nstrategic inventory of XAI requirements, demonstrate their connection to a\nhistory of XAI ideas, and synthesize those ideas into a simple framework to\ncalibrate five successive levels of XAI.",
      "citation_count": 32,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1ea26f19d99cbc108530aeb18c636762b882e1ef",
      "published_date": "2020-05-05",
      "downloaded_date": "2025-02-01",
      "filename": "Atakishiyev-A multi-component framework for the analysis and design of explainable artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.01908v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2107.07459v1": {
      "title": "Bridging Nano and Micro-scale X-ray Tomography for Battery Research by Leveraging Artificial Intelligence",
      "authors": [
        "Jonathan Scharf",
        "Mehdi Chouchane",
        "Donal P. Finegan",
        "Bingyu Lu",
        "Christopher Redquest",
        "Min-cheol Kim",
        "Weiliang Yao",
        "Alejandro A. Franco",
        "Dan Gostovic",
        "Zhao Liu",
        "Mark Riccio",
        "FrantiÅ¡ek Zelenka",
        "Jean-Marie Doux",
        "Ying Shirley Meng"
      ],
      "abstract": "X-ray Computed Tomography (X-ray CT) is a well-known non-destructive imaging\ntechnique where contrast originates from the materials' absorption\ncoefficients. Novel battery characterization studies on increasingly\nchallenging samples have been enabled by the rapid development of both\nsynchrotron and laboratory-scale imaging systems as well as innovative analysis\ntechniques. Furthermore, the recent development of laboratory nano-scale CT\n(NanoCT) systems has pushed the limits of battery material imaging towards\nvoxel sizes previously achievable only using synchrotron facilities. Such\nsystems are now able to reach spatial resolutions down to 50 nm. Given the\nnon-destructive nature of CT, in-situ and operando studies have emerged as\npowerful methods to quantify morphological parameters, such as tortuosity\nfactor, porosity, surface area, and volume expansion during battery operation\nor cycling. Combined with powerful Artificial Intelligence (AI)/Machine\nLearning (ML) analysis techniques, extracted 3D tomograms and battery-specific\nmorphological parameters enable the development of predictive physics-based\nmodels that can provide valuable insights for battery engineering. These models\ncan predict the impact of the electrode microstructure on cell performances or\nanalyze the influence of material heterogeneities on electrochemical responses.\nIn this work, we review the increasing role of X-ray CT experimentation in the\nbattery field, discuss the incorporation of AI/ML in analysis, and provide a\nperspective on how the combination of multi-scale CT imaging techniques can\nexpand the development of predictive multiscale battery behavioral models.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-07-15",
      "downloaded_date": "2025-02-01",
      "filename": "Scharf-Bridging Nano and Micro-scale X-ray Tomography for Battery Research by Leveraging Artificial Intelli....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.07459v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall",
        "physics.app-ph"
      ]
    },
    "2102.06045v1": {
      "title": "Artificial Intelligence based Autonomous Molecular Design for Medical Therapeutic: A Perspective",
      "authors": [
        "Rajendra P. Joshi",
        "Neeraj Kumar"
      ],
      "abstract": "Domain-aware machine learning (ML) models have been increasingly adopted for\naccelerating small molecule therapeutic design in the recent years. These\nmodels have been enabled by significant advancement in state-of-the-art\nartificial intelligence (AI) and computing infrastructures. Several ML\narchitectures are pre-dominantly and independently used either for predicting\nthe properties of small molecules, or for generating lead therapeutic\ncandidates. Synergetically using these individual components along with robust\nrepresentation and data generation techniques autonomously in closed loops\nholds enormous promise for accelerated drug design which is a time consuming\nand expensive task otherwise. In this perspective, we present the most recent\nbreakthrough achieved by each of the components, and how such autonomous AI and\nML workflow can be realized to radically accelerate the hit identification and\nlead optimization. Taken together, this could significantly shorten the\ntimeline for end-to-end antiviral discovery and optimization times to weeks\nupon the arrival of a novel zoonotic transmission event. Our perspective serves\nas a guide for researchers to practice autonomous molecular design in\ntherapeutic discovery.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bb6a7f1dedacda7d64710c17f27ec1ecce4a0a89",
      "published_date": "2021-02-10",
      "downloaded_date": "2025-02-01",
      "filename": "Joshi-Artificial Intelligence based Autonomous Molecular Design for Medical Therapeutic A Perspective.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.06045v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ]
    },
    "2208.08039v1": {
      "title": "Artificial Intelligence Empowered Multiple Access for Ultra Reliable and Low Latency THz Wireless Networks",
      "authors": [
        "Alexandros-Apostolos A. Boulogeorgos",
        "Edwin Yaqub",
        "Rachana Desai",
        "Tachporn Sanguanpuak",
        "Nikos Katzouris",
        "Fotis Lazarakis",
        "Angeliki Alexiou",
        "Marco Di Renzo"
      ],
      "abstract": "Terahertz (THz) wireless networks are expected to catalyze the beyond fifth\ngeneration (B5G) era. However, due to the directional nature and the\nline-of-sight demand of THz links, as well as the ultra-dense deployment of THz\nnetworks, a number of challenges that the medium access control (MAC) layer\nneeds to face are created. In more detail, the need of rethinking user\nassociation and resource allocation strategies by incorporating artificial\nintelligence (AI) capable of providing \"real-time\" solutions in complex and\nfrequently changing environments becomes evident. Moreover, to satisfy the\nultra-reliability and low-latency demands of several B5G applications, novel\nmobility management approaches are required. Motivated by this, this article\npresents a holistic MAC layer approach that enables intelligent user\nassociation and resource allocation, as well as flexible and adaptive mobility\nmanagement, while maximizing systems' reliability through blockage\nminimization. In more detail, a fast and centralized joint user association,\nradio resource allocation, and blockage avoidance by means of a novel\nmetaheuristic-machine learning framework is documented, that maximizes the THz\nnetworks performance, while minimizing the association latency by approximately\nthree orders of magnitude. To support, within the access point (AP) coverage\narea, mobility management and blockage avoidance, a deep reinforcement learning\n(DRL) approach for beam-selection is discussed. Finally, to support user\nmobility between coverage areas of neighbor APs, a proactive hand-over\nmechanism based on AI-assisted fast channel prediction is~reported.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cbda11ef343e3c40570e37c64112572b6387d90e",
      "published_date": "2022-08-17",
      "downloaded_date": "2025-02-01",
      "filename": "Boulogeorgos-Artificial Intelligence Empowered Multiple Access for Ultra Reliable and Low Latency THz Wireless Ne....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2208.08039v1",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ]
    },
    "2302.03180v2": {
      "title": "Understanding User Preferences in Explainable Artificial Intelligence: A Survey and a Mapping Function Proposal",
      "authors": [
        "Maryam Hashemi",
        "Ali Darejeh",
        "Francisco Cruz"
      ],
      "abstract": "The increasing complexity of AI systems has led to the growth of the field of\nExplainable Artificial Intelligence (XAI), which aims to provide explanations\nand justifications for the outputs of AI algorithms. While there is\nconsiderable demand for XAI, there remains a scarcity of studies aimed at\ncomprehensively understanding the practical distinctions among different\nmethods and effectively aligning each method with users individual needs, and\nideally, offer a mapping function which can map each user with its specific\nneeds to a method of explainability. This study endeavors to bridge this gap by\nconducting a thorough review of extant research in XAI, with a specific focus\non Explainable Machine Learning (XML), and a keen eye on user needs. Our main\nobjective is to offer a classification of XAI methods within the realm of XML,\ncategorizing current works into three distinct domains: philosophy, theory, and\npractice, and providing a critical review for each category. Moreover, our\nstudy seeks to facilitate the connection between XAI users and the most\nsuitable methods for them and tailor explanations to meet their specific needs\nby proposing a mapping function that take to account users and their desired\nproperties and suggest an XAI method to them. This entails an examination of\nprevalent XAI approaches and an evaluation of their properties. The primary\noutcome of this study is the formulation of a clear and concise strategy for\nselecting the optimal XAI method to achieve a given goal, all while delivering\npersonalized explanations tailored to individual users.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-02-07",
      "downloaded_date": "2025-02-01",
      "filename": "Hashemi-Understanding User Preferences in Explainable Artificial Intelligence A Survey and a Mapping Functio....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.03180v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2312.14977v1": {
      "title": "Diffusion Models for Generative Artificial Intelligence: An Introduction for Applied Mathematicians",
      "authors": [
        "Catherine F. Higham",
        "Desmond J. Higham",
        "Peter Grindrod"
      ],
      "abstract": "Generative artificial intelligence (AI) refers to algorithms that create\nsynthetic but realistic output. Diffusion models currently offer state of the\nart performance in generative AI for images. They also form a key component in\nmore general tools, including text-to-image generators and large language\nmodels. Diffusion models work by adding noise to the available training data\nand then learning how to reverse the process. The reverse operation may then be\napplied to new random data in order to produce new outputs. We provide a brief\nintroduction to diffusion models for applied mathematicians and statisticians.\nOur key aims are (a) to present illustrative computational examples, (b) to\ngive a careful derivation of the underlying mathematical formulas involved, and\n(c) to draw a connection with partial differential equation (PDE) diffusion\nmodels. We provide code for the computational experiments. We hope that this\ntopic will be of interest to advanced undergraduate students and postgraduate\nstudents. Portions of the material may also provide useful motivational\nexamples for those who teach courses in stochastic processes, inference,\nmachine learning, PDEs or scientific computing.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-12-21",
      "downloaded_date": "2025-02-01",
      "filename": "Higham-Diffusion Models for Generative Artificial Intelligence An Introduction for Applied Mathematicians.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.14977v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07, 60J60",
        "I.2; I.2.6"
      ]
    },
    "2405.13462v1": {
      "title": "Blockchain and Artificial Intelligence: Synergies and Conflicts",
      "authors": [
        "Leon Witt",
        "Armando Teles Fortes",
        "Kentaroh Toyoda",
        "Wojciech Samek",
        "Dan Li"
      ],
      "abstract": "Blockchain technology and Artificial Intelligence (AI) have emerged as\ntransformative forces in their respective domains. This paper explores\nsynergies and challenges between these two technologies. Our research analyses\nthe biggest projects combining blockchain and AI, based on market\ncapitalization, and derives a novel framework to categorize contemporary and\nfuture use cases. Despite the theoretical compatibility, current real-world\napplications combining blockchain and AI remain in their infancy.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-05-22",
      "downloaded_date": "2025-02-01",
      "filename": "Witt-Blockchain and Artificial Intelligence Synergies and Conflicts.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.13462v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.DC"
      ]
    },
    "2207.06233v1": {
      "title": "Continual Learning with Deep Learning Methods in an Application-Oriented Context",
      "authors": [
        "Benedikt PfÃ¼lb"
      ],
      "abstract": "Abstract knowledge is deeply grounded in many computer-based applications. An\nimportant research area of Artificial Intelligence (AI) deals with the\nautomatic derivation of knowledge from data. Machine learning offers the\naccording algorithms. One area of research focuses on the development of\nbiologically inspired learning algorithms. The respective machine learning\nmethods are based on neurological concepts so that they can systematically\nderive knowledge from data and store it. One type of machine learning\nalgorithms that can be categorized as \"deep learning\" model is referred to as\nDeep Neural Networks (DNNs). DNNs consist of multiple artificial neurons\narranged in layers that are trained by using the backpropagation algorithm.\nThese deep learning methods exhibit amazing capabilities for inferring and\nstoring complex knowledge from high-dimensional data. However, DNNs are\naffected by a problem that prevents new knowledge from being added to an\nexisting base. The ability to continuously accumulate knowledge is an important\nfactor that contributed to evolution and is therefore a prerequisite for the\ndevelopment of strong AIs. The so-called \"catastrophic forgetting\" (CF) effect\ncauses DNNs to immediately loose already derived knowledge after a few training\niterations on a new data distribution. Only an energetically expensive\nretraining with the joint data distribution of past and new data enables the\nabstraction of the entire new set of knowledge. In order to counteract the\neffect, various techniques have been and are still being developed with the\ngoal to mitigate or even solve the CF problem. These published CF avoidance\nstudies usually imply the effectiveness of their approaches for various\ncontinual learning tasks. This dissertation is set in the context of continual\nmachine learning with deep learning methods. The first part deals with the\ndevelopment of an ...",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/07377f79941491fda4d83b2ae8dcb13bd00e31e5",
      "published_date": "2022-07-12",
      "downloaded_date": "2025-02-01",
      "filename": "PfÃ¼lb-Continual Learning with Deep Learning Methods in an Application-Oriented Context.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2207.06233v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1712.07199v1": {
      "title": "Cognitive Database: A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities",
      "authors": [
        "Rajesh Bordawekar",
        "Bortik Bandyopadhyay",
        "Oded Shmueli"
      ],
      "abstract": "We propose Cognitive Databases, an approach for transparently enabling\nArtificial Intelligence (AI) capabilities in relational databases. A novel\naspect of our design is to first view the structured data source as meaningful\nunstructured text, and then use the text to build an unsupervised neural\nnetwork model using a Natural Language Processing (NLP) technique called word\nembedding. This model captures the hidden inter-/intra-column relationships\nbetween database tokens of different types. For each database token, the model\nincludes a vector that encodes contextual semantic relationships. We seamlessly\nintegrate the word embedding model into existing SQL query infrastructure and\nuse it to enable a new class of SQL-based analytics queries called cognitive\nintelligence (CI) queries. CI queries use the model vectors to enable complex\nqueries such as semantic matching, inductive reasoning queries such as\nanalogies, predictive queries using entities not present in a database, and,\nmore generally, using knowledge from external sources. We demonstrate unique\ncapabilities of Cognitive Databases using an Apache Spark based prototype to\nexecute inductive reasoning CI queries over a multi-modal database containing\ntext and images. We believe our first-of-a-kind system exemplifies using AI\nfunctionality to endow relational databases with capabilities that were\npreviously very hard to realize in practice.",
      "citation_count": 27,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/99dc409372f64e22e89074331d22e37a22274adb",
      "published_date": "2017-12-19",
      "downloaded_date": "2025-02-01",
      "filename": "Bordawekar-Cognitive Database A Step towards Endowing Relational Databases with Artificial Intelligence Capabil....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1712.07199v1",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ]
    },
    "2011.05186v1": {
      "title": "Pristine annotations-based multi-modal trained artificial intelligence solution to triage chest X-ray for COVID-19",
      "authors": [
        "Tao Tan",
        "Bipul Das",
        "Ravi Soni",
        "Mate Fejes",
        "Sohan Ranjan",
        "Daniel Attila Szabo",
        "Vikram Melapudi",
        "K S Shriram",
        "Utkarsh Agrawal",
        "Laszlo Rusko",
        "Zita Herczeg",
        "Barbara Darazs",
        "Pal Tegzes",
        "Lehel Ferenczi",
        "Rakesh Mullick",
        "Gopal Avinash"
      ],
      "abstract": "The COVID-19 pandemic continues to spread and impact the well-being of the\nglobal population. The front-line modalities including computed tomography (CT)\nand X-ray play an important role for triaging COVID patients. Considering the\nlimited access of resources (both hardware and trained personnel) and\ndecontamination considerations, CT may not be ideal for triaging suspected\nsubjects. Artificial intelligence (AI) assisted X-ray based applications for\ntriaging and monitoring require experienced radiologists to identify COVID\npatients in a timely manner and to further delineate the disease region\nboundary are seen as a promising solution. Our proposed solution differs from\nexisting solutions by industry and academic communities, and demonstrates a\nfunctional AI model to triage by inferencing using a single x-ray image, while\nthe deep-learning model is trained using both X-ray and CT data. We report on\nhow such a multi-modal training improves the solution compared to X-ray only\ntraining. The multi-modal solution increases the AUC (area under the receiver\noperating characteristic curve) from 0.89 to 0.93 and also positively impacts\nthe Dice coefficient (0.59 to 0.62) for localizing the pathology. To the best\nour knowledge, it is the first X-ray solution by leveraging multi-modal\ninformation for the development.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2f38511e2c8f7c9da8a5676fbefa25d52c0b6e4f",
      "published_date": "2020-11-10",
      "downloaded_date": "2025-02-01",
      "filename": "Tan-Pristine annotations-based multi-modal trained artificial intelligence solution to triage chest X-ra....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2011.05186v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2211.00286v1": {
      "title": "Strategies for Optimizing End-to-End Artificial Intelligence Pipelines on Intel Xeon Processors",
      "authors": [
        "Meena Arunachalam",
        "Vrushabh Sanghavi",
        "Yi A Yao",
        "Yi A Zhou",
        "Lifeng A Wang",
        "Zongru Wen",
        "Niroop Ammbashankar",
        "Ning W Wang",
        "Fahim Mohammad"
      ],
      "abstract": "End-to-end (E2E) artificial intelligence (AI) pipelines are composed of\nseveral stages including data preprocessing, data ingestion, defining and\ntraining the model, hyperparameter optimization, deployment, inference,\npostprocessing, followed by downstream analyses. To obtain efficient E2E\nworkflow, it is required to optimize almost all the stages of pipeline. Intel\nXeon processors come with large memory capacities, bundled with AI acceleration\n(e.g., Intel Deep Learning Boost), well suited to run multiple instances of\ntraining and inference pipelines in parallel and has low total cost of\nownership (TCO). To showcase the performance on Xeon processors, we applied\ncomprehensive optimization strategies coupled with software and hardware\nacceleration on variety of E2E pipelines in the areas of Computer Vision, NLP,\nRecommendation systems, etc. We were able to achieve a performance improvement,\nranging from 1.8x to 81.7x across different E2E pipelines. In this paper, we\nwill be highlighting the optimization strategies adopted by us to achieve this\nperformance on Intel Xeon processors with a set of eight different E2E\npipelines.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-11-01",
      "downloaded_date": "2025-02-01",
      "filename": "Arunachalam-Strategies for Optimizing End-to-End Artificial Intelligence Pipelines on Intel Xeon Processors.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.00286v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC",
        "cs.NE"
      ]
    },
    "2012.09610v1": {
      "title": "Validate and Enable Machine Learning in Industrial AI",
      "authors": [
        "Hongbo Zou",
        "Guangjing Chen",
        "Pengtao Xie",
        "Sean Chen",
        "Yongtian He",
        "Hochih Huang",
        "Zheng Nie",
        "Hongbao Zhang",
        "Tristan Bala",
        "Kazi Tulip",
        "Yuqi Wang",
        "Shenlin Qin",
        "Eric P. Xing"
      ],
      "abstract": "Industrial Artificial Intelligence (Industrial AI) is an emerging concept\nwhich refers to the application of artificial intelligence to industry.\nIndustrial AI promises more efficient future industrial control systems.\nHowever, manufacturers and solution partners need to understand how to\nimplement and integrate an AI model into the existing industrial control\nsystem. A well-trained machine learning (ML) model provides many benefits and\nopportunities for industrial control optimization; however, an inferior\nIndustrial AI design and integration limits the capability of ML models. To\nbetter understand how to develop and integrate trained ML models into the\ntraditional industrial control system, test the deployed AI control system, and\nultimately outperform traditional systems, manufacturers and their AI solution\npartners need to address a number of challenges. Six top challenges, which were\nreal problems we ran into when deploying Industrial AI, are explored in the\npaper. The Petuum Optimum system is used as an example to showcase the\nchallenges in making and testing AI models, and more importantly, how to\naddress such challenges in an Industrial AI system.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-10-30",
      "downloaded_date": "2025-02-01",
      "filename": "Zou-Validate and Enable Machine Learning in Industrial AI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.09610v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2201.00966v1": {
      "title": "AI visualization in Nanoscale Microscopy",
      "authors": [
        "Rajagopal A",
        "Nirmala V",
        "Andrew J",
        "Arun Muthuraj Vedamanickam."
      ],
      "abstract": "Artificial Intelligence & Nanotechnology are promising areas for the future\nof humanity. While Deep Learning based Computer Vision has found applications\nin many fields from medicine to automotive, its application in nanotechnology\ncan open doors for new scientific discoveries. Can we apply AI to explore\nobjects that our eyes can't see such as nano scale sized objects? An AI\nplatform to visualize nanoscale patterns learnt by a Deep Learning neural\nnetwork can open new frontiers for nanotechnology. The objective of this paper\nis to develop a Deep Learning based visualization system on images of\nnanomaterials obtained by scanning electron microscope. This paper contributes\nan AI platform to enable any nanoscience researcher to use AI in visual\nexploration of nanoscale morphologies of nanomaterials. This AI is developed by\na technique of visualizing intermediate activations of a Convolutional\nAutoEncoder. In this method, a nano scale specimen image is transformed into\nits feature representations by a Convolution Neural Network. The Convolutional\nAutoEncoder is trained on 100% SEM dataset, and then CNN visualization is\napplied. This AI generates various conceptual feature representations of the\nnanomaterial.\n  While Deep Learning based image classification of SEM images are widely\npublished in literature, there are not much publications that have visualized\nDeep neural networks of nanomaterials. There is a significant opportunity to\ngain insights from the learnings extracted by machine learning. This paper\nunlocks the potential of applying Deep Learning based Visualization on electron\nmicroscopy to offer AI extracted features and architectural patterns of various\nnanomaterials. This is a contribution in Explainable AI in nano scale objects.\nThis paper contributes an open source AI with reproducible results at URL\n(https://sites.google.com/view/aifornanotechnology)",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-01-04",
      "downloaded_date": "2025-02-01",
      "filename": "A-AI visualization in Nanoscale Microscopy.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2201.00966v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "I.2.0; J.2"
      ]
    },
    "1907.12386v1": {
      "title": "Artificial Intelligence and the Future of Psychiatry: Insights from a Global Physician Survey",
      "authors": [
        "P. Murali Doraiswamy",
        "Charlotte Blease",
        "Kaylee Bodner"
      ],
      "abstract": "Futurists have predicted that new technologies, embedded with artificial\nintelligence (AI) and machine learning (ML), will lead to substantial job loss\nin many sectors disrupting many aspects of healthcare. Mental health appears\nripe for such disruption given the global illness burden, stigma, and shortage\nof care providers. Using Sermo, a global networking platform open to verified\nand licensed physicians, we measured the opinions of psychiatrists about the\nlikelihood that future autonomous technology (referred to as AI/ML) would be\nable to fully replace the average psychiatrist in performing 10 key tasks (e.g.\nmental status exam, suicidality assessment, treatment planning) carried out in\nmental health care. Survey respondents were 791 psychiatrists from 22\ncountries. Only 3.8% of respondents felt that AI/ML was likely to replace a\nhuman clinician for providing empathetic care. Documenting (e.g. updating\nmedical records) and synthesizing information to reach a diagnosis were the two\ntasks where a majority predicted that future AI/ML would replace human doctors.\nAbout 1 in 2 doctors believed their jobs could be changed substantially by\nfuture AI/ML. However, female and US-based doctors were more uncertain that the\npossible benefits of AI would outweigh potential risks, versus their male and\nglobal counterparts. To our knowledge, this is the first global survey to seek\nthe opinions of physicians on the impact of autonomous AI/ML on the future of\npsychiatry. Our findings provide compelling insights into how physicians think\nabout intelligent technologies which may better help us integrate such tools\nand reskill doctors, as needed, to enhance mental health care.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-07-29",
      "downloaded_date": "2025-02-01",
      "filename": "Doraiswamy-Artificial Intelligence and the Future of Psychiatry Insights from a Global Physician Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.12386v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2309.05682v1": {
      "title": "A compendium of data sources for data science, machine learning, and artificial intelligence",
      "authors": [
        "Paul Bilokon",
        "Oleksandr Bilokon",
        "Saeed Amen"
      ],
      "abstract": "Recent advances in data science, machine learning, and artificial\nintelligence, such as the emergence of large language models, are leading to an\nincreasing demand for data that can be processed by such models. While data\nsources are application-specific, and it is impossible to produce an exhaustive\nlist of such data sources, it seems that a comprehensive, rather than complete,\nlist would still benefit data scientists and machine learning experts of all\nlevels of seniority. The goal of this publication is to provide just such an\n(inevitably incomplete) list -- or compendium -- of data sources across\nmultiple areas of applications, including finance and economics, legal (laws\nand regulations), life sciences (medicine and drug discovery), news sentiment\nand social media, retail and ecommerce, satellite imagery, and shipping and\nlogistics, and sports.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-09-10",
      "downloaded_date": "2025-02-01",
      "filename": "Bilokon-A compendium of data sources for data science machine learning and artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.05682v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "q-bio.QM",
        "q-fin.CP"
      ]
    },
    "2104.10683v4": {
      "title": "Explainable artificial intelligence for mechanics: physics-informing neural networks for constitutive models",
      "authors": [
        "Arnd Koeppe",
        "Franz Bamer",
        "Michael Selzer",
        "Britta Nestler",
        "Bernd Markert"
      ],
      "abstract": "(Artificial) neural networks have become increasingly popular in mechanics to\naccelerate computations with model order reduction techniques and as universal\nmodels for a wide variety of materials. However, the major disadvantage of\nneural networks remains: their numerous parameters are challenging to interpret\nand explain. Thus, neural networks are often labeled as black boxes, and their\nresults often elude human interpretation. In mechanics, the new and active\nfield of physics-informed neural networks attempts to mitigate this\ndisadvantage by designing deep neural networks on the basis of mechanical\nknowledge. By using this a priori knowledge, deeper and more complex neural\nnetworks became feasible, since the mechanical assumptions could be explained.\nHowever, the internal reasoning and explanation of neural network parameters\nremain mysterious.\n  Complementary to the physics-informed approach, we propose a first step\ntowards a physics-informing approach, which explains neural networks trained on\nmechanical data a posteriori. This novel explainable artificial intelligence\napproach aims at elucidating the black box of neural networks and their\nhigh-dimensional representations. Therein, the principal component analysis\ndecorrelates the distributed representations in cell states of RNNs and allows\nthe comparison to known and fundamental functions. The novel approach is\nsupported by a systematic hyperparameter search strategy that identifies the\nbest neural network architectures and training parameters. The findings of\nthree case studies on fundamental constitutive models (hyperelasticity,\nelastoplasticity, and viscoelasticity) imply that the proposed strategy can\nhelp identify numerical and analytical closed-form solutions to characterize\nnew materials.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-04-20",
      "downloaded_date": "2025-02-01",
      "filename": "Koeppe-Explainable artificial intelligence for mechanics physics-informing neural networks for constitutive....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.10683v4",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2205.08404v1": {
      "title": "A Comprehensive Study on Artificial Intelligence Algorithms to Implement Safety Using Communication Technologies",
      "authors": [
        "Rafia Inam",
        "Alberto Yukinobu Hata",
        "Vlasjov Prifti",
        "Sara Abbaspour Asadollah"
      ],
      "abstract": "The recent development of artificial intelligence (AI) has increased the\ninterest of researchers and practitioners towards applying its techniques into\nmultiple domains like automotive, health care and air space to achieve\nautomation. Combined to these applications, the attempt to use AI techniques\ninto carrying out safety issues is momentarily at a progressive state. As AI\nproblems are getting even more complex, large processing power is demanded for\nsafety-critical systems to fulfill real-time requirements. These challenges can\nbe solved through edge or cloud computing, which makes the communication an\nintegral part of the solution. This study aims at providing a comprehensive\npicture of the state of the art AI based safety solutions that uses different\ncommunication technologies in diverse application domains. To achieve this, a\nsystematic mapping study is conducted and 565 relevant papers are shortlisted\nthrough a multistage selection process, which are then analyzed according to a\nsystematically defined classification framework. The results of the study are\nbased on these main objectives: to clarify current research gaps in the field,\nto identify the possibility of increased usage of cellular communication in\nmultiple domains, to identify the mostly used AI algorithms and to summarize\nthe emerging future research trends on the topic. The results demonstrate that\nautomotive domain is the one applying AI and communication the most to\nimplement safety and the most used AI in this domain is neural networks,\nclustering and computer vision; applying cellular communication to automotive\ndomain is highest; the use of non-cellular communication technologies is\ndominant however a clear trend of a rapid increase in the use of cellular\ncommunication is observed specially from 2020 with the roll-out of 5G\ntechnology.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1fcfde72386a62ab1a0a62949c34cbe7931b0409",
      "published_date": "2022-05-17",
      "downloaded_date": "2025-02-01",
      "filename": "Inam-A Comprehensive Study on Artificial Intelligence Algorithms to Implement Safety Using Communication ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.08404v1",
      "categories": [
        "cs.AI",
        "cs.NI"
      ]
    },
    "2103.15004v3": {
      "title": "eXtended Artificial Intelligence: New Prospects of Human-AI Interaction Research",
      "authors": [
        "Carolin Wienrich",
        "Marc Erich Latoschik"
      ],
      "abstract": "Artificial Intelligence (AI) covers a broad spectrum of computational\nproblems and use cases. Many of those implicate profound and sometimes\nintricate questions of how humans interact or should interact with AIs.\nMoreover, many users or future users do have abstract ideas of what AI is,\nsignificantly depending on the specific embodiment of AI applications.\nHuman-centered-design approaches would suggest evaluating the impact of\ndifferent embodiments on human perception of and interaction with AI. An\napproach that is difficult to realize due to the sheer complexity of\napplication fields and embodiments in reality. However, here XR opens new\npossibilities to research human-AI interactions. The article's contribution is\ntwofold: First, it provides a theoretical treatment and model of human-AI\ninteraction based on an XR-AI continuum as a framework for and a perspective of\ndifferent approaches of XR-AI combinations. It motivates XR-AI combinations as\na method to learn about the effects of prospective human-AI interfaces and\nshows why the combination of XR and AI fruitfully contributes to a valid and\nsystematic investigation of human-AI interactions and interfaces. Second, the\narticle provides two exemplary experiments investigating the aforementioned\napproach for two distinct AI-systems. The first experiment reveals an\ninteresting gender effect in human-robot interaction, while the second\nexperiment reveals an Eliza effect of a recommender system. Here the article\nintroduces two paradigmatic implementations of the proposed XR testbed for\nhuman-AI interactions and interfaces and shows how a valid and systematic\ninvestigation can be conducted. In sum, the article opens new perspectives on\nhow XR benefits human-centered AI design and development.",
      "citation_count": 41,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9c0dd1ac233a20c6e7848d54942f7e646f0a6a97",
      "published_date": "2021-03-27",
      "downloaded_date": "2025-02-01",
      "filename": "Wienrich-eXtended Artificial Intelligence New Prospects of Human-AI Interaction Research.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.15004v3",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    "2412.19688v1": {
      "title": "A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation",
      "authors": [
        "Jana Zakall",
        "Birgit Pohn",
        "Antonia Graf",
        "Daniel Kovatchki",
        "Arezoo Borji",
        "Ragib Shahriar Islam",
        "Hossam Haick",
        "Heinz Strohmer",
        "Sepideh Hatamikia"
      ],
      "abstract": "Artificial intelligence (AI) has emerged as a powerful tool to enhance\ndecision-making and optimize treatment protocols in in vitro fertilization\n(IVF). In particular, AI shows significant promise in supporting\ndecision-making during the ovarian stimulation phase of the IVF process. This\nreview evaluates studies focused on the applications of AI combined with\nmedical imaging in ovarian stimulation, examining methodologies, outcomes, and\ncurrent limitations. Our analysis of 13 studies on this topic reveals that,\nreveal that while AI algorithms demonstrated notable potential in predicting\noptimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the\nmedical imaging data utilized predominantly came from two-dimensional (2D)\nultrasound which mainly involved basic quantifications, such as follicle size\nand number, with limited use of direct feature extraction or advanced image\nanalysis techniques. This points to an underexplored opportunity where advanced\nimage analysis approaches, such as deep learning, and more diverse imaging\nmodalities, like three-dimensional (3D) ultrasound, could unlock deeper\ninsights. Additionally, the lack of explainable AI (XAI) in most studies raises\nconcerns about the transparency and traceability of AI-driven decisions - key\nfactors for clinical adoption and trust. Furthermore, many studies relied on\nsingle-center designs and small datasets, which limit the generalizability of\ntheir findings. This review highlights the need for integrating advanced\nimaging analysis techniques with explainable AI methodologies, as well as the\nimportance of leveraging multicenter collaborations and larger datasets.\nAddressing these gaps has the potential to enhance ovarian stimulation\nmanagement, paving the way for efficient, personalized, and data-driven\ntreatment pathways that improve IVF outcomes.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a8678bd1f5eb22b55ddf8187171d6f9179374fae",
      "published_date": "2024-12-27",
      "downloaded_date": "2025-02-01",
      "filename": "Zakall-A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulatio....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.19688v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    "1709.07615v3": {
      "title": "Neural Networks for Predicting Algorithm Runtime Distributions",
      "authors": [
        "Katharina Eggensperger",
        "Marius Lindauer",
        "Frank Hutter"
      ],
      "abstract": "Many state-of-the-art algorithms for solving hard combinatorial problems in\nartificial intelligence (AI) include elements of stochasticity that lead to\nhigh variations in runtime, even for a fixed problem instance. Knowledge about\nthe resulting runtime distributions (RTDs) of algorithms on given problem\ninstances can be exploited in various meta-algorithmic procedures, such as\nalgorithm selection, portfolios, and randomized restarts. Previous work has\nshown that machine learning can be used to individually predict mean, median\nand variance of RTDs. To establish a new state-of-the-art in predicting RTDs,\nwe demonstrate that the parameters of an RTD should be learned jointly and that\nneural networks can do this well by directly optimizing the likelihood of an\nRTD given runtime observations. In an empirical study involving five algorithms\nfor SAT solving and AI planning, we show that neural networks predict the true\nRTDs of unseen instances better than previous methods, and can even do so when\nonly few runtime observations are available per training instance.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-09-22",
      "downloaded_date": "2025-02-01",
      "filename": "Eggensperger-Neural Networks for Predicting Algorithm Runtime Distributions.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1709.07615v3",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "0705.3360v1": {
      "title": "The Road to Quantum Artificial Intelligence",
      "authors": [
        "Kyriakos N. Sgarbas"
      ],
      "abstract": "This paper overviews the basic principles and recent advances in the emerging\nfield of Quantum Computation (QC), highlighting its potential application to\nArtificial Intelligence (AI). The paper provides a very brief introduction to\nbasic QC issues like quantum registers, quantum gates and quantum algorithms\nand then it presents references, ideas and research guidelines on how QC can be\nused to deal with some basic AI problems, such as search and pattern matching,\nas soon as quantum computers become widely available.",
      "citation_count": 17,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f66c1e4bf653ae86a17387f57c13d64202de7839",
      "published_date": "2007-05-23",
      "downloaded_date": "2025-02-01",
      "filename": "Sgarbas-The Road to Quantum Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/0705.3360v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1806.10518v2": {
      "title": "Autonomous Wireless Systems with Artificial Intelligence",
      "authors": [
        "Haris Gacanin"
      ],
      "abstract": "This paper discusses technology and opportunities to embrace artificial\nintelligence (AI) in the design of autonomous wireless systems. We aim to\nprovide readers with motivation and general AI methodology of autonomous agents\nin the context of self-organization in real time by unifying knowledge\nmanagement with sensing, reasoning and active learning. We highlight\ndifferences between training-based methods for matching problems and\ntraining-free methods for environment-specific problems. Finally, we\nconceptually introduce the functions of an autonomous agent with knowledge\nmanagement.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ecf071407c8161d0f07cf50dcdf3accd58ebed10",
      "published_date": "2018-06-27",
      "downloaded_date": "2025-02-01",
      "filename": "Gacanin-Autonomous Wireless Systems with Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1806.10518v2",
      "categories": [
        "cs.NI",
        "cs.AI"
      ]
    },
    "2402.17554v1": {
      "title": "Evaluation of Predictive Reliability to Foster Trust in Artificial Intelligence. A case study in Multiple Sclerosis",
      "authors": [
        "Lorenzo Peracchio",
        "Giovanna Nicora",
        "Enea Parimbelli",
        "Tommaso Mario Buonocore",
        "Roberto Bergamaschi",
        "Eleonora Tavazzi",
        "Arianna Dagliati",
        "Riccardo Bellazzi"
      ],
      "abstract": "Applying Artificial Intelligence (AI) and Machine Learning (ML) in critical\ncontexts, such as medicine, requires the implementation of safety measures to\nreduce risks of harm in case of prediction errors. Spotting ML failures is of\nparamount importance when ML predictions are used to drive clinical decisions.\nML predictive reliability measures the degree of trust of a ML prediction on a\nnew instance, thus allowing decision-makers to accept or reject it based on its\nreliability. To assess reliability, we propose a method that implements two\nprinciples. First, our approach evaluates whether an instance to be classified\nis coming from the same distribution of the training set. To do this, we\nleverage Autoencoders (AEs) ability to reconstruct the training set with low\nerror. An instance is considered Out-of-Distribution (OOD) if the AE\nreconstructs it with a high error. Second, it is evaluated whether the ML\nclassifier has good performances on samples similar to the newly classified\ninstance by using a proxy model. We show that this approach is able to assess\nreliability both in a simulated scenario and on a model trained to predict\ndisease progression of Multiple Sclerosis patients. We also developed a Python\npackage, named relAI, to embed reliability measures into ML pipelines. We\npropose a simple approach that can be used in the deployment phase of any ML\nmodel to suggest whether to trust predictions or not. Our method holds the\npromise to provide effective support to clinicians by spotting potential ML\nfailures during deployment.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e60d8ea6ce143fb16d82a5f2cca1fa0b165470be",
      "published_date": "2024-02-27",
      "downloaded_date": "2025-02-01",
      "filename": "Peracchio-Evaluation of Predictive Reliability to Foster Trust in Artificial Intelligence A case study in Mult....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.17554v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2406.11524v1": {
      "title": "Explainable Artificial Intelligence and Multicollinearity : A Mini Review of Current Approaches",
      "authors": [
        "Ahmed M Salih"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) methods help to understand the\ninternal mechanism of machine learning models and how they reach a specific\ndecision or made a specific action. The list of informative features is one of\nthe most common output of XAI methods. Multicollinearity is one of the big\nissue that should be considered when XAI generates the explanation in terms of\nthe most informative features in an AI system. No review has been dedicated to\ninvestigate the current approaches to handle such significant issue. In this\npaper, we provide a review of the current state-of-the-art approaches in\nrelation to the XAI in the context of recent advances in dealing with the\nmulticollinearity issue. To do so, we searched in three repositories that are:\nWeb of Science, Scopus and IEEE Xplore to find pertinent published papers.\nAfter excluding irrelevant papers, seven papers were considered in the review.\nIn addition, we discuss the current XAI methods and their limitations in\ndealing with the multicollinearity and suggest future directions.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-06-17",
      "downloaded_date": "2025-02-01",
      "filename": "Salih-Explainable Artificial Intelligence and Multicollinearity  A Mini Review of Current Approaches.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.11524v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2411.02345v1": {
      "title": "Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking",
      "authors": [
        "Shahab Kavousinejad"
      ],
      "abstract": "Nanorobots are a promising development in targeted drug delivery and the\ntreatment of neurological disorders, with potential for crossing the\nblood-brain barrier (BBB). These small devices leverage advancements in\nnanotechnology and bioengineering for precise navigation and targeted payload\ndelivery, particularly for conditions like brain tumors, Alzheimer's disease,\nand Parkinson's disease. Recent progress in artificial intelligence (AI) and\nmachine learning (ML) has improved the navigation and effectiveness of\nnanorobots, allowing them to detect and interact with cancer cells through\nbiomarker analysis. This study presents a new reinforcement learning (RL)\nframework for optimizing nanorobot navigation in complex biological\nenvironments, focusing on cancer cell detection by analyzing the concentration\ngradients of surrounding biomarkers. We utilize a computer simulation model to\nexplore the behavior of nanorobots in a three-dimensional space with cancer\ncells and biological barriers. The proposed method uses Q-learning to refine\nmovement strategies based on real-time biomarker concentration data, enabling\nnanorobots to autonomously navigate to cancerous tissues for targeted drug\ndelivery. This research lays the groundwork for future laboratory experiments\nand clinical applications, with implications for personalized medicine and less\ninvasive cancer treatments. The integration of intelligent nanorobots could\nrevolutionize therapeutic strategies, reducing side effects and enhancing\ntreatment effectiveness for cancer patients. Further research will investigate\nthe practical deployment of these technologies in medical settings, aiming to\nunlock the full potential of nanorobotics in healthcare.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5406e58704c53bfc946ff6800cb7f781f9207bfe",
      "published_date": "2024-11-04",
      "downloaded_date": "2025-02-01",
      "filename": "Kavousinejad-Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.02345v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "physics.med-ph",
        "q-bio.OT",
        "Artificial intelligence"
      ]
    },
    "1802.01274v1": {
      "title": "Dream Formulations and Deep Neural Networks: Humanistic Themes in the Iconology of the Machine-Learned Image",
      "authors": [
        "Emily L. Spratt"
      ],
      "abstract": "This paper addresses the interpretability of deep learning-enabled image\nrecognition processes in computer vision science in relation to theories in art\nhistory and cognitive psychology on the vision-related perceptual capabilities\nof humans. Examination of what is determinable about the machine-learned image\nin comparison to humanistic theories of visual perception, particularly in\nregard to art historian Erwin Panofsky's methodology for image analysis and\npsychologist Eleanor Rosch's theory of graded categorization according to\nprototypes, finds that there are surprising similarities between the two that\nsuggest that researchers in the arts and the sciences would have much to\nbenefit from closer collaborations. Utilizing the examples of Google's\nDeepDream and the Machine Learning and Perception Lab at Georgia Tech's\nGrad-CAM: Gradient-weighted Class Activation Mapping programs, this study\nsuggests that a revival of art historical research in iconography and formalism\nin the age of AI is essential for shaping the future navigation and\ninterpretation of all machine-learned images, given the rapid developments in\nimage recognition technologies.",
      "citation_count": 12,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d3398739038cb6ea63746b4cc6f4c25acfa0e2c4",
      "published_date": "2018-02-05",
      "downloaded_date": "2025-02-01",
      "filename": "Spratt-Dream Formulations and Deep Neural Networks Humanistic Themes in the Iconology of the Machine-Learne....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1802.01274v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV"
      ]
    },
    "1803.00758v2": {
      "title": "Driving Digital Rock towards Machine Learning: predicting permeability with Gradient Boosting and Deep Neural Networks",
      "authors": [
        "Oleg Sudakov",
        "Evgeny Burnaev",
        "Dmitry Koroteev"
      ],
      "abstract": "We present a research study aimed at testing of applicability of machine\nlearning techniques for prediction of permeability of digitized rock samples.\nWe prepare a training set containing 3D images of sandstone samples imaged with\nX-ray microtomography and corresponding permeability values simulated with Pore\nNetwork approach. We also use Minkowski functionals and Deep Learning-based\ndescriptors of 3D images and 2D slices as input features for predictive model\ntraining and prediction. We compare predictive power of various feature sets\nand methods. The later include Gradient Boosting and various architectures of\nDeep Neural Networks (DNN). The results demonstrate applicability of machine\nlearning for image-based permeability prediction and open a new area of Digital\nRock research.",
      "citation_count": 159,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/11ed9140c75dbc323188fe89e9646c736d5feaf8",
      "published_date": "2018-03-02",
      "downloaded_date": "2025-02-01",
      "filename": "Sudakov-Driving Digital Rock towards Machine Learning predicting permeability with Gradient Boosting and Dee....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1803.00758v2",
      "categories": [
        "physics.geo-ph",
        "cs.CV",
        "physics.comp-ph"
      ]
    },
    "2408.14811v1": {
      "title": "Brain-inspired Artificial Intelligence: A Comprehensive Review",
      "authors": [
        "Jing Ren",
        "Feng Xia"
      ],
      "abstract": "Current artificial intelligence (AI) models often focus on enhancing\nperformance through meticulous parameter tuning and optimization techniques.\nHowever, the fundamental design principles behind these models receive\ncomparatively less attention, which can limit our understanding of their\npotential and constraints. This comprehensive review explores the diverse\ndesign inspirations that have shaped modern AI models, i.e., brain-inspired\nartificial intelligence (BIAI). We present a classification framework that\ncategorizes BIAI approaches into physical structure-inspired and human\nbehavior-inspired models. We also examine the real-world applications where\ndifferent BIAI models excel, highlighting their practical benefits and\ndeployment challenges. By delving into these areas, we provide new insights and\npropose future research directions to drive innovation and address current gaps\nin the field. This review offers researchers and practitioners a comprehensive\noverview of the BIAI landscape, helping them harness its potential and expedite\nadvancements in AI development.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-08-27",
      "downloaded_date": "2025-02-01",
      "filename": "Ren-Brain-inspired Artificial Intelligence A Comprehensive Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.14811v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2006.16106v3": {
      "title": "COVID-19 Screening Using Residual Attention Network an Artificial Intelligence Approach",
      "authors": [
        "Vishal Sharma",
        "Curtis Dyreson"
      ],
      "abstract": "Coronavirus Disease 2019 (COVID-19) is caused by severe acute respiratory\nsyndrome coronavirus 2 virus (SARS-CoV-2). The virus transmits rapidly; it has\na basic reproductive number R of 2.2-2.7. In March 2020, the World Health\nOrganization declared the COVID-19 outbreak a pandemic. COVID-19 is currently\naffecting more than 200 countries with 6M active cases. An effective testing\nstrategy for COVID-19 is crucial to controlling the outbreak but the demand for\ntesting surpasses the availability of test kits that use Reverse Transcription\nPolymerase Chain Reaction (RT-PCR). In this paper, we present a technique to\nscreen for COVID-19 using artificial intelligence. Our technique takes only\nseconds to screen for the presence of the virus in a patient. We collected a\ndataset of chest X-ray images and trained several popular deep convolution\nneural network-based models (VGG, MobileNet, Xception, DenseNet,\nInceptionResNet) to classify the chest X-rays. Unsatisfied with these models,\nwe then designed and built a Residual Attention Network that was able to screen\nCOVID-19 with a testing accuracy of 98% and a validation accuracy of 100%. A\nfeature maps visual of our model show areas in a chest X-ray which are\nimportant for classification. Our work can help to increase the adaptation of\nAI-assisted applications in clinical practice. The code and dataset used in\nthis project are available at\nhttps://github.com/vishalshar/covid-19-screening-using-RAN-on-X-ray-images.",
      "citation_count": 18,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7e956b5b1c07fa1fc37fb406040c01b8b5dc188e",
      "published_date": "2020-06-26",
      "downloaded_date": "2025-02-01",
      "filename": "Sharma-COVID-19 Screening Using Residual Attention Network an Artificial Intelligence Approach.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2006.16106v3",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "2201.00437v1": {
      "title": "Artificial Intelligence and Statistical Techniques in Short-Term Load Forecasting: A Review",
      "authors": [
        "Ali Bou Nassif",
        "Bassel Soudan",
        "Mohammad Azzeh",
        "Imtinan Attilli",
        "Omar AlMulla"
      ],
      "abstract": "Electrical utilities depend on short-term demand forecasting to proactively\nadjust production and distribution in anticipation of major variations. This\nsystematic review analyzes 240 works published in scholarly journals between\n2000 and 2019 that focus on applying Artificial Intelligence (AI), statistical,\nand hybrid models to short-term load forecasting (STLF). This work represents\nthe most comprehensive review of works on this subject to date. A complete\nanalysis of the literature is conducted to identify the most popular and\naccurate techniques as well as existing gaps. The findings show that although\nArtificial Neural Networks (ANN) continue to be the most commonly used\nstandalone technique, researchers have been exceedingly opting for hybrid\ncombinations of different techniques to leverage the combined advantages of\nindividual methods. The review demonstrates that it is commonly possible with\nthese hybrid combinations to achieve prediction accuracy exceeding 99%. The\nmost successful duration for short-term forecasting has been identified as\nprediction for a duration of one day at an hourly interval. The review has\nidentified a deficiency in access to datasets needed for training of the\nmodels. A significant gap has been identified in researching regions other than\nAsia, Europe, North America, and Australia.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-12-29",
      "downloaded_date": "2025-02-01",
      "filename": "Nassif-Artificial Intelligence and Statistical Techniques in Short-Term Load Forecasting A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2201.00437v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ]
    },
    "2204.05138v1": {
      "title": "Artificial Intelligence Software Structured to Simulate Human Working Memory, Mental Imagery, and Mental Continuity",
      "authors": [
        "Jared Edward Reser"
      ],
      "abstract": "This article presents an artificial intelligence (AI) architecture intended\nto simulate the human working memory system as well as the manner in which it\nis updated iteratively. It features several interconnected neural networks\ndesigned to emulate the specialized modules of the cerebral cortex. These are\nstructured hierarchically and integrated into a global workspace. They are\ncapable of temporarily maintaining high-level patterns akin to the\npsychological items maintained in working memory. This maintenance is made\npossible by persistent neural activity in the form of two modalities: sustained\nneural firing (resulting in a focus of attention) and synaptic potentiation\n(resulting in a short-term store). This persistent activity is updated\niteratively resulting in incremental changes to the content of the working\nmemory system. As the content stored in working memory gradually evolves,\nsuccessive states overlap and are continuous with one another. The present\narticle will explore how this architecture can lead to gradual shift in the\ndistribution of coactive representations, ultimately leading to mental\ncontinuity between processing states, and thus to human-like cognition.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-03-29",
      "downloaded_date": "2025-02-01",
      "filename": "Reser-Artificial Intelligence Software Structured to Simulate Human Working Memory Mental Imagery and Ment....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2204.05138v1",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "cs.SC"
      ]
    },
    "2103.07262v1": {
      "title": "Robust and generalizable embryo selection based on artificial intelligence and time-lapse image sequences",
      "authors": [
        "JÃ¸rgen Berntsen",
        "Jens Rimestad",
        "Jacob Theilgaard Lassen",
        "Dang Tran",
        "Mikkel Fly Kragh"
      ],
      "abstract": "Assessing and selecting the most viable embryos for transfer is an essential\npart of in vitro fertilization (IVF). In recent years, several approaches have\nbeen made to improve and automate the procedure using artificial intelligence\n(AI) and deep learning. Based on images of embryos with known implantation data\n(KID), AI models have been trained to automatically score embryos related to\ntheir chance of achieving a successful implantation. However, as of now, only\nlimited research has been conducted to evaluate how embryo selection models\ngeneralize to new clinics and how they perform in subgroup analyses across\nvarious conditions. In this paper, we investigate how a deep learning-based\nembryo selection model using only time-lapse image sequences performs across\ndifferent patient ages and clinical conditions, and how it correlates with\ntraditional morphokinetic parameters. The model was trained and evaluated based\non a large dataset from 18 IVF centers consisting of 115,832 embryos, of which\n14,644 embryos were transferred KID embryos. In an independent test set, the AI\nmodel sorted KID embryos with an area under the curve (AUC) of a receiver\noperating characteristic curve of 0.67 and all embryos with an AUC of 0.95. A\nclinic hold-out test showed that the model generalized to new clinics with an\nAUC range of 0.60-0.75 for KID embryos. Across different subgroups of age,\ninsemination method, incubation time, and transfer protocol, the AUC ranged\nbetween 0.63 and 0.69. Furthermore, model predictions correlated positively\nwith blastocyst grading and negatively with direct cleavages. The fully\nautomated iDAScore v1.0 model was shown to perform at least as good as a\nstate-of-the-art manual embryo selection model. Moreover, full automatization\nof embryo scoring implies fewer manual evaluations and eliminates biases due to\ninter- and intraobserver variation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-03-12",
      "downloaded_date": "2025-02-01",
      "filename": "Berntsen-Robust and generalizable embryo selection based on artificial intelligence and time-lapse image sequ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.07262v1",
      "categories": [
        "cs.LG",
        "cs.CV"
      ]
    },
    "2012.10232v1": {
      "title": "Artificial Intelligence ordered 3D vertex importance",
      "authors": [
        "Iva Vasic",
        "Bata Vasic",
        "Zorica Nikolic"
      ],
      "abstract": "Ranking vertices of multidimensional networks is crucial in many areas of\nresearch, including selecting and determining the importance of decisions. Some\ndecisions are significantly more important than others, and their weight\ncategorization is also imortant. This paper defines a completely new method for\ndetermining the weight decisions using artificial intelligence for importance\nranking of three-dimensional network vertices, improving the existing Ordered\nStatistics Vertex Extraction and Tracking Algorithm (OSVETA) based on\nmodulation of quantized indices (QIM) and error correction codes. The technique\nwe propose in this paper offers significant improvements the efficiency of\ndetermination the importance of network vertices in relation to statistical\nOSVETA criteria, replacing heuristic methods with methods of precise prediction\nof modern neural networks. The new artificial intelligence technique enables a\nsignificantly better definition of the 3D meshes and a better assessment of\ntheir topological features. The new method contributions result in a greater\nprecision in defining stable vertices, significantly reducing the probability\nof deleting mesh vertices.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-12-17",
      "downloaded_date": "2025-02-01",
      "filename": "Vasic-Artificial Intelligence ordered 3D vertex importance.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.10232v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2111.00992v1": {
      "title": "Artificial Intelligence, Surveillance, and Big Data",
      "authors": [
        "David Karpa",
        "Torben Klarl",
        "Michael Rochlitz"
      ],
      "abstract": "The most important resource to improve technologies in the field of\nartificial intelligence is data. Two types of policies are crucial in this\nrespect: privacy and data-sharing regulations, and the use of surveillance\ntechnologies for policing. Both types of policies vary substantially across\ncountries and political regimes. In this chapter, we examine how authoritarian\nand democratic political institutions can influence the quality of research in\nartificial intelligence, and the availability of large-scale datasets to\nimprove and train deep learning algorithms. We focus mainly on the Chinese\ncase, and find that -- ceteris paribus -- authoritarian political institutions\ncontinue to have a negative effect on innovation. They can, however, have a\npositive effect on research in deep learning, via the availability of\nlarge-scale datasets that have been obtained through government surveillance.\nWe propose a research agenda to study which of the two effects might dominate\nin a race for leadership in artificial intelligence between countries with\ndifferent political institutions, such as the United States and China.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/62548d6132ce81f0177856788f4535119fdff6dc",
      "published_date": "2021-11-01",
      "downloaded_date": "2025-02-01",
      "filename": "Karpa-Artificial Intelligence Surveillance and Big Data.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.00992v1",
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ]
    },
    "1804.03928v1": {
      "title": "Deep Learning For Computer Vision Tasks: A review",
      "authors": [
        "Rajat Kumar Sinha",
        "Ruchi Pandey",
        "Rohan Pattnaik"
      ],
      "abstract": "Deep learning has recently become one of the most popular sub-fields of\nmachine learning owing to its distributed data representation with multiple\nlevels of abstraction. A diverse range of deep learning algorithms are being\nemployed to solve conventional artificial intelligence problems. This paper\ngives an overview of some of the most widely used deep learning algorithms\napplied in the field of computer vision. It first inspects the various\napproaches of deep learning algorithms, followed by a description of their\napplications in image classification, object identification, image extraction\nand semantic segmentation in the presence of noise. The paper concludes with\nthe discussion of the future scope and challenges for construction and training\nof deep neural networks.",
      "citation_count": 52,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0ae8452aa5a1cb2ad4637b22ec9651f84abf7878",
      "published_date": "2018-04-11",
      "downloaded_date": "2025-02-01",
      "filename": "Sinha-Deep Learning For Computer Vision Tasks A review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1804.03928v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2401.06148v1": {
      "title": "Artificial Intelligence for Digital and Computational Pathology",
      "authors": [
        "Andrew H. Song",
        "Guillaume Jaume",
        "Drew F. K. Williamson",
        "Ming Y. Lu",
        "Anurag Vaidya",
        "Tiffany R. Miller",
        "Faisal Mahmood"
      ],
      "abstract": "Advances in digitizing tissue slides and the fast-paced progress in\nartificial intelligence, including deep learning, have boosted the field of\ncomputational pathology. This field holds tremendous potential to automate\nclinical diagnosis, predict patient prognosis and response to therapy, and\ndiscover new morphological biomarkers from tissue images. Some of these\nartificial intelligence-based systems are now getting approved to assist\nclinical diagnosis; however, technical barriers remain for their widespread\nclinical adoption and integration as a research tool. This Review consolidates\nrecent methodological advances in computational pathology for predicting\nclinical end points in whole-slide images and highlights how these developments\nenable the automation of clinical practice and the discovery of new biomarkers.\nWe then provide future perspectives as the field expands into a broader range\nof clinical and research tasks with increasingly diverse modalities of clinical\ndata.",
      "citation_count": 90,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b313140bde3d9d8ed96f405674fd243e270104fb",
      "published_date": "2023-12-13",
      "downloaded_date": "2025-02-01",
      "filename": "Song-Artificial Intelligence for Digital and Computational Pathology.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.06148v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.QM"
      ]
    },
    "2307.11794v1": {
      "title": "Artificial Intelligence-Generated Terahertz Multi-Resonant Metasurfaces via Improved Transformer and CGAN Neural Networks",
      "authors": [
        "Yangpeng Huang",
        "Naixing Feng",
        "Yijun Cai"
      ],
      "abstract": "It is well known that the inverse design of terahertz (THz) multi-resonant\ngraphene metasurfaces by using traditional deep neural networks (DNNs) has\nlimited generalization ability. In this paper, we propose improved Transformer\nand conditional generative adversarial neural networks (CGAN) for the inverse\ndesign of graphene metasurfaces based upon THz multi-resonant absorption\nspectra. The improved Transformer can obtain higher accuracy and generalization\nperformance in the StoV (Spectrum to Vector) design compared to traditional\nmultilayer perceptron (MLP) neural networks, while the StoI (Spectrum to Image)\ndesign achieved through CGAN can provide more comprehensive information and\nhigher accuracy than the StoV design obtained by MLP. Moreover, the improved\nCGAN can achieve the inverse design of graphene metasurface images directly\nfrom the desired multi-resonant absorption spectra. It is turned out that this\nwork can finish facilitating the design process of artificial\nintelligence-generated metasurfaces (AIGM), and even provide a useful guide for\ndeveloping complex THz metasurfaces based on 2D materials using generative\nneural networks.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a4d9794d174f22f9c6c0c24b7be495fcc6862701",
      "published_date": "2023-07-21",
      "downloaded_date": "2025-02-01",
      "filename": "Huang-Artificial Intelligence-Generated Terahertz Multi-Resonant Metasurfaces via Improved Transformer and....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.11794v1",
      "categories": [
        "physics.optics",
        "cs.LG",
        "physics.app-ph"
      ]
    },
    "2005.12137v1": {
      "title": "The challenges of deploying artificial intelligence models in a rapidly evolving pandemic",
      "authors": [
        "Yipeng Hu",
        "Joseph Jacob",
        "Geoffrey JM Parker",
        "David J Hawkes",
        "John R Hurst",
        "Danail Stoyanov"
      ],
      "abstract": "The COVID-19 pandemic, caused by the severe acute respiratory syndrome\ncoronavirus 2, emerged into a world being rapidly transformed by artificial\nintelligence (AI) based on big data, computational power and neural networks.\nThe gaze of these networks has in recent years turned increasingly towards\napplications in healthcare. It was perhaps inevitable that COVID-19, a global\ndisease propagating health and economic devastation, should capture the\nattention and resources of the world's computer scientists in academia and\nindustry. The potential for AI to support the response to the pandemic has been\nproposed across a wide range of clinical and societal challenges, including\ndisease forecasting, surveillance and antiviral drug discovery. This is likely\nto continue as the impact of the pandemic unfolds on the world's people,\nindustries and economy but a surprising observation on the current pandemic has\nbeen the limited impact AI has had to date in the management of COVID-19. This\ncorrespondence focuses on exploring potential reasons behind the lack of\nsuccessful adoption of AI models developed for COVID-19 diagnosis and\nprognosis, in front-line healthcare services. We highlight the moving clinical\nneeds that models have had to address at different stages of the epidemic, and\nexplain the importance of translating models to reflect local healthcare\nenvironments. We argue that both basic and applied research are essential to\naccelerate the potential of AI models, and this is particularly so during a\nrapidly evolving pandemic. This perspective on the response to COVID-19, may\nprovide a glimpse into how the global scientific community should react to\ncombat future disease outbreaks more effectively.",
      "citation_count": 64,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b90482e2b4c30aa9f2329f361b4f09bd07145630",
      "published_date": "2020-05-19",
      "downloaded_date": "2025-02-01",
      "filename": "Hu-The challenges of deploying artificial intelligence models in a rapidly evolving pandemic.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.12137v1",
      "categories": [
        "cs.CY",
        "cs.LG"
      ]
    },
    "2012.09318v2": {
      "title": "Applying Deutsch's concept of good explanations to artificial intelligence and neuroscience -- an initial exploration",
      "authors": [
        "Daniel C. Elton"
      ],
      "abstract": "Artificial intelligence has made great strides since the deep learning\nrevolution, but AI systems still struggle to extrapolate outside of their\ntraining data and adapt to new situations. For inspiration we look to the\ndomain of science, where scientists have been able to develop theories which\nshow remarkable ability to extrapolate and sometimes predict the existence of\nphenomena which have never been observed before. According to David Deutsch,\nthis type of extrapolation, which he calls \"reach\", is due to scientific\ntheories being hard to vary. In this work we investigate Deutsch's hard-to-vary\nprinciple and how it relates to more formalized principles in deep learning\nsuch as the bias-variance trade-off and Occam's razor. We distinguish internal\nvariability, how much a model/theory can be varied internally while still\nyielding the same predictions, with external variability, which is how much a\nmodel must be varied to accurately predict new, out-of-distribution data. We\ndiscuss how to measure internal variability using the size of the Rashomon set\nand how to measure external variability using Kolmogorov complexity. We explore\nwhat role hard-to-vary explanations play in intelligence by looking at the\nhuman brain and distinguish two learning systems in the brain. The first system\noperates similar to deep learning and likely underlies most of perception and\nmotor control while the second is a more creative system capable of generating\nhard-to-vary explanations of the world. We argue that figuring out how\nreplicate this second system, which is capable of generating hard-to-vary\nexplanations, is a key challenge which needs to be solved in order to realize\nartificial general intelligence. We make contact with the framework of\nPopperian epistemology which rejects induction and asserts that knowledge\ngeneration is an evolutionary process which proceeds through conjecture and\nrefutation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-12-16",
      "downloaded_date": "2025-02-01",
      "filename": "Elton-Applying Deutschs concept of good explanations to artificial intelligence and neuroscience -- an ini....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.09318v2",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "I.2.0"
      ]
    },
    "2211.04890v1": {
      "title": "Artificial intelligence for improved fitting of trajectories of elementary particles in inhomogeneous dense materials immersed in a magnetic field",
      "authors": [
        "SaÃºl Alonso-Monsalve",
        "Davide Sgalaberna",
        "Xingyu Zhao",
        "Clark McGrew",
        "AndrÃ© Rubbia"
      ],
      "abstract": "In this article, we use artificial intelligence algorithms to show how to\nenhance the resolution of the elementary particle track fitting in\ninhomogeneous dense detectors, such as plastic scintillators. We use deep\nlearning to replace more traditional Bayesian filtering methods, drastically\nimproving the reconstruction of the interacting particle kinematics. We show\nthat a specific form of neural network, inherited from the field of natural\nlanguage processing, is very close to the concept of a Bayesian filter that\nadopts a hyper-informative prior. Such a paradigm change can influence the\ndesign of future particle physics experiments and their data exploitation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-11-09",
      "downloaded_date": "2025-02-01",
      "filename": "Alonso-Monsalve-Artificial intelligence for improved fitting of trajectories of elementary particles in inhomogeneou....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.04890v1",
      "categories": [
        "physics.data-an",
        "cs.LG",
        "hep-ex"
      ]
    },
    "2308.07778v1": {
      "title": "An Interpretable Machine Learning Model with Deep Learning-based Imaging Biomarkers for Diagnosis of Alzheimer's Disease",
      "authors": [
        "Wenjie Kang",
        "Bo Li",
        "Janne M. Papma",
        "Lize C. Jiskoot",
        "Peter Paul De Deyn",
        "Geert Jan Biessels",
        "Jurgen A. H. R. Claassen",
        "Huub A. M. Middelkoop",
        "Wiesje M. van der Flier",
        "Inez H. G. B. Ramakers",
        "Stefan Klein",
        "Esther E. Bron"
      ],
      "abstract": "Machine learning methods have shown large potential for the automatic early\ndiagnosis of Alzheimer's Disease (AD). However, some machine learning methods\nbased on imaging data have poor interpretability because it is usually unclear\nhow they make their decisions. Explainable Boosting Machines (EBMs) are\ninterpretable machine learning models based on the statistical framework of\ngeneralized additive modeling, but have so far only been used for tabular data.\nTherefore, we propose a framework that combines the strength of EBM with\nhigh-dimensional imaging data using deep learning-based feature extraction. The\nproposed framework is interpretable because it provides the importance of each\nfeature. We validated the proposed framework on the Alzheimer's Disease\nNeuroimaging Initiative (ADNI) dataset, achieving accuracy of 0.883 and\narea-under-the-curve (AUC) of 0.970 on AD and control classification.\nFurthermore, we validated the proposed framework on an external testing set,\nachieving accuracy of 0.778 and AUC of 0.887 on AD and subjective cognitive\ndecline (SCD) classification. The proposed framework significantly outperformed\nan EBM model using volume biomarkers instead of deep learning-based features,\nas well as an end-to-end convolutional neural network (CNN) with optimized\narchitecture.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3e4a20d71da179d122f8d3ed4312c6126c9804c2",
      "published_date": "2023-08-15",
      "downloaded_date": "2025-02-01",
      "filename": "Kang-An Interpretable Machine Learning Model with Deep Learning-based Imaging Biomarkers for Diagnosis of....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.07778v1",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "1706.01040v1": {
      "title": "Brain Intelligence: Go Beyond Artificial Intelligence",
      "authors": [
        "Huimin Lu",
        "Yujie Li",
        "Min Chen",
        "Hyoungseop Kim",
        "Seiichi Serikawa"
      ],
      "abstract": "Artificial intelligence (AI) is an important technology that supports daily\nsocial life and economic activities. It contributes greatly to the sustainable\ngrowth of Japan's economy and solves various social problems. In recent years,\nAI has attracted attention as a key for growth in developed countries such as\nEurope and the United States and developing countries such as China and India.\nThe attention has been focused mainly on developing new artificial intelligence\ninformation communication technology (ICT) and robot technology (RT). Although\nrecently developed AI technology certainly excels in extracting certain\npatterns, there are many limitations. Most ICT models are overly dependent on\nbig data, lack a self-idea function, and are complicated. In this paper, rather\nthan merely developing next-generation artificial intelligence technology, we\naim to develop a new concept of general-purpose intelligence cognition\ntechnology called Beyond AI. Specifically, we plan to develop an intelligent\nlearning model called Brain Intelligence (BI) that generates new ideas about\nevents without having experienced them by using artificial life with an imagine\nfunction. We will also conduct demonstrations of the developed BI intelligence\nlearning model on automatic driving, precision medical care, and industrial\nrobots.",
      "citation_count": 927,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/32754d496768685cfcc7fbdb323d87db2b33a09c",
      "published_date": "2017-06-04",
      "downloaded_date": "2025-02-01",
      "filename": "Lu-Brain Intelligence Go Beyond Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1706.01040v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2210.08962v1": {
      "title": "Artificial Intelligence and Innovation to Reduce the Impact of Extreme Weather Events on Sustainable Production",
      "authors": [
        "Derrick Effah",
        "Chunguang Bai",
        "Matthew Quayson"
      ],
      "abstract": "Frequent occurrences of extreme weather events substantially impact the lives\nof the less privileged in our societies, particularly in agriculture-inclined\neconomies. The unpredictability of extreme fires, floods, drought, cyclones,\nand others endangers sustainable production and life on land (SDG goal 15),\nwhich translates into food insecurity and poorer populations. Fortunately,\nmodern technologies such as Artificial Intelligent (AI), the Internet of Things\n(IoT), blockchain, 3D printing, and virtual and augmented reality (VR and AR)\nare promising to reduce the risk and impact of extreme weather in our\nsocieties. However, research directions on how these technologies could help\nreduce the impact of extreme weather are unclear. This makes it challenging to\nemploring digital technologies within the spheres of extreme weather. In this\npaper, we employed the Delphi Best Worst method and Machine learning approaches\nto identify and assess the push factors of technology. The BWM evaluation\nrevealed that predictive nature was AI's most important criterion and role,\nwhile the mass-market potential was the less important criterion. Based on this\noutcome, we tested the predictive ability of machine elarning on a publilcly\navailable dataset to affrm the predictive rols of AI. We presented the\nmanagerial and methodological implications of the study, which are crucial for\nresearch and practice. The methodology utilized in this study could aid\ndecision-makers in devising strategies and interventions to safeguard\nsustainable production. This will also facilitate allocating scarce resources\nand investment in improving AI techniques to reduce the adverse impacts of\nextreme events. Correspondingly, we put forward the limitations of this, which\nnecessitate future research.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/04719c367f34da8aba62e898ac50810a09af077e",
      "published_date": "2022-09-21",
      "downloaded_date": "2025-02-01",
      "filename": "Effah-Artificial Intelligence and Innovation to Reduce the Impact of Extreme Weather Events on Sustainable....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.08962v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2007.00523v2": {
      "title": "Drug discovery with explainable artificial intelligence",
      "authors": [
        "JosÃ© JimÃ©nez-Luna",
        "Francesca Grisoni",
        "Gisbert Schneider"
      ],
      "abstract": "Deep learning bears promise for drug discovery, including advanced image\nanalysis, prediction of molecular structure and function, and automated\ngeneration of innovative chemical entities with bespoke properties. Despite the\ngrowing number of successful prospective applications, the underlying\nmathematical models often remain elusive to interpretation by the human mind.\nThere is a demand for 'explainable' deep learning methods to address the need\nfor a new narrative of the machine language of the molecular sciences. This\nreview summarizes the most prominent algorithmic concepts of explainable\nartificial intelligence, and dares a forecast of the future opportunities,\npotential applications, and remaining challenges.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-07-01",
      "downloaded_date": "2025-02-01",
      "filename": "JimÃ©nez-Luna-Drug discovery with explainable artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.00523v2",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    "1907.07771v1": {
      "title": "Classification Schemas for Artificial Intelligence Failures",
      "authors": [
        "Peter J. Scott",
        "Roman V. Yampolskiy"
      ],
      "abstract": "In this paper we examine historical failures of artificial intelligence (AI)\nand propose a classification scheme for categorizing future failures. By doing\nso we hope that (a) the responses to future failures can be improved through\napplying a systematic classification that can be used to simplify the choice of\nresponse and (b) future failures can be reduced through augmenting development\nlifecycles with targeted risk assessments.",
      "citation_count": 20,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6ff7df5f32fca05658ebb10243b0a8a3831aba20",
      "published_date": "2019-07-15",
      "downloaded_date": "2025-02-01",
      "filename": "Scott-Classification Schemas for Artificial Intelligence Failures.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.07771v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2404.03325v2": {
      "title": "Embodied Neuromorphic Artificial Intelligence for Robotics: Perspectives, Challenges, and Research Development Stack",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Alberto Marchisio",
        "Fakhreddine Zayer",
        "Jorge Dias",
        "Muhammad Shafique"
      ],
      "abstract": "Robotic technologies have been an indispensable part for improving human\nproductivity since they have been helping humans in completing diverse,\ncomplex, and intensive tasks in a fast yet accurate and efficient way.\nTherefore, robotic technologies have been deployed in a wide range of\napplications, ranging from personal to industrial use-cases. However, current\nrobotic technologies and their computing paradigm still lack embodied\nintelligence to efficiently interact with operational environments, respond\nwith correct/expected actions, and adapt to changes in the environments. Toward\nthis, recent advances in neuromorphic computing with Spiking Neural Networks\n(SNN) have demonstrated the potential to enable the embodied intelligence for\nrobotics through bio-plausible computing paradigm that mimics how the\nbiological brain works, known as \"neuromorphic artificial intelligence (AI)\".\nHowever, the field of neuromorphic AI-based robotics is still at an early\nstage, therefore its development and deployment for solving real-world problems\nexpose new challenges in different design aspects, such as accuracy,\nadaptability, efficiency, reliability, and security. To address these\nchallenges, this paper will discuss how we can enable embodied neuromorphic AI\nfor robotic systems through our perspectives: (P1) Embodied intelligence based\non effective learning rule, training mechanism, and adaptability; (P2)\nCross-layer optimizations for energy-efficient neuromorphic computing; (P3)\nRepresentative and fair benchmarks; (P4) Low-cost reliability and safety\nenhancements; (P5) Security and privacy for neuromorphic computing; and (P6) A\nsynergistic development for energy-efficient and robust neuromorphic-based\nrobotics. Furthermore, this paper identifies research challenges and\nopportunities, as well as elaborates our vision for future research development\ntoward embodied neuromorphic AI for robotics.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a37c236803455afd7da3dc027e7865a0414a5697",
      "published_date": "2024-04-04",
      "downloaded_date": "2025-02-01",
      "filename": "Putra-Embodied Neuromorphic Artificial Intelligence for Robotics Perspectives Challenges and Research Deve....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.03325v2",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2404.16885v1": {
      "title": "Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience",
      "authors": [
        "Rayner Kay Jin Tan",
        "Dilruk Perera",
        "Salomi Arasaratnam",
        "Yudara Kularathne"
      ],
      "abstract": "Artificial Intelligence applications have shown promise in the management of\npandemics and have been widely used to assist the identification,\nclassification, and diagnosis of medical images. In response to the global\noutbreak of Monkeypox (Mpox), the HeHealth.ai team leveraged an existing tool\nto screen for sexually transmitted diseases to develop a digital screening test\nfor symptomatic Mpox through AI approaches. Prior to the global outbreak of\nMpox, the team developed a smartphone app, where app users can use their own\nsmartphone cameras to take pictures of their own penises to screen for\nsymptomatic STD. The AI model was initially developed using 5000 cases and use\na modified convolutional neural network to output prediction scores across\nvisually diagnosable penis pathologies including Syphilis, Herpes Simplex\nVirus, and Human Papilloma Virus. From June 2022 to October 2022, a total of\nabout 22,000 users downloaded the HeHealth app, and about 21,000 images have\nbeen analyzed using HeHealth AI technology. We then engaged in formative\nresearch, stakeholder engagement, rapid consolidation images, a validation\nstudy, and implementation of the tool from July 2022. From July 2022 to October\n2022, a total of 1000 Mpox related images had been used to train the Mpox\nsymptom checker tool. Our digital symptom checker tool showed accuracy of 87%\nto rule in Mpox and 90% to rule out symptomatic Mpox. Several hurdles\nidentified included issues of data privacy and security for app users, initial\nlack of data to train the AI tool, and the potential generalizability of input\ndata. We offer several suggestions to help others get started on similar\nprojects in emergency situations, including engaging a wide range of\nstakeholders, having a multidisciplinary team, prioritizing pragmatism, as well\nas the concept that big data in fact is made up of small data.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e60f716b0b300e238088dd241f767410b8bc812b",
      "published_date": "2024-04-23",
      "downloaded_date": "2025-02-01",
      "filename": "Tan-Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Dete....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.16885v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    "1610.01925v1": {
      "title": "Metaheuristic Algorithms for Convolution Neural Network",
      "authors": [
        "L. M. Rasdi Rere",
        "Mohamad Ivan Fanany",
        "Aniati Murni Arymurthy"
      ],
      "abstract": "A typical modern optimization technique is usually either heuristic or\nmetaheuristic. This technique has managed to solve some optimization problems\nin the research area of science, engineering, and industry. However,\nimplementation strategy of metaheuristic for accuracy improvement on\nconvolution neural networks (CNN), a famous deep learning method, is still\nrarely investigated. Deep learning relates to a type of machine learning\ntechnique, where its aim is to move closer to the goal of artificial\nintelligence of creating a machine that could successfully perform any\nintellectual tasks that can be carried out by a human. In this paper, we\npropose the implementation strategy of three popular metaheuristic approaches,\nthat is, simulated annealing, differential evolution, and harmony search, to\noptimize CNN. The performances of these metaheuristic methods in optimizing CNN\non classifying MNIST and CIFAR dataset were evaluated and compared.\nFurthermore, the proposed methods are also compared with the original CNN.\nAlthough the proposed methods show an increase in the computation time, their\naccuracy has also been improved (up to 7.14 percent).",
      "citation_count": 90,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6c4d94efea9981c5591446c4eba7c7afa50abc0f",
      "published_date": "2016-10-06",
      "downloaded_date": "2025-02-01",
      "filename": "Rere-Metaheuristic Algorithms for Convolution Neural Network.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1610.01925v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE",
        "68Txx",
        "I.2.10"
      ]
    },
    "2305.05092v1": {
      "title": "Artificial Intelligence in 3GPP 5G-Advanced: A Survey",
      "authors": [
        "Xingqin Lin"
      ],
      "abstract": "Industries worldwide are being transformed by artificial intelligence (AI),\nand the telecom industry is no different. Standardization is critical for\nindustry alignment to achieve widespread adoption of AI in telecom. The 3rd\ngeneration partnership project (3GPP) Release 18 is the first release of\n5G-Advanced, which includes a diverse set of study and work items dedicated to\nAI. This article provides a holistic overview of the state of the art in the\n3GPP work on AI in 5G-Advanced, by presenting the various 3GPP Release-18\nactivities on AI as an organic whole, explaining in detail the design aspects,\nand sharing various design rationales influencing standardization.",
      "citation_count": 23,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a0a1efec3de4c2949482e9e5d5612ce6a0648fbc",
      "published_date": "2023-05-08",
      "downloaded_date": "2025-02-01",
      "filename": "Lin-Artificial Intelligence in 3GPP 5G-Advanced A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.05092v1",
      "categories": [
        "cs.NI",
        "cs.AI"
      ]
    },
    "2308.16377v1": {
      "title": "Science Communications for Explainable Artificial Intelligence",
      "authors": [
        "Simon Hudson",
        "Matija Franklin"
      ],
      "abstract": "Artificial Intelligence (AI) has a communication problem. XAI methods have\nbeen used to make AI more understandable and helped resolve some of the\ntransparency issues that inhibit AI's broader usability. However, user\nevaluation studies reveal that the often numerical explanations provided by XAI\nmethods have not always been effective for many types of users of AI systems.\nThis article aims to adapt the major communications models from Science\nCommunications into a framework for practitioners to understand, influence, and\nintegrate the context of audiences both for their communications supporting AI\nliteracy in the public and in designing XAI systems that are more adaptive to\ndifferent users.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/348a7448a5926e2ace4aadf5a0b6c04c8baff8d0",
      "published_date": "2023-08-31",
      "downloaded_date": "2025-02-01",
      "filename": "Hudson-Science Communications for Explainable Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.16377v1",
      "categories": [
        "cs.HC"
      ]
    },
    "2409.15903v1": {
      "title": "Five questions and answers about artificial intelligence",
      "authors": [
        "Alberto Prieto",
        "Beatriz Prieto"
      ],
      "abstract": "Rapid advances in Artificial Intelligence (AI) are generating much\ncontroversy in society, often without scientific basis. As occurred the\ndevelopment of other emerging technologies, such as the introduction of\nelectricity in the early 20th century, AI causes both fascination and fear.\nFollowing the advice of the philosopher R.W. Emerson's: advice the knowledge is\nthe antidote to fear; this paper seeks to contribute to the dissemination of\nknowledge about AI. To this end, it reflects on the following questions: the\norigins of AI, its possible future evolution, its ability to show feelings, the\nassociated threats and dangers, and the concept of AI singularity.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/651806ed6c77033c8abe9dd75d094e17fd53c418",
      "published_date": "2024-09-24",
      "downloaded_date": "2025-02-01",
      "filename": "Prieto-Five questions and answers about artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.15903v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2012.15754v1": {
      "title": "Limitations of Deep Neural Networks: a discussion of G. Marcus' critical appraisal of deep learning",
      "authors": [
        "Stefanos Tsimenidis"
      ],
      "abstract": "Deep neural networks have triggered a revolution in artificial intelligence,\nhaving been applied with great results in medical imaging, semi-autonomous\nvehicles, ecommerce, genetics research, speech recognition, particle physics,\nexperimental art, economic forecasting, environmental science, industrial\nmanufacturing, and a wide variety of applications in nearly every field. This\nsudden success, though, may have intoxicated the research community and blinded\nthem to the potential pitfalls of assigning deep learning a higher status than\nwarranted. Also, research directed at alleviating the weaknesses of deep\nlearning may seem less attractive to scientists and engineers, who focus on the\nlow-hanging fruit of finding more and more applications for deep learning\nmodels, thus letting short-term benefits hamper long-term scientific progress.\nGary Marcus wrote a paper entitled Deep Learning: A Critical Appraisal, and\nhere we discuss Marcus' core ideas, as well as attempt a general assessment of\nthe subject. This study examines some of the limitations of deep neural\nnetworks, with the intention of pointing towards potential paths for future\nresearch, and of clearing up some metaphysical misconceptions, held by numerous\nresearchers, that may misdirect them.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8650a0b0f5b5fde870d525021ea1ec50e4a74c2b",
      "published_date": "2020-12-22",
      "downloaded_date": "2025-02-01",
      "filename": "Tsimenidis-Limitations of Deep Neural Networks a discussion of G Marcus critical appraisal of deep learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.15754v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    "1903.08495v1": {
      "title": "Artificial Intelligence : from Research to Application ; the Upper-Rhine Artificial Intelligence Symposium (UR-AI 2019)",
      "authors": [
        "Andreas Christ",
        "Franz Quint"
      ],
      "abstract": "The TriRhenaTech alliance universities and their partners presented their\ncompetences in the field of artificial intelligence and their cross-border\ncooperations with the industry at the tri-national conference 'Artificial\nIntelligence : from Research to Application' on March 13th, 2019 in Offenburg.\nThe TriRhenaTech alliance is a network of universities in the Upper Rhine\nTrinational Metropolitan Region comprising of the German universities of\napplied sciences in Furtwangen, Kaiserslautern, Karlsruhe, and Offenburg, the\nBaden-Wuerttemberg Cooperative State University Loerrach, the French university\nnetwork Alsace Tech (comprised of 14 'grandes \\'ecoles' in the fields of\nengineering, architecture and management) and the University of Applied\nSciences and Arts Northwestern Switzerland. The alliance's common goal is to\nreinforce the transfer of knowledge, research, and technology, as well as the\ncross-border mobility of students.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c621d6b505a8e4633bf9e36830664ee0b0041581",
      "published_date": "2019-03-20",
      "downloaded_date": "2025-02-01",
      "filename": "Christ-Artificial Intelligence  from Research to Application  the Upper-Rhine Artificial Intelligence Sympo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1903.08495v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2105.02357v1": {
      "title": "Explainable Artificial Intelligence for Human Decision-Support System in Medical Domain",
      "authors": [
        "Samanta KnapiÄ",
        "Avleen Malhi",
        "Rohit Saluja",
        "Kary FrÃ¤mling"
      ],
      "abstract": "In the present paper we present the potential of Explainable Artificial\nIntelligence methods for decision-support in medical image analysis scenarios.\nWith three types of explainable methods applied to the same medical image data\nset our aim was to improve the comprehensibility of the decisions provided by\nthe Convolutional Neural Network (CNN). The visual explanations were provided\non in-vivo gastral images obtained from a Video capsule endoscopy (VCE), with\nthe goal of increasing the health professionals' trust in the black box\npredictions. We implemented two post-hoc interpretable machine learning methods\nLIME and SHAP and the alternative explanation approach CIU, centered on the\nContextual Value and Utility (CIU). The produced explanations were evaluated\nusing human evaluation. We conducted three user studies based on the\nexplanations provided by LIME, SHAP and CIU. Users from different non-medical\nbackgrounds carried out a series of tests in the web-based survey setting and\nstated their experience and understanding of the given explanations. Three user\ngroups (n=20, 20, 20) with three distinct forms of explanations were\nquantitatively analyzed. We have found that, as hypothesized, the CIU\nexplainable method performed better than both LIME and SHAP methods in terms of\nincreasing support for human decision-making as well as being more transparent\nand thus understandable to users. Additionally, CIU outperformed LIME and SHAP\nby generating explanations more rapidly. Our findings suggest that there are\nnotable differences in human decision-making between various explanation\nsupport settings. In line with that, we present three potential explainable\nmethods that can with future improvements in implementation be generalized on\ndifferent medical data sets and can provide great decision-support for medical\nexperts.",
      "citation_count": 90,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/622d9a25590108aaecc96ab05721f071de59e283",
      "published_date": "2021-05-05",
      "downloaded_date": "2025-02-01",
      "filename": "KnapiÄ-Explainable Artificial Intelligence for Human Decision-Support System in Medical Domain.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.02357v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ]
    },
    "2203.08429v1": {
      "title": "A Survey of Machine Learning Algorithms for 6G Wireless Networks",
      "authors": [
        "Anita Patil",
        "Sridhar Iyer",
        "Rahul Jashvantbhai Pandya"
      ],
      "abstract": "The primary focus of Artificial Intelligence/Machine Learning (AI/ML)\nintegration within the wireless technology is to reduce capital expenditures,\noptimize network performance, and build new revenue streams. Replacing\ntraditional algorithms with deep learning AI techniques have dramatically\nreduced the power consumption and improved the system performance. Further,\nimplementation of ML algorithms also enables the wireless network service\nproviders to (i) offer high automation levels from distributed AI/ML\narchitectures applicable at the network edge, (ii) implement application-based\ntraffic steering across the access networks, (iii) enable dynamic network\nslicing for addressing different scenarios with varying quality of service\nrequirements, and (iv) enable ubiquitous connectivity across the various 6G\ncommunication platforms.\n  In this chapter, we review/survey the ML techniques which are applicable to\nthe 6G wireless networks. and also list the open problems of research which\nrequire timely solutions.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-03-16",
      "downloaded_date": "2025-02-01",
      "filename": "Patil-A Survey of Machine Learning Algorithms for 6G Wireless Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.08429v1",
      "categories": [
        "cs.NI"
      ]
    },
    "2001.01818v1": {
      "title": "Artificial Intelligence for Social Good: A Survey",
      "authors": [
        "Zheyuan Ryan Shi",
        "Claire Wang",
        "Fei Fang"
      ],
      "abstract": "Artificial intelligence for social good (AI4SG) is a research theme that aims\nto use and advance artificial intelligence to address societal issues and\nimprove the well-being of the world. AI4SG has received lots of attention from\nthe research community in the past decade with several successful applications.\nBuilding on the most comprehensive collection of the AI4SG literature to date\nwith over 1000 contributed papers, we provide a detailed account and analysis\nof the work under the theme in the following ways. (1) We quantitatively\nanalyze the distribution and trend of the AI4SG literature in terms of\napplication domains and AI techniques used. (2) We propose three conceptual\nmethods to systematically group the existing literature and analyze the eight\nAI4SG application domains in a unified framework. (3) We distill five research\ntopics that represent the common challenges in AI4SG across various application\ndomains. (4) We discuss five issues that, we hope, can shed light on the future\ndevelopment of the AI4SG research.",
      "citation_count": 75,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a55d2f36a6d5192454795f61b05f7fa8f589c505",
      "published_date": "2020-01-07",
      "downloaded_date": "2025-02-01",
      "filename": "Shi-Artificial Intelligence for Social Good A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2001.01818v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2402.15011v2": {
      "title": "A Conversational Brain-Artificial Intelligence Interface",
      "authors": [
        "Anja Meunier",
        "Michal Robert Å½Ã¡k",
        "Lucas Munz",
        "Sofiya Garkot",
        "Manuel Eder",
        "Jiachen Xu",
        "Moritz Grosse-Wentrup"
      ],
      "abstract": "We introduce Brain-Artificial Intelligence Interfaces (BAIs) as a new class\nof Brain-Computer Interfaces (BCIs). Unlike conventional BCIs, which rely on\nintact cognitive capabilities, BAIs leverage the power of artificial\nintelligence to replace parts of the neuro-cognitive processing pipeline. BAIs\nallow users to accomplish complex tasks by providing high-level intentions,\nwhile a pre-trained AI agent determines low-level details. This approach\nenlarges the target audience of BCIs to individuals with cognitive impairments,\na population often excluded from the benefits of conventional BCIs. We present\nthe general concept of BAIs and illustrate the potential of this new approach\nwith a Conversational BAI based on EEG. In particular, we show in an experiment\nwith simulated phone conversations that the Conversational BAI enables complex\ncommunication without the need to generate language. Our work thus\ndemonstrates, for the first time, the ability of a speech neuroprosthesis to\nenable fluent communication in realistic scenarios with non-invasive\ntechnologies.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a3c24b0c2b5f1893fdbd4677ba2cdb1fe3409fb0",
      "published_date": "2024-02-22",
      "downloaded_date": "2025-02-01",
      "filename": "Meunier-A Conversational Brain-Artificial Intelligence Interface.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.15011v2",
      "categories": [
        "cs.HC",
        "cs.AI",
        "eess.SP"
      ]
    },
    "2108.04770v1": {
      "title": "Examining correlation between trust and transparency with explainable artificial intelligence",
      "authors": [
        "Arnav Kartikeya"
      ],
      "abstract": "Trust between humans and artificial intelligence(AI) is an issue which has\nimplications in many fields of human computer interaction. The current issue\nwith artificial intelligence is a lack of transparency into its decision\nmaking, and literature shows that increasing transparency increases trust.\nExplainable artificial intelligence has the ability to increase transparency of\nAI, which could potentially increase trust for humans. This paper attempts to\nuse the task of predicting yelp review star ratings with assistance from an\nexplainable and non explainable artificial intelligence to see if trust is\nincreased with increased transparency. Results show that for these tasks,\nexplainable artificial intelligence provided significant increase in trust as a\nmeasure of influence.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-08-10",
      "downloaded_date": "2025-02-01",
      "filename": "Kartikeya-Examining correlation between trust and transparency with explainable artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.04770v1",
      "categories": [
        "cs.HC"
      ]
    },
    "1412.3489v2": {
      "title": "Quantum Deep Learning",
      "authors": [
        "Nathan Wiebe",
        "Ashish Kapoor",
        "Krysta M. Svore"
      ],
      "abstract": "In recent years, deep learning has had a profound impact on machine learning\nand artificial intelligence. At the same time, algorithms for quantum computers\nhave been shown to efficiently solve some problems that are intractable on\nconventional, classical computers. We show that quantum computing not only\nreduces the time required to train a deep restricted Boltzmann machine, but\nalso provides a richer and more comprehensive framework for deep learning than\nclassical computing and leads to significant improvements in the optimization\nof the underlying objective function. Our quantum methods also permit efficient\ntraining of full Boltzmann machines and multi-layer, fully connected models and\ndo not have well known classical counterparts.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8d2bb9280a0eff6c8254dcb9dfa789691cd01c84",
      "published_date": "2014-12-10",
      "downloaded_date": "2025-02-01",
      "filename": "Wiebe-Quantum Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1412.3489v2",
      "categories": [
        "quant-ph",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2409.19916v4": {
      "title": "Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Object-Oriented Programming",
      "authors": [
        "Tianyang Wang",
        "Ziqian Bi",
        "Keyu Chen",
        "Jiawei Xu",
        "Qian Niu",
        "Junyu Liu",
        "Benji Peng",
        "Ming Li",
        "Sen Zhang",
        "Xuanhe Pan",
        "Jinlang Wang",
        "Pohsun Feng",
        "Yizhu Wen",
        "Ming Liu"
      ],
      "abstract": "Object-Oriented Programming (OOP) has become a crucial paradigm for managing\nthe growing complexity of modern software systems, particularly in fields like\nmachine learning, deep learning, large language models (LLM), and data\nanalytics. This work provides a comprehensive introduction to the integration\nof OOP techniques within these domains, with a focus on improving code\nmodularity, maintainability, and scalability. We begin by outlining the\nevolution of computing and the rise of OOP, followed by an in-depth discussion\nof key OOP principles such as encapsulation, inheritance, polymorphism, and\nabstraction. The practical application of these principles is demonstrated\nusing Python, a widely adopted language in AI and data science. Furthermore, we\nexamine how design patterns and modular programming can be employed to enhance\nthe structure and efficiency of machine learning systems. In subsequent\nsections, we apply these OOP concepts to real-world AI tasks, including the\nencapsulation of preprocessing workflows, machine learning model training, and\nevaluation. Detailed examples illustrate how OOP can be used to build reusable,\nscalable machine learning systems while maintaining code clarity and reducing\nredundancy.This work is intended to serve as a bridge for both beginners and\nexperienced developers, equipping them with the necessary knowledge to apply\nOOP methodologies in AI-driven projects, ultimately fostering the development\nof more robust and maintainable systems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-09-30",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Deep Learning and Machine Learning Advancing Big Data Analytics and Management Object-Oriented Progr....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.19916v4",
      "categories": [
        "cs.CL",
        "cs.SE"
      ]
    },
    "2311.09255v1": {
      "title": "Artificial intelligence and the skill premium",
      "authors": [
        "David E. Bloom",
        "Klaus Prettner",
        "Jamel Saadaoui",
        "Mario Veruete"
      ],
      "abstract": "What will likely be the effect of the emergence of ChatGPT and other forms of\nartificial intelligence (AI) on the skill premium? To address this question, we\ndevelop a nested constant elasticity of substitution production function that\ndistinguishes between industrial robots and AI. Industrial robots predominantly\nsubstitute for low-skill workers, whereas AI mainly helps to perform the tasks\nof high-skill workers. We show that AI reduces the skill premium as long as it\nis more substitutable for high-skill workers than low-skill workers are for\nhigh-skill workers.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a56191e26ef819bde340e204a8a50271482cf0b9",
      "published_date": "2023-11-14",
      "downloaded_date": "2025-02-01",
      "filename": "Bloom-Artificial intelligence and the skill premium.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.09255v1",
      "categories": [
        "econ.TH",
        "cs.AI",
        "34C60 (Primary)"
      ]
    },
    "1711.10089v3": {
      "title": "Big Data Analytics, Machine Learning and Artificial Intelligence in Next-Generation Wireless Networks",
      "authors": [
        "Mirza Golam Kibria",
        "Kien Nguyen",
        "Gabriel Porto Villardi",
        "Ou Zhao",
        "Kentaro Ishizu",
        "Fumihide Kojima"
      ],
      "abstract": "The next-generation wireless networks are evolving into very complex systems\nbecause of the very diversified service requirements, heterogeneity in\napplications, devices, and networks. The mobile network operators (MNOs) need\nto make the best use of the available resources, for example, power, spectrum,\nas well as infrastructures. Traditional networking approaches, i.e., reactive,\ncentrally-managed, one-size-fits-all approaches and conventional data analysis\ntools that have limited capability (space and time) are not competent anymore\nand cannot satisfy and serve that future complex networks in terms of operation\nand optimization in a cost-effective way. A novel paradigm of proactive,\nself-aware, self- adaptive and predictive networking is much needed. The MNOs\nhave access to large amounts of data, especially from the network and the\nsubscribers. Systematic exploitation of the big data greatly helps in making\nthe network smart, intelligent and facilitates cost-effective operation and\noptimization. In view of this, we consider a data-driven next-generation\nwireless network model, where the MNOs employ advanced data analytics for their\nnetworks. We discuss the data sources and strong drivers for the adoption of\nthe data analytics and the role of machine learning, artificial intelligence in\nmaking the network intelligent in terms of being self-aware, self-adaptive,\nproactive and prescriptive. A set of network design and optimization schemes\nare presented with respect to data analytics. The paper is concluded with a\ndiscussion of challenges and benefits of adopting big data analytics and\nartificial intelligence in the next-generation communication system.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-11-28",
      "downloaded_date": "2025-02-01",
      "filename": "Kibria-Big Data Analytics Machine Learning and Artificial Intelligence in Next-Generation Wireless Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1711.10089v3",
      "categories": [
        "cs.IT",
        "math.IT"
      ]
    },
    "2407.14559v1": {
      "title": "Predicting Star Scientists in the Field of Artificial Intelligence: A Machine Learning Approach",
      "authors": [
        "Koosha Shirouyeh",
        "Andrea Schiffauerova",
        "Ashkan Ebadi"
      ],
      "abstract": "Star scientists are highly influential researchers who have made significant\ncontributions to their field, gained widespread recognition, and often\nattracted substantial research funding. They are critical for the advancement\nof science and innovation, and they have a significant influence on the\ntransfer of knowledge and technology to industry. Identifying potential star\nscientists before their performance becomes outstanding is important for\nrecruitment, collaboration, networking, or research funding decisions. Using\nmachine learning techniques, this study proposes a model to predict star\nscientists in the field of artificial intelligence while highlighting features\nrelated to their success. Our results confirm that rising stars follow\ndifferent patterns compared to their non-rising stars counterparts in almost\nall the early-career features. We also found that certain features such as\ngender and ethnic diversity play important roles in scientific collaboration\nand that they can significantly impact an author's career development and\nsuccess. The most important features in predicting star scientists in the field\nof artificial intelligence were the number of articles, group discipline\ndiversity, and weighted degree centrality. The proposed approach offers\nvaluable insights for researchers, practitioners, and funding agencies\ninterested in identifying and supporting talented researchers.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-07-18",
      "downloaded_date": "2025-02-01",
      "filename": "Shirouyeh-Predicting Star Scientists in the Field of Artificial Intelligence A Machine Learning Approach.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.14559v1",
      "categories": [
        "cs.OH",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2104.00075v2": {
      "title": "Ultra-Reliable Indoor Millimeter Wave Communications using Multiple Artificial Intelligence-Powered Intelligent Surfaces",
      "authors": [
        "Mehdi Naderi Soorki",
        "Walid Saad",
        "Mehdi Bennis",
        "Choong Seon Hong"
      ],
      "abstract": "In this paper, a novel framework for guaranteeing ultra-reliable millimeter\nwave (mmW) communications using multiple artificial intelligence (AI)-enabled\nreconfigurable intelligent surfaces (RISs) is proposed. The use of multiple\nAI-powered RISs allows changing the propagation direction of the signals\ntransmitted from a mmW access point (AP) thereby improving coverage\nparticularly for non-line-of-sight (NLoS) areas. However, due to the\npossibility of highly stochastic blockage over mmW links, designing an\nintelligent controller to jointly optimize the mmW AP beam and RIS phase shifts\nis a daunting task. In this regard, first, a parametric risk-sensitive episodic\nreturn is proposed to maximize the expected bit rate and mitigate the risk of\nmmW link blockage. Then, a closed-form approximation of the policy gradient of\nthe risk-sensitive episodic return is analytically derived. Next, the problem\nof joint beamforming for mmW AP and phase shift control for mmW RISs is modeled\nas an identical payoff stochastic game within a cooperative multi-agent\nenvironment, in which the agents are the mmW AP and the RISs. Two centralized\nand distributed controllers are proposed to control the policies of the mmW AP\nand RISs. To directly find an optimal solution, the parametric functional-form\npolicies for these controllers are modeled using deep recurrent neural networks\n(RNNs). Simulation results show that the error between policies of the optimal\nand the RNN-based controllers is less than 1.5%. Moreover, the variance of the\nachievable rates resulting from the deep RNN-based controllers is 60% less than\nthe variance of the risk-averse baseline.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e12128b6cd8759b5a61d8a154725333babb6941f",
      "published_date": "2021-03-31",
      "downloaded_date": "2025-02-01",
      "filename": "Soorki-Ultra-Reliable Indoor Millimeter Wave Communications using Multiple Artificial Intelligence-Powered ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.00075v2",
      "categories": [
        "cs.NI",
        "cs.LG"
      ]
    },
    "2206.09223v1": {
      "title": "Exploring Parameter Spaces with Artificial Intelligence and Machine Learning Black-Box Optimisation Algorithms",
      "authors": [
        "Fernando Abreu de Souza",
        "Miguel Crispim RomÃ£o",
        "Nuno Filipe Castro",
        "Mehraveh Nikjoo",
        "Werner Porod"
      ],
      "abstract": "Constraining Beyond the Standard Model theories usually involves scanning\nhighly multi-dimensional parameter spaces and check observable predictions\nagainst experimental bounds and theoretical constraints. Such task is often\ntimely and computationally expensive, especially when the model is severely\nconstrained and thus leading to very low random sampling efficiency. In this\nwork we tackled this challenge using Artificial Intelligence and Machine\nLearning search algorithms used for Black-Box optimisation problems. Using the\ncMSSM and the pMSSM parameter spaces, we consider both the Higgs mass and the\nDark Matter Relic Density constraints to study their sampling efficiency and\nparameter space coverage. We find our methodology to produce orders of\nmagnitude improvement of sampling efficiency whilst reasonably covering the\nparameter space.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-06-18",
      "downloaded_date": "2025-02-01",
      "filename": "Souza-Exploring Parameter Spaces with Artificial Intelligence and Machine Learning Black-Box Optimisation ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.09223v1",
      "categories": [
        "hep-ph",
        "physics.comp-ph",
        "physics.data-an"
      ]
    },
    "2501.18071v1": {
      "title": "Towards Transparent and Accurate Diabetes Prediction Using Machine Learning and Explainable Artificial Intelligence",
      "authors": [
        "Pir Bakhsh Khokhar",
        "Viviana Pentangelo",
        "Fabio Palomba",
        "Carmine Gravino"
      ],
      "abstract": "Diabetes mellitus (DM) is a global health issue of significance that must be\ndiagnosed as early as possible and managed well. This study presents a\nframework for diabetes prediction using Machine Learning (ML) models,\ncomplemented with eXplainable Artificial Intelligence (XAI) tools, to\ninvestigate both the predictive accuracy and interpretability of the\npredictions from ML models. Data Preprocessing is based on the Synthetic\nMinority Oversampling Technique (SMOTE) and feature scaling used on the\nDiabetes Binary Health Indicators dataset to deal with class imbalance and\nvariability of clinical features. The ensemble model provided high accuracy,\nwith a test accuracy of 92.50% and an ROC-AUC of 0.975. BMI, Age, General\nHealth, Income, and Physical Activity were the most influential predictors\nobtained from the model explanations. The results of this study suggest that ML\ncombined with XAI is a promising means of developing accurate and\ncomputationally transparent tools for use in healthcare systems.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/87c47470da3ae47a74dd974545d1352c54257721",
      "published_date": "2025-01-30",
      "downloaded_date": "2025-02-01",
      "filename": "Khokhar-Towards Transparent and Accurate Diabetes Prediction Using Machine Learning and Explainable Artifici....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.18071v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ]
    },
    "1809.07842v1": {
      "title": "Bias Amplification in Artificial Intelligence Systems",
      "authors": [
        "Kirsten Lloyd"
      ],
      "abstract": "As Artificial Intelligence (AI) technologies proliferate, concern has\ncentered around the long-term dangers of job loss or threats of machines\ncausing harm to humans. All of this concern, however, detracts from the more\npertinent and already existing threats posed by AI today: its ability to\namplify bias found in training datasets, and swiftly impact marginalized\npopulations at scale. Government and public sector institutions have a\nresponsibility to citizens to establish a dialogue with technology developers\nand release thoughtful policy around data standards to ensure diverse\nrepresentation in datasets to prevent bias amplification and ensure that AI\nsystems are built with inclusion in mind.",
      "citation_count": 41,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d3485f2d36b548ce7e5a73d7b7cdc84f7439fddd",
      "published_date": "2018-09-20",
      "downloaded_date": "2025-02-01",
      "filename": "Lloyd-Bias Amplification in Artificial Intelligence Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1809.07842v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1811.08792v2": {
      "title": "Artificial Intelligence-Defined 5G Radio Access Networks",
      "authors": [
        "Miao Yao",
        "Munawwar Sohul",
        "Vuk Marojevic",
        "Jeffrey H. Reed"
      ],
      "abstract": "Massive multiple-input multiple-output antenna systems, millimeter wave\ncommunications, and ultra-dense networks have been widely perceived as the\nthree key enablers that facilitate the development and deployment of 5G\nsystems. This article discusses the intelligent agent in 5G base station which\ncombines sensing, learning, understanding and optimizing to facilitate these\nenablers. We present a flexible, rapidly deployable, and cross-layer artificial\nintelligence (AI)-based framework to enable the imminent and future demands on\n5G and beyond infrastructure. We present example AI-enabled 5G use cases that\naccommodate important 5G-specific capabilities and discuss the value of AI for\nenabling beyond 5G network evolution.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-11-21",
      "downloaded_date": "2025-02-01",
      "filename": "Yao-Artificial Intelligence-Defined 5G Radio Access Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1811.08792v2",
      "categories": [
        "eess.SP",
        "cs.AI"
      ]
    },
    "2408.04609v1": {
      "title": "Criticizing Ethics According to Artificial Intelligence",
      "authors": [
        "Irina Spiegel"
      ],
      "abstract": "This article presents a critique of ethics in the context of artificial\nintelligence (AI). It argues for the need to question established patterns of\nthought and traditional authorities, including core concepts such as autonomy,\nmorality, and ethics. These concepts are increasingly inadequate to deal with\nthe complexities introduced by emerging AI and autonomous agents. This critique\nhas several key components: clarifying conceptual ambiguities, honestly\naddressing epistemic issues, and thoroughly exploring fundamental normative\nproblems. The ultimate goal is to reevaluate and possibly redefine some\ntraditional ethical concepts to better address the challenges posed by AI.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3770ff8ffdd7581c785f0d9dd7132c81210de05f",
      "published_date": "2024-08-08",
      "downloaded_date": "2025-02-01",
      "filename": "Spiegel-Criticizing Ethics According to Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.04609v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2408.10726v1": {
      "title": "Quantum Artificial Intelligence: A Brief Survey",
      "authors": [
        "Matthias Klusch",
        "JÃ¶rg LÃ¤ssig",
        "Daniel MÃ¼ssig",
        "Antonio Macaluso",
        "Frank K. Wilhelm"
      ],
      "abstract": "Quantum Artificial Intelligence (QAI) is the intersection of quantum\ncomputing and AI, a technological synergy with expected significant benefits\nfor both. In this paper, we provide a brief overview of what has been achieved\nin QAI so far and point to some open questions for future research. In\nparticular, we summarize some major key findings on the feasability and the\npotential of using quantum computing for solving computationally hard problems\nin various subfields of AI, and vice versa, the leveraging of AI methods for\nbuilding and operating quantum computing devices.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b9a57cdcab9b5158a150941f7a8da8c868800d2e",
      "published_date": "2024-08-20",
      "downloaded_date": "2025-02-01",
      "filename": "Klusch-Quantum Artificial Intelligence A Brief Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.10726v1",
      "categories": [
        "quant-ph",
        "cs.AI"
      ]
    },
    "2501.03250v1": {
      "title": "Machine Learning and Deep Learning Techniques used in Cybersecurity and Digital Forensics: a Review",
      "authors": [
        "Jaouhar Fattahi"
      ],
      "abstract": "In the paced realms of cybersecurity and digital forensics machine learning\n(ML) and deep learning (DL) have emerged as game changing technologies that\nintroduce methods to identify stop and analyze cyber risks. This review\npresents an overview of the ML and DL approaches used in these fields\nshowcasing their advantages drawbacks and possibilities. It covers a range of\nAI techniques used in spotting intrusions in systems and classifying malware to\nprevent cybersecurity attacks, detect anomalies and enhance resilience. This\nstudy concludes by highlighting areas where further research is needed and\nsuggesting ways to create transparent and scalable ML and DL solutions that are\nsuited to the evolving landscape of cybersecurity and digital forensics.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8a0a74470ad6b02a9a25d9e033ba0a55fa5bfff2",
      "published_date": "2024-12-24",
      "downloaded_date": "2025-02-01",
      "filename": "Fattahi-Machine Learning and Deep Learning Techniques used in Cybersecurity and Digital Forensics a Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.03250v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    "2404.19157v1": {
      "title": "Scalable Bayesian Inference in the Era of Deep Learning: From Gaussian Processes to Deep Neural Networks",
      "authors": [
        "Javier Antoran"
      ],
      "abstract": "Large neural networks trained on large datasets have become the dominant\nparadigm in machine learning. These systems rely on maximum likelihood point\nestimates of their parameters, precluding them from expressing model\nuncertainty. This may result in overconfident predictions and it prevents the\nuse of deep learning models for sequential decision making. This thesis\ndevelops scalable methods to equip neural networks with model uncertainty. In\nparticular, we leverage the linearised Laplace approximation to equip\npre-trained neural networks with the uncertainty estimates provided by their\ntangent linear models. This turns the problem of Bayesian inference in neural\nnetworks into one of Bayesian inference in conjugate Gaussian-linear models.\nAlas, the cost of this remains cubic in either the number of network parameters\nor in the number of observations times output dimensions. By assumption,\nneither are tractable. We address this intractability by using stochastic\ngradient descent (SGD) -- the workhorse algorithm of deep learning -- to\nperform posterior sampling in linear models and their convex duals: Gaussian\nprocesses. With this, we turn back to linearised neural networks, finding the\nlinearised Laplace approximation to present a number of incompatibilities with\nmodern deep learning practices -- namely, stochastic optimisation, early\nstopping and normalisation layers -- when used for hyperparameter learning. We\nresolve these and construct a sample-based EM algorithm for scalable\nhyperparameter learning with linearised neural networks. We apply the above\nmethods to perform linearised neural network inference with ResNet-50 (25M\nparameters) trained on Imagenet (1.2M observations and 1000 output dimensions).\nAdditionally, we apply our methods to estimate uncertainty for 3d tomographic\nreconstructions obtained with the deep image prior network.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c4d23a3eb3225dbc9a0c7e943353aa657913497b",
      "published_date": "2024-04-29",
      "downloaded_date": "2025-02-01",
      "filename": "Antoran-Scalable Bayesian Inference in the Era of Deep Learning From Gaussian Processes to Deep Neural Netwo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.19157v1",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    "1809.04797v1": {
      "title": "Focus Group on Artificial Intelligence for Health",
      "authors": [
        "Marcel SalathÃ©",
        "Thomas Wiegand",
        "Markus Wenzel"
      ],
      "abstract": "Artificial Intelligence (AI) - the phenomenon of machines being able to solve\nproblems that require human intelligence - has in the past decade seen an\nenormous rise of interest due to significant advances in effectiveness and use.\nThe health sector, one of the most important sectors for societies and\neconomies worldwide, is particularly interesting for AI applications, given the\nongoing digitalisation of all types of health information. The potential for AI\nassistance in the health domain is immense, because AI can support medical\ndecision making at reduced costs, everywhere. However, due to the complexity of\nAI algorithms, it is difficult to distinguish good from bad AI-based solutions\nand to understand their strengths and weaknesses, which is crucial for\nclarifying responsibilities and for building trust. For this reason, the\nInternational Telecommunication Union (ITU) has established a new Focus Group\non \"Artificial Intelligence for Health\" (FG-AI4H) in partnership with the World\nHealth Organization (WHO). Health and care services are usually the\nresponsibility of a government - even when provided through private insurance\nsystems - and thus under the responsibility of WHO/ITU member states. FG-AI4H\nwill identify opportunities for international standardization, which will\nfoster the application of AI to health issues on a global scale. In particular,\nit will establish a standardized assessment framework with open benchmarks for\nthe evaluation of AI-based methods for health, such as AI-based diagnosis,\ntriage or treatment decisions.",
      "citation_count": 31,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6c3d2d147832ed5a75135623b7aa09aa625e4bda",
      "published_date": "2018-09-13",
      "downloaded_date": "2025-02-01",
      "filename": "SalathÃ©-Focus Group on Artificial Intelligence for Health.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1809.04797v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "2402.18784v1": {
      "title": "Brain-inspired and Self-based Artificial Intelligence",
      "authors": [
        "Yi Zeng",
        "Feifei Zhao",
        "Yuxuan Zhao",
        "Dongcheng Zhao",
        "Enmeng Lu",
        "Qian Zhang",
        "Yuwei Wang",
        "Hui Feng",
        "Zhuoya Zhao",
        "Jihang Wang",
        "Qingqun Kong",
        "Yinqian Sun",
        "Yang Li",
        "Guobin Shen",
        "Bing Han",
        "Yiting Dong",
        "Wenxuan Pan",
        "Xiang He",
        "Aorigele Bao",
        "Jin Wang"
      ],
      "abstract": "The question \"Can machines think?\" and the Turing Test to assess whether\nmachines could achieve human-level intelligence is one of the roots of AI. With\nthe philosophical argument \"I think, therefore I am\", this paper challenge the\nidea of a \"thinking machine\" supported by current AIs since there is no sense\nof self in them. Current artificial intelligence is only seemingly intelligent\ninformation processing and does not truly understand or be subjectively aware\nof oneself and perceive the world with the self as human intelligence does. In\nthis paper, we introduce a Brain-inspired and Self-based Artificial\nIntelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to\ncoordinating various cognitive functions and learning strategies in a\nself-organized manner to build human-level AI models and robotic applications.\nSpecifically, BriSe AI emphasizes the crucial role of the Self in shaping the\nfuture AI, rooted with a practical hierarchical Self framework, including\nPerception and Learning, Bodily Self, Autonomous Self, Social Self, and\nConceptual Self. The hierarchical framework of the Self highlights self-based\nenvironment perception, self-bodily modeling, autonomous interaction with the\nenvironment, social interaction and collaboration with others, and even more\nabstract understanding of the Self. Furthermore, the positive mutual promotion\nand support among multiple levels of Self, as well as between Self and\nlearning, enhance the BriSe AI's conscious understanding of information and\nflexible adaptation to complex environments, serving as a driving force\npropelling BriSe AI towards real Artificial General Intelligence.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-02-29",
      "downloaded_date": "2025-02-01",
      "filename": "Zeng-Brain-inspired and Self-based Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.18784v1",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ]
    },
    "1906.00537v1": {
      "title": "Incorporating Biological Knowledge with Factor Graph Neural Network for Interpretable Deep Learning",
      "authors": [
        "Tianle Ma",
        "Aidong Zhang"
      ],
      "abstract": "While deep learning has achieved great success in many fields, one common\ncriticism about deep learning is its lack of interpretability. In most cases,\nthe hidden units in a deep neural network do not have a clear semantic meaning\nor correspond to any physical entities. However, model interpretability and\nexplainability are crucial in many biomedical applications. To address this\nchallenge, we developed the Factor Graph Neural Network model that is\ninterpretable and predictable by combining probabilistic graphical models with\ndeep learning. We directly encode biological knowledge such as Gene Ontology as\na factor graph into the model architecture, making the model transparent and\ninterpretable. Furthermore, we devised an attention mechanism that can capture\nmulti-scale hierarchical interactions among biological entities such as genes\nand Gene Ontology terms. With parameter sharing mechanism, the unrolled Factor\nGraph Neural Network model can be trained with stochastic depth and generalize\nwell. We applied our model to two cancer genomic datasets to predict target\nclinical variables and achieved better results than other traditional machine\nlearning and deep learning models. Our model can also be used for gene set\nenrichment analysis and selecting Gene Ontology terms that are important to\ntarget clinical variables.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e5bb5a9700491eec10c4e5982ccb5a3509a23ce1",
      "published_date": "2019-06-03",
      "downloaded_date": "2025-02-01",
      "filename": "Ma-Incorporating Biological Knowledge with Factor Graph Neural Network for Interpretable Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1906.00537v1",
      "categories": [
        "q-bio.GN",
        "cs.LG"
      ]
    },
    "2409.18397v1": {
      "title": "Scientific Machine Learning Seismology",
      "authors": [
        "Tomohisa Okazaki"
      ],
      "abstract": "Scientific machine learning (SciML) is an interdisciplinary research field\nthat integrates machine learning, particularly deep learning, with physics\ntheory to understand and predict complex natural phenomena. By incorporating\nphysical knowledge, SciML reduces the dependency on observational data, which\nis often limited in the natural sciences. In this article, the fundamental\nconcepts of SciML, its applications in seismology, and prospects are described.\nSpecifically, two popular methods are mainly discussed: physics-informed neural\nnetworks (PINNs) and neural operators (NOs). PINNs can address both forward and\ninverse problems by incorporating governing laws into the loss functions. The\nuse of PINNs is expanding into areas such as simultaneous solutions of\ndifferential equations, inference in underdetermined systems, and\nregularization based on physics. These research directions would broaden the\nscope of deep learning in natural sciences. NOs are models designed for\noperator learning, which deals with relationships between infinite-dimensional\nspaces. NOs show promise in modeling the time evolution of complex systems\nbased on observational or simulation data. Since large amounts of data are\noften required, combining NOs with physics-informed learning holds significant\npotential. Finally, SciML is considered from a broader perspective beyond deep\nlearning: statistical (or mathematical) frameworks that integrate observational\ndata with physical principles to model natural phenomena. In seismology,\nmathematically rigorous Bayesian statistics has been developed over the past\ndecades, whereas more flexible and scalable deep learning has only emerged\nrecently. Both approaches can be considered as part of SciML in a broad sense.\nTheoretical and practical insights in both directions would advance SciML\nmethodologies and thereby deepen our understanding of earthquake phenomena.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e2d1b5c0079a3a9ecf3246ad8037423c64a54415",
      "published_date": "2024-09-27",
      "downloaded_date": "2025-02-01",
      "filename": "Okazaki-Scientific Machine Learning Seismology.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.18397v1",
      "categories": [
        "physics.geo-ph",
        "cs.LG",
        "physics.comp-ph"
      ]
    },
    "2102.03356v1": {
      "title": "Artificial Intelligence based Sensor Data Analytics Framework for Remote Electricity Network Condition Monitoring",
      "authors": [
        "Tharmakulasingam Sirojan"
      ],
      "abstract": "Rural electrification demands the use of inexpensive technologies such as\nsingle wire earth return (SWER) networks. There is a steadily growing energy\ndemand from remote consumers, and the capacity of existing lines may become\ninadequate soon. Furthermore, high impedance arcing faults (HIF) from SWER\nlines can cause catastrophic bushfires such as the 2009 Black Saturday event.\nAs a solution, reliable remote electricity networks can be established through\nbreaking the existing systems down into microgrids, and existing SWER lines can\nbe utilised to interconnect those microgrids. The development of such reliable\nnetworks with better energy demand management will rely on having an integrated\nnetwork-wide condition monitoring system. As the first contribution of this\nthesis, a distributed online monitoring platform is developed that incorporates\npower quality monitoring, real-time HIF identification and transient\nclassification in SWER network. Artificial Intelligence (AI) based techniques\nare developed to classify faults and transients. The proposed approach\ndemonstrates higher HIF detection accuracy (98.67%) and reduced detection\nlatency (115.2 ms). Secondly, a remote consumer load identification methodology\nis developed to detect the load type from its transients. An edge\ncomputing-based architecture is proposed to facilitate the high-frequency\nanalysis for load identification. The proposed approach is evaluated in\nreal-time, and it achieves an average accuracy of 98% in identifying different\nloads. Finally, a deep neural network-based energy disaggregation framework is\ndeveloped to separate the load specific energy usage from an aggregated signal.\nThe proposed framework is evaluated using a real-world data set. It improves\nthe signal aggregate error by 44% and mean aggregate error by 19% in comparison\nwith the state-of-the-art techniques.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d56beb25a9386bcb17d7b8be6c23bef21b13d3f1",
      "published_date": "2021-01-21",
      "downloaded_date": "2025-02-01",
      "filename": "Sirojan-Artificial Intelligence based Sensor Data Analytics Framework for Remote Electricity Network Conditi....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.03356v1",
      "categories": [
        "eess.SP",
        "cs.LG"
      ]
    },
    "1911.04469v1": {
      "title": "A Proposed Artificial intelligence Model for Real-Time Human Action Localization and Tracking",
      "authors": [
        "Ahmed Ali Hammam",
        "Mona Soliman",
        "Aboul Ella Hassanien"
      ],
      "abstract": "In recent years, artificial intelligence (AI) based on deep learning (DL) has\nsparked tremendous global interest. DL is widely used today and has expanded\ninto various interesting areas. It is becoming more popular in cross-subject\nresearch, such as studies of smart city systems, which combine computer science\nwith engineering applications. Human action detection is one of these areas.\nHuman action detection is an interesting challenge due to its stringent\nrequirements in terms of computing speed and accuracy. High-accuracy real-time\nobject tracking is also considered a significant challenge. This paper\nintegrates the YOLO detection network, which is considered a state-of-the-art\ntool for real-time object detection, with motion vectors and the Coyote\nOptimization Algorithm (COA) to construct a real-time human action localization\nand tracking system. The proposed system starts with the extraction of motion\ninformation from a compressed video stream and the extraction of appearance\ninformation from RGB frames using an object detector. Then, a fusion step\nbetween the two streams is performed, and the results are fed into the proposed\naction tracking model. The COA is used in object tracking due to its accuracy\nand fast convergence. The basic foundation of the proposed model is the\nutilization of motion vectors, which already exist in a compressed video bit\nstream and provide sufficient information to improve the localization of the\ntarget action without requiring high consumption of computational resources\ncompared with other popular methods of extracting motion information, such as\noptical flows. This advantage allows the proposed approach to be implemented in\nchallenging environments where the computational resources are limited, such as\nInternet of Things (IoT) systems.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7fe6f034179cfe95317abf579d8b7f0b5bfd328e",
      "published_date": "2019-11-09",
      "downloaded_date": "2025-02-01",
      "filename": "Hammam-A Proposed Artificial intelligence Model for Real-Time Human Action Localization and Tracking.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.04469v1",
      "categories": [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    },
    "2210.14611v2": {
      "title": "Automatic Diagnosis of Myocarditis Disease in Cardiac MRI Modality using Deep Transformers and Explainable Artificial Intelligence",
      "authors": [
        "Mahboobeh Jafari",
        "Afshin Shoeibi",
        "Navid Ghassemi",
        "Jonathan Heras",
        "Sai Ho Ling",
        "Amin Beheshti",
        "Yu-Dong Zhang",
        "Shui-Hua Wang",
        "Roohallah Alizadehsani",
        "Juan M. Gorriz",
        "U. Rajendra Acharya",
        "Hamid Alinejad Rokny"
      ],
      "abstract": "Myocarditis is a significant cardiovascular disease (CVD) that poses a threat\nto the health of many individuals by causing damage to the myocardium. The\noccurrence of microbes and viruses, including the likes of HIV, plays a crucial\nrole in the development of myocarditis disease (MCD). The images produced\nduring cardiac magnetic resonance imaging (CMRI) scans are low contrast, which\ncan make it challenging to diagnose cardiovascular diseases. In other hand,\nchecking numerous CMRI slices for each CVD patient can be a challenging task\nfor medical doctors. To overcome the existing challenges, researchers have\nsuggested the use of artificial intelligence (AI)-based computer-aided\ndiagnosis systems (CADS). The presented paper outlines a CADS for the detection\nof MCD from CMR images, utilizing deep learning (DL) methods. The proposed CADS\nconsists of several steps, including dataset, preprocessing, feature\nextraction, classification, and post-processing. First, the Z-Alizadeh dataset\nwas selected for the experiments. Subsequently, the CMR images underwent\nvarious preprocessing steps, including denoising, resizing, as well as data\naugmentation (DA) via CutMix and MixUp techniques. In the following, the most\ncurrent deep pre-trained and transformer models are used for feature extraction\nand classification on the CMR images. The findings of our study reveal that\ntransformer models exhibit superior performance in detecting MCD as opposed to\npre-trained architectures. In terms of DL architectures, the Turbulence Neural\nTransformer (TNT) model exhibited impressive accuracy, reaching 99.73%\nutilizing a 10-fold cross-validation approach. Additionally, to pinpoint areas\nof suspicion for MCD in CMRI images, the Explainable-based Grad Cam method was\nemployed.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d7e180bf88a42c67357ff97ef88063c74ed6fac1",
      "published_date": "2022-10-26",
      "downloaded_date": "2025-02-01",
      "filename": "Jafari-Automatic Diagnosis of Myocarditis Disease in Cardiac MRI Modality using Deep Transformers and Expla....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.14611v2",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    "1706.04319v2": {
      "title": "Searching for Exoplanets Using Artificial Intelligence",
      "authors": [
        "Kyle A. Pearson",
        "Leon Palafox",
        "Caitlin A. Griffith"
      ],
      "abstract": "In the last decade, over a million stars were monitored to detect transiting\nplanets. Manual interpretation of potential exoplanet candidates is labor\nintensive and subject to human error, the results of which are difficult to\nquantify. Here we present a new method of detecting exoplanet candidates in\nlarge planetary search projects which, unlike current methods uses a neural\nnetwork. Neural networks, also called \"deep learning\" or \"deep nets\" are\ndesigned to give a computer perception into a specific problem by training it\nto recognize patterns. Unlike past transit detection algorithms deep nets learn\nto recognize planet features instead of relying on hand-coded metrics that\nhumans perceive as the most representative. Our convolutional neural network is\ncapable of detecting Earth-like exoplanets in noisy time-series data with a\ngreater accuracy than a least-squares method. Deep nets are highly\ngeneralizable allowing data to be evaluated from different time series after\ninterpolation without compromising performance. As validated by our deep net\nanalysis of Kepler light curves, we detect periodic transits consistent with\nthe true period without any model fitting. Our study indicates that machine\nlearning will facilitate the characterization of exoplanets in future analysis\nof large astronomy data sets.",
      "citation_count": 93,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/18276d7a695d428a4e4e509b690d97d55054232c",
      "published_date": "2017-06-14",
      "downloaded_date": "2025-02-01",
      "filename": "Pearson-Searching for Exoplanets Using Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1706.04319v2",
      "categories": [
        "astro-ph.IM",
        "astro-ph.EP"
      ]
    },
    "2308.02558v1": {
      "title": "The Paradigm Shifts in Artificial Intelligence",
      "authors": [
        "Vasant Dhar"
      ],
      "abstract": "Kuhn's framework of scientific progress (Kuhn, 1962) provides a useful\nframing of the paradigm shifts that have occurred in Artificial Intelligence\nover the last 60 years. The framework is also useful in understanding what is\narguably a new paradigm shift in AI, signaled by the emergence of large\npre-trained systems such as GPT-3, on which conversational agents such as\nChatGPT are based. Such systems make intelligence a commoditized general\npurpose technology that is configurable to applications. In this paper, I\nsummarize the forces that led to the rise and fall of each paradigm, and\ndiscuss the pressing issues and risks associated with the current paradigm\nshift in AI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-08-02",
      "downloaded_date": "2025-02-01",
      "filename": "Dhar-The Paradigm Shifts in Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.02558v1",
      "categories": [
        "cs.AI",
        "I.2.0"
      ]
    },
    "2308.10921v1": {
      "title": "Artificial intelligence-driven antimicrobial peptide discovery",
      "authors": [
        "Paulina Szymczak",
        "Ewa Szczurek"
      ],
      "abstract": "Antimicrobial peptides (AMPs) emerge as promising agents against\nantimicrobial resistance, providing an alternative to conventional antibiotics.\nArtificial intelligence (AI) revolutionized AMP discovery through both\ndiscrimination and generation approaches. The discriminators aid the\nidentification of promising candidates by predicting key peptide properties\nsuch as activity and toxicity, while the generators learn the distribution over\npeptides and enable sampling novel AMP candidates, either de novo, or as\nanalogues of a prototype peptide. Moreover, the controlled generation of AMPs\nwith desired properties is achieved by discriminator-guided filtering,\npositive-only learning, latent space sampling, as well as conditional and\noptimized generation. Here we review recent achievements in AI-driven AMP\ndiscovery, highlighting the most exciting directions.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c13b991235ad29e4ffd7e2db2e12fb25865dc926",
      "published_date": "2023-08-21",
      "downloaded_date": "2025-02-01",
      "filename": "Szymczak-Artificial intelligence-driven antimicrobial peptide discovery.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.10921v1",
      "categories": [
        "q-bio.BM",
        "cs.LG"
      ]
    },
    "2402.13272v1": {
      "title": "Spontaneous Theory of Mind for Artificial Intelligence",
      "authors": [
        "Nikolos Gurney",
        "David V. Pynadath",
        "Volkan Ustun"
      ],
      "abstract": "Existing approaches to Theory of Mind (ToM) in Artificial Intelligence (AI)\noveremphasize prompted, or cue-based, ToM, which may limit our collective\nability to develop Artificial Social Intelligence (ASI). Drawing from research\nin computer science, cognitive science, and related disciplines, we contrast\nprompted ToM with what we call spontaneous ToM -- reasoning about others'\nmental states that is grounded in unintentional, possibly uncontrollable\ncognitive functions. We argue for a principled approach to studying and\ndeveloping AI ToM and suggest that a robust, or general, ASI will respond to\nprompts \\textit{and} spontaneously engage in social reasoning.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1dc13d0fae5037c93a86938c3a19763ad288300e",
      "published_date": "2024-02-16",
      "downloaded_date": "2025-02-01",
      "filename": "Gurney-Spontaneous Theory of Mind for Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.13272v1",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    "1912.00747v3": {
      "title": "The Transformative Potential of Artificial Intelligence",
      "authors": [
        "Ross Gruetzemacher",
        "Jess Whittlestone"
      ],
      "abstract": "The terms 'human-level artificial intelligence' and 'artificial general\nintelligence' are widely used to refer to the possibility of advanced\nartificial intelligence (AI) with potentially extreme impacts on society. These\nterms are poorly defined and do not necessarily indicate what is most important\nwith respect to future societal impacts. We suggest that the term\n'transformative AI' is a helpful alternative, reflecting the possibility that\nadvanced AI systems could have very large impacts on society without reaching\nhuman-level cognitive abilities. To be most useful, however, more analysis of\nwhat it means for AI to be 'transformative' is needed. In this paper, we\npropose three different levels on which AI might be said to be transformative,\nassociated with different levels of societal change. We suggest that these\ndistinctions would improve conversations between policy makers and decision\nmakers concerning the mid- to long-term impacts of advances in AI. Further, we\nfeel this would have a positive effect on strategic foresight efforts involving\nadvanced AI, which we expect to illuminate paths to alternative futures. We\nconclude with a discussion of the benefits of our new framework and by\nhighlighting directions for future work in this area.",
      "citation_count": 95,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0d758632a5ea35bb2590e199e0aac29a026f2632",
      "published_date": "2019-11-27",
      "downloaded_date": "2025-02-01",
      "filename": "Gruetzemacher-The Transformative Potential of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1912.00747v3",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2007.06849v1": {
      "title": "Additively Homomorphical Encryption based Deep Neural Network for Asymmetrically Collaborative Machine Learning",
      "authors": [
        "Yifei Zhang",
        "Hao Zhu"
      ],
      "abstract": "The financial sector presents many opportunities to apply various machine\nlearning techniques. Centralized machine learning creates a constraint which\nlimits further applications in finance sectors. Data privacy is a fundamental\nchallenge for a variety of finance and insurance applications that account on\nlearning a model across different sections. In this paper, we define a new\npractical scheme of collaborative machine learning that one party owns data,\nbut another party owns labels only, and term this \\textbf{Asymmetrically\nCollaborative Machine Learning}. For this scheme, we propose a novel\nprivacy-preserving architecture where two parties can collaboratively train a\ndeep learning model efficiently while preserving the privacy of each party's\ndata. More specifically, we decompose the forward propagation and\nbackpropagation of the neural network into four different steps and propose a\nnovel protocol to handle information leakage in these steps. Our extensive\nexperiments on different datasets demonstrate not only stable training without\naccuracy loss, but also more than 100 times speedup compared with the\nstate-of-the-art system.",
      "citation_count": 39,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/709affecc644067b62663a5ccc2eee7047549cc2",
      "published_date": "2020-07-14",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Additively Homomorphical Encryption based Deep Neural Network for Asymmetrically Collaborative Machi....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.06849v1",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2008.07141v7": {
      "title": "AIPerf: Automated machine learning as an AI-HPC benchmark",
      "authors": [
        "Zhixiang Ren",
        "Yongheng Liu",
        "Tianhui Shi",
        "Lei Xie",
        "Yue Zhou",
        "Jidong Zhai",
        "Youhui Zhang",
        "Yunquan Zhang",
        "Wenguang Chen"
      ],
      "abstract": "The plethora of complex artificial intelligence (AI) algorithms and available\nhigh performance computing (HPC) power stimulates the expeditious development\nof AI components with heterogeneous designs. Consequently, the need for\ncross-stack performance benchmarking of AI-HPC systems emerges rapidly. The de\nfacto HPC benchmark LINPACK can not reflect AI computing power and I/O\nperformance without representative workload. The current popular AI benchmarks\nlike MLPerf have fixed problem size therefore limited scalability. To address\nthese issues, we propose an end-to-end benchmark suite utilizing automated\nmachine learning (AutoML), which not only represents real AI scenarios, but\nalso is auto-adaptively scalable to various scales of machines. We implement\nthe algorithms in a highly parallel and flexible way to ensure the efficiency\nand optimization potential on diverse systems with customizable configurations.\nWe utilize operations per second (OPS), which is measured in an analytical and\nsystematic approach, as the major metric to quantify the AI performance. We\nperform evaluations on various systems to ensure the benchmark's stability and\nscalability, from 4 nodes with 32 NVIDIA Tesla T4 (56.1 Tera-OPS measured), up\nto 512 nodes with 4096 Huawei Ascend 910 (194.53 Peta-OPS measured), and the\nresults show near-linear weak scalability. With flexible workload and single\nmetric, our benchmark can scale and rank AI-HPC easily.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-08-17",
      "downloaded_date": "2025-02-01",
      "filename": "Ren-AIPerf Automated machine learning as an AI-HPC benchmark.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.07141v7",
      "categories": [
        "cs.DC",
        "cs.LG"
      ]
    },
    "2112.15538v1": {
      "title": "Machine learning based disease diagnosis: A comprehensive review",
      "authors": [
        "Md Manjurul Ahsan",
        "Zahed Siddique"
      ],
      "abstract": "Globally, there is a substantial unmet need to diagnose various diseases\neffectively. The complexity of the different disease mechanisms and underlying\nsymptoms of the patient population presents massive challenges to developing\nthe early diagnosis tool and effective treatment. Machine Learning (ML), an\narea of Artificial Intelligence (AI), enables researchers, physicians, and\npatients to solve some of these issues. Based on relevant research, this review\nexplains how Machine Learning (ML) and Deep Learning (DL) are being used to\nhelp in the early identification of numerous diseases. To begin, a bibliometric\nstudy of the publication is given using data from the Scopus and Web of Science\n(WOS) databases. The bibliometric study of 1216 publications was undertaken to\ndetermine the most prolific authors, nations, organizations, and most cited\narticles. The review then summarizes the most recent trends and approaches in\nMachine Learning-based Disease Diagnosis (MLBDD), considering the following\nfactors: algorithm, disease types, data type, application, and evaluation\nmetrics. Finally, the paper highlights key results and provides insight into\nfuture trends and opportunities in the MLBDD area.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-12-31",
      "downloaded_date": "2025-02-01",
      "filename": "Ahsan-Machine learning based disease diagnosis A comprehensive review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2112.15538v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2406.10653v1": {
      "title": "Justice in Healthcare Artificial Intelligence in Africa",
      "authors": [
        "Aloysius Ochasi",
        "Abdoul Jalil Djiberou Mahamadou",
        "Russ B. Altman"
      ],
      "abstract": "There is an ongoing debate on balancing the benefits and risks of artificial\nintelligence (AI) as AI is becoming critical to improving healthcare delivery\nand patient outcomes. Such improvements are essential in resource-constrained\nsettings where millions lack access to adequate healthcare services, such as in\nAfrica. AI in such a context can potentially improve the effectiveness,\nefficiency, and accessibility of healthcare services. Nevertheless, the\ndevelopment and use of AI-driven healthcare systems raise numerous ethical,\nlegal, and socio-economic issues. Justice is a major concern in AI that has\nimplications for amplifying social inequities. This paper discusses these\nimplications and related justice concepts such as solidarity, Common Good,\nsustainability, AI bias, and fairness. For Africa to effectively benefit from\nAI, these principles should align with the local context while balancing the\nrisks. Compared to mainstream ethical debates on justice, this perspective\noffers context-specific considerations for equitable healthcare AI development\nin Africa.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2491beb11c79b63cab29f0b6687acc61a444f9cd",
      "published_date": "2024-06-15",
      "downloaded_date": "2025-02-01",
      "filename": "Ochasi-Justice in Healthcare Artificial Intelligence in Africa.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.10653v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0"
      ]
    },
    "2312.00103v1": {
      "title": "DeepEn2023: Energy Datasets for Edge Artificial Intelligence",
      "authors": [
        "Xiaolong Tu",
        "Anik Mallik",
        "Haoxin Wang",
        "Jiang Xie"
      ],
      "abstract": "Climate change poses one of the most significant challenges to humanity. As a\nresult of these climatic changes, the frequency of weather, climate, and\nwater-related disasters has multiplied fivefold over the past 50 years,\nresulting in over 2 million deaths and losses exceeding $3.64 trillion USD.\nLeveraging AI-powered technologies for sustainable development and combating\nclimate change is a promising avenue. Numerous significant publications are\ndedicated to using AI to improve renewable energy forecasting, enhance waste\nmanagement, and monitor environmental changes in real time. However, very few\nresearch studies focus on making AI itself environmentally sustainable. This\noversight regarding the sustainability of AI within the field might be\nattributed to a mindset gap and the absence of comprehensive energy datasets.\nIn addition, with the ubiquity of edge AI systems and applications, especially\non-device learning, there is a pressing need to measure, analyze, and optimize\ntheir environmental sustainability, such as energy efficiency. To this end, in\nthis paper, we propose large-scale energy datasets for edge AI, named\nDeepEn2023, covering a wide range of kernels, state-of-the-art deep neural\nnetwork models, and popular edge AI applications. We anticipate that DeepEn2023\nwill improve transparency in sustainability in on-device deep learning across a\nrange of edge AI systems and applications. For more information, including\naccess to the dataset and code, please visit\nhttps://amai-gsu.github.io/DeepEn2023.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0353179719c9eb5793654f18d8732629ee3f16dd",
      "published_date": "2023-11-30",
      "downloaded_date": "2025-02-01",
      "filename": "Tu-DeepEn2023 Energy Datasets for Edge Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.00103v1",
      "categories": [
        "cs.LG",
        "cs.PF"
      ]
    },
    "2101.09429v1": {
      "title": "Explainable Artificial Intelligence Approaches: A Survey",
      "authors": [
        "Sheikh Rabiul Islam",
        "William Eberle",
        "Sheikh Khaled Ghafoor",
        "Mohiuddin Ahmed"
      ],
      "abstract": "The lack of explainability of a decision from an Artificial Intelligence (AI)\nbased \"black box\" system/model, despite its superiority in many real-world\napplications, is a key stumbling block for adopting AI in many high stakes\napplications of different domain or industry. While many popular Explainable\nArtificial Intelligence (XAI) methods or approaches are available to facilitate\na human-friendly explanation of the decision, each has its own merits and\ndemerits, with a plethora of open challenges. We demonstrate popular XAI\nmethods with a mutual case study/task (i.e., credit default prediction),\nanalyze for competitive advantages from multiple perspectives (e.g., local,\nglobal), provide meaningful insight on quantifying explainability, and\nrecommend paths towards responsible or human-centered AI using XAI as a medium.\nPractitioners can use this work as a catalog to understand, compare, and\ncorrelate competitive advantages of popular XAI methods. In addition, this\nsurvey elicits future research directions towards responsible or human-centric\nAI systems, which is crucial to adopt AI in high stakes applications.",
      "citation_count": 97,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e404a67659f85cccaac81ba2da275a04f72c4064",
      "published_date": "2021-01-23",
      "downloaded_date": "2025-02-01",
      "filename": "Islam-Explainable Artificial Intelligence Approaches A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.09429v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2204.05983v1": {
      "title": "Comparison Analysis of Traditional Machine Learning and Deep Learning Techniques for Data and Image Classification",
      "authors": [
        "Efstathios Karypidis",
        "Stylianos G. Mouslech",
        "Kassiani Skoulariki",
        "Alexandros Gazis"
      ],
      "abstract": "The purpose of the study is to analyse and compare the most common machine\nlearning and deep learning techniques used for computer vision 2D object\nclassification tasks. Firstly, we will present the theoretical background of\nthe Bag of Visual words model and Deep Convolutional Neural Networks (DCNN).\nSecondly, we will implement a Bag of Visual Words model, the VGG16 CNN\nArchitecture. Thirdly, we will present our custom and novice DCNN in which we\ntest the aforementioned implementations on a modified version of the Belgium\nTraffic Sign dataset. Our results showcase the effects of hyperparameters on\ntraditional machine learning and the advantage in terms of accuracy of DCNNs\ncompared to classical machine learning methods. As our tests indicate, our\nproposed solution can achieve similar - and in some cases better - results than\nexisting DCNNs architectures. Finally, the technical merit of this article lies\nin the presented computationally simpler DCNN architecture, which we believe\ncan pave the way towards using more efficient architectures for basic tasks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-04-11",
      "downloaded_date": "2025-02-01",
      "filename": "Karypidis-Comparison Analysis of Traditional Machine Learning and Deep Learning Techniques for Data and Image ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2204.05983v1",
      "categories": [
        "cs.CV",
        "cs.LG",
        "K.6.3; C.5.2; C.5.3; C.5.5; C.5.m; C.5.0"
      ]
    },
    "2501.15489v1": {
      "title": "AI in Oncology: Transforming Cancer Detection through Machine Learning and Deep Learning Applications",
      "authors": [
        "Muhammad Aftab",
        "Faisal Mehmood",
        "Chengjuan Zhang",
        "Alishba Nadeem",
        "Zigang Dong",
        "Yanan Jiang",
        "Kangdongs Liu"
      ],
      "abstract": "Artificial intelligence (AI) has potential to revolutionize the field of\noncology by enhancing the precision of cancer diagnosis, optimizing treatment\nstrategies, and personalizing therapies for a variety of cancers. This review\nexamines the limitations of conventional diagnostic techniques and explores the\ntransformative role of AI in diagnosing and treating cancers such as lung,\nbreast, colorectal, liver, stomach, esophageal, cervical, thyroid, prostate,\nand skin cancers. The primary objective of this paper is to highlight the\nsignificant advancements that AI algorithms have brought to oncology within the\nmedical industry. By enabling early cancer detection, improving diagnostic\naccuracy, and facilitating targeted treatment delivery, AI contributes to\nsubstantial improvements in patient outcomes. The integration of AI in medical\nimaging, genomic analysis, and pathology enhances diagnostic precision and\nintroduces a novel, less invasive approach to cancer screening. This not only\nboosts the effectiveness of medical facilities but also reduces operational\ncosts. The study delves into the application of AI in radiomics for detailed\ncancer characterization, predictive analytics for identifying associated risks,\nand the development of algorithm-driven robots for immediate diagnosis.\nFurthermore, it investigates the impact of AI on addressing healthcare\nchallenges, particularly in underserved and remote regions. The overarching\ngoal of this platform is to support the development of expert recommendations\nand to provide universal, efficient diagnostic procedures. By reviewing\nexisting research and clinical studies, this paper underscores the pivotal role\nof AI in improving the overall cancer care system. It emphasizes how AI-enabled\nsystems can enhance clinical decision-making and expand treatment options,\nthereby underscoring the importance of AI in advancing precision oncology",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7da5843ff91acd60321aedb70ad794bbea42c428",
      "published_date": "2025-01-26",
      "downloaded_date": "2025-02-01",
      "filename": "Aftab-AI in Oncology Transforming Cancer Detection through Machine Learning and Deep Learning Applications.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.15489v1",
      "categories": [
        "cs.AI",
        "eess.IV",
        "q-bio.QM"
      ]
    },
    "1907.03848v1": {
      "title": "Artificial Intelligence Governance and Ethics: Global Perspectives",
      "authors": [
        "Angela Daly",
        "Thilo Hagendorff",
        "Li Hui",
        "Monique Mann",
        "Vidushi Marda",
        "Ben Wagner",
        "Wei Wang",
        "Saskia Witteborn"
      ],
      "abstract": "Artificial intelligence (AI) is a technology which is increasingly being\nutilised in society and the economy worldwide, and its implementation is\nplanned to become more prevalent in coming years. AI is increasingly being\nembedded in our lives, supplementing our pervasive use of digital technologies.\nBut this is being accompanied by disquiet over problematic and dangerous\nimplementations of AI, or indeed, even AI itself deciding to do dangerous and\nproblematic actions, especially in fields such as the military, medicine and\ncriminal justice. These developments have led to concerns about whether and how\nAI systems adhere, and will adhere to ethical standards. These concerns have\nstimulated a global conversation on AI ethics, and have resulted in various\nactors from different countries and sectors issuing ethics and governance\ninitiatives and guidelines for AI. Such developments form the basis for our\nresearch in this report, combining our international and interdisciplinary\nexpertise to give an insight into what is happening in Australia, China,\nEurope, India and the US.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-06-28",
      "downloaded_date": "2025-02-01",
      "filename": "Daly-Artificial Intelligence Governance and Ethics Global Perspectives.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.03848v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2107.06747v1": {
      "title": "Artificial Intelligence in PET: an Industry Perspective",
      "authors": [
        "Arkadiusz Sitek",
        "Sangtae Ahn",
        "Evren Asma",
        "Adam Chandler",
        "Alvin Ihsani",
        "Sven Prevrhal",
        "Arman Rahmim",
        "Babak Saboury",
        "Kris Thielemans"
      ],
      "abstract": "Artificial intelligence (AI) has significant potential to positively impact\nand advance medical imaging, including positron emission tomography (PET)\nimaging applications. AI has the ability to enhance and optimize all aspects of\nthe PET imaging chain from patient scheduling, patient setup, protocoling, data\nacquisition, detector signal processing, reconstruction, image processing and\ninterpretation. AI poses industry-specific challenges which will need to be\naddressed and overcome to maximize the future potentials of AI in PET. This\npaper provides an overview of these industry-specific challenges for the\ndevelopment, standardization, commercialization, and clinical adoption of AI,\nand explores the potential enhancements to PET imaging brought on by AI in the\nnear future. In particular, the combination of on-demand image reconstruction,\nAI, and custom designed data processing workflows may open new possibilities\nfor innovation which would positively impact the industry and ultimately\npatients.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e29d06a8d07f19a562e3ef0cb5b81765f876e801",
      "published_date": "2021-07-14",
      "downloaded_date": "2025-02-01",
      "filename": "Sitek-Artificial Intelligence in PET an Industry Perspective.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.06747v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "2412.02834v1": {
      "title": "Artificial Intelligence Policy Framework for Institutions",
      "authors": [
        "William Franz Lamberti"
      ],
      "abstract": "Artificial intelligence (AI) has transformed various sectors and\ninstitutions, including education and healthcare. Although AI offers immense\npotential for innovation and problem solving, its integration also raises\nsignificant ethical concerns, such as privacy and bias. This paper delves into\nkey considerations for developing AI policies within institutions. We explore\nthe importance of interpretability and explainability in AI elements, as well\nas the need to mitigate biases and ensure privacy. Additionally, we discuss the\nenvironmental impact of AI and the importance of energy-efficient practices.\nThe culmination of these important components is centralized in a generalized\nframework to be utilized for institutions developing their AI policy. By\naddressing these critical factors, institutions can harness the power of AI\nwhile safeguarding ethical principles.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2a4ab22df07e4cb12645ff0dfd17205e3ef503b5",
      "published_date": "2024-12-03",
      "downloaded_date": "2025-02-01",
      "filename": "Lamberti-Artificial Intelligence Policy Framework for Institutions.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.02834v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2011.13464v1": {
      "title": "Meta-learning in natural and artificial intelligence",
      "authors": [
        "Jane X. Wang"
      ],
      "abstract": "Meta-learning, or learning to learn, has gained renewed interest in recent\nyears within the artificial intelligence community. However, meta-learning is\nincredibly prevalent within nature, has deep roots in cognitive science and\npsychology, and is currently studied in various forms within neuroscience. The\naim of this review is to recast previous lines of research in the study of\nbiological intelligence within the lens of meta-learning, placing these works\ninto a common framework. More recent points of interaction between AI and\nneuroscience will be discussed, as well as interesting new directions that\narise under this perspective.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-11-26",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Meta-learning in natural and artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2011.13464v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2301.04751v1": {
      "title": "Artificial Intelligence Generated Coins for Size Comparison",
      "authors": [
        "Gerald Artner"
      ],
      "abstract": "Authors of scientific articles use coins in photographs as a size reference\nfor objects. For this purpose, coins are placed next to objects when taking the\nphoto. In this letter we propose a novel method that uses artificial\nintelligence (AI) generated images of coins to provide a size reference in\nphotos. The newest generation is able to quickly generate realistic\nhigh-quality images from textual descriptions. With the proposed method no\nphysical coin is required while taking photos. Coins can be added to photos\nthat contain none. Furthermore, we show how the coin motif can be matched to\nthe object.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-01-11",
      "downloaded_date": "2025-02-01",
      "filename": "Artner-Artificial Intelligence Generated Coins for Size Comparison.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2301.04751v1",
      "categories": [
        "cs.CV"
      ]
    },
    "1909.11145v2": {
      "title": "Brain-Inspired Hardware for Artificial Intelligence: Accelerated Learning in a Physical-Model Spiking Neural Network",
      "authors": [
        "Timo C. Wunderlich",
        "Akos F. Kungl",
        "Eric MÃ¼ller",
        "Johannes Schemmel",
        "Mihai Petrovici"
      ],
      "abstract": "Future developments in artificial intelligence will profit from the existence\nof novel, non-traditional substrates for brain-inspired computing. Neuromorphic\ncomputers aim to provide such a substrate that reproduces the brain's\ncapabilities in terms of adaptive, low-power information processing. We present\nresults from a prototype chip of the BrainScaleS-2 mixed-signal neuromorphic\nsystem that adopts a physical-model approach with a 1000-fold acceleration of\nspiking neural network dynamics relative to biological real time. Using the\nembedded plasticity processor, we both simulate the Pong arcade video game and\nimplement a local plasticity rule that enables reinforcement learning, allowing\nthe on-chip neural network to learn to play the game. The experiment\ndemonstrates key aspects of the employed approach, such as accelerated and\nflexible learning, high energy efficiency and resilience to noise.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-09-24",
      "downloaded_date": "2025-02-01",
      "filename": "Wunderlich-Brain-Inspired Hardware for Artificial Intelligence Accelerated Learning in a Physical-Model Spiking....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1909.11145v2",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.ET"
      ]
    },
    "2008.01578v1": {
      "title": "Automatic Dataset Builder for Machine Learning Applications to Satellite Imagery",
      "authors": [
        "Alessandro Sebastianelli",
        "Maria Pia Del Rosso",
        "Silvia Liberata Ullo"
      ],
      "abstract": "Nowadays the use of Machine Learning (ML) algorithms is spreading in the\nfield of Remote Sensing, with applications ranging from detection and\nclassification of land use and monitoring to the prediction of many natural or\nanthropic phenomena of interest. One main limit of their employment is related\nto the need for a huge amount of data for training the neural network, chosen\nfor the specific application, and the resulting computational weight and time\nrequired to collect the necessary data. In this letter the architecture of an\ninnovative tool, enabling researchers to create in an automatic way suitable\ndatasets for AI (Artificial Intelligence) applications in the EO (Earth\nObservation) context, is presented. Two versions of the architecture have been\nimplemented and made available on Git-Hub, with a specific Graphical User\nInterface (GUI) for non-expert users.",
      "citation_count": 20,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/12795fbab43c1c5f54db63a78e8083b33aea8714",
      "published_date": "2020-08-04",
      "downloaded_date": "2025-02-01",
      "filename": "Sebastianelli-Automatic Dataset Builder for Machine Learning Applications to Satellite Imagery.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.01578v1",
      "categories": [
        "eess.IV"
      ]
    },
    "1910.10147v2": {
      "title": "Machine learning and serving of discrete field theories -- when artificial intelligence meets the discrete universe",
      "authors": [
        "Hong Qin"
      ],
      "abstract": "A method for machine learning and serving of discrete field theories in\nphysics is developed. The learning algorithm trains a discrete field theory\nfrom a set of observational data on a spacetime lattice, and the serving\nalgorithm uses the learned discrete field theory to predict new observations of\nthe field for new boundary and initial conditions. The approach to learn\ndiscrete field theories overcomes the difficulties associated with learning\ncontinuous theories by artificial intelligence. The serving algorithm of\ndiscrete field theories belongs to the family of structure-preserving geometric\nalgorithms, which have been proven to be superior to the conventional\nalgorithms based on discretization of differential equations. The effectiveness\nof the method and algorithms developed is demonstrated using the examples of\nnonlinear oscillations and the Kepler problem. In particular, the learning\nalgorithm learns a discrete field theory from a set of data of planetary orbits\nsimilar to what Kepler inherited from Tycho Brahe in 1601, and the serving\nalgorithm correctly predicts other planetary orbits, including parabolic and\nhyperbolic escaping orbits, of the solar system without learning or knowing\nNewton's laws of motion and universal gravitation. The proposed algorithms are\nalso applicable when effects of special relativity and general relativity are\nimportant. The illustrated advantages of discrete field theories relative to\ncontinuous theories in terms of machine learning compatibility are consistent\nwith Bostrom's simulation hypothesis.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-10-22",
      "downloaded_date": "2025-02-01",
      "filename": "Qin-Machine learning and serving of discrete field theories -- when artificial intelligence meets the di....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1910.10147v2",
      "categories": [
        "physics.comp-ph",
        "cs.LG",
        "hep-lat"
      ]
    },
    "1706.03021v1": {
      "title": "Ethical Artificial Intelligence - An Open Question",
      "authors": [
        "Alice Pavaloiu",
        "Utku Kose"
      ],
      "abstract": "Artificial Intelligence (AI) is an effective science which employs strong\nenough approaches, methods, and techniques to solve unsolvable real world based\nproblems. Because of its unstoppable rise towards the future, there are also\nsome discussions about its ethics and safety. Shaping an AI friendly\nenvironment for people and a people friendly environment for AI can be a\npossible answer for finding a shared context of values for both humans and\nrobots. In this context, objective of this paper is to address the ethical\nissues of AI and explore the moral dilemmas that arise from ethical algorithms,\nfrom pre set or acquired values. In addition, the paper will also focus on the\nsubject of AI safety. As general, the paper will briefly analyze the concerns\nand potential solutions to solving the ethical issues presented and increase\nreaders awareness on AI safety as another related research interest.",
      "citation_count": 21,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b952eaffb220ed192728d2ce7436235827132057",
      "published_date": "2017-05-16",
      "downloaded_date": "2025-02-01",
      "filename": "Pavaloiu-Ethical Artificial Intelligence - An Open Question.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1706.03021v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "2001.07038v4": {
      "title": "Measuring Diversity of Artificial Intelligence Conferences",
      "authors": [
        "Ana Freire",
        "Lorenzo Porcaro",
        "Emilia GÃ³mez"
      ],
      "abstract": "The lack of diversity of the Artificial Intelligence (AI) field is nowadays a\nconcern, and several initiatives such as funding schemes and mentoring programs\nhave been designed to overcome it. However, there is no indication on how these\ninitiatives actually impact AI diversity in the short and long term. This work\nstudies the concept of diversity in this particular context and proposes a\nsmall set of diversity indicators (i.e. indexes) of AI scientific events. These\nindicators are designed to quantify the diversity of the AI field and monitor\nits evolution. We consider diversity in terms of gender, geographical location\nand business (understood as the presence of academia versus industry). We\ncompute these indicators for the different communities of a conference:\nauthors, keynote speakers and organizing committee. From these components we\ncompute a summarized diversity indicator for each AI event. We evaluate the\nproposed indexes for a set of recent major AI conferences and we discuss their\nvalues and limitations.",
      "citation_count": 23,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/245d66ecc31c2441efd60c526052de016513c933",
      "published_date": "2020-01-20",
      "downloaded_date": "2025-02-01",
      "filename": "Freire-Measuring Diversity of Artificial Intelligence Conferences.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2001.07038v4",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2107.03721v4": {
      "title": "Demystifying the Draft EU Artificial Intelligence Act",
      "authors": [
        "Michael Veale",
        "Frederik Zuiderveen Borgesius"
      ],
      "abstract": "In April 2021, the European Commission proposed a Regulation on Artificial\nIntelligence, known as the AI Act. We present an overview of the Act and\nanalyse its implications, drawing on scholarship ranging from the study of\ncontemporary AI practices to the structure of EU product safety regimes over\nthe last four decades. Aspects of the AI Act, such as different rules for\ndifferent risk-levels of AI, make sense. But we also find that some provisions\nof the Draft AI Act have surprising legal implications, whilst others may be\nlargely ineffective at achieving their stated goals. Several overarching\naspects, including the enforcement regime and the risks of maximum\nharmonisation pre-empting legitimate national AI policy, engender significant\nconcern. These issues should be addressed as a priority in the legislative\nprocess.",
      "citation_count": 295,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8b165eba2d0b9308682fdc4d775c00d1d3907a59",
      "published_date": "2021-07-08",
      "downloaded_date": "2025-02-01",
      "filename": "Veale-Demystifying the Draft EU Artificial Intelligence Act.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.03721v4",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.5.0; K.5.1"
      ]
    },
    "2110.02007v3": {
      "title": "Empowering Local Communities Using Artificial Intelligence",
      "authors": [
        "Yen-Chia Hsu",
        "Ting-Hao 'Kenneth' Huang",
        "Himanshu Verma",
        "Andrea Mauri",
        "Illah Nourbakhsh",
        "Alessandro Bozzon"
      ],
      "abstract": "Artificial Intelligence (AI) is increasingly used to analyze large amounts of\ndata in various practices, such as object recognition. We are specifically\ninterested in using AI-powered systems to engage local communities in\ndeveloping plans or solutions for pressing societal and environmental concerns.\nSuch local contexts often involve multiple stakeholders with different and even\ncontradictory agendas, resulting in mismatched expectations of these systems'\nbehaviors and desired outcomes. There is a need to investigate if AI models and\npipelines can work as expected in different contexts through co-creation and\nfield deployment. Based on case studies in co-creating AI-powered systems with\nlocal people, we explain challenges that require more attention and provide\nviable paths to bridge AI research with citizen needs. We advocate for\ndeveloping new collaboration approaches and mindsets that are needed to\nco-create AI-powered systems in multi-stakeholder contexts to address local\nconcerns.",
      "citation_count": 26,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/946942368bf092ade858d5ea843fa114e2762b4e",
      "published_date": "2021-10-05",
      "downloaded_date": "2025-02-01",
      "filename": "Hsu-Empowering Local Communities Using Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.02007v3",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    "2401.09857v1": {
      "title": "Artificial Intelligence-based algorithms in medical image scan seg-mentation and intelligent visual-content generation -- a concise overview",
      "authors": [
        "Zofia Rudnicka",
        "Janusz Szczepanski",
        "Agnieszka Pregowska"
      ],
      "abstract": "Recently, Artificial Intelligence (AI)-based algorithms have revolutionized\nthe medical image segmentation processes. Thus, the precise segmentation of\norgans and their lesions may contribute to an efficient diagnostics process and\na more effective selection of targeted therapies as well as increasing the\neffectiveness of the training process. In this context, AI may contribute to\nthe automatization of the image scan segmentation process and increase the\nquality of the resulting 3D objects, which may lead to the generation of more\nrealistic virtual objects. In this paper, we focus on the AI-based solutions\napplied in the medical image scan segmentation, and intelligent visual-content\ngeneration, i.e. computer-generated three-dimensional (3D) images in the\ncontext of Extended Reality (XR). We consider different types of neural\nnetworks used with a special emphasis on the learning rules applied, taking\ninto account algorithm accuracy and performance, as well as open data\navailability. This paper attempts to summarize the current development of\nAI-based segmentation methods in medical imaging and intelligent visual content\ngeneration that are applied in XR. It concludes also with possible developments\nand open challenges in AI application in Extended Reality-based solutions.\nFinally, the future lines of research and development directions of Artificial\nIntelligence applications both in medical image segmentation and Extended\nReality-based medical solutions are discussed",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-01-18",
      "downloaded_date": "2025-02-01",
      "filename": "Rudnicka-Artificial Intelligence-based algorithms in medical image scan seg-mentation and intelligent visual-....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.09857v1",
      "categories": [
        "q-bio.NC"
      ]
    },
    "2310.13192v3": {
      "title": "The Opaque Law of Artificial Intelligence",
      "authors": [
        "Vincenzo Calderonio"
      ],
      "abstract": "The purpose of this paper is to analyse the opacity of algorithms,\ncontextualized in the open debate on responsibility for artificial intelligence\ncausation; with an experimental approach by which, applying the proposed\nconversational methodology of the Turing Test, we expect to evaluate the\nperformance of one of the best existing NLP model of generative AI (Chat-GPT)\nto see how far it can go right now and how the shape of a legal regulation of\nit could be. The analysis of the problem will be supported by a comment of\nItalian classical law categories such as causality, intent and fault to\nunderstand the problem of the usage of AI, focusing in particular on the\nhuman-machine interaction. On the computer science side, for a technical point\nof view of the logic used to craft these algorithms, in the second chapter will\nbe proposed a practical interrogation of Chat-GPT aimed at finding some\ncritical points of the functioning of AI. The end of the paper will concentrate\non some existing legal solutions which can be applied to the problem, plus a\nbrief description of the approach proposed by EU Artificial Intelligence act.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/237d561b8a3791492370f0f9997ea9081cfc7a69",
      "published_date": "2023-10-19",
      "downloaded_date": "2025-02-01",
      "filename": "Calderonio-The Opaque Law of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.13192v3",
      "categories": [
        "cs.AI",
        "F.0; I.2; J.4; K.4; K.5"
      ]
    },
    "2410.19998v1": {
      "title": "Artificial Intelligence of Things: A Survey",
      "authors": [
        "Shakhrul Iman Siam",
        "Hyunho Ahn",
        "Li Liu",
        "Samiul Alam",
        "Hui Shen",
        "Zhichao Cao",
        "Ness Shroff",
        "Bhaskar Krishnamachari",
        "Mani Srivastava",
        "Mi Zhang"
      ],
      "abstract": "The integration of the Internet of Things (IoT) and modern Artificial\nIntelligence (AI) has given rise to a new paradigm known as the Artificial\nIntelligence of Things (AIoT). In this survey, we provide a systematic and\ncomprehensive review of AIoT research. We examine AIoT literature related to\nsensing, computing, and networking & communication, which form the three key\ncomponents of AIoT. In addition to advancements in these areas, we review\ndomain-specific AIoT systems that are designed for various important\napplication domains. We have also created an accompanying GitHub repository,\nwhere we compile the papers included in this survey:\nhttps://github.com/AIoT-MLSys-Lab/AIoT-Survey. This repository will be actively\nmaintained and updated with new research as it becomes available. As both IoT\nand AI become increasingly critical to our society, we believe AIoT is emerging\nas an essential research field at the intersection of IoT and modern AI. We\nhope this survey will serve as a valuable resource for those engaged in AIoT\nresearch and act as a catalyst for future explorations to bridge gaps and drive\nadvancements in this exciting field.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/030a0eb433176436116ffb75b59ce60305e6374f",
      "published_date": "2024-10-25",
      "downloaded_date": "2025-02-01",
      "filename": "Siam-Artificial Intelligence of Things A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.19998v1",
      "categories": [
        "cs.NI",
        "cs.AI"
      ]
    },
    "1810.02688v2": {
      "title": "Wikistat 2.0: Educational Resources for Artificial Intelligence",
      "authors": [
        "Philippe Besse",
        "Brendan Guillouet",
        "BÃ©atrice Laurent"
      ],
      "abstract": "Big data, data science, deep learning, artificial intelligence are the key\nwords of intense hype related with a job market in full evolution, that impose\nto adapt the contents of our university professional trainings. Which\nartificial intelligence is mostly concerned by the job offers? Which\nmethodologies and technologies should be favored in the training programs?\nWhich objectives, tools and educational resources do we needed to put in place\nto meet these pressing needs? We answer these questions in describing the\ncontents and operational resources in the Data Science orientation of the\nspecialty Applied Mathematics at INSA Toulouse. We focus on basic mathematics\ntraining (Optimization, Probability, Statistics), associated with the practical\nimplementation of the most performing statistical learning algorithms, with the\nmost appropriate technologies and on real examples. Considering the huge\nvolatility of the technologies, it is imperative to train students in\nseft-training, this will be their technological watch tool when they will be in\nprofessional activity. This explains the structuring of the educational site\ngithub.com/wikistat into a set of tutorials. Finally, to motivate the thorough\npractice of these tutorials, a serious game is organized each year in the form\nof a prediction contest between students of Master degrees in Applied\nMathematics for IA.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-09-28",
      "downloaded_date": "2025-02-01",
      "filename": "Besse-Wikistat 20 Educational Resources for Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1810.02688v2",
      "categories": [
        "cs.CY",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    "2305.11897v2": {
      "title": "Critical Appraisal of Artificial Intelligence-Mediated Communication",
      "authors": [
        "Dara Tafazoli"
      ],
      "abstract": "Over the last two decades, technology use in language learning and teaching\nhas significantly advanced and is now referred to as Computer-Assisted Language\nLearning (CALL). Recently, the integration of Artificial Intelligence (AI) into\nCALL has brought about a significant shift in the traditional approach to\nlanguage education both inside and outside the classroom. In line with this\nbook's scope, I explore the advantages and disadvantages of AI-mediated\ncommunication in language education. I begin with a brief review of AI in\neducation. I then introduce the ICALL and give a critical appraisal of the\npotential of AI-powered automatic speech recognition (ASR), Machine Translation\n(MT), Intelligent Tutoring Systems (ITSs), AI-powered chatbots, and Extended\nReality (XR). In conclusion, I argue that it is crucial for language teachers\nto engage in CALL teacher education and professional development to keep up\nwith the ever-evolving technology landscape and improve their teaching\neffectiveness.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-05-15",
      "downloaded_date": "2025-02-01",
      "filename": "Tafazoli-Critical Appraisal of Artificial Intelligence-Mediated Communication.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.11897v2",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    "2012.09609v1": {
      "title": "Draw your Neural Networks",
      "authors": [
        "Jatin Sharma",
        "Shobha Lata"
      ],
      "abstract": "Deep Neural Networks are the basic building blocks of modern Artificial\nIntelligence. They are increasingly replacing or augmenting existing software\nsystems due to their ability to learn directly from the data and superior\naccuracy on variety of tasks. Existing Software Development Life Cycle (SDLC)\nmethodologies fall short on representing the unique capabilities and\nrequirements of AI Development and must be replaced with Artificial\nIntelligence Development Life Cycle (AIDLC) methodologies. In this paper, we\ndiscuss an alternative and more natural approach to develop neural networks\nthat involves intuitive GUI elements such as blocks and lines to draw them\ninstead of complex computer programming. We present Sketch framework, that uses\nthis GUI-based approach to design and modify the neural networks and provides\ninteroperability with traditional frameworks. The system provides popular\nlayers and operations out-of-the-box and could import any supported pre-trained\nmodel making it a faster method to design and train complex neural networks and\nultimately democratizing the AI by removing the learning curve.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-12-12",
      "downloaded_date": "2025-02-01",
      "filename": "Sharma-Draw your Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.09609v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2012.05876v2": {
      "title": "Neurosymbolic AI: The 3rd Wave",
      "authors": [
        "Artur d'Avila Garcez",
        "Luis C. Lamb"
      ],
      "abstract": "Current advances in Artificial Intelligence (AI) and Machine Learning (ML)\nhave achieved unprecedented impact across research communities and industry.\nNevertheless, concerns about trust, safety, interpretability and accountability\nof AI were raised by influential thinkers. Many have identified the need for\nwell-founded knowledge representation and reasoning to be integrated with deep\nlearning and for sound explainability. Neural-symbolic computing has been an\nactive area of research for many years seeking to bring together robust\nlearning in neural networks with reasoning and explainability via symbolic\nrepresentations for network models. In this paper, we relate recent and early\nresearch results in neurosymbolic AI with the objective of identifying the key\ningredients of the next wave of AI systems. We focus on research that\nintegrates in a principled way neural network-based learning with symbolic\nknowledge representation and logical reasoning. The insights provided by 20\nyears of neural-symbolic computing are shown to shed new light onto the\nincreasingly prominent role of trust, safety, interpretability and\naccountability of AI. We also identify promising directions and challenges for\nthe next decade of AI research from the perspective of neural-symbolic systems.",
      "citation_count": 256,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d5901f15a0214b50e6a0085337e49a9b966775a7",
      "published_date": "2020-12-10",
      "downloaded_date": "2025-02-01",
      "filename": "Garcez-Neurosymbolic AI The 3rd Wave.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.05876v2",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.4; I.2.6"
      ]
    },
    "2210.11943v1": {
      "title": "Computer-Aided Cancer Diagnosis via Machine Learning and Deep Learning: A comparative review",
      "authors": [
        "Solene Bechelli"
      ],
      "abstract": "The past years have seen a considerable increase in cancer cases. However, a\ncancer diagnosis is often complex and depends on the types of images provided\nfor analysis. It requires highly skilled practitioners but is often\ntime-consuming and error-prone. If Machine Learning and deep learning\nalgorithms have been widely used, a comprehensive review of the techniques used\nfrom the pre-processing steps to the final prediction is lacking. With this\nreview, we aim to provide a comprehensive overview of the current steps\nrequired in building efficient and accurate machine learning algorithm for\ncancer prediction, detection and classification. To do so, we compile the\nresults of cancer related study using AI over the past years. We include\nvarious cancers that encompass different types of images, and therefore\ndifferent related techniques. We show that tremendous improvements have been\nmade in the early detection of cancerous tumors and tissues. The techniques\nused are various and often problem-tailored and our findings is confirmed\nthrough the study of a large number of research. Moreover, we investigate the\napproaches best suited for different types of images such as histology,\ndermoscopic, MRI, etc. With this work, we summarize the main finding over the\npast years in cancer detection using deep learning techniques. We discuss the\nchallenges of cancer research related to the large discrepancies in the images,\nand we provide some notable results in the field for lung, breast, and skin\ncancers.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-10-19",
      "downloaded_date": "2025-02-01",
      "filename": "Bechelli-Computer-Aided Cancer Diagnosis via Machine Learning and Deep Learning A comparative review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.11943v1",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2311.09452v3": {
      "title": "Close the Gates: How we can keep the future human by choosing not to develop superhuman general-purpose artificial intelligence",
      "authors": [
        "Anthony Aguirre"
      ],
      "abstract": "Recent dramatic advances in artificial intelligence indicate that in the\ncoming years, humanity may irreversibly cross a threshold by creating\nsuperhuman general-purpose AI: AI that is better than humans at cognitive tasks\nin general in the way that AI is currently unbeatable in certain domains. This\nwould upend core aspects of human society, present many unprecedented risks,\nand is likely to be uncontrollable in several senses. We can choose to not do\nso, starting by instituting hard limits - placed at the national and\ninternational level, and verified by hardware security measures - on the\ncomputation that can be used to train and run neural networks. With these\nlimits in place, AI research and industry can focus on making both narrow and\ngeneral-purpose AI that humans can understand and control, and from which we\ncan reap enormous benefit.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c7613dcb4a5590cdb9f4720c9e7e2fe1d3cdca10",
      "published_date": "2023-11-15",
      "downloaded_date": "2025-02-01",
      "filename": "Aguirre-Close the Gates How we can keep the future human by choosing not to develop superhuman general-purpo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.09452v3",
      "categories": [
        "cs.CY"
      ]
    },
    "2205.11082v1": {
      "title": "YouTube Ad View Sentiment Analysis using Deep Learning and Machine Learning",
      "authors": [
        "Tanvi Mehta",
        "Ganesh Deshmukh"
      ],
      "abstract": "Sentiment Analysis is currently a vital area of research. With the\nadvancement in the use of the internet, the creation of social media, websites,\nblogs, opinions, ratings, etc. has increased rapidly. People express their\nfeedback and emotions on social media posts in the form of likes, dislikes,\ncomments, etc. The rapid growth in the volume of viewer-generated or\nuser-generated data or content on YouTube has led to an increase in YouTube\nsentiment analysis. Due to this, analyzing the public reactions has become an\nessential need for information extraction and data visualization in the\ntechnical domain. This research predicts YouTube Ad view sentiments using Deep\nLearning and Machine Learning algorithms like Linear Regression (LR), Support\nVector Machine (SVM), Decision Tree (DT), Random Forest (RF), and Artificial\nNeural Network (ANN). Finally, a comparative analysis is done based on\nexperimental results acquired from different models.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2a8420c6228042d55e18844729c055fd0231c15c",
      "published_date": "2022-05-23",
      "downloaded_date": "2025-02-01",
      "filename": "Mehta-YouTube Ad View Sentiment Analysis using Deep Learning and Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.11082v1",
      "categories": [
        "cs.LG",
        "cs.IR"
      ]
    },
    "2406.04993v1": {
      "title": "Development and Validation of a Deep-Learning Model for Differential Treatment Benefit Prediction for Adults with Major Depressive Disorder Deployed in the Artificial Intelligence in Depression Medication Enhancement (AIDME) Study",
      "authors": [
        "David Benrimoh",
        "Caitrin Armstrong",
        "Joseph Mehltretter",
        "Robert Fratila",
        "Kelly Perlman",
        "Sonia Israel",
        "Adam Kapelner",
        "Sagar V. Parikh",
        "Jordan F. Karp",
        "Katherine Heller",
        "Gustavo Turecki"
      ],
      "abstract": "INTRODUCTION: The pharmacological treatment of Major Depressive Disorder\n(MDD) relies on a trial-and-error approach. We introduce an artificial\nintelligence (AI) model aiming to personalize treatment and improve outcomes,\nwhich was deployed in the Artificial Intelligence in Depression Medication\nEnhancement (AIDME) Study. OBJECTIVES: 1) Develop a model capable of predicting\nprobabilities of remission across multiple pharmacological treatments for\nadults with at least moderate major depression. 2) Validate model predictions\nand examine them for amplification of harmful biases. METHODS: Data from\nprevious clinical trials of antidepressant medications were standardized into a\ncommon framework and included 9,042 adults with moderate to severe major\ndepression. Feature selection retained 25 clinical and demographic variables.\nUsing Bayesian optimization, a deep learning model was trained on the training\nset, refined using the validation set, and tested once on the held-out test\nset. RESULTS: In the evaluation on the held-out test set, the model\ndemonstrated achieved an AUC of 0.65. The model outperformed a null model on\nthe test set (p = 0.01). The model demonstrated clinical utility, achieving an\nabsolute improvement in population remission rate in hypothetical and actual\nimprovement testing. While the model did identify one drug (escitalopram) as\ngenerally outperforming the other drugs (consistent with the input data), there\nwas otherwise significant variation in drug rankings. On bias testing, the\nmodel did not amplify potentially harmful biases. CONCLUSIONS: We demonstrate\nthe first model capable of predicting outcomes for 10 different treatment\noptions for patients with MDD, intended to be used at or near the start of\ntreatment to personalize treatment. The model was put into clinical practice\nduring the AIDME randomized controlled trial whose results are reported\nseparately.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-06-07",
      "downloaded_date": "2025-02-01",
      "filename": "Benrimoh-Development and Validation of a Deep-Learning Model for Differential Treatment Benefit Prediction fo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.04993v1",
      "categories": [
        "q-bio.NC",
        "cs.LG"
      ]
    },
    "1910.12892v1": {
      "title": "Hyperbolic Graph Neural Networks",
      "authors": [
        "Qi Liu",
        "Maximilian Nickel",
        "Douwe Kiela"
      ],
      "abstract": "Learning from graph-structured data is an important task in machine learning\nand artificial intelligence, for which Graph Neural Networks (GNNs) have shown\ngreat promise. Motivated by recent advances in geometric representation\nlearning, we propose a novel GNN architecture for learning representations on\nRiemannian manifolds with differentiable exponential and logarithmic maps. We\ndevelop a scalable algorithm for modeling the structural properties of graphs,\ncomparing Euclidean and hyperbolic geometry. In our experiments, we show that\nhyperbolic GNNs can lead to substantial improvements on various benchmark\ndatasets.",
      "citation_count": 336,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/784b018c87c7dcbbe772374e45d5191bae9938ee",
      "published_date": "2019-10-28",
      "downloaded_date": "2025-02-01",
      "filename": "Liu-Hyperbolic Graph Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1910.12892v1",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2403.15766v1": {
      "title": "BEND: Bagging Deep Learning Training Based on Efficient Neural Network Diffusion",
      "authors": [
        "Jia Wei",
        "Xingjun Zhang",
        "Witold Pedrycz"
      ],
      "abstract": "Bagging has achieved great success in the field of machine learning by\nintegrating multiple base classifiers to build a single strong classifier to\nreduce model variance. The performance improvement of bagging mainly relies on\nthe number and diversity of base classifiers. However, traditional deep\nlearning model training methods are expensive to train individually and\ndifficult to train multiple models with low similarity in a restricted dataset.\nRecently, diffusion models, which have been tremendously successful in the\nfields of imaging and vision, have been found to be effective in generating\nneural network model weights and biases with diversity. We creatively propose a\nBagging deep learning training algorithm based on Efficient Neural network\nDiffusion (BEND). The originality of BEND comes from the first use of a neural\nnetwork diffusion model to efficiently build base classifiers for bagging. Our\napproach is simple but effective, first using multiple trained model weights\nand biases as inputs to train autoencoder and latent diffusion model to realize\na diffusion model from noise to valid neural network parameters. Subsequently,\nwe generate several base classifiers using the trained diffusion model.\nFinally, we integrate these ba se classifiers for various inference tasks using\nthe Bagging method. Resulting experiments on multiple models and datasets show\nthat our proposed BEND algorithm can consistently outperform the mean and\nmedian accuracies of both the original trained model and the diffused model. At\nthe same time, new models diffused using the diffusion model have higher\ndiversity and lower cost than multiple models trained using traditional\nmethods. The BEND approach successfully introduces diffusion models into the\nnew deep learning training domain and provides a new paradigm for future deep\nlearning training and inference.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0709f82dca3b4ca6c7e7bffdf07c5c5030cf015c",
      "published_date": "2024-03-23",
      "downloaded_date": "2025-02-01",
      "filename": "Wei-BEND Bagging Deep Learning Training Based on Efficient Neural Network Diffusion.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.15766v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2110.02640v1": {
      "title": "Bach Style Music Authoring System based on Deep Learning",
      "authors": [
        "Minghe Kong",
        "Lican Huang"
      ],
      "abstract": "With the continuous improvement in various aspects in the field of artificial\nintelligence, the momentum of artificial intelligence with deep learning\ncapabilities into the field of music is coming. The research purpose of this\npaper is to design a Bach style music authoring system based on deep learning.\nWe use a LSTM neural network to train serialized and standardized music feature\ndata. By repeated experiments, we find the optimal LSTM model which can\ngenerate imitation of Bach music. Finally the generated music is\ncomprehensively evaluated in the form of online audition and Turing test. The\nrepertoires which the music generation system constructed in this article are\nvery close to the style of Bach's original music, and it is relatively\ndifficult for ordinary people to distinguish the musics Bach authored and AI\ncreated.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/88b38ead4850fa87d12696f7569b591593061bdb",
      "published_date": "2021-10-06",
      "downloaded_date": "2025-02-01",
      "filename": "Kong-Bach Style Music Authoring System based on Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.02640v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1202.6153v1": {
      "title": "One Decade of Universal Artificial Intelligence",
      "authors": [
        "Marcus Hutter"
      ],
      "abstract": "The first decade of this century has seen the nascency of the first\nmathematical theory of general artificial intelligence. This theory of\nUniversal Artificial Intelligence (UAI) has made significant contributions to\nmany theoretical, philosophical, and practical AI questions. In a series of\npapers culminating in book (Hutter, 2005), an exciting sound and complete\nmathematical model for a super intelligent agent (AIXI) has been developed and\nrigorously analyzed. While nowadays most AI researchers avoid discussing\nintelligence, the award-winning PhD thesis (Legg, 2008) provided the\nphilosophical embedding and investigated the UAI-based universal measure of\nrational intelligence, which is formal, objective and non-anthropocentric.\nRecently, effective approximations of AIXI have been derived and experimentally\ninvestigated in JAIR paper (Veness et al. 2011). This practical breakthrough\nhas resulted in some impressive applications, finally muting earlier critique\nthat UAI is only a theory. For the first time, without providing any domain\nknowledge, the same agent is able to self-adapt to a diverse range of\ninteractive environments. For instance, AIXI is able to learn from scratch to\nplay TicTacToe, Pacman, Kuhn Poker, and other games by trial and error, without\neven providing the rules of the games.\n  These achievements give new hope that the grand goal of Artificial General\nIntelligence is not elusive.\n  This article provides an informal overview of UAI in context. It attempts to\ngently introduce a very theoretical, formal, and mathematical subject, and\ndiscusses philosophical and technical ingredients, traits of intelligence, some\nsocial questions, and the past and future of UAI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2012-02-28",
      "downloaded_date": "2025-02-01",
      "filename": "Hutter-One Decade of Universal Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1202.6153v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2011.08612v1": {
      "title": "Empowering Things with Intelligence: A Survey of the Progress, Challenges, and Opportunities in Artificial Intelligence of Things",
      "authors": [
        "Jing Zhang",
        "Dacheng Tao"
      ],
      "abstract": "In the Internet of Things (IoT) era, billions of sensors and devices collect\nand process data from the environment, transmit them to cloud centers, and\nreceive feedback via the internet for connectivity and perception. However,\ntransmitting massive amounts of heterogeneous data, perceiving complex\nenvironments from these data, and then making smart decisions in a timely\nmanner are difficult. Artificial intelligence (AI), especially deep learning,\nis now a proven success in various areas including computer vision, speech\nrecognition, and natural language processing. AI introduced into the IoT\nheralds the era of artificial intelligence of things (AIoT). This paper\npresents a comprehensive survey on AIoT to show how AI can empower the IoT to\nmake it faster, smarter, greener, and safer. Specifically, we briefly present\nthe AIoT architecture in the context of cloud computing, fog computing, and\nedge computing. Then, we present progress in AI research for IoT from four\nperspectives: perceiving, learning, reasoning, and behaving. Next, we summarize\nsome promising applications of AIoT that are likely to profoundly reshape our\nworld. Finally, we highlight the challenges facing AIoT and some potential\nresearch opportunities.",
      "citation_count": 420,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3e3df220673388402b6b114eab68a9c5396210b1",
      "published_date": "2020-11-17",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Empowering Things with Intelligence A Survey of the Progress Challenges and Opportunities in Artific....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2011.08612v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ]
    },
    "2105.07659v1": {
      "title": "Comparison of machine learning and deep learning techniques in promoter prediction across diverse species",
      "authors": [
        "Nikita Bhandari",
        "Satyajeet Khare",
        "Rahee Walambe",
        "Ketan Kotecha"
      ],
      "abstract": "Gene promoters are the key DNA regulatory elements positioned around the\ntranscription start sites and are responsible for regulating gene transcription\nprocess. Various alignment-based, signal-based and content-based approaches are\nreported for the prediction of promoters. However, since all promoter sequences\ndo not show explicit features, the prediction performance of these techniques\nis poor. Therefore, many machine learning and deep learning models have been\nproposed for promoter prediction. In this work, we studied methods for vector\nencoding and promoter classification using genome sequences of three distinct\nhigher eukaryotes viz. yeast (Saccharomyces cerevisiae), A. thaliana (plant)\nand human (Homo sapiens). We compared one-hot vector encoding method with\nfrequency-based tokenization (FBT) for data pre-processing on 1-D Convolutional\nNeural Network (CNN) model. We found that FBT gives a shorter input dimension\nreducing the training time without affecting the sensitivity and specificity of\nclassification. We employed the deep learning techniques, mainly CNN and\nrecurrent neural network with Long Short Term Memory (LSTM) and random forest\n(RF) classifier for promoter classification at k-mer sizes of 2, 4 and 8. We\nfound CNN to be superior in classification of promoters from non-promoter\nsequences (binary classification) as well as species-specific classification of\npromoter sequences (multiclass classification). In summary, the contribution of\nthis work lies in the use of synthetic shuffled negative dataset and\nfrequency-based tokenization for pre-processing. This study provides a\ncomprehensive and generic framework for classification tasks in genomic\napplications and can be extended to various classification problems.",
      "citation_count": 24,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d90abb15038b08cc051cd513f2177d6174cfd6f3",
      "published_date": "2021-05-17",
      "downloaded_date": "2025-02-01",
      "filename": "Bhandari-Comparison of machine learning and deep learning techniques in promoter prediction across diverse sp....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.07659v1",
      "categories": [
        "q-bio.GN",
        "cs.LG"
      ]
    },
    "2107.13454v1": {
      "title": "Artificial Intelligence in Healthcare: Lost In Translation?",
      "authors": [
        "Vince I. Madai",
        "David C. Higgins"
      ],
      "abstract": "Artificial intelligence (AI) in healthcare is a potentially revolutionary\ntool to achieve improved healthcare outcomes while reducing overall health\ncosts. While many exploratory results hit the headlines in recent years there\nare only few certified and even fewer clinically validated products available\nin the clinical setting. This is a clear indication of failing translation due\nto shortcomings of the current approach to AI in healthcare. In this work, we\nhighlight the major areas, where we observe current challenges for translation\nin AI in healthcare, namely precision medicine, reproducible science, data\nissues and algorithms, causality, and product development. For each field, we\noutline possible solutions for these challenges. Our work will lead to improved\ntranslation of AI in healthcare products into the clinical setting",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7e4058161b7c9897a74ac6a20054c4fd1bef804b",
      "published_date": "2021-07-28",
      "downloaded_date": "2025-02-01",
      "filename": "Madai-Artificial Intelligence in Healthcare Lost In Translation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.13454v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2306.01495v1": {
      "title": "Accelerating science with human-aware artificial intelligence",
      "authors": [
        "Jamshid Sourati",
        "James Evans"
      ],
      "abstract": "Artificial intelligence (AI) models trained on published scientific findings\nhave been used to invent valuable materials and targeted therapies, but they\ntypically ignore the human scientists who continually alter the landscape of\ndiscovery. Here we show that incorporating the distribution of human expertise\nby training unsupervised models on simulated inferences cognitively accessible\nto experts dramatically improves (up to 400%) AI prediction of future\ndiscoveries beyond those focused on research content alone, especially when\nrelevant literature is sparse. These models succeed by predicting human\npredictions and the scientists who will make them. By tuning human-aware AI to\navoid the crowd, we can generate scientifically promising \"alien\" hypotheses\nunlikely to be imagined or pursued without intervention until the distant\nfuture, which hold promise to punctuate scientific advance beyond questions\ncurrently pursued. Accelerating human discovery or probing its blind spots,\nhuman-aware AI enables us to move toward and beyond the contemporary scientific\nfrontier.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-06-02",
      "downloaded_date": "2025-02-01",
      "filename": "Sourati-Accelerating science with human-aware artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.01495v1",
      "categories": [
        "cs.AI",
        "cs.SI"
      ]
    },
    "1404.7828v4": {
      "title": "Deep Learning in Neural Networks: An Overview",
      "authors": [
        "Juergen Schmidhuber"
      ],
      "abstract": "In recent years, deep artificial neural networks (including recurrent ones)\nhave won numerous contests in pattern recognition and machine learning. This\nhistorical survey compactly summarises relevant work, much of it from the\nprevious millennium. Shallow and deep learners are distinguished by the depth\nof their credit assignment paths, which are chains of possibly learnable,\ncausal links between actions and effects. I review deep supervised learning\n(also recapitulating the history of backpropagation), unsupervised learning,\nreinforcement learning & evolutionary computation, and indirect search for\nshort programs encoding deep and large networks.",
      "citation_count": 15834,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/193edd20cae92c6759c18ce93eeea96afd9528eb",
      "published_date": "2014-04-30",
      "downloaded_date": "2025-02-01",
      "filename": "Schmidhuber-Deep Learning in Neural Networks An Overview.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1404.7828v4",
      "categories": [
        "cs.NE",
        "cs.LG"
      ]
    },
    "2411.19858v1": {
      "title": "What fifty-one years of Linguistics and Artificial Intelligence research tell us about their correlation: A scientometric review",
      "authors": [
        "Mohammed Q. Shormani"
      ],
      "abstract": "There is a strong correlation between linguistics and artificial intelligence\n(AI), best manifested by deep learning language models. This study provides a\nthorough scientometric analysis of this correlation, synthesizing the\nintellectual production during 51 years, from 1974 to 2024. It involves 5750\nWeb of Science-indexed articles published in 2124 journals, which are written\nby 20835 authors belonging to 13773 research centers in 794 countries. Two\npowerful software, viz., CiteSpace and VOSviewer, were used to generate mapping\nvisualizations of the intellectual landscape, trending issues and (re)emerging\nhotspots. The results indicate that in the 1980s and 1990s, linguistics and AI\nresearch was not robust, characterized by unstable publication over time. It\nhas, however, witnessed a remarkable increase of publication since then,\nreaching 1478 articles in 2023, and 546 articles in January-March timespan in\n2024, involving emerging issues and hotspots, addressing new horizons, new\ntopics, and launching new applications and powerful deep learning language\nmodels including ChatGPT.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f86517182f596ac4154fa129a64a079277c50e13",
      "published_date": "2024-11-29",
      "downloaded_date": "2025-02-01",
      "filename": "Shormani-What fifty-one years of Linguistics and Artificial Intelligence research tell us about their correla....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.19858v1",
      "categories": [
        "cs.CL",
        "cs-CL",
        "F.2.2; I.2.7"
      ]
    },
    "2312.12022v1": {
      "title": "LightGCNet: A Lightweight Geometric Constructive Neural Network for Data-Driven Soft sensors",
      "authors": [
        "Jing Nan",
        "Yan Qin",
        "Wei Dai",
        "Chau Yuen"
      ],
      "abstract": "Data-driven soft sensors provide a potentially cost-effective and more\naccurate modeling approach to measure difficult-to-measure indices in\nindustrial processes compared to mechanistic approaches. Artificial\nintelligence (AI) techniques, such as deep learning, have become a popular soft\nsensors modeling approach in the area of machine learning and big data.\nHowever, soft sensors models based deep learning potentially lead to complex\nmodel structures and excessive training time. In addition, industrial processes\noften rely on distributed control systems (DCS) characterized by resource\nconstraints. Herein, guided by spatial geometric, a lightweight geometric\nconstructive neural network, namely LightGCNet, is proposed, which utilizes\ncompact angle constraint to assign the hidden parameters from dynamic\nintervals. At the same time, a node pool strategy and spatial geometric\nrelationships are used to visualize and optimize the process of assigning\nhidden parameters, enhancing interpretability. In addition, the universal\napproximation property of LightGCNet is proved by spatial geometric analysis.\nTwo versions algorithmic implementations of LightGCNet are presented in this\narticle. Simulation results concerning both benchmark datasets and the ore\ngrinding process indicate remarkable merits of LightGCNet in terms of small\nnetwork size, fast learning speed, and sound generalization.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-12-19",
      "downloaded_date": "2025-02-01",
      "filename": "Nan-LightGCNet A Lightweight Geometric Constructive Neural Network for Data-Driven Soft sensors.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.12022v1",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    "2104.11142v1": {
      "title": "Deep learning for detecting bid rigging: Flagging cartel participants based on convolutional neural networks",
      "authors": [
        "Martin Huber",
        "David Imhof"
      ],
      "abstract": "Adding to the literature on the data-driven detection of bid-rigging cartels,\nwe propose a novel approach based on deep learning (a subfield of artificial\nintelligence) that flags cartel participants based on their pairwise bidding\ninteractions with other firms. More concisely, we combine a so-called\nconvolutional neural network for image recognition with graphs that in a\npairwise manner plot the normalized bid values of some reference firm against\nthe normalized bids of any other firms participating in the same tenders as the\nreference firm. Based on Japanese and Swiss procurement data, we construct such\ngraphs for both collusive and competitive episodes (i.e when a bid-rigging\ncartel is or is not active) and use a subset of graphs to train the neural\nnetwork such that it learns distinguishing collusive from competitive bidding\npatterns. We use the remaining graphs to test the neural network's\nout-of-sample performance in correctly classifying collusive and competitive\nbidding interactions. We obtain a very decent average accuracy of around 90% or\nslightly higher when either applying the method within Japanese, Swiss, or\nmixed data (in which Swiss and Japanese graphs are pooled). When using data\nfrom one country for training to test the trained model's performance in the\nother country (i.e. transnationally), predictive performance decreases (likely\ndue to institutional differences in procurement procedures across countries),\nbut often remains satisfactorily high. All in all, the generally quite high\naccuracy of the convolutional neural network despite being trained in a rather\nsmall sample of a few 100 graphs points to a large potential of deep learning\napproaches for flagging and fighting bid-rigging cartels.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-04-22",
      "downloaded_date": "2025-02-01",
      "filename": "Huber-Deep learning for detecting bid rigging Flagging cartel participants based on convolutional neural n....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.11142v1",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    "2308.15339v1": {
      "title": "AI Framework for Early Diagnosis of Coronary Artery Disease: An Integration of Borderline SMOTE, Autoencoders and Convolutional Neural Networks Approach",
      "authors": [
        "Elham Nasarian",
        "Danial Sharifrazi",
        "Saman Mohsenirad",
        "Kwok Tsui",
        "Roohallah Alizadehsani"
      ],
      "abstract": "The accuracy of coronary artery disease (CAD) diagnosis is dependent on a\nvariety of factors, including demographic, symptom, and medical examination,\nECG, and echocardiography data, among others. In this context, artificial\nintelligence (AI) can help clinicians identify high-risk patients early in the\ndiagnostic process, by synthesizing information from multiple factors. To this\naim, Machine Learning algorithms are used to classify patients based on their\nCAD disease risk. In this study, we contribute to this research filed by\ndeveloping a methodology for balancing and augmenting data for more accurate\nprediction when the data is imbalanced and the sample size is small. The\nmethodology can be used in a variety of other situations, particularly when\ndata collection is expensive and the sample size is small. The experimental\nresults revealed that the average accuracy of our proposed method for CAD\nprediction was 95.36, and was higher than random forest (RF), decision tree\n(DT), support vector machine (SVM), logistic regression (LR), and artificial\nneural network (ANN).",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-08-29",
      "downloaded_date": "2025-02-01",
      "filename": "Nasarian-AI Framework for Early Diagnosis of Coronary Artery Disease An Integration of Borderline SMOTE Autoe....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.15339v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2406.15132v1": {
      "title": "Younger: The First Dataset for Artificial Intelligence-Generated Neural Network Architecture",
      "authors": [
        "Zhengxin Yang",
        "Wanling Gao",
        "Luzhou Peng",
        "Yunyou Huang",
        "Fei Tang",
        "Jianfeng Zhan"
      ],
      "abstract": "Designing and optimizing neural network architectures typically requires\nextensive expertise, starting with handcrafted designs and then manual or\nautomated refinement. This dependency presents a significant barrier to rapid\ninnovation. Recognizing the complexity of automatically generating neural\nnetwork architecture from scratch, we introduce Younger, a pioneering dataset\nto advance this ambitious goal. Derived from over 174K real-world models across\nmore than 30 tasks from various public model hubs, Younger includes 7,629\nunique architectures, and each is represented as a directed acyclic graph with\ndetailed operator-level information. The dataset facilitates two primary design\nparadigms: global, for creating complete architectures from scratch, and local,\nfor detailed architecture component refinement. By establishing these\ncapabilities, Younger contributes to a new frontier, Artificial\nIntelligence-Generated Neural Network Architecture (AIGNNA). Our experiments\nexplore the potential and effectiveness of Younger for automated architecture\ngeneration and, as a secondary benefit, demonstrate that Younger can serve as a\nbenchmark dataset, advancing the development of graph neural networks. We\nrelease the dataset and code publicly to lower the entry barriers and encourage\nfurther research in this challenging area.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0e00df5915c1c58d01c1e0f81b6045cf9f64aaf3",
      "published_date": "2024-06-20",
      "downloaded_date": "2025-02-01",
      "filename": "Yang-Younger The First Dataset for Artificial Intelligence-Generated Neural Network Architecture.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.15132v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2112.09325v2": {
      "title": "Dilemma of the Artificial Intelligence Regulatory Landscape",
      "authors": [
        "Weiyue Wu",
        "Shaoshan Liu"
      ],
      "abstract": "As a startup company in the autonomous driving space, we have undergone four\nyears of painful experiences dealing with a broad spectrum of regulatory\nrequirements. Compared to the software industry norm, which spends 13% of their\noverall budget on compliances, we were forced to spend 42% of our budget on\ncompliances. Our situation is not alone and, in a way, reflects the dilemma of\nthe artificial intelligence (AI) regulatory landscape. The root cause is the\nlack of AI expertise in the legislative and executive branches, leading to a\nlack of standardization for the industry to follow. In this article, we share\nour first-hand experiences and advocate for the establishment of an FDA-like\nagency to regulate AI properly.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-12-17",
      "downloaded_date": "2025-02-01",
      "filename": "Wu-Dilemma of the Artificial Intelligence Regulatory Landscape.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2112.09325v2",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2303.12732v1": {
      "title": "Unfinished Architectures: A Perspective from Artificial Intelligence",
      "authors": [
        "Elena Merino-GÃ³mez",
        "Pedro Reviriego",
        "Fernando Moral"
      ],
      "abstract": "Unfinished buildings are a constant throughout the history of architecture\nand have given rise to intense debates on the opportuneness of their\ncompletion, in addition to offering alibis for theorizing about the\ncompositional possibilities in coherence with the finished parts. The\ndevelopment of Artificial Intelligence (AI) opens new avenues for the proposal\nof possibilities for the completion of unfinished architectures. Specifically,\nwith the recent appearance of tools such as DALL-E, capable of completing\nimages guided by a textual description, it is possible to count on the help of\nAI for architectural design tasks. In this article we explore the use of these\nnew AI tools for the completion of unfinished facades of historical temples and\nanalyse the still germinal stadium in the field of architectural graphic\ncomposition.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/24b27ae89d1946d7e0baa686e6cac2c6e9e3df7c",
      "published_date": "2023-03-03",
      "downloaded_date": "2025-02-01",
      "filename": "Merino-GÃ³mez-Unfinished Architectures A Perspective from Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.12732v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "1901.02256v2": {
      "title": "Artificial Intelligence and Machine Learning to Predict and Improve Efficiency in Manufacturing Industry",
      "authors": [
        "Ibtissam El Hassani",
        "Choumicha El Mazgualdi",
        "Tawfik Masrour"
      ],
      "abstract": "The overall equipment effectiveness (OEE) is a performance measurement metric\nwidely used. Its calculation provides to the managers the possibility to\nidentify the main losses that reduce the machine effectiveness and then take\nthe necessary decisions in order to improve the situation. However, this\ncalculation is done a-posterior which is often too late. In the present\nresearch, we implemented different Machine Learning algorithms namely; Support\nvector machine, Optimized Support vector Machine (using Genetic Algorithm),\nRandom Forest, XGBoost and Deep Learning to predict the estimate OEE value. The\ndata used to train our models was provided by an automotive cable production\nindustry. The results show that the Deep Learning and Random Forest are more\naccurate and present better performance for the prediction of the overall\nequipment effectiveness in our case study.",
      "citation_count": 12,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7f5e94fb0a52d4be90f5107d3304721edebe3e0a",
      "published_date": "2019-01-08",
      "downloaded_date": "2025-02-01",
      "filename": "Hassani-Artificial Intelligence and Machine Learning to Predict and Improve Efficiency in Manufacturing Indu....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.02256v2",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2109.06098v1": {
      "title": "The mathematics of adversarial attacks in AI -- Why deep learning is unstable despite the existence of stable neural networks",
      "authors": [
        "Alexander Bastounis",
        "Anders C Hansen",
        "Verner VlaÄiÄ"
      ],
      "abstract": "The unprecedented success of deep learning (DL) makes it unchallenged when it\ncomes to classification problems. However, it is well established that the\ncurrent DL methodology produces universally unstable neural networks (NNs). The\ninstability problem has caused an enormous research effort -- with a vast\nliterature on so-called adversarial attacks -- yet there has been no solution\nto the problem. Our paper addresses why there has been no solution to the\nproblem, as we prove the following mathematical paradox: any training procedure\nbased on training neural networks for classification problems with a fixed\narchitecture will yield neural networks that are either inaccurate or unstable\n(if accurate) -- despite the provable existence of both accurate and stable\nneural networks for the same classification problems. The key is that the\nstable and accurate neural networks must have variable dimensions depending on\nthe input, in particular, variable dimensions is a necessary condition for\nstability.\n  Our result points towards the paradox that accurate and stable neural\nnetworks exist, however, modern algorithms do not compute them. This yields the\nquestion: if the existence of neural networks with desirable properties can be\nproven, can one also find algorithms that compute them? There are cases in\nmathematics where provable existence implies computability, but will this be\nthe case for neural networks? The contrary is true, as we demonstrate how\nneural networks can provably exist as approximate minimisers to standard\noptimisation problems with standard cost functions, however, no randomised\nalgorithm can compute them with probability better than 1/2.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-09-13",
      "downloaded_date": "2025-02-01",
      "filename": "Bastounis-The mathematics of adversarial attacks in AI -- Why deep learning is unstable despite the existence ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2109.06098v1",
      "categories": [
        "cs.LG",
        "cs.CV",
        "cs.NA",
        "math.NA",
        "stat.ML"
      ]
    },
    "1909.12063v1": {
      "title": "Artificial Intelligence BlockCloud (AIBC) Technical Whitepaper",
      "authors": [
        "Qi Deng"
      ],
      "abstract": "The AIBC is an Artificial Intelligence and blockchain technology based\nlarge-scale decentralized ecosystem that allows system-wide low-cost sharing of\ncomputing and storage resources. The AIBC consists of four layers: a\nfundamental layer, a resource layer, an application layer, and an ecosystem\nlayer. The AIBC implements a two-consensus scheme to enforce upper-layer\neconomic policies and achieve fundamental layer performance and robustness: the\nDPoEV incentive consensus on the application and resource layers, and the DABFT\ndistributed consensus on the fundamental layer. The DABFT uses deep learning\ntechniques to predict and select the most suitable BFT algorithm in order to\nachieve the best balance of performance, robustness, and security. The DPoEV\nuses the knowledge map algorithm to accurately assess the economic value of\ndigital assets.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7f09ef93e31b88abee3ec3d5034405acd232d133",
      "published_date": "2019-09-26",
      "downloaded_date": "2025-02-01",
      "filename": "Deng-Artificial Intelligence BlockCloud AIBC Technical Whitepaper.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1909.12063v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-fin.ST",
        "stat.ML"
      ]
    },
    "2205.10768v1": {
      "title": "Neuro-Symbolic Artificial Intelligence (AI) for Intent based Semantic Communication",
      "authors": [
        "Christo Kurisummoottil Thomas",
        "Walid Saad"
      ],
      "abstract": "Intent-based networks that integrate sophisticated machine reasoning\ntechnologies will be a cornerstone of future wireless 6G systems. Intent-based\ncommunication requires the network to consider the semantics (meanings) and\neffectiveness (at end-user) of the data transmission. This is essential if 6G\nsystems are to communicate reliably with fewer bits while simultaneously\nproviding connectivity to heterogeneous users. In this paper, contrary to state\nof the art, which lacks explainability of data, the framework of neuro-symbolic\nartificial intelligence (NeSy AI) is proposed as a pillar for learning causal\nstructure behind the observed data. In particular, the emerging concept of\ngenerative flow networks (GFlowNet) is leveraged for the first time in a\nwireless system to learn the probabilistic structure which generates the data.\nFurther, a novel optimization problem for learning the optimal encoding and\ndecoding functions is rigorously formulated with the intent of achieving higher\nsemantic reliability. Novel analytical formulations are developed to define key\nmetrics for semantic message transmission, including semantic distortion,\nsemantic similarity, and semantic reliability. These semantic measure functions\nrely on the proposed definition of semantic content of the knowledge base and\nthis information measure is reflective of the nodes' reasoning capabilities.\nSimulation results validate the ability to communicate efficiently (with less\nbits but same semantics) and significantly better compared to a conventional\nsystem which does not exploit the reasoning capabilities.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-05-22",
      "downloaded_date": "2025-02-01",
      "filename": "Thomas-Neuro-Symbolic Artificial Intelligence AI for Intent based Semantic Communication.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.10768v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ]
    },
    "1708.05969v5": {
      "title": "Applying Data Augmentation to Handwritten Arabic Numeral Recognition Using Deep Learning Neural Networks",
      "authors": [
        "Akm Ashiquzzaman",
        "Abdul Kawsar Tushar",
        "Md Ashiqur Rahman"
      ],
      "abstract": "Handwritten character recognition has been the center of research and a\nbenchmark problem in the sector of pattern recognition and artificial\nintelligence, and it continues to be a challenging research topic. Due to its\nenormous application many works have been done in this field focusing on\ndifferent languages. Arabic, being a diversified language has a huge scope of\nresearch with potential challenges. A convolutional neural network model for\nrecognizing handwritten numerals in Arabic language is proposed in this paper,\nwhere the dataset is subject to various augmentation in order to add robustness\nneeded for deep learning approach. The proposed method is empowered by the\npresence of dropout regularization to do away with the problem of data\noverfitting. Moreover, suitable change is introduced in activation function to\novercome the problem of vanishing gradient. With these modifications, the\nproposed system achieves an accuracy of 99.4\\% which performs better than every\nprevious work on the dataset.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f11a44998a09d2e3dc732e7331237f198485ff04",
      "published_date": "2017-08-20",
      "downloaded_date": "2025-02-01",
      "filename": "Ashiquzzaman-Applying Data Augmentation to Handwritten Arabic Numeral Recognition Using Deep Learning Neural Netw....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1708.05969v5",
      "categories": [
        "cs.CV"
      ]
    },
    "1801.08570v2": {
      "title": "Deep Learning in Pharmacogenomics: From Gene Regulation to Patient Stratification",
      "authors": [
        "Alexandr A. Kalinin",
        "Gerald A. Higgins",
        "Narathip Reamaroon",
        "S. M. Reza Soroushmehr",
        "Ari Allyn-Feuer",
        "Ivo D. Dinov",
        "Kayvan Najarian",
        "Brian D. Athey"
      ],
      "abstract": "This Perspective provides examples of current and future applications of deep\nlearning in pharmacogenomics, including: (1) identification of novel regulatory\nvariants located in noncoding domains and their function as applied to\npharmacoepigenomics; (2) patient stratification from medical records; and (3)\nprediction of drugs, targets, and their interactions. Deep learning\nencapsulates a family of machine learning algorithms that over the last decade\nhas transformed many important subfields of artificial intelligence (AI) and\nhas demonstrated breakthrough performance improvements on a wide range of tasks\nin biomedicine. We anticipate that in the future deep learning will be widely\nused to predict personalized drug response and optimize medication selection\nand dosing, using knowledge extracted from large and complex molecular,\nepidemiological, clinical, and demographic datasets.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-01-25",
      "downloaded_date": "2025-02-01",
      "filename": "Kalinin-Deep Learning in Pharmacogenomics From Gene Regulation to Patient Stratification.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1801.08570v2",
      "categories": [
        "q-bio.QM",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2212.10535v2": {
      "title": "A Survey of Deep Learning for Mathematical Reasoning",
      "authors": [
        "Pan Lu",
        "Liang Qiu",
        "Wenhao Yu",
        "Sean Welleck",
        "Kai-Wei Chang"
      ],
      "abstract": "Mathematical reasoning is a fundamental aspect of human intelligence and is\napplicable in various fields, including science, engineering, finance, and\neveryday life. The development of artificial intelligence (AI) systems capable\nof solving math problems and proving theorems has garnered significant interest\nin the fields of machine learning and natural language processing. For example,\nmathematics serves as a testbed for aspects of reasoning that are challenging\nfor powerful deep learning models, driving new algorithmic and modeling\nadvances. On the other hand, recent advances in large-scale neural language\nmodels have opened up new benchmarks and opportunities to use deep learning for\nmathematical reasoning. In this survey paper, we review the key tasks,\ndatasets, and methods at the intersection of mathematical reasoning and deep\nlearning over the past decade. We also evaluate existing benchmarks and\nmethods, and discuss future research directions in this domain.",
      "citation_count": 114,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2dbec38fe353ab0e495ad09263389dbc9260824d",
      "published_date": "2022-12-20",
      "downloaded_date": "2025-02-01",
      "filename": "Lu-A Survey of Deep Learning for Mathematical Reasoning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2212.10535v2",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2008.12672v2": {
      "title": "From the digital data revolution to digital health and digital economy toward a digital society: Pervasiveness of Artificial Intelligence",
      "authors": [
        "Frank Emmert-Streib"
      ],
      "abstract": "Technological progress has led to powerful computers and communication\ntechnologies that penetrate nowadays all areas of science, industry and our\nprivate lives. As a consequence, all these areas are generating digital traces\nof data amounting to big data resources. This opens unprecedented opportunities\nbut also challenges toward the analysis, management, interpretation and\nutilization of these data. Fortunately, recent breakthroughs in deep learning\nalgorithms complement now machine learning and statistics methods for an\nefficient analysis of such data. Furthermore, advances in text mining and\nnatural language processing, e.g., word-embedding methods, enable also the\nprocessing of large amounts of text data from diverse sources as governmental\nreports, blog entries in social media or clinical health records of patients.\nIn this paper, we present a perspective on the role of artificial intelligence\nin these developments and discuss also potential problems we are facing in a\ndigital society.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fc780b74de8f34156f9905d6a032aff301cc2e02",
      "published_date": "2020-08-03",
      "downloaded_date": "2025-02-01",
      "filename": "Emmert-Streib-From the digital data revolution to digital health and digital economy toward a digital society Perv....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.12672v2",
      "categories": [
        "cs.GL"
      ]
    },
    "2004.07580v2": {
      "title": "If deep learning is the answer, then what is the question?",
      "authors": [
        "Andrew Saxe",
        "Stephanie Nelli",
        "Christopher Summerfield"
      ],
      "abstract": "Neuroscience research is undergoing a minor revolution. Recent advances in\nmachine learning and artificial intelligence (AI) research have opened up new\nways of thinking about neural computation. Many researchers are excited by the\npossibility that deep neural networks may offer theories of perception,\ncognition and action for biological brains. This perspective has the potential\nto radically reshape our approach to understanding neural systems, because the\ncomputations performed by deep networks are learned from experience, not\nendowed by the researcher. If so, how can neuroscientists use deep networks to\nmodel and understand biological brains? What is the outlook for neuroscientists\nwho seek to characterise computations or neural codes, or who wish to\nunderstand perception, attention, memory, and executive functions? In this\nPerspective, our goal is to offer a roadmap for systems neuroscience research\nin the age of deep learning. We discuss the conceptual and methodological\nchallenges of comparing behaviour, learning dynamics, and neural representation\nin artificial and biological systems. We highlight new research questions that\nhave emerged for neuroscience as a direct consequence of recent advances in\nmachine learning.",
      "citation_count": 21,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/40beead5569bd6797e2de4b30e1b7358097ab16f",
      "published_date": "2020-04-16",
      "downloaded_date": "2025-02-01",
      "filename": "Saxe-If deep learning is the answer then what is the question.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.07580v2",
      "categories": [
        "q-bio.NC"
      ]
    },
    "1409.0813v2": {
      "title": "Friendly Artificial Intelligence: the Physics Challenge",
      "authors": [
        "Max Tegmark"
      ],
      "abstract": "Relentless progress in artificial intelligence (AI) is increasingly raising\nconcerns that machines will replace humans on the job market, and perhaps\naltogether. Eliezer Yudkowski and others have explored the possibility that a\npromising future for humankind could be guaranteed by a superintelligent\n\"Friendly AI\", designed to safeguard humanity and its values. I argue that,\nfrom a physics perspective where everything is simply an arrangement of\nelementary particles, this might be even harder than it appears. Indeed, it may\nrequire thinking rigorously about the meaning of life: What is \"meaning\" in a\nparticle arrangement? What is \"life\"? What is the ultimate ethical imperative,\ni.e., how should we strive to rearrange the particles of our Universe and shape\nits future? If we fail to answer the last question rigorously, this future is\nunlikely to contain humans.",
      "citation_count": 12,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2fdfd65ef5a23866daf8448361f85ae5ae55ba18",
      "published_date": "2014-09-02",
      "downloaded_date": "2025-02-01",
      "filename": "Tegmark-Friendly Artificial Intelligence the Physics Challenge.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1409.0813v2",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "1812.11509v2": {
      "title": "AIR5: Five Pillars of Artificial Intelligence Research",
      "authors": [
        "Yew-Soon Ong",
        "Abhishek Gupta"
      ],
      "abstract": "In this article, we provide and overview of what we consider to be some of\nthe most pressing research questions facing the fields of artificial\nintelligence (AI) and computational intelligence (CI); with the latter focusing\non algorithms that are inspired by various natural phenomena. We demarcate\nthese questions using five unique Rs - namely, (i) rationalizability, (ii)\nresilience, (iii) reproducibility, (iv) realism, and (v) responsibility.\nNotably, just as air serves as the basic element of biological life, the term\nAIR5 - cumulatively referring to the five aforementioned Rs - is introduced\nherein to mark some of the basic elements of artificial life (supporting the\nsustained growth of AI and CI). A brief summary of each of the Rs is presented,\nhighlighting their relevance as pillars of future research in this arena.",
      "citation_count": 27,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7315225938ab144cedf30c9a4c5a035956a270b0",
      "published_date": "2018-12-30",
      "downloaded_date": "2025-02-01",
      "filename": "Ong-AIR5 Five Pillars of Artificial Intelligence Research.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1812.11509v2",
      "categories": [
        "cs.AI"
      ]
    },
    "1803.09992v1": {
      "title": "Applications of Artificial Intelligence to Network Security",
      "authors": [
        "Alberto Perez Veiga"
      ],
      "abstract": "Attacks to networks are becoming more complex and sophisticated every day.\nBeyond the so-called script-kiddies and hacking newbies, there is a myriad of\nprofessional attackers seeking to make serious profits infiltrating in\ncorporate networks. Either hostile governments, big corporations or mafias are\nconstantly increasing their resources and skills in cybercrime in order to spy,\nsteal or cause damage more effectively. traditional approaches to Network\nSecurity seem to start hitting their limits and it is being recognized the need\nfor a smarter approach to threat detections. This paper provides an\nintroduction on the need for evolution of Cyber Security techniques and how\nArtificial Intelligence could be of application to help solving some of the\nproblems. It provides also, a high-level overview of some state of the art AI\nNetwork Security techniques, to finish analysing what is the foreseeable future\nof the application of AI to Network Security.",
      "citation_count": 13,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1105eece0d09cf210aeb3a2a14432aa035c032b3",
      "published_date": "2018-03-27",
      "downloaded_date": "2025-02-01",
      "filename": "Veiga-Applications of Artificial Intelligence to Network Security.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1803.09992v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ]
    },
    "2105.10866v1": {
      "title": "Towards Artificial Intelligence Enabled Financial Crime Detection",
      "authors": [
        "Zeinab Rouhollahi"
      ],
      "abstract": "Recently, financial institutes have been dealing with an increase in\nfinancial crimes. In this context, financial services firms started to improve\ntheir vigilance and use new technologies and approaches to identify and predict\nfinancial fraud and crime possibilities. This task is challenging as\ninstitutions need to upgrade their data and analytics capabilities to enable\nnew technologies such as Artificial Intelligence (AI) to predict and detect\nfinancial crimes. In this paper, we put a step towards AI-enabled financial\ncrime detection in general and money laundering detection in particular to\naddress this challenge. We study and analyse the recent works done in financial\ncrime detection and present a novel model to detect money laundering cases with\nminimum human intervention needs.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/23dd8c80851032c88ecb6eb2bf116eaceddbb0a7",
      "published_date": "2021-05-23",
      "downloaded_date": "2025-02-01",
      "filename": "Rouhollahi-Towards Artificial Intelligence Enabled Financial Crime Detection.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.10866v1",
      "categories": [
        "cs.LG",
        "cs.IR",
        "q-fin.ST"
      ]
    },
    "2210.05103v1": {
      "title": "Leveraging Artificial Intelligence on Binary Code Comprehension",
      "authors": [
        "Yifan Zhang"
      ],
      "abstract": "Understanding binary code is an essential but complex software engineering\ntask for reverse engineering, malware analysis, and compiler optimization.\nUnlike source code, binary code has limited semantic information, which makes\nit challenging for human comprehension. At the same time, compiling source to\nbinary code, or transpiling among different programming languages (PLs) can\nprovide a way to introduce external knowledge into binary comprehension. We\npropose to develop Artificial Intelligence (AI) models that aid human\ncomprehension of binary code. Specifically, we propose to incorporate domain\nknowledge from large corpora of source code (e.g., variable names, comments) to\nbuild AI models that capture a generalizable representation of binary code.\nLastly, we will investigate metrics to assess the performance of models that\napply to binary code by using human studies of comprehension.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-10-11",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Leveraging Artificial Intelligence on Binary Code Comprehension.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.05103v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    "2310.20474v1": {
      "title": "Critical Role of Artificially Intelligent Conversational Chatbot",
      "authors": [
        "Seraj A. M. Mostafa",
        "Md Z. Islam",
        "Mohammad Z. Islam",
        "Fairose Jeehan",
        "Saujanna Jafreen",
        "Raihan U. Islam"
      ],
      "abstract": "Artificially intelligent chatbot, such as ChatGPT, represents a recent and\npowerful advancement in the AI domain. Users prefer them for obtaining quick\nand precise answers, avoiding the usual hassle of clicking through multiple\nlinks in traditional searches. ChatGPT's conversational approach makes it\ncomfortable and accessible for finding answers quickly and in an organized\nmanner. However, it is important to note that these chatbots have limitations,\nespecially in terms of providing accurate answers as well as ethical concerns.\nIn this study, we explore various scenarios involving ChatGPT's ethical\nimplications within academic contexts, its limitations, and the potential\nmisuse by specific user groups. To address these challenges, we propose\narchitectural solutions aimed at preventing inappropriate use and promoting\nresponsible AI interactions.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ff790f1121c5960ca3c91e48dcfe835f483a1aed",
      "published_date": "2023-10-31",
      "downloaded_date": "2025-02-01",
      "filename": "Mostafa-Critical Role of Artificially Intelligent Conversational Chatbot.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.20474v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1802.03417v1": {
      "title": "Narrow Artificial Intelligence with Machine Learning for Real-Time Estimation of a Mobile Agents Location Using Hidden Markov Models",
      "authors": [
        "CÃ©dric Beaulac",
        "Fabrice Larribe"
      ],
      "abstract": "We propose to use a supervised machine learning technique to track the\nlocation of a mobile agent in real time. Hidden Markov Models are used to build\nartificial intelligence that estimates the unknown position of a mobile target\nmoving in a defined environment. This narrow artificial intelligence performs\ntwo distinct tasks. First, it provides real-time estimation of the mobile\nagent's position using the forward algorithm. Second, it uses the Baum-Welch\nalgorithm as a statistical learning tool to gain knowledge of the mobile\ntarget. Finally, an experimental environment is proposed, namely a video game\nthat we use to test our artificial intelligence. We present statistical and\ngraphical results to illustrate the efficiency of our method.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e86d0100a40638fec425a608c2e1cb3fe30289aa",
      "published_date": "2018-02-09",
      "downloaded_date": "2025-02-01",
      "filename": "Beaulac-Narrow Artificial Intelligence with Machine Learning for Real-Time Estimation of a Mobile Agents Loc....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1802.03417v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2407.19277v2": {
      "title": "Predicting the Progression of Cancerous Tumors in Mice: A Machine and Deep Learning Intuition",
      "authors": [
        "Amit K Chattopadhyay",
        "Aimee Pascaline N Unkundiye",
        "Gillian Pearce",
        "Steven Russell"
      ],
      "abstract": "The study explores Artificial Intelligence (AI) powered modeling to predict\nthe evolution of cancer tumor cells in mice under different forms of treatment.\nThe AI models are analyzed against varying ambient and systemic parameters,\ne.g. drug dosage, volume of the cancer cell mass, and time taken to destroy the\ncancer cell mass. The data required for the analysis have been synthetically\nextracted from plots available in both published and unpublished literature\n(primarily using a Matlab architecture called \"Grabit\"), that are then\nstatistically standardized around the same baseline for comparison. Three forms\nof treatment are considered - saline (multiple concentrations used), magnetic\nnanoparticles (mNPs) and fluorodeoxyglycose iron oxide magnetic nanoparticles\n(mNP-FDGs) - analyzed using three Machine Learning (ML) algorithms, Decision\nTree (DT), Random Forest (RF), Multilinear Regression (MLR), and a Deep\nLearning (DL) module, the Adaptive Neural Network (ANN). The AI models are\ntrained on 60-80% data, the rest used for validation. Assessed over all three\nforms of treatment, ANN consistently outperforms other predictive models. Our\nmodels predict mNP-FDG as the most potent treatment regime that kills the\ncancerous tumor completely in ca 13 days from the start of treatment. The\nmodels can be generalized to other forms of cancer treatment regimens.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9be5e5de1a6156bbe16ed0e4ab0c7f59852e7f61",
      "published_date": "2024-07-27",
      "downloaded_date": "2025-02-01",
      "filename": "Chattopadhyay-Predicting the Progression of Cancerous Tumors in Mice A Machine and Deep Learning Intuition.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.19277v2",
      "categories": [
        "physics.bio-ph",
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    },
    "2107.04540v2": {
      "title": "Objective task-based evaluation of artificial intelligence-based medical imaging methods: Framework, strategies and role of the physician",
      "authors": [
        "Abhinav K. Jha",
        "Kyle J. Myers",
        "Nancy A. Obuchowski",
        "Ziping Liu",
        "Md Ashequr Rahman",
        "Babak Saboury",
        "Arman Rahmim",
        "Barry A. Siegel"
      ],
      "abstract": "Artificial intelligence (AI)-based methods are showing promise in multiple\nmedical-imaging applications. Thus, there is substantial interest in clinical\ntranslation of these methods, requiring in turn, that they be evaluated\nrigorously. In this paper, our goal is to lay out a framework for objective\ntask-based evaluation of AI methods. We will also provide a list of tools\navailable in the literature to conduct this evaluation. Further, we outline the\nimportant role of physicians in conducting these evaluation studies. The\nexamples in this paper will be proposed in the context of PET with a focus on\nneural-network-based methods. However, the framework is also applicable to\nevaluate other medical-imaging modalities and other types of AI methods.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-07-09",
      "downloaded_date": "2025-02-01",
      "filename": "Jha-Objective task-based evaluation of artificial intelligence-based medical imaging methods Framework s....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.04540v2",
      "categories": [
        "physics.med-ph",
        "eess.IV"
      ]
    },
    "2402.13077v1": {
      "title": "Mechanistic Neural Networks for Scientific Machine Learning",
      "authors": [
        "Adeel Pervez",
        "Francesco Locatello",
        "Efstratios Gavves"
      ],
      "abstract": "This paper presents Mechanistic Neural Networks, a neural network design for\nmachine learning applications in the sciences. It incorporates a new\nMechanistic Block in standard architectures to explicitly learn governing\ndifferential equations as representations, revealing the underlying dynamics of\ndata and enhancing interpretability and efficiency in data modeling. Central to\nour approach is a novel Relaxed Linear Programming Solver (NeuRLP) inspired by\na technique that reduces solving linear ODEs to solving linear programs. This\nintegrates well with neural networks and surpasses the limitations of\ntraditional ODE solvers enabling scalable GPU parallel processing. Overall,\nMechanistic Neural Networks demonstrate their versatility for scientific\nmachine learning applications, adeptly managing tasks from equation discovery\nto dynamic systems modeling. We prove their comprehensive capabilities in\nanalyzing and interpreting complex scientific data across various applications,\nshowing significant performance against specialized state-of-the-art methods.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4cd3609d94a7eb6cc232794308689ea4784ae9df",
      "published_date": "2024-02-20",
      "downloaded_date": "2025-02-01",
      "filename": "Pervez-Mechanistic Neural Networks for Scientific Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.13077v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ]
    },
    "2409.16676v1": {
      "title": "An Integrated Machine Learning and Deep Learning Framework for Credit Card Approval Prediction",
      "authors": [
        "Kejian Tong",
        "Zonglin Han",
        "Yanxin Shen",
        "Yujian Long",
        "Yijing Wei"
      ],
      "abstract": "Credit scoring is vital in the financial industry, assessing the risk of\nlending to credit card applicants. Traditional credit scoring methods face\nchallenges with large datasets and data imbalance between creditworthy and\nnon-creditworthy applicants. This paper introduces an advanced machine learning\nand deep learning framework to improve the accuracy and reliability of credit\ncard approval predictions. We utilized extensive datasets of user application\nrecords and credit history, implementing a comprehensive preprocessing\nstrategy, feature engineering, and model integration. Our methodology combines\nneural networks with an ensemble of base models, including logistic regression,\nsupport vector machines, k-nearest neighbors, decision trees, random forests,\nand gradient boosting. The ensemble approach addresses data imbalance using\nSynthetic Minority Over-sampling Technique (SMOTE) and mitigates overfitting\nrisks. Experimental results show that our integrated model surpasses\ntraditional single-model approaches in precision, recall, F1-score, AUC, and\nKappa, providing a robust and scalable solution for credit card approval\npredictions. This research underscores the potential of advanced machine\nlearning techniques to transform credit risk assessment and financial\ndecision-making.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/87ea5af15b93b01e1d25da6767699bffaab8a5d1",
      "published_date": "2024-09-25",
      "downloaded_date": "2025-02-01",
      "filename": "Tong-An Integrated Machine Learning and Deep Learning Framework for Credit Card Approval Prediction.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.16676v1",
      "categories": [
        "cs.CE"
      ]
    },
    "2011.14808v1": {
      "title": "Bringing AI To Edge: From Deep Learning's Perspective",
      "authors": [
        "Di Liu",
        "Hao Kong",
        "Xiangzhong Luo",
        "Weichen Liu",
        "Ravi Subramaniam"
      ],
      "abstract": "Edge computing and artificial intelligence (AI), especially deep learning for\nnowadays, are gradually intersecting to build a novel system, called edge\nintelligence. However, the development of edge intelligence systems encounters\nsome challenges, and one of these challenges is the \\textit{computational gap}\nbetween computation-intensive deep learning algorithms and less-capable edge\nsystems. Due to the computational gap, many edge intelligence systems cannot\nmeet the expected performance requirements. To bridge the gap, a plethora of\ndeep learning techniques and optimization methods are proposed in the past\nyears: light-weight deep learning models, network compression, and efficient\nneural architecture search. Although some reviews or surveys have partially\ncovered this large body of literature, we lack a systematic and comprehensive\nreview to discuss all aspects of these deep learning techniques which are\ncritical for edge intelligence implementation. As various and diverse methods\nwhich are applicable to edge systems are proposed intensively, a holistic\nreview would enable edge computing engineers and community to know the\nstate-of-the-art deep learning techniques which are instrumental for edge\nintelligence and to facilitate the development of edge intelligence systems.\nThis paper surveys the representative and latest deep learning techniques that\nare useful for edge intelligence systems, including hand-crafted models, model\ncompression, hardware-aware neural architecture search and adaptive deep\nlearning models. Finally, based on observations and simple experiments we\nconducted, we discuss some future directions.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-11-25",
      "downloaded_date": "2025-02-01",
      "filename": "Liu-Bringing AI To Edge From Deep Learnings Perspective.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2011.14808v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1901.03415v2": {
      "title": "Context Aware Machine Learning",
      "authors": [
        "Yun Zeng"
      ],
      "abstract": "We propose a principle for exploring context in machine learning models.\nStarting with a simple assumption that each observation may or may not depend\non its context, a conditional probability distribution is decomposed into two\nparts: context-free and context-sensitive. Then by employing the log-linear\nword production model for relating random variables to their embedding space\nrepresentation and making use of the convexity of natural exponential function,\nwe show that the embedding of an observation can also be decomposed into a\nweighted sum of two vectors, representing its context-free and\ncontext-sensitive parts, respectively. This simple treatment of context\nprovides a unified view of many existing deep learning models, leading to\nrevisions of these models able to achieve significant performance boost.\nSpecifically, our upgraded version of a recent sentence embedding model not\nonly outperforms the original one by a large margin, but also leads to a new,\nprincipled approach for compositing the embeddings of bag-of-words features, as\nwell as a new architecture for modeling attention in deep neural networks. More\nsurprisingly, our new principle provides a novel understanding of the gates and\nequations defined by the long short term memory model, which also leads to a\nnew model that is able to converge significantly faster and achieve much lower\nprediction errors. Furthermore, our principle also inspires a new type of\ngeneric neural network layer that better resembles real biological neurons than\nthe traditional linear mapping plus nonlinear activation based architecture.\nIts multi-layer extension provides a new principle for deep neural networks\nwhich subsumes residual network (ResNet) as its special case, and its extension\nto convolutional neutral network model accounts for irrelevant input (e.g.,\nbackground in an image) in addition to filtering.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-01-10",
      "downloaded_date": "2025-02-01",
      "filename": "Zeng-Context Aware Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.03415v2",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2501.10390v1": {
      "title": "Towards an Environmental Ethics of Artificial Intelligence",
      "authors": [
        "Nynke van Uffelen",
        "Lode Lauwaert",
        "Mark Coeckelbergh",
        "Olya Kudina"
      ],
      "abstract": "In recent years, much research has been dedicated to uncovering the\nenvironmental impact of Artificial Intelligence (AI), showing that training and\ndeploying AI systems require large amounts of energy and resources, and the\noutcomes of AI may lead to decisions and actions that may negatively impact the\nenvironment. This new knowledge raises new ethical questions, such as: When is\nit (un)justifiable to develop an AI system, and how to make design choices,\nconsidering its environmental impact? However, so far, the environmental impact\nof AI has largely escaped ethical scrutiny, as AI ethics tends to focus\nstrongly on themes such as transparency, privacy, safety, responsibility, and\nbias. Considering the environmental impact of AI from an ethical perspective\nexpands the scope of AI ethics beyond an anthropocentric focus towards\nincluding more-than-human actors such as animals and ecosystems. This paper\nexplores the ethical implications of the environmental impact of AI for\ndesigning AI systems by drawing on environmental justice literature, in which\nthree categories of justice are distinguished, referring to three elements that\ncan be unjust: the distribution of benefits and burdens (distributive justice),\ndecision-making procedures (procedural justice), and institutionalized social\nnorms (justice as recognition). Based on these tenets of justice, we outline\ncriteria for developing environmentally just AI systems, given their ecological\nimpact.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-12-19",
      "downloaded_date": "2025-02-01",
      "filename": "Uffelen-Towards an Environmental Ethics of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.10390v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2207.12958v1": {
      "title": "From Interpretable Filters to Predictions of Convolutional Neural Networks with Explainable Artificial Intelligence",
      "authors": [
        "Shagufta Henna",
        "Juan Miguel Lopez Alcaraz"
      ],
      "abstract": "Convolutional neural networks (CNN) are known for their excellent feature\nextraction capabilities to enable the learning of models from data, yet are\nused as black boxes. An interpretation of the convolutional filtres and\nassociated features can help to establish an understanding of CNN to\ndistinguish various classes. In this work, we focus on the explainability of a\nCNN model called as cnnexplain that is used for Covid-19 and non-Covid-19\nclassification with a focus on the interpretability of features by the\nconvolutional filters, and how these features contribute to classification.\nSpecifically, we have used various explainable artificial intelligence (XAI)\nmethods, such as visualizations, SmoothGrad, Grad-CAM, and LIME to provide\ninterpretation of convolutional filtres, and relevant features, and their role\nin classification. We have analyzed the explanation of these methods for\nCovid-19 detection using dry cough spectrograms. Explanation results obtained\nfrom the LIME, SmoothGrad, and Grad-CAM highlight important features of\ndifferent spectrograms and their relevance to classification.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/eabc2a58e6a45cbd3337b70ac4ee34975f6a2a05",
      "published_date": "2022-07-26",
      "downloaded_date": "2025-02-01",
      "filename": "Henna-From Interpretable Filters to Predictions of Convolutional Neural Networks with Explainable Artifici....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2207.12958v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2209.03166v1": {
      "title": "Explainable Artificial Intelligence to Detect Image Spam Using Convolutional Neural Network",
      "authors": [
        "Zhibo Zhang",
        "Ernesto Damiani",
        "Hussam Al Hamadi",
        "Chan Yeob Yeun",
        "Fatma Taher"
      ],
      "abstract": "Image spam threat detection has continually been a popular area of research\nwith the internet's phenomenal expansion. This research presents an explainable\nframework for detecting spam images using Convolutional Neural Network(CNN)\nalgorithms and Explainable Artificial Intelligence (XAI) algorithms. In this\nwork, we use CNN model to classify image spam respectively whereas the post-hoc\nXAI methods including Local Interpretable Model Agnostic Explanation (LIME) and\nShapley Additive Explanations (SHAP) were deployed to provide explanations for\nthe decisions that the black-box CNN models made about spam image detection. We\ntrain and then evaluate the performance of the proposed approach on a 6636\nimage dataset including spam images and normal images collected from three\ndifferent publicly available email corpora. The experimental results show that\nthe proposed framework achieved satisfactory detection results in terms of\ndifferent performance metrics whereas the model-independent XAI algorithms\ncould provide explanations for the decisions of different models which could be\nutilized for comparison for the future study.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a55fd0143199c6b5d167b05ec110343788d7f2ef",
      "published_date": "2022-09-07",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Explainable Artificial Intelligence to Detect Image Spam Using Convolutional Neural Network.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.03166v1",
      "categories": [
        "cs.CV",
        "cs.CR"
      ]
    },
    "2009.06366v1": {
      "title": "Comparison of Deep Learning and Traditional Machine Learning Techniques for Classification of Pap Smear Images",
      "authors": [
        "Abdurrahim Yilmaz",
        "Ali Anil Demircali",
        "Sena Kocaman",
        "Huseyin Uvet"
      ],
      "abstract": "A comprehensive study on machine and deep learning techniques for\nclassification of normal and abnormal cervical cells by using pap smear images\nfrom Herlev dataset results are presented. This dataset includes 917 images and\n7 different classes. All techniques used in this study are modeled by using\nGoogle Colab platform with scikit-learn and Keras library inside TensorFlow. In\nthe first study, traditional machine learning methods such as logistic\nregression, k-Nearest Neighbors (kNN), Support Vector Machine (SVM), Decision\nTree, Random Forest and eXtreme Gradient Boosting (XGBoost) are used and\ncompared with each other to find binary classification as normal and abnormal\ncervical cells. Better results are observed by XGBoost and kNN classifiers\namong the others with an accuracy of 85%. In the second study, a deep learning\nmodel based on Convolutional Neural Network(CNN) is used for the same dataset.\nAccordingly, accuracies of 99% and 93% are obtained for the training and the\ntest dataset, respectively. In this model, it takes 50 epochs to have these\naccuracies within 20 minutes of computational time.",
      "citation_count": 20,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4bd0fd109e1e6d96023e3f9cff8dd0f58eed501b",
      "published_date": "2020-09-11",
      "downloaded_date": "2025-02-01",
      "filename": "Yilmaz-Comparison of Deep Learning and Traditional Machine Learning Techniques for Classification of Pap Sm....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.06366v1",
      "categories": [
        "eess.IV"
      ]
    },
    "2501.03654v1": {
      "title": "Data Augmentation for Deep Learning Regression Tasks by Machine Learning Models",
      "authors": [
        "Assaf Shmuel",
        "Oren Glickman",
        "Teddy Lazebnik"
      ],
      "abstract": "Deep learning (DL) models have gained prominence in domains such as computer\nvision and natural language processing but remain underutilized for regression\ntasks involving tabular data. In these cases, traditional machine learning (ML)\nmodels often outperform DL models. In this study, we propose and evaluate\nvarious data augmentation (DA) techniques to improve the performance of DL\nmodels for tabular data regression tasks. We compare the performance gain of\nNeural Networks by different DA strategies ranging from a naive method of\nduplicating existing observations and adding noise to a more sophisticated DA\nstrategy that preserves the underlying statistical relationship in the data.\nOur analysis demonstrates that the advanced DA method significantly improves DL\nmodel performance across multiple datasets and regression tasks, resulting in\nan average performance increase of over 10\\% compared to baseline models\nwithout augmentation. The efficacy of these DA strategies was rigorously\nvalidated across 30 distinct datasets, with multiple iterations and evaluations\nusing three different automated deep learning (AutoDL) frameworks: AutoKeras,\nH2O, and AutoGluon. This study demonstrates that by leveraging advanced DA\ntechniques, DL models can realize their full potential in regression tasks,\nthereby contributing to broader adoption and enhanced performance in practical\napplications.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ba456eba34037b8dad7638654f1e0e5ef1203d75",
      "published_date": "2025-01-07",
      "downloaded_date": "2025-02-01",
      "filename": "Shmuel-Data Augmentation for Deep Learning Regression Tasks by Machine Learning Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.03654v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2210.12247v1": {
      "title": "Benchmarking GPU and TPU Performance with Graph Neural Networks",
      "authors": [
        "xiangyang Ju",
        "Yunsong Wang",
        "Daniel Murnane",
        "Nicholas Choma",
        "Steven Farrell",
        "Paolo Calafiura"
      ],
      "abstract": "Many artificial intelligence (AI) devices have been developed to accelerate\nthe training and inference of neural networks models. The most common ones are\nthe Graphics Processing Unit (GPU) and Tensor Processing Unit (TPU). They are\nhighly optimized for dense data representations. However, sparse\nrepresentations such as graphs are prevalent in many domains, including\nscience. It is therefore important to characterize the performance of available\nAI accelerators on sparse data. This work analyzes and compares the GPU and TPU\nperformance training a Graph Neural Network (GNN) developed to solve a\nreal-life pattern recognition problem. Characterizing the new class of models\nacting on sparse data may prove helpful in optimizing the design of deep\nlearning libraries and future AI accelerators.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/084e81b240ac4728d0e0d70426b66488ef063137",
      "published_date": "2022-10-21",
      "downloaded_date": "2025-02-01",
      "filename": "Ju-Benchmarking GPU and TPU Performance with Graph Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.12247v1",
      "categories": [
        "cs.LG"
      ]
    },
    "1711.05860v1": {
      "title": "A General Neural Network Hardware Architecture on FPGA",
      "authors": [
        "Yufeng Hao"
      ],
      "abstract": "Field Programmable Gate Arrays (FPGAs) plays an increasingly important role\nin data sampling and processing industries due to its highly parallel\narchitecture, low power consumption, and flexibility in custom algorithms.\nEspecially, in the artificial intelligence field, for training and implement\nthe neural networks and machine learning algorithms, high energy efficiency\nhardware implement and massively parallel computing capacity are heavily\ndemanded. Therefore, many global companies have applied FPGAs into AI and\nMachine learning fields such as autonomous driving and Automatic Spoken\nLanguage Recognition (Baidu) [1] [2] and Bing search (Microsoft) [3].\nConsidering the FPGAs great potential in these fields, we tend to implement a\ngeneral neural network hardware architecture on XILINX ZU9CG System On Chip\n(SOC) platform [4], which contains abundant hardware resource and powerful\nprocessing capacity. The general neural network architecture on the FPGA SOC\nplatform can perform forward and backward algorithms in deep neural networks\n(DNN) with high performance and easily be adjusted according to the type and\nscale of the neural networks.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ff4bb7fce973c58619d033978dbc18936ae24103",
      "published_date": "2017-11-06",
      "downloaded_date": "2025-02-01",
      "filename": "Hao-A General Neural Network Hardware Architecture on FPGA.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1711.05860v1",
      "categories": [
        "cs.CV",
        "cs.AR",
        "cs.NE"
      ]
    },
    "2312.05481v10": {
      "title": "Artificial Intelligence in the Knowledge Economy",
      "authors": [
        "Enrique Ide",
        "Eduard Talamas"
      ],
      "abstract": "The rise of Artificial Intelligence (AI) has the potential to reshape the\nknowledge economy by automating cognitive, non-codifiable work. This paper\nintroduces a framework to analyze this transformation, incorporating AI into an\neconomy where humans form hierarchical firms to use their time and knowledge\nefficiently: Less knowledgeable individuals become \"workers\" solving routine\nproblems, while more knowledgeable individuals become \"solvers\" assisting\nworkers with exceptional problems. We model AI as a technology that transforms\ncomputing power into \"AI agents,\" which can either operate autonomously (as\nco-workers or solvers/co-pilots) or non-autonomously (only as co-pilots). We\nshow that basic autonomous AI displaces humans towards specialized problem\nsolving, leading to smaller, less productive, and less decentralized firms. In\ncontrast, advanced autonomous AI reallocates humans to routine knowledge work,\nresulting in larger, more productive, and more decentralized firms. While\nautonomous AI primarily benefits the most knowledgeable individuals,\nnon-autonomous AI disproportionately benefits the least knowledgeable. However,\nautonomous AI achieves higher overall output. These findings reconcile\nseemingly contradictory empirical evidence and reveal key tradeoffs involved in\nregulating AI autonomy.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fa4e77c21ad9a005b891e2c0dc0612a399736b7e",
      "published_date": "2023-12-09",
      "downloaded_date": "2025-02-01",
      "filename": "Ide-Artificial Intelligence in the Knowledge Economy.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.05481v10",
      "categories": [
        "econ.TH"
      ]
    },
    "2501.12644v1": {
      "title": "Current Opinions on Memristor-Accelerated Machine Learning Hardware",
      "authors": [
        "Mingrui Jiang",
        "Yichun Xu",
        "Zefan Li",
        "Can Li"
      ],
      "abstract": "The unprecedented advancement of artificial intelligence has placed immense\ndemands on computing hardware, but traditional silicon-based semiconductor\ntechnologies are approaching their physical and economic limit, prompting the\nexploration of novel computing paradigms. Memristor offers a promising\nsolution, enabling in-memory analog computation and massive parallelism, which\nleads to low latency and power consumption. This manuscript reviews the current\nstatus of memristor-based machine learning accelerators, highlighting the\nmilestones achieved in developing prototype chips, that not only accelerate\nneural networks inference but also tackle other machine learning tasks. More\nimportantly, it discusses our opinion on current key challenges that remain in\nthis field, such as device variation, the need for efficient peripheral\ncircuitry, and systematic co-design and optimization. We also share our\nperspective on potential future directions, some of which address existing\nchallenges while others explore untouched territories. By addressing these\nchallenges through interdisciplinary efforts spanning device engineering,\ncircuit design, and systems architecture, memristor-based accelerators could\nsignificantly advance the capabilities of AI hardware, particularly for edge\napplications where power efficiency is paramount.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2025-01-22",
      "downloaded_date": "2025-02-01",
      "filename": "Jiang-Current Opinions on Memristor-Accelerated Machine Learning Hardware.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.12644v1",
      "categories": [
        "cs.ET",
        "cs.AR",
        "cs.LG",
        "eess.SP",
        "physics.app-ph"
      ]
    },
    "1301.6359v2": {
      "title": "Subjective Reality and Strong Artificial Intelligence",
      "authors": [
        "Alexander Serov"
      ],
      "abstract": "The main prospective aim of modern research related to Artificial\nIntelligence is the creation of technical systems that implement the idea of\nStrong Intelligence. According our point of view the path to the development of\nsuch systems comes through the research in the field related to perceptions.\nHere we formulate the model of the perception of external world which may be\nused for the description of perceptual activity of intelligent beings. We\nconsider a number of issues related to the development of the set of patterns\nwhich will be used by the intelligent system when interacting with environment.\nThe key idea of the presented perception model is the idea of subjective\nreality. The principle of the relativity of perceived world is formulated. It\nis shown that this principle is the immediate consequence of the idea of\nsubjective reality. In this paper we show how the methodology of subjective\nreality may be used for the creation of different types of Strong AI systems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2013-01-27",
      "downloaded_date": "2025-02-01",
      "filename": "Serov-Subjective Reality and Strong Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1301.6359v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2206.11187v1": {
      "title": "Automated Compliance Blueprint Optimization with Artificial Intelligence",
      "authors": [
        "Abdulhamid Adebayo",
        "Daby Sow",
        "Muhammed Fatih Bulut"
      ],
      "abstract": "For highly regulated industries such as banking and healthcare, one of the\nmajor hindrances to the adoption of cloud computing is compliance with\nregulatory standards. This is a complex problem due to many regulatory and\ntechnical specification (techspec) documents that the companies need to comply\nwith. The critical problem is to establish the mapping between techspecs and\nregulation controls so that from day one, companies can comply with regulations\nwith minimal effort. We demonstrate the practicality of an approach to\nautomatically analyze regulatory standards using Artificial Intelligence (AI)\ntechniques. We present early results to identify the mapping between techspecs\nand regulation controls, and discuss challenges that must be overcome for this\nsolution to be fully practical.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d40a41543ef1e17763ff08ec962293744fd105d7",
      "published_date": "2022-06-22",
      "downloaded_date": "2025-02-01",
      "filename": "Adebayo-Automated Compliance Blueprint Optimization with Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.11187v1",
      "categories": [
        "cs.AI",
        "cs.CR"
      ]
    },
    "2301.05864v1": {
      "title": "Recent advances in artificial intelligence for retrosynthesis",
      "authors": [
        "Zipeng Zhong",
        "Jie Song",
        "Zunlei Feng",
        "Tiantao Liu",
        "Lingxiang Jia",
        "Shaolun Yao",
        "Tingjun Hou",
        "Mingli Song"
      ],
      "abstract": "Retrosynthesis is the cornerstone of organic chemistry, providing chemists in\nmaterial and drug manufacturing access to poorly available and brand-new\nmolecules. Conventional rule-based or expert-based computer-aided synthesis has\nobvious limitations, such as high labor costs and limited search space. In\nrecent years, dramatic breakthroughs driven by artificial intelligence have\nrevolutionized retrosynthesis. Here we aim to present a comprehensive review of\nrecent advances in AI-based retrosynthesis. For single-step and multi-step\nretrosynthesis both, we first list their goal and provide a thorough taxonomy\nof existing methods. Afterwards, we analyze these methods in terms of their\nmechanism and performance, and introduce popular evaluation metrics for them,\nin which we also provide a detailed comparison among representative methods on\nseveral public datasets. In the next part we introduce popular databases and\nestablished platforms for retrosynthesis. Finally, this review concludes with a\ndiscussion about promising research directions in this field.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9893d8b4c6279362c49a69e2a71086977c3351b2",
      "published_date": "2023-01-14",
      "downloaded_date": "2025-02-01",
      "filename": "Zhong-Recent advances in artificial intelligence for retrosynthesis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2301.05864v1",
      "categories": [
        "cs.LG",
        "physics.chem-ph",
        "q-bio.BM"
      ]
    },
    "2403.08802v3": {
      "title": "Governance of Generative Artificial Intelligence for Companies",
      "authors": [
        "Johannes Schneider",
        "Pauline Kuss",
        "Rene Abraham",
        "Christian Meske"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI), specifically large language\nmodels like ChatGPT, has swiftly entered organizations without adequate\ngovernance, posing both opportunities and risks. Despite extensive debates on\nGenAI's transformative nature and regulatory measures, limited research\naddresses organizational governance, encompassing technical and business\nperspectives. Although numerous frameworks for governance of AI exist, it is\nnot clear to what extent they apply to GenAI. Our review paper fills this gap\nby surveying recent works with the purpose of better understanding fundamental\ncharacteristics of GenAI and adjusting prior frameworks specifically towards\nGenAI governance within companies. To do so, it extends Nickerson's framework\ndevelopment processes to include prior conceptualizations. Our framework\noutlines the scope, objectives, and governance mechanisms tailored to harness\nbusiness opportunities as well as mitigate risks associated with GenAI\nintegration. Our research contributes a focused approach to GenAI governance,\noffering practical insights for companies navigating the challenges of GenAI\nadoption and highlighting research gaps.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-02-05",
      "downloaded_date": "2025-02-01",
      "filename": "Schneider-Governance of Generative Artificial Intelligence for Companies.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.08802v3",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    "2211.06318v1": {
      "title": "Artificial Intelligence and Life in 2030: The One Hundred Year Study on Artificial Intelligence",
      "authors": [
        "Peter Stone",
        "Rodney Brooks",
        "Erik Brynjolfsson",
        "Ryan Calo",
        "Oren Etzioni",
        "Greg Hager",
        "Julia Hirschberg",
        "Shivaram Kalyanakrishnan",
        "Ece Kamar",
        "Sarit Kraus",
        "Kevin Leyton-Brown",
        "David Parkes",
        "William Press",
        "AnnaLee Saxenian",
        "Julie Shah",
        "Milind Tambe",
        "Astro Teller"
      ],
      "abstract": "In September 2016, Stanford's \"One Hundred Year Study on Artificial\nIntelligence\" project (AI100) issued the first report of its planned long-term\nperiodic assessment of artificial intelligence (AI) and its impact on society.\nIt was written by a panel of 17 study authors, each of whom is deeply rooted in\nAI research, chaired by Peter Stone of the University of Texas at Austin. The\nreport, entitled \"Artificial Intelligence and Life in 2030,\" examines eight\ndomains of typical urban settings on which AI is likely to have impact over the\ncoming years: transportation, home and service robots, healthcare, education,\npublic safety and security, low-resource communities, employment and workplace,\nand entertainment. It aims to provide the general public with a scientifically\nand technologically accurate portrayal of the current state of AI and its\npotential and to help guide decisions in industry and governments, as well as\nto inform research and development in the field. The charge for this report was\ngiven to the panel by the AI100 Standing Committee, chaired by Barbara Grosz of\nHarvard University.",
      "citation_count": 149,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b4916c497d996ad21433a8fda701b6306b0854cd",
      "published_date": "2022-10-31",
      "downloaded_date": "2025-02-01",
      "filename": "Stone-Artificial Intelligence and Life in 2030 The One Hundred Year Study on Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.06318v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2409.02668v1": {
      "title": "Introduction to Machine Learning",
      "authors": [
        "Laurent Younes"
      ],
      "abstract": "This book introduces the mathematical foundations and techniques that lead to\nthe development and analysis of many of the algorithms that are used in machine\nlearning. It starts with an introductory chapter that describes notation used\nthroughout the book and serve at a reminder of basic concepts in calculus,\nlinear algebra and probability and also introduces some measure theoretic\nterminology, which can be used as a reading guide for the sections that use\nthese tools. The introductory chapters also provide background material on\nmatrix analysis and optimization. The latter chapter provides theoretical\nsupport to many algorithms that are used in the book, including stochastic\ngradient descent, proximal methods, etc. After discussing basic concepts for\nstatistical prediction, the book includes an introduction to reproducing kernel\ntheory and Hilbert space techniques, which are used in many places, before\naddressing the description of various algorithms for supervised statistical\nlearning, including linear methods, support vector machines, decision trees,\nboosting, or neural networks. The subject then switches to generative methods,\nstarting with a chapter that presents sampling methods and an introduction to\nthe theory of Markov chains. The following chapter describe the theory of\ngraphical models, an introduction to variational methods for models with latent\nvariables, and to deep-learning based generative models. The next chapters\nfocus on unsupervised learning methods, for clustering, factor analysis and\nmanifold learning. The final chapter of the book is theory-oriented and\ndiscusses concentration inequalities and generalization bounds.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-09-04",
      "downloaded_date": "2025-02-01",
      "filename": "Younes-Introduction to Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.02668v1",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    "2306.15337v1": {
      "title": "Homological Neural Networks: A Sparse Architecture for Multivariate Complexity",
      "authors": [
        "Yuanrong Wang",
        "Antonio Briola",
        "Tomaso Aste"
      ],
      "abstract": "The rapid progress of Artificial Intelligence research came with the\ndevelopment of increasingly complex deep learning models, leading to growing\nchallenges in terms of computational complexity, energy efficiency and\ninterpretability. In this study, we apply advanced network-based information\nfiltering techniques to design a novel deep neural network unit characterized\nby a sparse higher-order graphical architecture built over the homological\nstructure of underlying data. We demonstrate its effectiveness in two\napplication domains which are traditionally challenging for deep learning:\ntabular data and time series regression problems. Results demonstrate the\nadvantages of this novel design which can tie or overcome the results of\nstate-of-the-art machine learning and deep learning models using only a\nfraction of parameters.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1dc954057e3558e3e55681ce87fb6573708a2213",
      "published_date": "2023-06-27",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Homological Neural Networks A Sparse Architecture for Multivariate Complexity.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.15337v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1705.04286v1": {
      "title": "Phase recovery and holographic image reconstruction using deep learning in neural networks",
      "authors": [
        "Yair Rivenson",
        "Yibo Zhang",
        "Harun Gunaydin",
        "Da Teng",
        "Aydogan Ozcan"
      ],
      "abstract": "Phase recovery from intensity-only measurements forms the heart of coherent\nimaging techniques and holography. Here we demonstrate that a neural network\ncan learn to perform phase recovery and holographic image reconstruction after\nappropriate training. This deep learning-based approach provides an entirely\nnew framework to conduct holographic imaging by rapidly eliminating twin-image\nand self-interference related spatial artifacts. Compared to existing\napproaches, this neural network based method is significantly faster to\ncompute, and reconstructs improved phase and amplitude images of the objects\nusing only one hologram, i.e., requires less number of measurements in addition\nto being computationally faster. We validated this method by reconstructing\nphase and amplitude images of various samples, including blood and Pap smears,\nand tissue sections. These results are broadly applicable to any phase recovery\nproblem, and highlight that through machine learning challenging problems in\nimaging science can be overcome, providing new avenues to design powerful\ncomputational imaging systems.",
      "citation_count": 786,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d8df8e2c10fce631173aae694f017dd136226284",
      "published_date": "2017-05-10",
      "downloaded_date": "2025-02-01",
      "filename": "Rivenson-Phase recovery and holographic image reconstruction using deep learning in neural networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1705.04286v1",
      "categories": [
        "cs.CV",
        "cs.IR",
        "cs.LG",
        "physics.app-ph",
        "physics.optics",
        "68T01, 68T05, 68U10, 62M45, 78M32, 92C55, 94A08",
        "I.2; I.2.1; I.2.6; I.2.10; I.4.5; I.4.9"
      ]
    },
    "2004.03586v2": {
      "title": "From Artificial Neural Networks to Deep Learning for Music Generation -- History, Concepts and Trends",
      "authors": [
        "Jean-Pierre Briot"
      ],
      "abstract": "The current wave of deep learning (the hyper-vitamined return of artificial\nneural networks) applies not only to traditional statistical machine learning\ntasks: prediction and classification (e.g., for weather prediction and pattern\nrecognition), but has already conquered other areas, such as translation. A\ngrowing area of application is the generation of creative content, notably the\ncase of music, the topic of this paper. The motivation is in using the capacity\nof modern deep learning techniques to automatically learn musical styles from\narbitrary musical corpora and then to generate musical samples from the\nestimated distribution, with some degree of control over the generation. This\npaper provides a tutorial on music generation based on deep learning\ntechniques. After a short introduction to the topic illustrated by a recent\nexemple, the paper analyzes some early works from the late 1980s using\nartificial neural networks for music generation and how their pioneering\ncontributions have prefigured current techniques. Then, we introduce some\nconceptual framework to analyze the various concepts and dimensions involved.\nVarious examples of recent systems are introduced and analyzed to illustrate\nthe variety of concerns and of techniques.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-04-07",
      "downloaded_date": "2025-02-01",
      "filename": "Briot-From Artificial Neural Networks to Deep Learning for Music Generation -- History Concepts and Trends.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.03586v2",
      "categories": [
        "eess.AS",
        "cs.LG",
        "cs.MM",
        "cs.SD",
        "stat.ML"
      ]
    },
    "2412.20960v1": {
      "title": "Rise of Generative Artificial Intelligence in Science",
      "authors": [
        "Liangping Ding",
        "Cornelia Lawson",
        "Philip Shapira"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI, generative AI) has rapidly become\navailable as a tool in scientific research. To explore the use of generative AI\nin science, we conduct an empirical analysis using OpenAlex. Analyzing GenAI\npublications and other AI publications from 2017 to 2023, we profile growth\npatterns, the diffusion of GenAI publications across fields of study, and the\ngeographical spread of scientific research on generative AI. We also\ninvestigate team size and international collaborations to explore whether\nGenAI, as an emerging scientific research area, shows different collaboration\npatterns compared to other AI technologies. The results indicate that\ngenerative AI has experienced rapid growth and increasing presence in\nscientific publications. The use of GenAI now extends beyond computer science\nto other scientific research domains. Over the study period, U.S. researchers\ncontributed nearly two-fifths of global GenAI publications. The U.S. is\nfollowed by China, with several small and medium-sized advanced economies\ndemonstrating relatively high levels of GenAI deployment in their research\npublications. Although scientific research overall is becoming increasingly\nspecialized and collaborative, our results suggest that GenAI research groups\ntend to have slightly smaller team sizes than found in other AI fields.\nFurthermore, notwithstanding recent geopolitical tensions, GenAI research\ncontinues to exhibit levels of international collaboration comparable to other\nAI technologies.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-12-30",
      "downloaded_date": "2025-02-01",
      "filename": "Ding-Rise of Generative Artificial Intelligence in Science.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.20960v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.IR",
        "H.3.3; K.4.0"
      ]
    },
    "2104.05569v1": {
      "title": "Deep Learning for IoT",
      "authors": [
        "Tao Lin"
      ],
      "abstract": "Deep learning and other machine learning approaches are deployed to many\nsystems related to Internet of Things or IoT. However, it faces challenges that\nadversaries can take loopholes to hack these systems through tampering history\ndata. This paper first presents overall points of adversarial machine learning.\nThen, we illustrate traditional methods, such as Petri Net cannot solve this\nnew question efficiently. To help IoT data analysis more efficient, we propose\na retrieval method based on deep learning (recurrent neural network). Besides,\nthis paper presents a research on data retrieval solution to avoid hacking by\nadversaries in the fields of adversary machine leaning. It further directs the\nnew approaches in terms of how to implementing this framework in IoT settings\nbased on adversarial deep learning.",
      "citation_count": 1016,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d63b884d5ebc739f6e1bdf861fa9276260781404",
      "published_date": "2021-04-12",
      "downloaded_date": "2025-02-01",
      "filename": "Lin-Deep Learning for IoT.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.05569v1",
      "categories": [
        "cs.LG",
        "cs.NI"
      ]
    },
    "2301.04020v1": {
      "title": "Quant 4.0: Engineering Quantitative Investment with Automated, Explainable and Knowledge-driven Artificial Intelligence",
      "authors": [
        "Jian Guo",
        "Saizhuo Wang",
        "Lionel M. Ni",
        "Heung-Yeung Shum"
      ],
      "abstract": "Quantitative investment (``quant'') is an interdisciplinary field combining\nfinancial engineering, computer science, mathematics, statistics, etc. Quant\nhas become one of the mainstream investment methodologies over the past\ndecades, and has experienced three generations: Quant 1.0, trading by\nmathematical modeling to discover mis-priced assets in markets; Quant 2.0,\nshifting quant research pipeline from small ``strategy workshops'' to large\n``alpha factories''; Quant 3.0, applying deep learning techniques to discover\ncomplex nonlinear pricing rules. Despite its advantage in prediction, deep\nlearning relies on extremely large data volume and labor-intensive tuning of\n``black-box'' neural network models. To address these limitations, in this\npaper, we introduce Quant 4.0 and provide an engineering perspective for\nnext-generation quant. Quant 4.0 has three key differentiating components.\nFirst, automated AI changes quant pipeline from traditional hand-craft modeling\nto the state-of-the-art automated modeling, practicing the philosophy of\n``algorithm produces algorithm, model builds model, and eventually AI creates\nAI''. Second, explainable AI develops new techniques to better understand and\ninterpret investment decisions made by machine learning black-boxes, and\nexplains complicated and hidden risk exposures. Third, knowledge-driven AI is a\nsupplement to data-driven AI such as deep learning and it incorporates prior\nknowledge into modeling to improve investment decision, in particular for\nquantitative value investing. Moreover, we discuss how to build a system that\npractices the Quant 4.0 concept. Finally, we propose ten challenging research\nproblems for quant technology, and discuss potential solutions, research\ndirections, and future trends.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/497a1accfd0be6cad1be4f2b6fa88078dae7414a",
      "published_date": "2022-12-13",
      "downloaded_date": "2025-02-01",
      "filename": "Guo-Quant 40 Engineering Quantitative Investment with Automated Explainable and Knowledge-driven Artific....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2301.04020v1",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ]
    },
    "2408.09484v2": {
      "title": "Fredholm Neural Networks",
      "authors": [
        "Kyriakos Georgiou",
        "Constantinos Siettos",
        "Athanasios N. Yannacopoulos"
      ],
      "abstract": "Within the family of explainable machine-learning, we present Fredholm neural\nnetworks (Fredholm NNs), deep neural networks (DNNs) which replicate fixed\npoint iterations for the solution of linear and nonlinear Fredholm Integral\nEquations (FIE) of the second kind. Applications of FIEs include the solution\nof ordinary, as well as partial differential equations (ODEs, PDEs) and many\nmore. We first prove that Fredholm NNs provide accurate solutions. We then\nprovide insight into the values of the hyperparameters and\ntrainable/explainable weights and biases of the DNN, by directly connecting\ntheir values to the underlying mathematical theory. For our illustrations, we\nuse Fredholm NNs to solve both linear and nonlinear problems, including\nelliptic PDEs and boundary value problems. We show that the proposed scheme\nachieves significant numerical approximation accuracy across both the domain\nand boundary. The proposed methodology provides insight into the connection\nbetween neural networks and classical numerical methods, and we posit that it\ncan have applications in fields such as Uncertainty Quantification (UQ) and\nexplainable artificial intelligence (XAI). Thus, we believe that it will\ntrigger further advances in the intersection between scientific machine\nlearning and numerical analysis.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/82492de625c8a8250784a5764f6391b1b8426bbb",
      "published_date": "2024-08-18",
      "downloaded_date": "2025-02-01",
      "filename": "Georgiou-Fredholm Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.09484v2",
      "categories": [
        "math.NA",
        "cs.NA",
        "math.DS",
        "65R20 (Primary), 68T07, 45B05, 65N38 (Secondary)"
      ]
    },
    "2008.09000v1": {
      "title": "Generative chemistry: drug discovery with deep learning generative models",
      "authors": [
        "Yuemin Bian",
        "Xiang-Qun Xie"
      ],
      "abstract": "The de novo design of molecular structures using deep learning generative\nmodels introduces an encouraging solution to drug discovery in the face of the\ncontinuously increased cost of new drug development. From the generation of\noriginal texts, images, and videos, to the scratching of novel molecular\nstructures, the incredible creativity of deep learning generative models\nsurprised us about the height machine intelligence can achieve. The purpose of\nthis paper is to review the latest advances in generative chemistry which\nrelies on generative modeling to expedite the drug discovery process. This\nreview starts with a brief history of artificial intelligence in drug discovery\nto outline this emerging paradigm. Commonly used chemical databases, molecular\nrepresentations, and tools in cheminformatics and machine learning are covered\nas the infrastructure for the generative chemistry. The detailed discussions on\nutilizing cutting-edge generative architectures, including recurrent neural\nnetwork, variational autoencoder, adversarial autoencoder, and generative\nadversarial network for compound generation are focused. Challenges and future\nperspectives follow.",
      "citation_count": 83,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/557ed446503524c111d3c0d661672001d559b3c2",
      "published_date": "2020-08-20",
      "downloaded_date": "2025-02-01",
      "filename": "Bian-Generative chemistry drug discovery with deep learning generative models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.09000v1",
      "categories": [
        "q-bio.BM",
        "cs.LG",
        "q-bio.QM"
      ]
    },
    "2201.01943v1": {
      "title": "Machine Learning: Algorithms, Models, and Applications",
      "authors": [
        "Jaydip Sen",
        "Sidra Mehtab",
        "Rajdeep Sen",
        "Abhishek Dutta",
        "Pooja Kherwa",
        "Saheel Ahmed",
        "Pranay Berry",
        "Sahil Khurana",
        "Sonali Singh",
        "David W. W Cadotte",
        "David W. Anderson",
        "Kalum J. Ost",
        "Racheal S. Akinbo",
        "Oladunni A. Daramola",
        "Bongs Lainjo"
      ],
      "abstract": "Recent times are witnessing rapid development in machine learning algorithm\nsystems, especially in reinforcement learning, natural language processing,\ncomputer and robot vision, image processing, speech, and emotional processing\nand understanding. In tune with the increasing importance and relevance of\nmachine learning models, algorithms, and their applications, and with the\nemergence of more innovative uses cases of deep learning and artificial\nintelligence, the current volume presents a few innovative research works and\ntheir applications in real world, such as stock trading, medical and healthcare\nsystems, and software automation. The chapters in the book illustrate how\nmachine learning and deep learning algorithms and models are designed,\noptimized, and deployed. The volume will be useful for advanced graduate and\ndoctoral students, researchers, faculty members of universities, practicing\ndata scientists and data engineers, professionals, and consultants working on\nthe broad areas of machine learning, deep learning, and artificial\nintelligence.",
      "citation_count": 19,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/148e0d561acb2229dcd79aaade6e8ea45e3d9873",
      "published_date": "2022-01-06",
      "downloaded_date": "2025-02-01",
      "filename": "Sen-Machine Learning Algorithms Models and Applications.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2201.01943v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1905.03899v1": {
      "title": "Integrating Artificial Intelligence into Weapon Systems",
      "authors": [
        "Philip Feldman",
        "Aaron Dant",
        "Aaron Massey"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) into weapon systems is one of\nthe most consequential tactical and strategic decisions in the history of\nwarfare. Current AI development is a remarkable combination of accelerating\ncapability, hidden decision mechanisms, and decreasing costs. Implementation of\nthese systems is in its infancy and exists on a spectrum from resilient and\nflexible to simplistic and brittle. Resilient systems should be able to\neffectively handle the complexities of a high-dimensional battlespace.\nSimplistic AI implementations could be manipulated by an adversarial AI that\nidentifies and exploits their weaknesses.\n  In this paper, we present a framework for understanding the development of\ndynamic AI/ML systems that interactively and continuously adapt to their user's\nneeds. We explore the implications of increasingly capable AI in the kill chain\nand how this will lead inevitably to a fully automated, always on system,\nbarring regulation by treaty. We examine the potential of total integration of\ncyber and physical security and how this likelihood must inform the development\nof AI-enabled systems with respect to the \"fog of war\", human morals, and\nethics.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/96843bd2cdfb76fcea96110c31a3d0f91d63300a",
      "published_date": "2019-05-10",
      "downloaded_date": "2025-02-01",
      "filename": "Feldman-Integrating Artificial Intelligence into Weapon Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1905.03899v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.RO",
        "I.2.0; K.4.1; J.7"
      ]
    },
    "2305.04532v2": {
      "title": "Latest Trends in Artificial Intelligence Technology: A Scoping Review",
      "authors": [
        "Teemu Niskanen",
        "Tuomo Sipola",
        "Olli VÃ¤Ã¤nÃ¤nen"
      ],
      "abstract": "Artificial intelligence is more ubiquitous in multiple domains. Smartphones,\nsocial media platforms, search engines, and autonomous vehicles are just a few\nexamples of applications that utilize artificial intelligence technologies to\nenhance their performance. This study carries out a scoping review of the\ncurrent state-of-the-art artificial intelligence technologies following the\nPRISMA framework. The goal was to find the most advanced technologies used in\ndifferent domains of artificial intelligence technology research. Three\nrecognized journals were used from artificial intelligence and machine learning\ndomain: Journal of Artificial Intelligence Research, Journal of Machine\nLearning Research, and Machine Learning, and articles published in 2022 were\nobserved. Certain qualifications were laid for the technological solutions: the\ntechnology must be tested against comparable solutions, commonly approved or\notherwise well justified datasets must be used while applying, and results must\nshow improvements against comparable solutions. One of the most important parts\nof the technology development appeared to be how to process and exploit the\ndata gathered from multiple sources. The data can be highly unstructured and\nthe technological solution should be able to utilize the data with minimum\nmanual work from humans. The results of this review indicate that creating\nlabeled datasets is very laborious, and solutions exploiting unsupervised or\nsemi-supervised learning technologies are more and more researched. The\nlearning algorithms should be able to be updated efficiently, and predictions\nshould be interpretable. Using artificial intelligence technologies in\nreal-world applications, safety and explainable predictions are mandatory to\nconsider before mass adoption can occur.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ed3855cbf1c0baa0f0144ad456c92142437a24b3",
      "published_date": "2023-05-08",
      "downloaded_date": "2025-02-01",
      "filename": "Niskanen-Latest Trends in Artificial Intelligence Technology A Scoping Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.04532v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    "1707.09032v1": {
      "title": "Evolution towards Smart Optical Networking: Where Artificial Intelligence (AI) meets the World of Photonics",
      "authors": [
        "Admela Jukan",
        "Mohit Chamania"
      ],
      "abstract": "Smart optical networks are the next evolution of programmable networking and\nprogrammable automation of optical networks, with human-in-the-loop network\ncontrol and management. The paper discusses this evolution and the role of\nArtificial Intelligence (AI).",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c96bea7aba028f8e086fa15e5828e70213dc02e4",
      "published_date": "2017-07-27",
      "downloaded_date": "2025-02-01",
      "filename": "Jukan-Evolution towards Smart Optical Networking Where Artificial Intelligence AI meets the World of Photo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1707.09032v1",
      "categories": [
        "cs.NI"
      ]
    },
    "2308.15639v1": {
      "title": "Hyperbolic Convolutional Neural Networks",
      "authors": [
        "Andrii Skliar",
        "Maurice Weiler"
      ],
      "abstract": "Deep Learning is mostly responsible for the surge of interest in Artificial\nIntelligence in the last decade. So far, deep learning researchers have been\nparticularly successful in the domain of image processing, where Convolutional\nNeural Networks are used. Although excelling at image classification,\nConvolutional Neural Networks are quite naive in that no inductive bias is set\non the embedding space for images. Similar flaws are also exhibited by another\ntype of Convolutional Networks - Graph Convolutional Neural Networks. However,\nusing non-Euclidean space for embedding data might result in more robust and\nexplainable models. One example of such a non-Euclidean space is hyperbolic\nspace. Hyperbolic spaces are particularly useful due to their ability to fit\nmore data in a low-dimensional space and tree-likeliness properties. These\nattractive properties have been previously used in multiple papers which\nindicated that they are beneficial for building hierarchical embeddings using\nshallow models and, recently, using MLPs and RNNs.\n  However, no papers have yet suggested a general approach to using Hyperbolic\nConvolutional Neural Networks for structured data processing, although these\nare the most common examples of data used. Therefore, the goal of this work is\nto devise a general recipe for building Hyperbolic Convolutional Neural\nNetworks. We hypothesize that ability of hyperbolic space to capture hierarchy\nin the data would lead to better performance. This ability should be\nparticularly useful in cases where data has a tree-like structure. Since this\nis the case for many existing datasets \\citep{wordnet, imagenet, fb15k}, we\nargue that such a model would be advantageous both in terms of applications and\nfuture research prospects.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1eaf6b75037bca83ca8bb4f199e1e097b19ae2a1",
      "published_date": "2023-08-29",
      "downloaded_date": "2025-02-01",
      "filename": "Skliar-Hyperbolic Convolutional Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.15639v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "1912.05744v2": {
      "title": "Artificial Intelligence-Enabled Intelligent 6G Networks",
      "authors": [
        "Helin Yang",
        "Arokiaswami Alphones",
        "Zehui Xiong",
        "Dusit Niyato",
        "Jun Zhao",
        "Kaishun Wu"
      ],
      "abstract": "With the rapid development of smart terminals and infrastructures, as well as\ndiversified applications (e.g., virtual and augmented reality, remote surgery\nand holographic projection) with colorful requirements, current networks (e.g.,\n4G and upcoming 5G networks) may not be able to completely meet quickly rising\ntraffic demands. Accordingly, efforts from both industry and academia have\nalready been put to the research on 6G networks. Recently, artificial\nintelligence (AI) has been utilized as a new paradigm for the design and\noptimization of 6G networks with a high level of intelligence. Therefore, this\narticle proposes an AI-enabled intelligent architecture for 6G networks to\nrealize knowledge discovery, smart resource management, automatic network\nadjustment and intelligent service provisioning, where the architecture is\ndivided into four layers: intelligent sensing layer, data mining and analytics\nlayer, intelligent control layer and smart application layer. We then review\nand discuss the applications of AI techniques for 6G networks and elaborate how\nto employ the AI techniques to efficiently and effectively optimize the network\nperformance, including AI-empowered mobile edge computing, intelligent mobility\nand handover management, and smart spectrum management. Moreover, we highlight\nimportant future research directions and potential solutions for AI-enabled\nintelligent 6G networks, including computation efficiency, algorithms\nrobustness, hardware development and energy management.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-12-12",
      "downloaded_date": "2025-02-01",
      "filename": "Yang-Artificial Intelligence-Enabled Intelligent 6G Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1912.05744v2",
      "categories": [
        "cs.NI",
        "eess.SP"
      ]
    },
    "2401.15487v1": {
      "title": "Artificial Intelligence: Arguments for Catastrophic Risk",
      "authors": [
        "Adam Bales",
        "William D'Alessandro",
        "Cameron Domenico Kirk-Giannini"
      ],
      "abstract": "Recent progress in artificial intelligence (AI) has drawn attention to the\ntechnology's transformative potential, including what some see as its prospects\nfor causing large-scale harm. We review two influential arguments purporting to\nshow how AI could pose catastrophic risks. The first argument -- the Problem of\nPower-Seeking -- claims that, under certain assumptions, advanced AI systems\nare likely to engage in dangerous power-seeking behavior in pursuit of their\ngoals. We review reasons for thinking that AI systems might seek power, that\nthey might obtain it, that this could lead to catastrophe, and that we might\nbuild and deploy such systems anyway. The second argument claims that the\ndevelopment of human-level AI will unlock rapid further progress, culminating\nin AI systems far more capable than any human -- this is the Singularity\nHypothesis. Power-seeking behavior on the part of such systems might be\nparticularly dangerous. We discuss a variety of objections to both arguments\nand conclude by assessing the state of the debate.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-01-27",
      "downloaded_date": "2025-02-01",
      "filename": "Bales-Artificial Intelligence Arguments for Catastrophic Risk.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.15487v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2408.14700v1": {
      "title": "Artificial Intelligence in Landscape Architecture: A Survey",
      "authors": [
        "Yue Xing",
        "Wensheng Gan",
        "Qidi Chen"
      ],
      "abstract": "The development history of landscape architecture (LA) reflects the human\npursuit of environmental beautification and ecological balance. With the\nadvancement of artificial intelligence (AI) technologies that simulate and\nextend human intelligence, immense opportunities have been provided for LA,\noffering scientific and technological support throughout the entire workflow.\nIn this article, we comprehensively review the applications of AI technology in\nthe field of LA. First, we introduce the many potential benefits that AI brings\nto the design, planning, and management aspects of LA. Secondly, we discuss how\nAI can assist the LA field in solving its current development problems,\nincluding urbanization, environmental degradation and ecological decline,\nirrational planning, insufficient management and maintenance, and lack of\npublic participation. Furthermore, we summarize the key technologies and\npractical cases of applying AI in the LA domain, from design assistance to\nintelligent management, all of which provide innovative solutions for the\nplanning, design, and maintenance of LA. Finally, we look ahead to the problems\nand opportunities in LA, emphasizing the need to combine human expertise and\njudgment for rational decision-making. This article provides both theoretical\nand practical guidance for LA designers, researchers, and technology\ndevelopers. The successful integration of AI technology into LA holds great\npromise for enhancing the field's capabilities and achieving more sustainable,\nefficient, and user-friendly outcomes.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/03c00f41b7d9c05d5171db3bd12e169e5d424cf3",
      "published_date": "2024-08-26",
      "downloaded_date": "2025-02-01",
      "filename": "Xing-Artificial Intelligence in Landscape Architecture A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.14700v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1603.08631v1": {
      "title": "Classification of Alzheimer's Disease using fMRI Data and Deep Learning Convolutional Neural Networks",
      "authors": [
        "Saman Sarraf",
        "Ghassem Tofighi"
      ],
      "abstract": "Over the past decade, machine learning techniques especially predictive\nmodeling and pattern recognition in biomedical sciences from drug delivery\nsystem to medical imaging has become one of the important methods which are\nassisting researchers to have deeper understanding of entire issue and to solve\ncomplex medical problems. Deep learning is power learning machine learning\nalgorithm in classification while extracting high-level features. In this\npaper, we used convolutional neural network to classify Alzheimer's brain from\nnormal healthy brain. The importance of classifying this kind of medical data\nis to potentially develop a predict model or system in order to recognize the\ntype disease from normal subjects or to estimate the stage of the disease.\nClassification of clinical data such as Alzheimer's disease has been always\nchallenging and most problematic part has been always selecting the most\ndiscriminative features. Using Convolutional Neural Network (CNN) and the\nfamous architecture LeNet-5, we successfully classified functional MRI data of\nAlzheimer's subjects from normal controls where the accuracy of test data on\ntrained data reached 96.85%. This experiment suggests us the shift and scale\ninvariant features extracted by CNN followed by deep learning classification is\nmost powerful method to distinguish clinical data from healthy data in fMRI.\nThis approach also enables us to expand our methodology to predict more\ncomplicated systems.",
      "citation_count": 211,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e51f48fe145a40eb842732d1987cdb23209fbcd9",
      "published_date": "2016-03-29",
      "downloaded_date": "2025-02-01",
      "filename": "Sarraf-Classification of Alzheimers Disease using fMRI Data and Deep Learning Convolutional Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1603.08631v1",
      "categories": [
        "cs.CV"
      ]
    },
    "1607.06583v2": {
      "title": "Classification of Alzheimer's Disease Structural MRI Data by Deep Learning Convolutional Neural Networks",
      "authors": [
        "Saman Sarraf",
        "Ghassem Tofighi"
      ],
      "abstract": "Recently, machine learning techniques especially predictive modeling and\npattern recognition in biomedical sciences from drug delivery system to medical\nimaging has become one of the important methods which are assisting researchers\nto have deeper understanding of entire issue and to solve complex medical\nproblems. Deep learning is a powerful machine learning algorithm in\nclassification while extracting low to high-level features. In this paper, we\nused convolutional neural network to classify Alzheimer's brain from normal\nhealthy brain. The importance of classifying this kind of medical data is to\npotentially develop a predict model or system in order to recognize the type\ndisease from normal subjects or to estimate the stage of the disease.\nClassification of clinical data such as Alzheimer's disease has been always\nchallenging and most problematic part has been always selecting the most\ndiscriminative features. Using Convolutional Neural Network (CNN) and the\nfamous architecture LeNet-5, we successfully classified structural MRI data of\nAlzheimer's subjects from normal controls where the accuracy of test data on\ntrained data reached 98.84%. This experiment suggests us the shift and scale\ninvariant features extracted by CNN followed by deep learning classification is\nmost powerful method to distinguish clinical data from healthy data in fMRI.\nThis approach also enables us to expand our methodology to predict more\ncomplicated systems.",
      "citation_count": 78,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/243df22a0f92c6ec7461e698802c7fab5a527187",
      "published_date": "2016-07-22",
      "downloaded_date": "2025-02-01",
      "filename": "Sarraf-Classification of Alzheimers Disease Structural MRI Data by Deep Learning Convolutional Neural Netwo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1607.06583v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "1902.09904v1": {
      "title": "Diagnosis of Alzheimer's Disease via Multi-modality 3D Convolutional Neural Network",
      "authors": [
        "Yechong Huang",
        "Jiahang Xu",
        "Yuncheng Zhou",
        "Tong Tong",
        "Xiahai Zhuang",
        "the Alzheimer's Disease Neuroimaging Initiative"
      ],
      "abstract": "Alzheimer's Disease (AD) is one of the most concerned neurodegenerative\ndiseases. In the last decade, studies on AD diagnosis attached great\nsignificance to artificial intelligence (AI)-based diagnostic algorithms. Among\nthe diverse modality imaging data, T1-weighted MRI and 18F-FDGPET are widely\nresearched for this task. In this paper, we propose a novel convolutional\nneural network (CNN) to fuse the multi-modality information including T1-MRI\nand FDG-PDT images around the hippocampal area for the diagnosis of AD.\nDifferent from the traditional machine learning algorithms, this method does\nnot require manually extracted features, and utilizes the stateof-art 3D\nimage-processing CNNs to learn features for the diagnosis and prognosis of AD.\nTo validate the performance of the proposed network, we trained the classifier\nwith paired T1-MRI and FDG-PET images using the ADNI datasets, including 731\nNormal (NL) subjects, 647 AD subjects, 441 stable MCI (sMCI) subjects and 326\nprogressive MCI (pMCI) subjects. We obtained the maximal accuracies of 90.10%\nfor NL/AD task, 87.46% for NL/pMCI task, and 76.90% for sMCI/pMCI task. The\nproposed framework yields comparative results against state-of-the-art\napproaches. Moreover, the experimental results have demonstrated that (1)\nsegmentation is not a prerequisite by using CNN, (2) the hippocampal area\nprovides enough information to give a reference to AD diagnosis. Keywords:\nAlzheimer's Disease, Multi-modality, Image Classification, CNN, Deep Learning,\nHippocampal",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-02-26",
      "downloaded_date": "2025-02-01",
      "filename": "Huang-Diagnosis of Alzheimers Disease via Multi-modality 3D Convolutional Neural Network.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1902.09904v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2308.13570v6": {
      "title": "Stochastic Configuration Machines for Industrial Artificial Intelligence",
      "authors": [
        "Dianhui Wang",
        "Matthew J. Felicetti"
      ],
      "abstract": "Real-time predictive modelling with desired accuracy is highly expected in\nindustrial artificial intelligence (IAI), where neural networks play a key\nrole. Neural networks in IAI require powerful, high-performance computing\ndevices to operate a large number of floating point data. Based on stochastic\nconfiguration networks (SCNs), this paper proposes a new randomized learner\nmodel, termed stochastic configuration machines (SCMs), to stress effective\nmodelling and data size saving that are useful and valuable for industrial\napplications. Compared to SCNs and random vector functional-link (RVFL) nets\nwith binarized implementation, the model storage of SCMs can be significantly\ncompressed while retaining favourable prediction performance. Besides the\narchitecture of the SCM learner model and its learning algorithm, as an\nimportant part of this contribution, we also provide a theoretical basis on the\nlearning capacity of SCMs by analysing the model's complexity. Experimental\nstudies are carried out over some benchmark datasets and three industrial\napplications. The results demonstrate that SCM has great potential for dealing\nwith industrial data analytics.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a30e6ae3299fedbdd151cd67bd2e509691f4b411",
      "published_date": "2023-08-25",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Stochastic Configuration Machines for Industrial Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.13570v6",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ]
    },
    "2501.04472v1": {
      "title": "Hybrid Artificial Intelligence Strategies for Drone Navigation",
      "authors": [
        "RubÃ©n San-Segundo",
        "LucÃ­a Angulo",
        "Manuel Gil-MartÃ­n",
        "David CarramiÃ±ana",
        "Ana M. Bernardos"
      ],
      "abstract": "Objective: This paper describes the development of hybrid artificial\nintelligence strategies for drone navigation. Methods: The navigation module\ncombines a deep learning model with a rule-based engine depending on the agent\nstate. The deep learning model has been trained using reinforcement learning.\nThe rule-based engine uses expert knowledge to deal with specific situations.\nThe navigation module incorporates several strategies to explain the drone\ndecision based on its observation space, and different mechanisms for including\nhuman decisions in the navigation process. Finally, this paper proposes an\nevaluation methodology based on defining several scenarios and analyzing the\nperformance of the different strategies according to metrics adapted to each\nscenario. Results: Two main navigation problems have been studied. For the\nfirst scenario (reaching known targets), it has been possible to obtain a 90%\ntask completion rate, reducing significantly the number of collisions thanks to\nthe rule-based engine. For the second scenario, it has been possible to reduce\n20% of the time required to locate all the targets using the reinforcement\nlearning model. Conclusions: Reinforcement learning is a very good strategy to\nlearn policies for drone navigation, but in critical situations, it is\nnecessary to complement it with a rule-based module to increase task success\nrate.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4b139bd8e90e4150e5f2359efb0272b8b8b3bc3b",
      "published_date": "2025-01-08",
      "downloaded_date": "2025-02-01",
      "filename": "San-Segundo-Hybrid Artificial Intelligence Strategies for Drone Navigation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.04472v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    "2110.07151v1": {
      "title": "Machine Learning, Deep Learning, and Hedonic Methods for Real Estate Price Prediction",
      "authors": [
        "Mahdieh Yazdani"
      ],
      "abstract": "In recent years several complaints about racial discrimination in appraising\nhome values have been accumulating. For several decades, to estimate the sale\nprice of the residential properties, appraisers have been walking through the\nproperties, observing the property, collecting data, and making use of the\nhedonic pricing models. However, this method bears some costs and by nature is\nsubjective and biased. To minimize human involvement and the biases in the real\nestate appraisals and boost the accuracy of the real estate market price\nprediction models, in this research we design data-efficient learning machines\ncapable of learning and extracting the relation or patterns between the inputs\n(features for the house) and output (value of the houses). We compare the\nperformance of some machine learning and deep learning algorithms, specifically\nartificial neural networks, random forest, and k nearest neighbor approaches to\nthat of hedonic method on house price prediction in the city of Boulder,\nColorado. Even though this study has been done over the houses in the city of\nBoulder it can be generalized to the housing market in any cities. The results\nindicate non-linear association between the dwelling features and dwelling\nprices. In light of these findings, this study demonstrates that random forest\nand artificial neural networks algorithms can be better alternatives over the\nhedonic regression analysis for prediction of the house prices in the city of\nBoulder, Colorado.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/845682c7af0a4eb88709d1833ce19bed292b8e35",
      "published_date": "2021-10-14",
      "downloaded_date": "2025-02-01",
      "filename": "Yazdani-Machine Learning Deep Learning and Hedonic Methods for Real Estate Price Prediction.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.07151v1",
      "categories": [
        "econ.EM"
      ]
    },
    "1903.03171v1": {
      "title": "Challenges for an Ontology of Artificial Intelligence",
      "authors": [
        "Scott H. Hawley"
      ],
      "abstract": "Of primary importance in formulating a response to the increasing prevalence\nand power of artificial intelligence (AI) applications in society are questions\nof ontology. Questions such as: What \"are\" these systems? How are they to be\nregarded? How does an algorithm come to be regarded as an agent? We discuss\nthree factors which hinder discussion and obscure attempts to form a clear\nontology of AI: (1) the various and evolving definitions of AI, (2) the\ntendency for pre-existing technologies to be assimilated and regarded as\n\"normal,\" and (3) the tendency of human beings to anthropomorphize. This list\nis not intended as exhaustive, nor is it seen to preclude entirely a clear\nontology, however, these challenges are a necessary set of topics for\nconsideration. Each of these factors is seen to present a 'moving target' for\ndiscussion, which poses a challenge for both technical specialists and\nnon-practitioners of AI systems development (e.g., philosophers and\ntheologians) to speak meaningfully given that the corpus of AI structures and\ncapabilities evolves at a rapid pace. Finally, we present avenues for moving\nforward, including opportunities for collaborative synthesis for scholars in\nphilosophy and science.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7384a453334c67f44b922f7029539b5a064fbd1e",
      "published_date": "2019-02-25",
      "downloaded_date": "2025-02-01",
      "filename": "Hawley-Challenges for an Ontology of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1903.03171v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0; K.4.0"
      ]
    },
    "2101.08439v2": {
      "title": "Optical neural network architecture for deep learning with the temporal synthetic dimension",
      "authors": [
        "Bo Peng",
        "Shuo Yan",
        "Dali Cheng",
        "Danying Yu",
        "Zhanwei Liu",
        "Vladislav V. Yakovlev",
        "Luqi Yuan",
        "Xianfeng Chen"
      ],
      "abstract": "The physical concept of synthetic dimensions has recently been introduced\ninto optics. The fundamental physics and applications are not yet fully\nunderstood, and this report explores an approach to optical neural networks\nusing synthetic dimension in time domain, by theoretically proposing to utilize\na single resonator network, where the arrival times of optical pulses are\ninterconnected to construct a temporal synthetic dimension. The set of pulses\nin each roundtrip therefore provides the sites in each layer in the optical\nneural network, and can be linearly transformed with splitters and delay lines,\nincluding the phase modulators, when pulses circulate inside the network. Such\nlinear transformation can be arbitrarily controlled by applied modulation\nphases, which serve as the building block of the neural network together with a\nnonlinear component for pulses. We validate the functionality of the proposed\noptical neural network for the deep learning purpose with examples handwritten\ndigit recognition and optical pulse train distribution classification problems.\nThis proof of principle computational work explores the new concept of\ndeveloping a photonics-based machine learning in a single ring network using\nsynthetic dimensions, which allows flexibility and easiness of reconfiguration\nwith complex functionality in achieving desired optical tasks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-01-21",
      "downloaded_date": "2025-02-01",
      "filename": "Peng-Optical neural network architecture for deep learning with the temporal synthetic dimension.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.08439v2",
      "categories": [
        "physics.optics"
      ]
    },
    "1809.02069v1": {
      "title": "Deep learning for in vitro prediction of pharmaceutical formulations",
      "authors": [
        "Yilong Yang",
        "Zhuyifan Ye",
        "Yan Su",
        "Qianqian Zhao",
        "Xiaoshan Li",
        "Defang Ouyang"
      ],
      "abstract": "Current pharmaceutical formulation development still strongly relies on the\ntraditional trial-and-error approach by individual experiences of\npharmaceutical scientists, which is laborious, time-consuming and costly.\nRecently, deep learning has been widely applied in many challenging domains\nbecause of its important capability of automatic feature extraction. The aim of\nthis research is to use deep learning to predict pharmaceutical formulations.\nIn this paper, two different types of dosage forms were chosen as model\nsystems. Evaluation criteria suitable for pharmaceutics were applied to\nassessing the performance of the models. Moreover, an automatic dataset\nselection algorithm was developed for selecting the representative data as\nvalidation and test datasets. Six machine learning methods were compared with\ndeep learning. The result shows the accuracies of both two deep neural networks\nwere above 80% and higher than other machine learning models, which showed good\nprediction in pharmaceutical formulations. In summary, deep learning with the\nautomatic data splitting algorithm and the evaluation criteria suitable for\npharmaceutical formulation data was firstly developed for the prediction of\npharmaceutical formulations. The cross-disciplinary integration of\npharmaceutics and artificial intelligence may shift the paradigm of\npharmaceutical researches from experience-dependent studies to data-driven\nmethodologies.",
      "citation_count": 107,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5ba2316c2fa40c2c9eae95a83a3a707c6f741c12",
      "published_date": "2018-09-06",
      "downloaded_date": "2025-02-01",
      "filename": "Yang-Deep learning for in vitro prediction of pharmaceutical formulations.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1809.02069v1",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2312.12872v1": {
      "title": "Integration and Performance Analysis of Artificial Intelligence and Computer Vision Based on Deep Learning Algorithms",
      "authors": [
        "Bo Liu",
        "Liqiang Yu",
        "Chang Che",
        "Qunwei Lin",
        "Hao Hu",
        "Xinyu Zhao"
      ],
      "abstract": "This paper focuses on the analysis of the application effectiveness of the\nintegration of deep learning and computer vision technologies. Deep learning\nachieves a historic breakthrough by constructing hierarchical neural networks,\nenabling end-to-end feature learning and semantic understanding of images. The\nsuccessful experiences in the field of computer vision provide strong support\nfor training deep learning algorithms. The tight integration of these two\nfields has given rise to a new generation of advanced computer vision systems,\nsignificantly surpassing traditional methods in tasks such as machine vision\nimage classification and object detection. In this paper, typical image\nclassification cases are combined to analyze the superior performance of deep\nneural network models while also pointing out their limitations in\ngeneralization and interpretability, proposing directions for future\nimprovements. Overall, the efficient integration and development trend of deep\nlearning with massive visual data will continue to drive technological\nbreakthroughs and application expansion in the field of computer vision, making\nit possible to build truly intelligent machine vision systems. This deepening\nfusion paradigm will powerfully promote unprecedented tasks and functions in\ncomputer vision, providing stronger development momentum for related\ndisciplines and industries.",
      "citation_count": 43,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/725859ccb208cb326780bbcf4705b3c35011fc6c",
      "published_date": "2023-12-20",
      "downloaded_date": "2025-02-01",
      "filename": "Liu-Integration and Performance Analysis of Artificial Intelligence and Computer Vision Based on Deep Le....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.12872v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "2005.00986v1": {
      "title": "Using Artificial Intelligence to Analyze Fashion Trends",
      "authors": [
        "Mengyun Shi",
        "Van Dyk Lewis"
      ],
      "abstract": "Analyzing fashion trends is essential in the fashion industry. Current\nfashion forecasting firms, such as WGSN, utilize the visual information from\naround the world to analyze and predict fashion trends. However, analyzing\nfashion trends is time-consuming and extremely labor intensive, requiring\nindividual employees' manual editing and classification. To improve the\nefficiency of data analysis of such image-based information and lower the cost\nof analyzing fashion images, this study proposes a data-driven quantitative\nabstracting approach using an artificial intelligence (A.I.) algorithm.\nSpecifically, an A.I. model was trained on fashion images from a large-scale\ndataset under different scenarios, for example in online stores and street\nsnapshots. This model was used to detect garments and classify clothing\nattributes such as textures, garment style, and details for runway photos and\nvideos. It was found that the A.I. model can generate rich attribute\ndescriptions of detected regions and accurately bind the garments in the\nimages. Adoption of A.I. algorithm demonstrated promising results and the\npotential to classify garment types and details automatically, which can make\nthe process of trend forecasting more cost-effective and faster.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2de66c4cbc1977b9375b76a4219f980e4fd302cb",
      "published_date": "2020-05-03",
      "downloaded_date": "2025-02-01",
      "filename": "Shi-Using Artificial Intelligence to Analyze Fashion Trends.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.00986v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "2108.09959v1": {
      "title": "Artificial Intelligence Ethics: An Inclusive Global Discourse?",
      "authors": [
        "Cathy Roche",
        "Dave Lewis",
        "P. J. Wall"
      ],
      "abstract": "It is widely accepted that technology is ubiquitous across the planet and has\nthe potential to solve many of the problems existing in the Global South.\nMoreover, the rapid advancement of artificial intelligence (AI) brings with it\nthe potential to address many of the challenges outlined in the Sustainable\nDevelopment Goals (SDGs) in ways which were never before possible. However,\nthere are many questions about how such advanced technologies should be managed\nand governed, and whether or not the emerging ethical frameworks and standards\nfor AI are dominated by the Global North. This research examines the growing\nbody of documentation on AI ethics to examine whether or not there is equality\nof participation in the ongoing global discourse. Specifically, it seeks to\ndiscover if both countries in the Global South and women are underrepresented\nin this discourse. Findings indicate a dearth of references to both of these\nthemes in the AI ethics documents, suggesting that the associated ethical\nimplications and risks are being neglected. Without adequate input from both\ncountries in the Global South and from women, such ethical frameworks and\nstandards may be discriminatory with the potential to reinforce\nmarginalisation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-08-23",
      "downloaded_date": "2025-02-01",
      "filename": "Roche-Artificial Intelligence Ethics An Inclusive Global Discourse.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.09959v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2409.00264v1": {
      "title": "The Artificial Intelligence Act: critical overview",
      "authors": [
        "Nuno Sousa e Silva"
      ],
      "abstract": "This article provides a critical overview of the recently approved Artificial\nIntelligence Act. It starts by presenting the main structure, objectives, and\napproach of Regulation (EU) 2024/1689. A definition of key concepts follows,\nand then the material and territorial scope, as well as the timing of\napplication, are analyzed. Although the Regulation does not explicitly set out\nprinciples, the main ideas of fairness, accountability, transparency, and\nequity in AI underly a set of rules of the regulation. This is discussed before\nlooking at the ill-defined set of forbidden AI practices (manipulation and e\nexploitation of vulnerabilities, social scoring, biometric identification and\nclassification, and predictive policing). It is highlighted that those rules\ndeal with behaviors rather than AI systems. The qualification and regulation of\nhigh-risk AI systems are tackled, alongside the obligation of transparency for\ncertain systems, the regulation of general-purpose models, and the rules on\ncertification, supervision, and sanctions. The text concludes that even if the\noverall framework can be deemed adequate and balanced, the approach is so\ncomplex that it risks defeating its own purpose of promoting responsible\ninnovation within the European Union and beyond its borders.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d15cd18c26997255a0b4f4cec7735fdd513d4070",
      "published_date": "2024-08-30",
      "downloaded_date": "2025-02-01",
      "filename": "Silva-The Artificial Intelligence Act critical overview.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.00264v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2410.01871v1": {
      "title": "Auction-Based Regulation for Artificial Intelligence",
      "authors": [
        "Marco Bornstein",
        "Zora Che",
        "Suhas Julapalli",
        "Abdirisak Mohamed",
        "Amrit Singh Bedi",
        "Furong Huang"
      ],
      "abstract": "In an era of \"moving fast and breaking things\", regulators have moved slowly\nto pick up the safety, bias, and legal pieces left in the wake of broken\nArtificial Intelligence (AI) deployment. Since AI models, such as large\nlanguage models, are able to push misinformation and stoke division within our\nsociety, it is imperative for regulators to employ a framework that mitigates\nthese dangers and ensures user safety. While there is much-warranted discussion\nabout how to address the safety, bias, and legal woes of state-of-the-art AI\nmodels, the number of rigorous and realistic mathematical frameworks to\nregulate AI safety is lacking. We take on this challenge, proposing an\nauction-based regulatory mechanism that provably incentivizes model-building\nagents (i) to deploy safer models and (ii) to participate in the regulation\nprocess. We provably guarantee, via derived Nash Equilibria, that each\nparticipating agent's best strategy is to submit a model safer than a\nprescribed minimum-safety threshold. Empirical results show that our regulatory\nauction boosts safety and participation rates by 20% and 15% respectively,\noutperforming simple regulatory frameworks that merely enforce minimum safety\nstandards.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/82000db55600a297056f4847f3362cbe2b574232",
      "published_date": "2024-10-02",
      "downloaded_date": "2025-02-01",
      "filename": "Bornstein-Auction-Based Regulation for Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.01871v1",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CY",
        "econ.GN",
        "q-fin.EC"
      ]
    },
    "2412.02498v1": {
      "title": "Advancing global aerosol forecasting with artificial intelligence",
      "authors": [
        "Ke Gui",
        "Xutao Zhang",
        "Huizheng Che",
        "Lei Li",
        "Yu Zheng",
        "Linchang An",
        "Yucong Miao",
        "Hujia Zhao",
        "Oleg Dubovik",
        "Brent Holben",
        "Jun Wang",
        "Pawan Gupta",
        "Elena S. Lind",
        "Carlos Toledano",
        "Hong Wang",
        "Zhili Wang",
        "Yaqiang Wang",
        "Xiaomeng Huang",
        "Kan Dai",
        "Xiangao Xia",
        "Xiaofeng Xu",
        "Xiaoye Zhang"
      ],
      "abstract": "Aerosol forecasting is essential for air quality warnings, health risk\nassessment, and climate change mitigation. However, it is more complex than\nweather forecasting due to the intricate interactions between aerosol\nphysicochemical processes and atmospheric dynamics, resulting in significant\nuncertainty and high computational costs. Here, we develop an artificial\nintelligence-driven global aerosol-meteorology forecasting system (AI-GAMFS),\nwhich provides reliable 5-day, 3-hourly forecasts of aerosol optical components\nand surface concentrations at a 0.5{\\deg} x 0.625{\\deg} resolution. AI-GAMFS\ncombines Vision Transformer and U-Net in a backbone network, robustly capturing\nthe complex aerosol-meteorology interactions via global attention and\nspatiotemporal encoding. Trained on 42 years of advanced aerosol reanalysis\ndata and initialized with GEOS Forward Processing (GEOS-FP) analyses, AI-GAMFS\ndelivers operational 5-day forecasts in one minute. It outperforms the\nCopernicus Atmosphere Monitoring Service (CAMS) global forecasting system,\nGEOS-FP forecasts, and several regional dust forecasting systems in forecasting\nmost aerosol variables including aerosol optical depth and dust components. Our\nresults mark a significant step forward in leveraging AI to refine\nphysics-based aerosol forecasting, facilitating more accurate global warnings\nfor aerosol pollution events, such as dust storms and wildfires.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cfcd833cbf61a567114bb3a303fbda22c491c9d4",
      "published_date": "2024-12-03",
      "downloaded_date": "2025-02-01",
      "filename": "Gui-Advancing global aerosol forecasting with artificial intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.02498v1",
      "categories": [
        "physics.ao-ph"
      ]
    },
    "2412.17866v1": {
      "title": "Artificial Intelligence, Scientific Discovery, and Product Innovation",
      "authors": [
        "Aidan Toner-Rodgers"
      ],
      "abstract": "This paper studies the impact of artificial intelligence on innovation,\nexploiting the randomized introduction of a new materials discovery technology\nto 1,018 scientists in the R&D lab of a large U.S. firm. AI-assisted\nresearchers discover 44% more materials, resulting in a 39% increase in patent\nfilings and a 17% rise in downstream product innovation. These compounds\npossess more novel chemical structures and lead to more radical inventions.\nHowever, the technology has strikingly disparate effects across the\nproductivity distribution: while the bottom third of scientists see little\nbenefit, the output of top researchers nearly doubles. Investigating the\nmechanisms behind these results, I show that AI automates 57% of\n\"idea-generation\" tasks, reallocating researchers to the new task of evaluating\nmodel-produced candidate materials. Top scientists leverage their domain\nknowledge to prioritize promising AI suggestions, while others waste\nsignificant resources testing false positives. Together, these findings\ndemonstrate the potential of AI-augmented research and highlight the\ncomplementarity between algorithms and expertise in the innovative process.\nSurvey evidence reveals that these gains come at a cost, however, as 82% of\nscientists report reduced satisfaction with their work due to decreased\ncreativity and skill underutilization.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8a4dc36f8b5a3d5d7f01b777f5c92bf70f09f1bd",
      "published_date": "2024-12-21",
      "downloaded_date": "2025-02-01",
      "filename": "Toner-Rodgers-Artificial Intelligence Scientific Discovery and Product Innovation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.17866v1",
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ]
    },
    "2012.02891v1": {
      "title": "Review: Deep Learning Methods for Cybersecurity and Intrusion Detection Systems",
      "authors": [
        "Mayra Macas",
        "Chunming Wu"
      ],
      "abstract": "As the number of cyber-attacks is increasing, cybersecurity is evolving to a\nkey concern for any business. Artificial Intelligence (AI) and Machine Learning\n(ML) (in particular Deep Learning - DL) can be leveraged as key enabling\ntechnologies for cyber-defense, since they can contribute in threat detection\nand can even provide recommended actions to cyber analysts. A partnership of\nindustry, academia, and government on a global scale is necessary in order to\nadvance the adoption of AI/ML to cybersecurity and create efficient cyber\ndefense systems. In this paper, we are concerned with the investigation of the\nvarious deep learning techniques employed for network intrusion detection and\nwe introduce a DL framework for cybersecurity applications.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3c1f28254d3239db8c218f2f5c7b7c958951cd3d",
      "published_date": "2020-12-04",
      "downloaded_date": "2025-02-01",
      "filename": "Macas-Review Deep Learning Methods for Cybersecurity and Intrusion Detection Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.02891v1",
      "categories": [
        "cs.CR",
        "cs.LG"
      ]
    },
    "1903.04369v2": {
      "title": "Artificial intelligence in cyber physical systems",
      "authors": [
        "Petar Radanliev",
        "David De Roure",
        "Max Van Kleek",
        "Omar Santos",
        "Uchenna Ani"
      ],
      "abstract": "This article conducts a literature review of current and future challenges in\nthe use of artificial intelligence (AI) in cyber physical systems. The\nliterature review is focused on identifying a conceptual framework for\nincreasing resilience with AI through automation supporting both, a technical\nand human level. The methodology applied resembled a literature review and\ntaxonomic analysis of complex internet of things (IoT) interconnected and\ncoupled cyber physical systems. There is an increased attention on propositions\non models, infrastructures and frameworks of IoT in both academic and technical\npapers. These reports and publications frequently represent a juxtaposition of\nother related systems and technologies (e.g. Industrial Internet of Things,\nCyber Physical Systems, Industry 4.0 etc.). We review academic and industry\npapers published between 2010 and 2020. The results determine a new\nhierarchical cascading conceptual framework for analysing the evolution of AI\ndecision-making in cyber physical systems. We argue that such evolution is\ninevitable and autonomous because of the increased integration of connected\ndevices (IoT) in cyber physical systems. To support this argument, taxonomic\nmethodology is adapted and applied for transparency and justifications of\nconcepts selection decisions through building summary maps that are applied for\ndesigning the hierarchical cascading conceptual framework.",
      "citation_count": 85,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0a02f03f271429cff00541a84fe1c8422befe0ec",
      "published_date": "2019-03-11",
      "downloaded_date": "2025-02-01",
      "filename": "Radanliev-Artificial intelligence in cyber physical systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1903.04369v2",
      "categories": [
        "cs.CY"
      ]
    },
    "2408.12250v1": {
      "title": "Can Artificial Intelligence Embody Moral Values?",
      "authors": [
        "Torben Swoboda",
        "Lode Lauwaert"
      ],
      "abstract": "The neutrality thesis holds that technology cannot be laden with values. This\nlong-standing view has faced critiques, but much of the argumentation against\nneutrality has focused on traditional, non-smart technologies like bridges and\nrazors. In contrast, AI is a smart technology increasingly used in high-stakes\ndomains like healthcare, finance, and policing, where its decisions can cause\nmoral harm. In this paper, we argue that artificial intelligence, particularly\nartificial agents that autonomously make decisions to pursue their goals,\nchallenge the neutrality thesis. Our central claim is that the computational\nmodels underlying artificial agents can integrate representations of moral\nvalues such as fairness, honesty and avoiding harm. We provide a conceptual\nframework discussing the neutrality thesis, values, and AI. Moreover, we\nexamine two approaches to designing computational models of morality,\nartificial conscience and ethical prompting, and present empirical evidence\nfrom text-based game environments that artificial agents with such models\nexhibit more ethical behavior compared to agents without these models. The\nfindings support that AI can embody moral values, which contradicts the claim\nthat all technologies are necessarily value-neutral.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bf5a8bfa09498b39a4d736c96ec5ac1e2791c80a",
      "published_date": "2024-08-22",
      "downloaded_date": "2025-02-01",
      "filename": "Swoboda-Can Artificial Intelligence Embody Moral Values.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.12250v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2409.13187v2": {
      "title": "Cooperative Resilience in Artificial Intelligence Multiagent Systems",
      "authors": [
        "Manuela Chacon-Chamorro",
        "Luis Felipe Giraldo",
        "Nicanor Quijano",
        "Vicente Vargas-Panesso",
        "CÃ©sar GonzÃ¡lez",
        "Juan SebastiÃ¡n PinzÃ³n",
        "RubÃ©n Manrique",
        "Manuel RÃ­os",
        "Yesid Fonseca",
        "Daniel GÃ³mez-Barrera",
        "MÃ³nica Perdomo-PÃ©rez"
      ],
      "abstract": "Resilience refers to the ability of systems to withstand, adapt to, and\nrecover from disruptive events. While studies on resilience have attracted\nsignificant attention across various research domains, the precise definition\nof this concept within the field of cooperative artificial intelligence remains\nunclear. This paper addresses this gap by proposing a clear definition of\n`cooperative resilience' and outlining a methodology for its quantitative\nmeasurement. The methodology is validated in an environment with RL-based and\nLLM-augmented autonomous agents, subjected to environmental changes and the\nintroduction of agents with unsustainable behaviors. These events are\nparameterized to create various scenarios for measuring cooperative resilience.\nThe results highlight the crucial role of resilience metrics in analyzing how\nthe collective system prepares for, resists, recovers from, sustains\nwell-being, and transforms in the face of disruptions. These findings provide\nfoundational insights into the definition, measurement, and preliminary\nanalysis of cooperative resilience, offering significant implications for the\nbroader field of AI. Moreover, the methodology and metrics developed here can\nbe adapted to a wide range of AI applications, enhancing the reliability and\neffectiveness of AI in dynamic and unpredictable environments.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7db04ccbe0dcf9e6d763c2db62bd108ad6691957",
      "published_date": "2024-09-20",
      "downloaded_date": "2025-02-01",
      "filename": "Chacon-Chamorro-Cooperative Resilience in Artificial Intelligence Multiagent Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.13187v2",
      "categories": [
        "cs.MA",
        "cs.AI"
      ]
    },
    "2211.17139v2": {
      "title": "Multidimensional analysis using sensor arrays with deep learning for high-precision and high-accuracy diagnosis",
      "authors": [
        "Julie Payette",
        "Sylvain G. Cloutier",
        "Fabrice Vaussenat"
      ],
      "abstract": "In the upcoming years, artificial intelligence (AI) is going to transform the\npractice of medicine in most of its specialties. Deep learning can help achieve\nbetter and earlier problem detection, while reducing errors on diagnosis. By\nfeeding a deep neural network (DNN) with the data from a low-cost and\nlow-accuracy sensor array, we demonstrate that it becomes possible to\nsignificantly improve the measurements' precision and accuracy. The data\ncollection is done with an array composed of 32 temperature sensors, including\n16 analog and 16 digital sensors. All sensors have accuracies between\n0.5-2.0$^\\circ$C. 800 vectors are extracted, covering a range from to 30 to\n45$^\\circ$C. In order to improve the temperature readings, we use machine\nlearning to perform a linear regression analysis through a DNN. In an attempt\nto minimize the model's complexity in order to eventually run inferences\nlocally, the network with the best results involves only three layers using the\nhyperbolic tangent activation function and the Adam Stochastic Gradient Descent\n(SGD) optimizer. The model is trained with a randomly-selected dataset using\n640 vectors (80% of the data) and tested with 160 vectors (20%). Using the mean\nsquared error as a loss function between the data and the model's prediction,\nwe achieve a loss of only 1.47x10$^{-4}$ on the training set and 1.22x10$^{-4}$\non the test set. As such, we believe this appealing approach offers a new\npathway towards significantly better datasets using readily-available ultra\nlow-cost sensors.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-11-30",
      "downloaded_date": "2025-02-01",
      "filename": "Payette-Multidimensional analysis using sensor arrays with deep learning for high-precision and high-accurac....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.17139v2",
      "categories": [
        "cs.LG"
      ]
    },
    "2407.17844v4": {
      "title": "Innovative Speech-Based Deep Learning Approaches for Parkinson's Disease Classification: A Systematic Review",
      "authors": [
        "Lisanne van Gelderen",
        "Cristian Tejedor-GarcÃ­a"
      ],
      "abstract": "Parkinson's disease (PD), the second most prevalent neurodegenerative\ndisorder worldwide, frequently presents with early-stage speech impairments.\nRecent advancements in Artificial Intelligence (AI), particularly deep learning\n(DL), have significantly enhanced PD diagnosis through the analysis of speech\ndata. Nevertheless, the progress of research is restricted by the limited\navailability of publicly accessible speech-based PD datasets, primarily due to\nprivacy concerns. The goal of this systematic review is to explore the current\nlandscape of speech-based DL approaches for PD classification, based on 33\nscientific works published between January 2020 and March 2024. We discuss\ntheir available resources, capabilities, and potential limitations, and issues\nrelated to bias, explainability, and privacy. Furthermore, this review provides\nan overview of publicly accessible speech-based datasets and open-source\nmaterial for PD. The DL approaches identified are categorized into end-to-end\n(E2E) learning, transfer learning (TL), and deep acoustic feature extraction\n(DAFE). Among E2E approaches, Convolutional Neural Networks (CNNs) are\nprevalent, though Transformers are increasingly popular. E2E approaches face\nchallenges such as limited data and computational resources, especially with\nTransformers. TL addresses these issues by providing more robust PD diagnosis\nand better generalizability across languages. DAFE aims to improve the\nexplainability and interpretability of results by examining the specific\neffects of deep features on both other DL approaches and more traditional\nmachine learning (ML) methods. However, it often underperforms compared to E2E\nand TL approaches.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5a9fecf4b9a86bf6d2f2dab9509577c8c1134fb2",
      "published_date": "2024-07-25",
      "downloaded_date": "2025-02-01",
      "filename": "Gelderen-Innovative Speech-Based Deep Learning Approaches for Parkinsons Disease Classification A Systematic ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.17844v4",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.AS"
      ]
    },
    "2205.00202v1": {
      "title": "Explainable Artificial Intelligence for Bayesian Neural Networks: Towards trustworthy predictions of ocean dynamics",
      "authors": [
        "Mariana C. A. Clare",
        "Maike Sonnewald",
        "Redouane Lguensat",
        "Julie Deshayes",
        "Venkatramani Balaji"
      ],
      "abstract": "The trustworthiness of neural networks is often challenged because they lack\nthe ability to express uncertainty and explain their skill. This can be\nproblematic given the increasing use of neural networks in high stakes\ndecision-making such as in climate change applications. We address both issues\nby successfully implementing a Bayesian Neural Network (BNN), where parameters\nare distributions rather than deterministic, and applying novel implementations\nof explainable AI (XAI) techniques. The uncertainty analysis from the BNN\nprovides a comprehensive overview of the prediction more suited to\npractitioners' needs than predictions from a classical neural network. Using a\nBNN means we can calculate the entropy (i.e. uncertainty) of the predictions\nand determine if the probability of an outcome is statistically significant. To\nenhance trustworthiness, we also spatially apply the two XAI techniques of\nLayer-wise Relevance Propagation (LRP) and SHapley Additive exPlanation (SHAP)\nvalues. These XAI methods reveal the extent to which the BNN is suitable and/or\ntrustworthy. Using two techniques gives a more holistic view of BNN skill and\nits uncertainty, as LRP considers neural network parameters, whereas SHAP\nconsiders changes to outputs. We verify these techniques using comparison with\nintuition from physical theory. The differences in explanation identify\npotential areas where new physical theory guided studies are needed.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-04-30",
      "downloaded_date": "2025-02-01",
      "filename": "Clare-Explainable Artificial Intelligence for Bayesian Neural Networks Towards trustworthy predictions of ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.00202v1",
      "categories": [
        "physics.ao-ph",
        "cs.LG",
        "68T07, 86A05, 86A08",
        "I.2.6; J.2"
      ]
    },
    "2103.00637v1": {
      "title": "Detection of Malicious Android Applications: Classical Machine Learning vs. Deep Neural Network Integrated with Clustering",
      "authors": [
        "Hemant Rathore",
        "Sanjay K. Sahay",
        "Shivin Thukral",
        "Mohit Sewak"
      ],
      "abstract": "Today anti-malware community is facing challenges due to the ever-increasing\nsophistication and volume of malware attacks developed by adversaries.\nTraditional malware detection mechanisms are not able to cope-up with\nnext-generation malware attacks. Therefore in this paper, we propose effective\nand efficient Android malware detection models based on machine learning and\ndeep learning integrated with clustering. We performed a comprehensive study of\ndifferent feature reduction, classification and clustering algorithms over\nvarious performance metrics to construct the Android malware detection models.\nOur experimental results show that malware detection models developed using\nRandom Forest eclipsed deep neural network and other classifiers on the\nmajority of performance metrics. The baseline Random Forest model without any\nfeature reduction achieved the highest AUC of 99.4%. Also, the segregating of\nvector space using clustering integrated with Random Forest further boosted the\nAUC to 99.6% in one cluster and direct detection of Android malware in another\ncluster, thus reducing the curse of dimensionality. Additionally, we found that\nfeature reduction in detection models does improve the model efficiency\n(training and testing time) many folds without much penalty on the\neffectiveness of the detection model.",
      "citation_count": 16,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ab81c71acbf21b05b1498d2e8d5534ca91cfe813",
      "published_date": "2021-02-28",
      "downloaded_date": "2025-02-01",
      "filename": "Rathore-Detection of Malicious Android Applications Classical Machine Learning vs Deep Neural Network Integr....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.00637v1",
      "categories": [
        "cs.CR",
        "cs.LG"
      ]
    },
    "2103.16323v2": {
      "title": "Thermal Neural Networks: Lumped-Parameter Thermal Modeling With State-Space Machine Learning",
      "authors": [
        "Wilhelm KirchgÃ¤ssner",
        "Oliver Wallscheid",
        "Joachim BÃ¶cker"
      ],
      "abstract": "With electric power systems becoming more compact and increasingly powerful,\nthe relevance of thermal stress especially during overload operation is\nexpected to increase ceaselessly. Whenever critical temperatures cannot be\nmeasured economically on a sensor base, a thermal model lends itself to\nestimate those unknown quantities. Thermal models for electric power systems\nare usually required to be both, real-time capable and of high estimation\naccuracy. Moreover, ease of implementation and time to production play an\nincreasingly important role. In this work, the thermal neural network (TNN) is\nintroduced, which unifies both, consolidated knowledge in the form of\nheat-transfer-based lumped-parameter models, and data-driven nonlinear function\napproximation with supervised machine learning. A quasi-linear\nparameter-varying system is identified solely from empirical data, where\nrelationships between scheduling variables and system matrices are inferred\nstatistically and automatically. At the same time, a TNN has physically\ninterpretable states through its state-space representation, is end-to-end\ntrainable -- similar to deep learning models -- with automatic differentiation,\nand requires no material, geometry, nor expert knowledge for its design.\nExperiments on an electric motor data set show that a TNN achieves higher\ntemperature estimation accuracies than previous white-/grey- or black-box\nmodels with a mean squared error of $3.18~\\text{K}^2$ and a worst-case error of\n$5.84~\\text{K}$ at 64 model parameters.",
      "citation_count": 32,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/766f6f9e61c31bec161a86e0deba3b0d4fc146e4",
      "published_date": "2021-03-30",
      "downloaded_date": "2025-02-01",
      "filename": "KirchgÃ¤ssner-Thermal Neural Networks Lumped-Parameter Thermal Modeling With State-Space Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.16323v2",
      "categories": [
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    },
    "2101.02486v2": {
      "title": "Deep Learning Methods for Vessel Trajectory Prediction based on Recurrent Neural Networks",
      "authors": [
        "Samuele Capobianco",
        "Leonardo M. Millefiori",
        "Nicola Forti",
        "Paolo Braca",
        "Peter Willett"
      ],
      "abstract": "Data-driven methods open up unprecedented possibilities for maritime\nsurveillance using Automatic Identification System (AIS) data. In this work, we\nexplore deep learning strategies using historical AIS observations to address\nthe problem of predicting future vessel trajectories with a prediction horizon\nof several hours. We propose novel sequence-to-sequence vessel trajectory\nprediction models based on encoder-decoder recurrent neural networks (RNNs)\nthat are trained on historical trajectory data to predict future trajectory\nsamples given previous observations. The proposed architecture combines Long\nShort-Term Memory (LSTM) RNNs for sequence modeling to encode the observed data\nand generate future predictions with different intermediate aggregation layers\nto capture space-time dependencies in sequential data. Experimental results on\nvessel trajectories from an AIS dataset made freely available by the Danish\nMaritime Authority show the effectiveness of deep-learning methods for\ntrajectory prediction based on sequence-to-sequence neural networks, which\nachieve better performance than baseline approaches based on linear regression\nor on the Multi-Layer Perceptron (MLP) architecture. The comparative evaluation\nof results shows: i) the superiority of attention pooling over static pooling\nfor the specific application, and ii) the remarkable performance improvement\nthat can be obtained with labeled trajectories, i.e., when predictions are\nconditioned on a low-level context representation encoded from the sequence of\npast observations, as well as on additional inputs (e.g., port of departure or\narrival) about the vessel's high-level intention, which may be available from\nAIS.",
      "citation_count": 119,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/31e54a60af88ce9a539c741cc8a63470152ff4fc",
      "published_date": "2021-01-07",
      "downloaded_date": "2025-02-01",
      "filename": "Capobianco-Deep Learning Methods for Vessel Trajectory Prediction based on Recurrent Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.02486v2",
      "categories": [
        "cs.CV"
      ]
    },
    "1708.09401v3": {
      "title": "Machine Learning Topological Invariants with Neural Networks",
      "authors": [
        "Pengfei Zhang",
        "Huitao Shen",
        "Hui Zhai"
      ],
      "abstract": "In this Letter we supervisedly train neural networks to distinguish different\ntopological phases in the context of topological band insulators. After\ntraining with Hamiltonians of one-dimensional insulators with chiral symmetry,\nthe neural network can predict their topological winding numbers with nearly\n100% accuracy, even for Hamiltonians with larger winding numbers that are not\nincluded in the training data. These results show a remarkable success that the\nneural network can capture the global and nonlinear topological features of\nquantum phases from local inputs. By opening up the neural network, we confirm\nthat the network does learn the discrete version of the winding number formula.\nWe also make a couple of remarks regarding the role of the symmetry and the\nopposite effect of regularization techniques when applying machine learning to\nphysical systems.",
      "citation_count": 191,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/45b6408310aec516c43a3763d67cd851bdd9123b",
      "published_date": "2017-08-30",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Machine Learning Topological Invariants with Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1708.09401v3",
      "categories": [
        "cond-mat.mes-hall",
        "cond-mat.dis-nn",
        "cond-mat.str-el",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2310.06506v1": {
      "title": "Runway Sign Classifier: A DAL C Certifiable Machine Learning System",
      "authors": [
        "Konstantin Dmitriev",
        "Johann Schumann",
        "Islam Bostanov",
        "Mostafa Abdelhamid",
        "Florian Holzapfel"
      ],
      "abstract": "In recent years, the remarkable progress of Machine Learning (ML)\ntechnologies within the domain of Artificial Intelligence (AI) systems has\npresented unprecedented opportunities for the aviation industry, paving the way\nfor further advancements in automation, including the potential for single\npilot or fully autonomous operation of large commercial airplanes. However, ML\ntechnology faces major incompatibilities with existing airborne certification\nstandards, such as ML model traceability and explainability issues or the\ninadequacy of traditional coverage metrics. Certification of ML-based airborne\nsystems using current standards is problematic due to these challenges. This\npaper presents a case study of an airborne system utilizing a Deep Neural\nNetwork (DNN) for airport sign detection and classification. Building upon our\nprevious work, which demonstrates compliance with Design Assurance Level (DAL)\nD, we upgrade the system to meet the more stringent requirements of Design\nAssurance Level C. To achieve DAL C, we employ an established architectural\nmitigation technique involving two redundant and dissimilar Deep Neural\nNetworks. The application of novel ML-specific data management techniques\nfurther enhances this approach. This work is intended to illustrate how the\ncertification challenges of ML-based systems can be addressed for medium\ncriticality airborne applications.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/088e64f8a1f3f4f574679fcc0b1507b4389f170f",
      "published_date": "2023-10-10",
      "downloaded_date": "2025-02-01",
      "filename": "Dmitriev-Runway Sign Classifier A DAL C Certifiable Machine Learning System.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.06506v1",
      "categories": [
        "cs.LG"
      ]
    },
    "1711.06517v2": {
      "title": "Wikipedia for Smart Machines and Double Deep Machine Learning",
      "authors": [
        "Moshe BenBassat"
      ],
      "abstract": "Very important breakthroughs in data centric deep learning algorithms led to\nimpressive performance in transactional point applications of Artificial\nIntelligence (AI) such as Face Recognition, or EKG classification. With all due\nappreciation, however, knowledge blind data only machine learning algorithms\nhave severe limitations for non-transactional AI applications, such as medical\ndiagnosis beyond the EKG results. Such applications require deeper and broader\nknowledge in their problem solving capabilities, e.g. integrating anatomy and\nphysiology knowledge with EKG results and other patient findings. Following a\nreview and illustrations of such limitations for several real life AI\napplications, we point at ways to overcome them. The proposed Wikipedia for\nSmart Machines initiative aims at building repositories of software structures\nthat represent humanity science & technology knowledge in various parts of\nlife; knowledge that we all learn in schools, universities and during our\nprofessional life. Target readers for these repositories are smart machines;\nnot human. AI software developers will have these Reusable Knowledge structures\nreadily available, hence, the proposed name ReKopedia. Big Data is by now a\nmature technology, it is time to focus on Big Knowledge. Some will be derived\nfrom data, some will be obtained from mankind gigantic repository of knowledge.\nWikipedia for smart machines along with the new Double Deep Learning approach\noffer a paradigm for integrating datacentric deep learning algorithms with\nalgorithms that leverage deep knowledge, e.g. evidential reasoning and\ncausality reasoning. For illustration, a project is described to produce\nReKopedia knowledge modules for medical diagnosis of about 1,000 disorders.\nData is important, but knowledge deep, basic, and commonsense is equally\nimportant.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/41576e274d4e7d8652d866df1eeb297cd37b213a",
      "published_date": "2017-11-17",
      "downloaded_date": "2025-02-01",
      "filename": "BenBassat-Wikipedia for Smart Machines and Double Deep Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1711.06517v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2308.10135v1": {
      "title": "A Review on Objective-Driven Artificial Intelligence",
      "authors": [
        "Apoorv Singh"
      ],
      "abstract": "While advancing rapidly, Artificial Intelligence still falls short of human\nintelligence in several key aspects due to inherent limitations in current AI\ntechnologies and our understanding of cognition. Humans have an innate ability\nto understand context, nuances, and subtle cues in communication, which allows\nus to comprehend jokes, sarcasm, and metaphors. Machines struggle to interpret\nsuch contextual information accurately. Humans possess a vast repository of\ncommon-sense knowledge that helps us make logical inferences and predictions\nabout the world. Machines lack this innate understanding and often struggle\nwith making sense of situations that humans find trivial. In this article, we\nreview the prospective Machine Intelligence candidates, a review from Prof.\nYann LeCun, and other work that can help close this gap between human and\nmachine intelligence. Specifically, we talk about what's lacking with the\ncurrent AI techniques such as supervised learning, reinforcement learning,\nself-supervised learning, etc. Then we show how Hierarchical planning-based\napproaches can help us close that gap and deep-dive into energy-based,\nlatent-variable methods and Joint embedding predictive architecture methods.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/80c8579a73d8bf9361c77fb52cdf0c933a5a0a03",
      "published_date": "2023-08-20",
      "downloaded_date": "2025-02-01",
      "filename": "Singh-A Review on Objective-Driven Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.10135v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ]
    },
    "2308.13458v1": {
      "title": "ARTIST: ARTificial Intelligence for Simplified Text",
      "authors": [
        "Lorenzo Corti",
        "Jie Yang"
      ],
      "abstract": "Complex text is a major barrier for many citizens when accessing public\ninformation and knowledge. While often done manually, Text Simplification is a\nkey Natural Language Processing task that aims for reducing the linguistic\ncomplexity of a text while preserving the original meaning. Recent advances in\nGenerative Artificial Intelligence (AI) have enabled automatic text\nsimplification both on the lexical and syntactical levels. However, as\napplications often focus on English, little is understood about the\neffectiveness of Generative AI techniques on low-resource languages such as\nDutch. For this reason, we carry out empirical studies to understand the\nbenefits and limitations of applying generative technologies for text\nsimplification and provide the following outcomes: 1) the design and\nimplementation for a configurable text simplification pipeline that\norchestrates state-of-the-art generative text simplification models, domain and\nreader adaptation, and visualisation modules; 2) insights and lessons learned,\nshowing the strengths of automatic text simplification while exposing the\nchallenges in handling cultural and commonsense knowledge. These outcomes\nrepresent a first step in the exploration of Dutch text simplification and shed\nlight on future endeavours both for research and practice.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ee1c3c28fcf13e92772e1855ca18ce82a8afd35c",
      "published_date": "2023-08-25",
      "downloaded_date": "2025-02-01",
      "filename": "Corti-ARTIST ARTificial Intelligence for Simplified Text.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.13458v1",
      "categories": [
        "cs.CL"
      ]
    },
    "2310.10013v1": {
      "title": "Riemannian Residual Neural Networks",
      "authors": [
        "Isay Katsman",
        "Eric Ming Chen",
        "Sidhanth Holalkere",
        "Anna Asch",
        "Aaron Lou",
        "Ser-Nam Lim",
        "Christopher De Sa"
      ],
      "abstract": "Recent methods in geometric deep learning have introduced various neural\nnetworks to operate over data that lie on Riemannian manifolds. Such networks\nare often necessary to learn well over graphs with a hierarchical structure or\nto learn over manifold-valued data encountered in the natural sciences. These\nnetworks are often inspired by and directly generalize standard Euclidean\nneural networks. However, extending Euclidean networks is difficult and has\nonly been done for a select few manifolds. In this work, we examine the\nresidual neural network (ResNet) and show how to extend this construction to\ngeneral Riemannian manifolds in a geometrically principled manner. Originally\nintroduced to help solve the vanishing gradient problem, ResNets have become\nubiquitous in machine learning due to their beneficial learning properties,\nexcellent empirical results, and easy-to-incorporate nature when building\nvaried neural networks. We find that our Riemannian ResNets mirror these\ndesirable properties: when compared to existing manifold neural networks\ndesigned to learn over hyperbolic space and the manifold of symmetric positive\ndefinite matrices, we outperform both kinds of networks in terms of relevant\ntesting metrics and training dynamics.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/916db7e60383e6688865904cd7f1c62f1425bc98",
      "published_date": "2023-10-16",
      "downloaded_date": "2025-02-01",
      "filename": "Katsman-Riemannian Residual Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.10013v1",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    "1511.07714v1": {
      "title": "A Python Engine for Teaching Artificial Intelligence in Games",
      "authors": [
        "Mark O. Riedl"
      ],
      "abstract": "Computer games play an important role in our society and motivate people to\nlearn computer science. Since artificial intelligence is integral to most\ngames, they can also be used to teach artificial intelligence. We introduce the\nGame AI Game Engine (GAIGE), a Python game engine specifically designed to\nteach about how AI is used in computer games. A progression of seven\nassignments builds toward a complete, working Multi-User Battle Arena (MOBA)\ngame. We describe the engine, the assignments, and our experiences using it in\na class on Game Artificial Intelligence.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a2fcd0fd3f74dbda2f7a1c402edaeeac95b5526c",
      "published_date": "2015-11-24",
      "downloaded_date": "2025-02-01",
      "filename": "Riedl-A Python Engine for Teaching Artificial Intelligence in Games.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1511.07714v1",
      "categories": [
        "cs.CY",
        "K.3.2; K.8.0; I.2.1; I.2.11"
      ]
    },
    "1904.00296v1": {
      "title": "Using Scratch to Teach Undergraduate Students' Skills on Artificial Intelligence",
      "authors": [
        "Julian Estevez",
        "Gorka Garate",
        "JM Lopez Guede",
        "Manuel GraÃ±a"
      ],
      "abstract": "This paper presents a educational workshop in Scratch that is proposed for\nthe active participation of undergraduate students in contexts of Artificial\nIntelligence. The main objective of the activity is to demystify the complexity\nof Artificial Intelligence and its algorithms. For this purpose, students must\nrealize simple exercises of clustering and two neural networks, in Scratch. The\ndetailed methodology to get that is presented in the article.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-03-30",
      "downloaded_date": "2025-02-01",
      "filename": "Estevez-Using Scratch to Teach Undergraduate Students Skills on Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1904.00296v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "1901.08247v3": {
      "title": "Machine Learning and Deep Learning Algorithms for Bearing Fault Diagnostics -- A Comprehensive Review",
      "authors": [
        "Shen Zhang",
        "Shibo Zhang",
        "Bingnan Wang",
        "Thomas G. Habetler"
      ],
      "abstract": "In this survey paper, we systematically summarize existing literature on\nbearing fault diagnostics with machine learning (ML) and data mining\ntechniques. While conventional ML methods, including artificial neural network\n(ANN), principal component analysis (PCA), support vector machines (SVM), etc.,\nhave been successfully applied to the detection and categorization of bearing\nfaults for decades, recent developments in deep learning (DL) algorithms in the\nlast five years have sparked renewed interest in both industry and academia for\nintelligent machine health monitoring. In this paper, we first provide a brief\nreview of conventional ML methods, before taking a deep dive into the\nstate-of-the-art DL algorithms for bearing fault applications. Specifically,\nthe superiority of DL based methods over conventional ML methods are analyzed\nin terms of fault feature extraction and classification performances; many new\nfunctionalities enabled by DL techniques are also summarized. In addition, to\nobtain a more intuitive insight, a comparative study is conducted on the\nclassification accuracy of different algorithms utilizing the open-source Case\nWestern Reserve University (CWRU) bearing dataset. Finally, to facilitate the\ntransition on applying various DL algorithms to bearing fault diagnostics,\ndetailed recommendations and suggestions are provided for specific application\nconditions such as the setup environment, the data size, and the number of\nsensors and sensor types. Future research directions to further enhance the\nperformance of DL algorithms on health monitoring are also discussed.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-01-24",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Machine Learning and Deep Learning Algorithms for Bearing Fault Diagnostics -- A Comprehensive Revie....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.08247v3",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2403.05595v1": {
      "title": "Comparison of gait phase detection using traditional machine learning and deep learning techniques",
      "authors": [
        "Farhad Nazari",
        "Navid Mohajer",
        "Darius Nahavandi",
        "Abbas Khosravi"
      ],
      "abstract": "Human walking is a complex activity with a high level of cooperation and\ninteraction between different systems in the body. Accurate detection of the\nphases of the gait in real-time is crucial to control lower-limb assistive\ndevices like exoskeletons and prostheses. There are several ways to detect the\nwalking gait phase, ranging from cameras and depth sensors to the sensors\nattached to the device itself or the human body. Electromyography (EMG) is one\nof the input methods that has captured lots of attention due to its precision\nand time delay between neuromuscular activity and muscle movement. This study\nproposes a few Machine Learning (ML) based models on lower-limb EMG data for\nhuman walking. The proposed models are based on Gaussian Naive Bayes (NB),\nDecision Tree (DT), Random Forest (RF), Linear Discriminant Analysis (LDA) and\nDeep Convolutional Neural Networks (DCNN). The traditional ML models are\ntrained on hand-crafted features or their reduced components using Principal\nComponent Analysis (PCA). On the contrary, the DCNN model utilises\nconvolutional layers to extract features from raw data. The results show up to\n75% average accuracy for traditional ML models and 79% for Deep Learning (DL)\nmodel. The highest achieved accuracy in 50 trials of the training DL model is\n89.5%.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d89aeff02646d9c4376377117e2ac37c8c103dce",
      "published_date": "2024-03-07",
      "downloaded_date": "2025-02-01",
      "filename": "Nazari-Comparison of gait phase detection using traditional machine learning and deep learning techniques.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.05595v1",
      "categories": [
        "eess.SP",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ]
    },
    "2406.00332v1": {
      "title": "A Structured Review of Literature on Uncertainty in Machine Learning & Deep Learning",
      "authors": [
        "Fahimeh Fakour",
        "Ali Mosleh",
        "Ramin Ramezani"
      ],
      "abstract": "The adaptation and use of Machine Learning (ML) in our daily lives has led to\nconcerns in lack of transparency, privacy, reliability, among others. As a\nresult, we are seeing research in niche areas such as interpretability,\ncausality, bias and fairness, and reliability. In this survey paper, we focus\non a critical concern for adaptation of ML in risk-sensitive applications,\nnamely understanding and quantifying uncertainty. Our paper approaches this\ntopic in a structured way, providing a review of the literature in the various\nfacets that uncertainty is enveloped in the ML process. We begin by defining\nuncertainty and its categories (e.g., aleatoric and epistemic), understanding\nsources of uncertainty (e.g., data and model), and how uncertainty can be\nassessed in terms of uncertainty quantification techniques (Ensembles, Bayesian\nNeural Networks, etc.). As part of our assessment and understanding of\nuncertainty in the ML realm, we cover metrics for uncertainty quantification\nfor a single sample, dataset, and metrics for accuracy of the uncertainty\nestimation itself. This is followed by discussions on calibration (model and\nuncertainty), and decision making under uncertainty. Thus, we provide a more\ncomplete treatment of uncertainty: from the sources of uncertainty to the\ndecision-making process. We have focused the review of uncertainty\nquantification methods on Deep Learning (DL), while providing the necessary\nbackground for uncertainty discussion within ML in general. Key contributions\nin this review are broadening the scope of uncertainty discussion, as well as\nan updated review of uncertainty quantification methods in DL.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-06-01",
      "downloaded_date": "2025-02-01",
      "filename": "Fakour-A Structured Review of Literature on Uncertainty in Machine Learning  Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.00332v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    "2210.06145v1": {
      "title": "Can Artificial Intelligence Reconstruct Ancient Mosaics?",
      "authors": [
        "Fernando Moral-AndrÃ©s",
        "Elena Merino-GÃ³mez",
        "Pedro Reviriego",
        "Fabrizio Lombardi"
      ],
      "abstract": "A large number of ancient mosaics have not reached us because they have been\ndestroyed by erosion, earthquakes, looting or even used as materials in newer\nconstruction. To make things worse, among the small fraction of mosaics that we\nhave been able to recover, many are damaged or incomplete. Therefore,\nrestoration and reconstruction of mosaics play a fundamental role to preserve\ncultural heritage and to understand the role of mosaics in ancient cultures.\nThis reconstruction has traditionally been done manually and more recently\nusing computer graphics programs but always by humans. In the last years,\nArtificial Intelligence (AI) has made impressive progress in the generation of\nimages from text descriptions and reference images. State of the art AI tools\nsuch as DALL-E2 can generate high quality images from text prompts and can take\na reference image to guide the process. In august 2022, DALL-E2 launched a new\nfeature called outpainting that takes as input an incomplete image and a text\nprompt and then generates a complete image filling the missing parts. In this\npaper, we explore whether this innovative technology can be used to reconstruct\nmosaics with missing parts. Hence a set of ancient mosaics have been used and\nreconstructed using DALL-E2; results are promising showing that AI is able to\ninterpret the key features of the mosaics and is able to produce\nreconstructions that capture the essence of the scene. However, in some cases\nAI fails to reproduce some details, geometric forms or introduces elements that\nare not consistent with the rest of the mosaic. This suggests that as AI image\ngeneration technology matures in the next few years, it could be a valuable\ntool for mosaic reconstruction going forward.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5cb7af161bcf0015ab5acde29e8f48671dda7164",
      "published_date": "2022-10-07",
      "downloaded_date": "2025-02-01",
      "filename": "Moral-AndrÃ©s-Can Artificial Intelligence Reconstruct Ancient Mosaics.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2210.06145v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "2012.15234v3": {
      "title": "Artificial Intelligence Development Races in Heterogeneous Settings",
      "authors": [
        "Theodor Cimpeanu",
        "Francisco C. Santos",
        "Luis Moniz Pereira",
        "Tom Lenaerts",
        "The Anh Han"
      ],
      "abstract": "Regulation of advanced technologies such as Artificial Intelligence (AI) has\nbecome increasingly important, given the associated risks and apparent ethical\nissues. With the great benefits promised from being able to first supply such\ntechnologies, safety precautions and societal consequences might be ignored or\nshortchanged in exchange for speeding up the development, therefore engendering\na racing narrative among the developers. Starting from a game-theoretical model\ndescribing an idealised technology race in a fully connected world of players,\nhere we investigate how different interaction structures among race\nparticipants can alter collective choices and requirements for regulatory\nactions. Our findings indicate that, when participants portray a strong\ndiversity in terms of connections and peer-influence (e.g., when scale-free\nnetworks shape interactions among parties), the conflicts that exist in\nhomogeneous settings are significantly reduced, thereby lessening the need for\nregulatory actions. Furthermore, our results suggest that technology governance\nand regulation may profit from the world's patent heterogeneity and inequality\namong firms and nations, so as to enable the design and implementation of\nmeticulous interventions on a minority of participants, which is capable of\ninfluencing an entire population towards an ethical and sustainable use of\nadvanced technologies.",
      "citation_count": 16,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/235a4725e4b4f6bfaf92d94f1bfb259c059e7af5",
      "published_date": "2020-12-30",
      "downloaded_date": "2025-02-01",
      "filename": "Cimpeanu-Artificial Intelligence Development Races in Heterogeneous Settings.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.15234v3",
      "categories": [
        "cs.AI",
        "cs.GT"
      ]
    },
    "2103.07637v1": {
      "title": "AIR4Children: Artificial Intelligence and Robotics for Children",
      "authors": [
        "Rocio Montenegro",
        "Elva Corona",
        "Donato Badillo-Perez",
        "Angel Mandujano",
        "Leticia Vazquez",
        "Dago Cruz",
        "Miguel Xochicale"
      ],
      "abstract": "We introduce AIR4Children, Artificial Intelligence for Children, as a way to\n(a) tackle aspects for inclusion, accessibility, transparency, equity, fairness\nand participation and (b) to create affordable child-centred materials in AI\nand Robotics (AIR). We present current challenges and opportunities for a\nchild-centred approaches for AIR. Similarly, we touch on open-sourced software\nand hardware technologies to make a more inclusive, affordable and fair\nparticipation of children in areas of AIR. Then, we describe the avenues that\nAIR4Children can take with the development of open-sourced software and\nhardware based on our initial pilots and experiences. Similarly, we propose to\nfollow the philosophy of Montessori education to help children to not only\ndevelop computational thinking but also to internalise new concepts and\nlearning skills through activities of movement and repetition. Finally, we\nconclude with the opportunities of our work and mainly we pose the future work\nof putting in practice what is proposed here to evaluate the potential impact\non AIR to children, instructors, parents and their community.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b45959f02aa9cdb4bc05534795cd9d21e2df61e2",
      "published_date": "2021-03-13",
      "downloaded_date": "2025-02-01",
      "filename": "Montenegro-AIR4Children Artificial Intelligence and Robotics for Children.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.07637v1",
      "categories": [
        "cs.RO"
      ]
    },
    "2311.05726v1": {
      "title": "Neural Network Methods for Radiation Detectors and Imaging",
      "authors": [
        "S. Lin",
        "S. Ning",
        "H. Zhu",
        "T. Zhou",
        "C. L. Morris",
        "S. Clayton",
        "M. Cherukara",
        "R. T. Chen",
        "Z. Wang"
      ],
      "abstract": "Recent advances in image data processing through machine learning and\nespecially deep neural networks (DNNs) allow for new optimization and\nperformance-enhancement schemes for radiation detectors and imaging hardware\nthrough data-endowed artificial intelligence. We give an overview of data\ngeneration at photon sources, deep learning-based methods for image processing\ntasks, and hardware solutions for deep learning acceleration. Most existing\ndeep learning approaches are trained offline, typically using large amounts of\ncomputational resources. However, once trained, DNNs can achieve fast inference\nspeeds and can be deployed to edge devices. A new trend is edge computing with\nless energy consumption (hundreds of watts or less) and real-time analysis\npotential. While popularly used for edge computing, electronic-based hardware\naccelerators ranging from general purpose processors such as central processing\nunits (CPUs) to application-specific integrated circuits (ASICs) are constantly\nreaching performance limits in latency, energy consumption, and other physical\nconstraints. These limits give rise to next-generation analog neuromorhpic\nhardware platforms, such as optical neural networks (ONNs), for high parallel,\nlow latency, and low energy computing to boost deep learning acceleration.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5390857d7a2e590353b1ddf9935d86b8e2e4e20e",
      "published_date": "2023-11-09",
      "downloaded_date": "2025-02-01",
      "filename": "Lin-Neural Network Methods for Radiation Detectors and Imaging.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.05726v1",
      "categories": [
        "physics.ins-det",
        "cs.LG",
        "physics.data-an"
      ]
    },
    "2005.04650v1": {
      "title": "Artificial intelligence control of a turbulent jet",
      "authors": [
        "Yu Zhou",
        "Dewei Fan",
        "Bingfu Zhang",
        "Ruiying Li",
        "Bernd R. Noack"
      ],
      "abstract": "An artificial intelligence (AI) control system is developed to maximize the\nmixing rate of a turbulent jet. This system comprises six independently\noperated unsteady minijet actuators, two hot-wire sensors placed in the jet,\nand genetic programming for the unsupervised learning of a near-optimal control\nlaw. The ansatz of this law includes multi-frequency open-loop forcing,\nsensor-feedback and nonlinear combinations thereof. Mixing performance is\nquantified by the decay rate of the centreline mean velocity of jet.\nIntriguingly, the learning process of AI control discovers the classical\nforcings, i.e. axisymmetric, helical and flapping achievable from conventional\ncontrol techniques, one by one in the order of increased performance, and\nfinally converges to a hitherto unexplored forcing. Careful examination of the\ncontrol landscape unveils typical control laws, generated in the learning\nprocess, and their evolutions. The best AI forcing produces a complex turbulent\nflow structure that is characterized by periodically generated mushroom\nstructures, helical motion and oscillating jet column, all enhancing the mixing\nrate and vastly outperforming others. Being never reported before, this flow\nstructure is examined in various aspects, including the velocity spectra, mean\nand fluctuating velocity fields and their downstream evolution, and flow\nvisualization images in three orthogonal planes, all compared with other\nclassical flow structures. Along with the knowledge of the minijet-produced\nflow and its effect on the initial condition of the main jet, these aspects\ncast valuable insight into the physics behind the highly effective mixing of\nthis newly found flow structure. The results point to the great potential of AI\nin conquering the vast opportunity space of control laws for many actuators and\nsensors and in optimizing turbulence.",
      "citation_count": 65,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bfe0bf22f813576e0feff53350c7c7edd1f0887c",
      "published_date": "2020-05-10",
      "downloaded_date": "2025-02-01",
      "filename": "Zhou-Artificial intelligence control of a turbulent jet.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.04650v1",
      "categories": [
        "physics.flu-dyn"
      ]
    },
    "2310.05985v2": {
      "title": "Does Artificial Intelligence benefit UK businesses? An empirical study of the impact of AI on productivity",
      "authors": [
        "Sam Hainsworth"
      ],
      "abstract": "Media hype and technological breakthroughs are fuelling the race to adopt\nArtificial Intelligence amongst the business community, but is there evidence\nto suggest this will increase productivity? This paper uses 2015-2019 microdata\nfrom the UK Office for National Statistics to identify if the adoption of\nArtificial Intelligence techniques increases labour productivity in UK\nbusinesses. Using fixed effects estimation (Within Group) with a log-linear\nregression specification the paper concludes that there is no statistically\nsignificant impact of AI adoption on labour productivity.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-10-06",
      "downloaded_date": "2025-02-01",
      "filename": "Hainsworth-Does Artificial Intelligence benefit UK businesses An empirical study of the impact of AI on product....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.05985v2",
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ]
    },
    "2111.01726v1": {
      "title": "Instructive artificial intelligence (AI) for human training, assistance, and explainability",
      "authors": [
        "Nicholas Kantack",
        "Nina Cohen",
        "Nathan Bos",
        "Corey Lowman",
        "James Everett",
        "Timothy Endres"
      ],
      "abstract": "We propose a novel approach to explainable AI (XAI) based on the concept of\n\"instruction\" from neural networks. In this case study, we demonstrate how a\nsuperhuman neural network might instruct human trainees as an alternative to\ntraditional approaches to XAI. Specifically, an AI examines human actions and\ncalculates variations on the human strategy that lead to better performance.\nExperiments with a JHU/APL-developed AI player for the cooperative card game\nHanabi suggest this technique makes unique contributions to explainability\nwhile improving human performance. One area of focus for Instructive AI is in\nthe significant discrepancies that can arise between a human's actual strategy\nand the strategy they profess to use. This inaccurate self-assessment presents\na barrier for XAI, since explanations of an AI's strategy may not be properly\nunderstood or implemented by human recipients. We have developed and are\ntesting a novel, Instructive AI approach that estimates human strategy by\nobserving human actions. With neural networks, this allows a direct calculation\nof the changes in weights needed to improve the human strategy to better\nemulate a more successful AI. Subjected to constraints (e.g. sparsity) these\nweight changes can be interpreted as recommended changes to human strategy\n(e.g. \"value A more, and value B less\"). Instruction from AI such as this\nfunctions both to help humans perform better at tasks, but also to better\nunderstand, anticipate, and correct the actions of an AI. Results will be\npresented on AI instruction's ability to improve human decision-making and\nhuman-AI teaming in Hanabi.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/86c9f0f8fddd0c60b41e2e571ee94d43220d0119",
      "published_date": "2021-11-02",
      "downloaded_date": "2025-02-01",
      "filename": "Kantack-Instructive artificial intelligence AI for human training assistance and explainability.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.01726v1",
      "categories": [
        "cs.AI",
        "I.2.6"
      ]
    },
    "2108.06216v1": {
      "title": "MAIR: Framework for mining relationships between research articles, strategies, and regulations in the field of explainable artificial intelligence",
      "authors": [
        "StanisÅaw Gizinski",
        "MichaÅ Kuzba",
        "Bartosz Pielinski",
        "Julian Sienkiewicz",
        "StanisÅaw Åaniewski",
        "PrzemysÅaw Biecek"
      ],
      "abstract": "The growing number of AI applications, also for high-stake decisions,\nincreases the interest in Explainable and Interpretable Machine Learning\n(XI-ML). This trend can be seen both in the increasing number of regulations\nand strategies for developing trustworthy AI and the growing number of\nscientific papers dedicated to this topic. To ensure the sustainable\ndevelopment of AI, it is essential to understand the dynamics of the impact of\nregulation on research papers as well as the impact of scientific discourse on\nAI-related policies. This paper introduces a novel framework for joint analysis\nof AI-related policy documents and eXplainable Artificial Intelligence (XAI)\nresearch papers. The collected documents are enriched with metadata and\ninterconnections, using various NLP methods combined with a methodology\ninspired by Institutional Grammar. Based on the information extracted from\ncollected documents, we showcase a series of analyses that help understand\ninteractions, similarities, and differences between documents at different\nstages of institutionalization. To the best of our knowledge, this is the first\nwork to use automatic language analysis tools to understand the dynamics\nbetween XI-ML methods and regulations. We believe that such a system\ncontributes to better cooperation between XAI researchers and AI policymakers.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ee33a3bb95027b0452bbbafd4e80da7037b7b580",
      "published_date": "2021-07-29",
      "downloaded_date": "2025-02-01",
      "filename": "Gizinski-MAIR Framework for mining relationships between research articles strategies and regulations in the ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2108.06216v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ]
    },
    "1608.06581v1": {
      "title": "Fathom: Reference Workloads for Modern Deep Learning Methods",
      "authors": [
        "Robert Adolf",
        "Saketh Rama",
        "Brandon Reagen",
        "Gu-Yeon Wei",
        "David Brooks"
      ],
      "abstract": "Deep learning has been popularized by its recent successes on challenging\nartificial intelligence problems. One of the reasons for its dominance is also\nan ongoing challenge: the need for immense amounts of computational power.\nHardware architects have responded by proposing a wide array of promising\nideas, but to date, the majority of the work has focused on specific algorithms\nin somewhat narrow application domains. While their specificity does not\ndiminish these approaches, there is a clear need for more flexible solutions.\nWe believe the first step is to examine the characteristics of cutting edge\nmodels from across the deep learning community.\n  Consequently, we have assembled Fathom: a collection of eight archetypal deep\nlearning workloads for study. Each of these models comes from a seminal work in\nthe deep learning community, ranging from the familiar deep convolutional\nneural network of Krizhevsky et al., to the more exotic memory networks from\nFacebook's AI research group. Fathom has been released online, and this paper\nfocuses on understanding the fundamental performance characteristics of each\nmodel. We use a set of application-level modeling tools built around the\nTensorFlow deep learning framework in order to analyze the behavior of the\nFathom workloads. We present a breakdown of where time is spent, the\nsimilarities between the performance profiles of our models, an analysis of\nbehavior in inference and training, and the effects of parallelism on scaling.",
      "citation_count": 177,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a4fb215dc03f5a2ff0e394ce9b68e493bd811f0d",
      "published_date": "2016-08-23",
      "downloaded_date": "2025-02-01",
      "filename": "Adolf-Fathom Reference Workloads for Modern Deep Learning Methods.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1608.06581v1",
      "categories": [
        "cs.LG"
      ]
    },
    "1907.08377v1": {
      "title": "DaiMoN: A Decentralized Artificial Intelligence Model Network",
      "authors": [
        "Surat Teerapittayanon",
        "H. T. Kung"
      ],
      "abstract": "We introduce DaiMoN, a decentralized artificial intelligence model network,\nwhich incentivizes peer collaboration in improving the accuracy of machine\nlearning models for a given classification problem. It is an autonomous network\nwhere peers may submit models with improved accuracy and other peers may verify\nthe accuracy improvement. The system maintains an append-only decentralized\nledger to keep the log of critical information, including who has trained the\nmodel and improved its accuracy, when it has been improved, by how much it has\nimproved, and where to find the newly updated model. DaiMoN rewards these\ncontributing peers with cryptographic tokens. A main feature of DaiMoN is that\nit allows peers to verify the accuracy improvement of submitted models without\nknowing the test labels. This is an essential component in order to mitigate\nintentional model overfitting by model-improving peers. To enable this model\naccuracy evaluation with hidden test labels, DaiMoN uses a novel learnable\nDistance Embedding for Labels (DEL) function proposed in this paper. Specific\nto each test dataset, DEL scrambles the test label vector by embedding it in a\nlow-dimension space while approximately preserving the distance between the\ndataset's test label vector and a label vector inferred by the classifier. It\ntherefore allows proof-of-improvement (PoI) by peers without providing them\naccess to true test labels. We provide analysis and empirical evidence that\nunder DEL, peers can accurately assess model accuracy. We also argue that it is\nhard to invert the embedding function and thus, DEL is resilient against\nattacks aiming to recover test labels in order to cheat. Our prototype\nimplementation of DaiMoN is available at https://github.com/steerapi/daimon.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d2c6bdae3781a9efb01fe32468fcc240851c0ead",
      "published_date": "2019-07-19",
      "downloaded_date": "2025-02-01",
      "filename": "Teerapittayanon-DaiMoN A Decentralized Artificial Intelligence Model Network.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.08377v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ]
    },
    "1909.12072v1": {
      "title": "Towards Explainable Artificial Intelligence",
      "authors": [
        "Wojciech Samek",
        "Klaus-Robert MÃ¼ller"
      ],
      "abstract": "In recent years, machine learning (ML) has become a key enabling technology\nfor the sciences and industry. Especially through improvements in methodology,\nthe availability of large databases and increased computational power, today's\nML algorithms are able to achieve excellent performance (at times even\nexceeding the human level) on an increasing number of complex tasks. Deep\nlearning models are at the forefront of this development. However, due to their\nnested non-linear structure, these powerful models have been generally\nconsidered \"black boxes\", not providing any information about what exactly\nmakes them arrive at their predictions. Since in many applications, e.g., in\nthe medical domain, such lack of transparency may be not acceptable, the\ndevelopment of methods for visualizing, explaining and interpreting deep\nlearning models has recently attracted increasing attention. This introductory\npaper presents recent developments and applications in this field and makes a\nplea for a wider use of explainable learning algorithms in practice.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-09-26",
      "downloaded_date": "2025-02-01",
      "filename": "Samek-Towards Explainable Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1909.12072v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2101.01759v2": {
      "title": "Machine Learning and Quantum Devices",
      "authors": [
        "Florian Marquardt"
      ],
      "abstract": "These brief lecture notes cover the basics of neural networks and deep\nlearning as well as their applications in the quantum domain, for physicists\nwithout prior knowledge. In the first part, we describe training using\nbackpropagation, image classification, convolutional networks and autoencoders.\nThe second part is about advanced techniques like reinforcement learning (for\ndiscovering control strategies), recurrent neural networks (for analyzing time\ntraces), and Boltzmann machines (for learning probability distributions). In\nthe third lecture, we discuss first recent applications to quantum physics,\nwith an emphasis on quantum information processing machines. Finally, the\nfourth lecture is devoted to the promise of using quantum effects to accelerate\nmachine learning.",
      "citation_count": 28,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a3aa247fc15f4c90d039dbc5157666d3833149ac",
      "published_date": "2021-01-05",
      "downloaded_date": "2025-02-01",
      "filename": "Marquardt-Machine Learning and Quantum Devices.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.01759v2",
      "categories": [
        "quant-ph"
      ]
    },
    "2205.13037v1": {
      "title": "Neuromorphic Artificial Intelligence Systems",
      "authors": [
        "Dmitry Ivanov",
        "Aleksandr Chezhegov",
        "Andrey Grunin",
        "Mikhail Kiselev",
        "Denis Larionov"
      ],
      "abstract": "Modern AI systems, based on von Neumann architecture and classical neural\nnetworks, have a number of fundamental limitations in comparison with the\nbrain. This article discusses such limitations and the ways they can be\nmitigated. Next, it presents an overview of currently available neuromorphic AI\nprojects in which these limitations are overcame by bringing some brain\nfeatures into the functioning and organization of computing systems (TrueNorth,\nLoihi, Tianjic, SpiNNaker, BrainScaleS, NeuronFlow, DYNAP, Akida). Also, the\narticle presents the principle of classifying neuromorphic AI systems by the\nbrain features they use (neural networks, parallelism and asynchrony, impulse\nnature of information transfer, local learning, sparsity, analog and in-memory\ncomputing). In addition to new architectural approaches used in neuromorphic\ndevices based on existing silicon microelectronics technologies, the article\nalso discusses the prospects of using new memristor element base. Examples of\nrecent advances in the use of memristors in euromorphic applications are also\ngiven.",
      "citation_count": 49,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d271b1ec404942fcac132493d66541882da6e9ae",
      "published_date": "2022-05-25",
      "downloaded_date": "2025-02-01",
      "filename": "Ivanov-Neuromorphic Artificial Intelligence Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.13037v1",
      "categories": [
        "cs.NE"
      ]
    },
    "2405.17406v3": {
      "title": "Deep Learning Calabi-Yau four folds with hybrid and recurrent neural network architectures",
      "authors": [
        "H. L. Dao"
      ],
      "abstract": "In this work, we report the results of applying deep learning based on hybrid\nconvolutional-recurrent and purely recurrent neural network architectures to\nthe dataset of almost one million complete intersection Calabi-Yau four-folds\n(CICY4) to machine-learn their four Hodge numbers $h^{1,1}, h^{2,1}, h^{3,1},\nh^{2,2}$. In particular, we explored and experimented with twelve different\nneural network models, nine of which are convolutional-recurrent (CNN-RNN)\nhybrids with the RNN unit being either GRU (Gated Recurrent Unit) or Long Short\nTerm Memory (LSTM). The remaining four models are purely recurrent neural\nnetworks based on LSTM. In terms of the $h^{1,1}, h^{2,1}, h^{3,1}, h^{2,2}$\nprediction accuracies, at 72% training ratio, our best performing individual\nmodel is CNN-LSTM-400, a hybrid CNN-LSTM with the LSTM hidden size of 400,\nwhich obtained 99.74%, 98.07%, 95.19%, 81.01%, our second best performing\nindividual model is LSTM-448, an LSTM-based model with the hidden size of 448,\nwhich obtained 99.74%, 97.51%, 94.24%, and 78.63%. These results were improved\nby forming ensembles of the top two, three or even four models. Our best\nensemble, consisting of the top four models, achieved the accuracies of 99.84%,\n98.71%, 96.26%, 85.03%. At 80% training ratio, the top two performing models\nLSTM-448 and LSTM-424 are both LSTM-based with the hidden sizes of 448 and 424.\nCompared with the 72% training ratio, there is a significant improvement of\naccuracies, which reached 99.85%, 98.66%, 96.26%, 84.77% for the best\nindividual model and 99.90%, 99.03%, 97.97%, 87.34% for the best ensemble. By\nnature a proof of concept, the results of this work conclusively established\nthe utility of RNN-based architectures and demonstrated their effective\nperformances compared to the well-explored purely CNN-based architectures in\nthe problem of deep learning Calabi Yau manifolds.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9def150cd6bcceec03122d561cf6af865f72faff",
      "published_date": "2024-05-27",
      "downloaded_date": "2025-02-01",
      "filename": "Dao-Deep Learning Calabi-Yau four folds with hybrid and recurrent neural network architectures.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.17406v3",
      "categories": [
        "hep-th",
        "cs.LG",
        "math.AG"
      ]
    },
    "1910.07738v2": {
      "title": "A Survey of Deep Learning Techniques for Autonomous Driving",
      "authors": [
        "Sorin Grigorescu",
        "Bogdan Trasnea",
        "Tiberiu Cocias",
        "Gigel Macesanu"
      ],
      "abstract": "The last decade witnessed increasingly rapid progress in self-driving vehicle\ntechnology, mainly backed up by advances in the area of deep learning and\nartificial intelligence. The objective of this paper is to survey the current\nstate-of-the-art on deep learning technologies used in autonomous driving. We\nstart by presenting AI-based self-driving architectures, convolutional and\nrecurrent neural networks, as well as the deep reinforcement learning paradigm.\nThese methodologies form a base for the surveyed driving scene perception, path\nplanning, behavior arbitration and motion control algorithms. We investigate\nboth the modular perception-planning-action pipeline, where each module is\nbuilt using deep learning methods, as well as End2End systems, which directly\nmap sensory information to steering commands. Additionally, we tackle current\nchallenges encountered in designing AI architectures for autonomous driving,\nsuch as their safety, training data sources and computational hardware. The\ncomparison presented in this survey helps to gain insight into the strengths\nand limitations of deep learning and AI approaches for autonomous driving and\nassist with design choices",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-10-17",
      "downloaded_date": "2025-02-01",
      "filename": "Grigorescu-A Survey of Deep Learning Techniques for Autonomous Driving.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1910.07738v2",
      "categories": [
        "cs.LG",
        "cs.RO"
      ]
    },
    "1901.02918v3": {
      "title": "Making AI meaningful again",
      "authors": [
        "Jobst Landgrebe",
        "Barry Smith"
      ],
      "abstract": "Artificial intelligence (AI) research enjoyed an initial period of enthusiasm\nin the 1970s and 80s. But this enthusiasm was tempered by a long interlude of\nfrustration when genuinely useful AI applications failed to be forthcoming.\nToday, we are experiencing once again a period of enthusiasm, fired above all\nby the successes of the technology of deep neural networks or deep machine\nlearning. In this paper we draw attention to what we take to be serious\nproblems underlying current views of artificial intelligence encouraged by\nthese successes, especially in the domain of language processing. We then show\nan alternative approach to language-centric AI, in which we identify a role for\nphilosophy.",
      "citation_count": 31,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b8a4f4d94bb80a53a3b63be6222c0442eafc9bec",
      "published_date": "2019-01-09",
      "downloaded_date": "2025-02-01",
      "filename": "Landgrebe-Making AI meaningful again.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.02918v3",
      "categories": [
        "cs.AI"
      ]
    },
    "1902.06827v3": {
      "title": "Evolutionary Neural AutoML for Deep Learning",
      "authors": [
        "Jason Liang",
        "Elliot Meyerson",
        "Babak Hodjat",
        "Dan Fink",
        "Karl Mutch",
        "Risto Miikkulainen"
      ],
      "abstract": "Deep neural networks (DNNs) have produced state-of-the-art results in many\nbenchmarks and problem domains. However, the success of DNNs depends on the\nproper configuration of its architecture and hyperparameters. Such a\nconfiguration is difficult and as a result, DNNs are often not used to their\nfull potential. In addition, DNNs in commercial applications often need to\nsatisfy real-world design constraints such as size or number of parameters. To\nmake configuration easier, automatic machine learning (AutoML) systems for deep\nlearning have been developed, focusing mostly on optimization of\nhyperparameters.\n  This paper takes AutoML a step further. It introduces an evolutionary AutoML\nframework called LEAF that not only optimizes hyperparameters but also network\narchitectures and the size of the network. LEAF makes use of both\nstate-of-the-art evolutionary algorithms (EAs) and distributed computing\nframeworks. Experimental results on medical image classification and natural\nlanguage analysis show that the framework can be used to achieve\nstate-of-the-art performance. In particular, LEAF demonstrates that\narchitecture optimization provides a significant boost over hyperparameter\noptimization, and that networks can be minimized at the same time with little\ndrop in performance. LEAF therefore forms a foundation for democratizing and\nimproving AI, as well as making AI practical in future applications.",
      "citation_count": 103,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a68eb478401d9d5d95fb5f92f838eb1a914170dc",
      "published_date": "2019-02-18",
      "downloaded_date": "2025-02-01",
      "filename": "Liang-Evolutionary Neural AutoML for Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1902.06827v3",
      "categories": [
        "cs.NE"
      ]
    },
    "1709.05871v1": {
      "title": "IBM Deep Learning Service",
      "authors": [
        "Bishwaranjan Bhattacharjee",
        "Scott Boag",
        "Chandani Doshi",
        "Parijat Dube",
        "Ben Herta",
        "Vatche Ishakian",
        "K. R. Jayaram",
        "Rania Khalaf",
        "Avesh Krishna",
        "Yu Bo Li",
        "Vinod Muthusamy",
        "Ruchir Puri",
        "Yufei Ren",
        "Florian Rosenberg",
        "Seetharami R. Seelam",
        "Yandong Wang",
        "Jian Ming Zhang",
        "Li Zhang"
      ],
      "abstract": "Deep learning driven by large neural network models is overtaking traditional\nmachine learning methods for understanding unstructured and perceptual data\ndomains such as speech, text, and vision. At the same time, the\n\"as-a-Service\"-based business model on the cloud is fundamentally transforming\nthe information technology industry. These two trends: deep learning, and\n\"as-a-service\" are colliding to give rise to a new business model for cognitive\napplication delivery: deep learning as a service in the cloud. In this paper,\nwe will discuss the details of the software architecture behind IBM's deep\nlearning as a service (DLaaS). DLaaS provides developers the flexibility to use\npopular deep learning libraries such as Caffe, Torch and TensorFlow, in the\ncloud in a scalable and resilient manner with minimal effort. The platform uses\na distribution and orchestration layer that facilitates learning from a large\namount of data in a reasonable amount of time across compute nodes. A resource\nprovisioning layer enables flexible job management on heterogeneous resources,\nsuch as graphics processing units (GPUs) and central processing units (CPUs),\nin an infrastructure as a service (IaaS) cloud.",
      "citation_count": 31,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/46327573638d6a3dc7f21d2f41973c8a95e00161",
      "published_date": "2017-09-18",
      "downloaded_date": "2025-02-01",
      "filename": "Bhattacharjee-IBM Deep Learning Service.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1709.05871v1",
      "categories": [
        "cs.DC"
      ]
    },
    "2209.14907v1": {
      "title": "Patients' Severity States Classification based on Electronic Health Record (EHR) Data using Multiple Machine Learning and Deep Learning Approaches",
      "authors": [
        "A. N. M. Sajedul Alam",
        "Rimi Reza",
        "Asir Abrar",
        "Tanvir Ahmed",
        "Salsabil Ahmed",
        "Shihab Sharar",
        "Annajiat Alim Rasel"
      ],
      "abstract": "This research presents an examination of categorizing the severity states of\npatients based on their electronic health records during a certain time range\nusing multiple machine learning and deep learning approaches. The suggested\nmethod uses an EHR dataset collected from an open-source platform to categorize\nseverity. Some tools were used in this research, such as openRefine was used to\npre-process, RapidMiner was used for implementing three algorithms (Fast Large\nMargin, Generalized Linear Model, Multi-layer Feed-forward Neural Network) and\nTableau was used to visualize the data, for implementation of algorithms we\nused Google Colab. Here we implemented several supervised and unsupervised\nalgorithms along with semi-supervised and deep learning algorithms. The\nexperimental results reveal that hyperparameter-tuned Random Forest\noutperformed all the other supervised machine learning algorithms with 76%\naccuracy as well as Generalized Linear algorithm achieved the highest precision\nscore 78%, whereas the hyperparameter-tuned Hierarchical Clustering with 86%\nprecision score and Gaussian Mixture Model with 61% accuracy outperformed other\nunsupervised approaches. Dimensionality Reduction improved results a lot for\nmost unsupervised techniques. For implementing Deep Learning we employed a\nfeed-forward neural network (multi-layer) and the Fast Large Margin approach\nfor semi-supervised learning. The Fast Large Margin performed really well with\na recall score of 84% and an F1 score of 78%. Finally, the Multi-layer\nFeed-forward Neural Network performed admirably with 75% accuracy, 75%\nprecision, 87% recall, 81% F1 score.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5a2bd249f75acb3d652814b29402df534415f861",
      "published_date": "2022-09-29",
      "downloaded_date": "2025-02-01",
      "filename": "Alam-Patients Severity States Classification based on Electronic Health Record EHR Data using Multiple Ma....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.14907v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2302.01259v2": {
      "title": "Geometric Deep Learning for Autonomous Driving: Unlocking the Power of Graph Neural Networks With CommonRoad-Geometric",
      "authors": [
        "Eivind Meyer",
        "Maurice Brenner",
        "Bowen Zhang",
        "Max Schickert",
        "Bilal Musani",
        "Matthias Althoff"
      ],
      "abstract": "Heterogeneous graphs offer powerful data representations for traffic, given\ntheir ability to model the complex interaction effects among a varying number\nof traffic participants and the underlying road infrastructure. With the recent\nadvent of graph neural networks (GNNs) as the accompanying deep learning\nframework, the graph structure can be efficiently leveraged for various machine\nlearning applications such as trajectory prediction. As a first of its kind,\nour proposed Python framework offers an easy-to-use and fully customizable data\nprocessing pipeline to extract standardized graph datasets from traffic\nscenarios. Providing a platform for GNN-based autonomous driving research, it\nimproves comparability between approaches and allows researchers to focus on\nmodel implementation instead of dataset curation.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a883718bc19116e8deb9336ba6469985f3471133",
      "published_date": "2023-02-02",
      "downloaded_date": "2025-02-01",
      "filename": "Meyer-Geometric Deep Learning for Autonomous Driving Unlocking the Power of Graph Neural Networks With Com....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.01259v2",
      "categories": [
        "cs.LG"
      ]
    },
    "2402.05975v1": {
      "title": "A Deep Learning Approach for Brain Tumor Classification and Segmentation Using a Multiscale Convolutional Neural Network",
      "authors": [
        "Francisco Javier DÃ­az-Pernas",
        "Mario MartÃ­nez-Zarzuela",
        "MÃ­riam AntÃ³n-RodrÃ­guez",
        "David GonzÃ¡lez-Ortega"
      ],
      "abstract": "In this paper, we present a fully automatic brain tumor segmentation and\nclassification model using a Deep Convolutional Neural Network that includes a\nmultiscale approach. One of the differences of our proposal with respect to\nprevious works is that input images are processed in three spatial scales along\ndifferent processing pathways. This mechanism is inspired in the inherent\noperation of the Human Visual System. The proposed neural model can analyze MRI\nimages containing three types of tumors: meningioma, glioma, and pituitary\ntumor, over sagittal, coronal, and axial views and does not need preprocessing\nof input images to remove skull or vertebral column parts in advance. The\nperformance of our method on a publicly available MRI image dataset of 3064\nslices from 233 patients is compared with previously classical machine learning\nand deep learning published methods. In the comparison, our method remarkably\nobtained a tumor classification accuracy of 0.973, higher than the other\napproaches using the same database.",
      "citation_count": 300,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/50988431d1010952877e81d3c0e5c222859a33b6",
      "published_date": "2024-02-04",
      "downloaded_date": "2025-02-01",
      "filename": "DÃ­az-Pernas-A Deep Learning Approach for Brain Tumor Classification and Segmentation Using a Multiscale Convolut....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.05975v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2203.14132v1": {
      "title": "A comparative analysis of Graph Neural Networks and commonly used machine learning algorithms on fake news detection",
      "authors": [
        "Fahim Belal Mahmud",
        "Mahi Md. Sadek Rayhan",
        "Mahdi Hasan Shuvo",
        "Islam Sadia",
        "Md. Kishor Morol"
      ],
      "abstract": "Fake news on social media is increasingly regarded as one of the most\nconcerning issues. Low cost, simple accessibility via social platforms, and a\nplethora of low-budget online news sources are some of the factors that\ncontribute to the spread of false news. Most of the existing fake news\ndetection algorithms are solely focused on the news content only but engaged\nusers prior posts or social activities provide a wealth of information about\ntheir views on news and have significant ability to improve fake news\nidentification. Graph Neural Networks are a form of deep learning approach that\nconducts prediction on graph-described data. Social media platforms are\nfollowed graph structure in their representation, Graph Neural Network are\nspecial types of neural networks that could be usually applied to graphs,\nmaking it much easier to execute edge, node, and graph-level prediction.\nTherefore, in this paper, we present a comparative analysis among some commonly\nused machine learning algorithms and Graph Neural Networks for detecting the\nspread of false news on social media platforms. In this study, we take the UPFD\ndataset and implement several existing machine learning algorithms on text data\nonly. Besides this, we create different GNN layers for fusing graph-structured\nnews propagation data and the text data as the node feature in our GNN models.\nGNNs provide the best solutions to the dilemma of identifying false news in our\nresearch.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-03-26",
      "downloaded_date": "2025-02-01",
      "filename": "Mahmud-A comparative analysis of Graph Neural Networks and commonly used machine learning algorithms on fak....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.14132v1",
      "categories": [
        "cs.LG",
        "cs.CL",
        "cs.SI"
      ]
    },
    "2303.09660v1": {
      "title": "Explainable GeoAI: Can saliency maps help interpret artificial intelligence's learning process? An empirical study on natural feature detection",
      "authors": [
        "Chia-Yu Hsu",
        "Wenwen Li"
      ],
      "abstract": "Improving the interpretability of geospatial artificial intelligence (GeoAI)\nmodels has become critically important to open the \"black box\" of complex AI\nmodels, such as deep learning. This paper compares popular saliency map\ngeneration techniques and their strengths and weaknesses in interpreting GeoAI\nand deep learning models' reasoning behaviors, particularly when applied to\ngeospatial analysis and image processing tasks. We surveyed two broad classes\nof model explanation methods: perturbation-based and gradient-based methods.\nThe former identifies important image areas, which help machines make\npredictions by modifying a localized area of the input image. The latter\nevaluates the contribution of every single pixel of the input image to the\nmodel's prediction results through gradient backpropagation. In this study,\nthree algorithms-the occlusion method, the integrated gradients method, and the\nclass activation map method-are examined for a natural feature detection task\nusing deep learning. The algorithms' strengths and weaknesses are discussed,\nand the consistency between model-learned and human-understandable concepts for\nobject recognition is also compared. The experiments used two GeoAI-ready\ndatasets to demonstrate the generalizability of the research findings.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-03-16",
      "downloaded_date": "2025-02-01",
      "filename": "Hsu-Explainable GeoAI Can saliency maps help interpret artificial intelligences learning process An empi....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.09660v1",
      "categories": [
        "cs.CV"
      ]
    },
    "1805.09112v2": {
      "title": "Hyperbolic Neural Networks",
      "authors": [
        "Octavian-Eugen Ganea",
        "Gary BÃ©cigneul",
        "Thomas Hofmann"
      ],
      "abstract": "Hyperbolic spaces have recently gained momentum in the context of machine\nlearning due to their high capacity and tree-likeliness properties. However,\nthe representational power of hyperbolic geometry is not yet on par with\nEuclidean geometry, mostly because of the absence of corresponding hyperbolic\nneural network layers. This makes it hard to use hyperbolic embeddings in\ndownstream tasks. Here, we bridge this gap in a principled manner by combining\nthe formalism of M\\\"obius gyrovector spaces with the Riemannian geometry of the\nPoincar\\'e model of hyperbolic spaces. As a result, we derive hyperbolic\nversions of important deep learning tools: multinomial logistic regression,\nfeed-forward and recurrent neural networks such as gated recurrent units. This\nallows to embed sequential data and perform classification in the hyperbolic\nspace. Empirically, we show that, even if hyperbolic optimization tools are\nlimited, hyperbolic sentence embeddings either outperform or are on par with\ntheir Euclidean variants on textual entailment and noisy-prefix recognition\ntasks.",
      "citation_count": 539,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/562fa7faef812294bb1f235c97584f8560fb5cc0",
      "published_date": "2018-05-23",
      "downloaded_date": "2025-02-01",
      "filename": "Ganea-Hyperbolic Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1805.09112v2",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2107.09599v1": {
      "title": "Quantum Bayesian Neural Networks",
      "authors": [
        "Noah Berner",
        "Vincent Fortuin",
        "Jonas Landman"
      ],
      "abstract": "Quantum machine learning promises great speedups over classical algorithms,\nbut it often requires repeated computations to achieve a desired level of\naccuracy for its point estimates. Bayesian learning focuses more on sampling\nfrom posterior distributions than on point estimation, thus it might be more\nforgiving in the face of additional quantum noise. We propose a quantum\nalgorithm for Bayesian neural network inference, drawing on recent advances in\nquantum deep learning, and simulate its empirical performance on several tasks.\nWe find that already for small numbers of qubits, our algorithm approximates\nthe true posterior well, while it does not require any repeated computations\nand thus fully realizes the quantum speedups.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a4e72fb8c7d2e368b685498b5f98c28118b2fdbf",
      "published_date": "2021-07-20",
      "downloaded_date": "2025-02-01",
      "filename": "Berner-Quantum Bayesian Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.09599v1",
      "categories": [
        "quant-ph"
      ]
    },
    "2004.03722v1": {
      "title": "Challenges in Vessel Behavior and Anomaly Detection: From Classical Machine Learning to Deep Learning",
      "authors": [
        "Lucas May Petry",
        "Amilcar Soares",
        "Vania Bogorny",
        "Bruno Brandoli",
        "Stan Matwin"
      ],
      "abstract": "The global expansion of maritime activities and the development of the\nAutomatic Identification System (AIS) have driven the advances in maritime\nmonitoring systems in the last decade. Monitoring vessel behavior is\nfundamental to safeguard maritime operations, protecting other vessels sailing\nthe ocean and the marine fauna and flora. Given the enormous volume of vessel\ndata continually being generated, real-time analysis of vessel behaviors is\nonly possible because of decision support systems provided with event and\nanomaly detection methods. However, current works on vessel event detection are\nad-hoc methods able to handle only a single or a few predefined types of vessel\nbehavior. Most of the existing approaches do not learn from the data and\nrequire the definition of queries and rules for describing each behavior. In\nthis paper, we discuss challenges and opportunities in classical machine\nlearning and deep learning for vessel event and anomaly detection. We hope to\nmotivate the research of novel methods and tools, since addressing these\nchallenges is an essential step towards actual intelligent maritime monitoring\nsystems.",
      "citation_count": 24,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/78156538036a6acb82b4824e5de4aa473e880a5c",
      "published_date": "2020-04-07",
      "downloaded_date": "2025-02-01",
      "filename": "Petry-Challenges in Vessel Behavior and Anomaly Detection From Classical Machine Learning to Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.03722v1",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "1805.09944v1": {
      "title": "Reachability Analysis and Safety Verification for Neural Network Control Systems",
      "authors": [
        "Weiming Xiang",
        "Taylor T. Johnson"
      ],
      "abstract": "Autonomous cyber-physical systems (CPS) rely on the correct operation of\nnumerous components, with state-of-the-art methods relying on machine learning\n(ML) and artificial intelligence (AI) components in various stages of sensing\nand control. This paper develops methods for estimating the reachable set and\nverifying safety properties of dynamical systems under control of neural\nnetwork-based controllers that may be implemented in embedded software. The\nneural network controllers we consider are feedforward neural networks called\nmultilayer perceptrons (MLP) with general activation functions. As such\nfeedforward networks are memoryless, they may be abstractly represented as\nmathematical functions, and the reachability analysis of the network amounts to\nrange (image) estimation of this function provided a set of inputs. By\ndiscretizing the input set of the MLP into a finite number of hyper-rectangular\ncells, our approach develops a linear programming (LP) based algorithm for\nover-approximating the output set of the MLP with its input set as a union of\nhyper-rectangular cells. Combining the over-approximation for the output set of\nan MLP based controller and reachable set computation routines for ordinary\ndifference/differential equation (ODE) models, an algorithm is developed to\nestimate the reachable set of the closed-loop system. Finally, safety\nverification for neural network control systems can be performed by checking\nthe existence of intersections between the estimated reachable set and unsafe\nregions. The approach is implemented in a computational software prototype and\nevaluated on numerical examples.",
      "citation_count": 54,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/eb6eca24a6a5fd913614adb6bcd641aa6f854891",
      "published_date": "2018-05-25",
      "downloaded_date": "2025-02-01",
      "filename": "Xiang-Reachability Analysis and Safety Verification for Neural Network Control Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1805.09944v1",
      "categories": [
        "cs.SY"
      ]
    },
    "2401.07386v4": {
      "title": "How do machines learn? Evaluating the AIcon2abs method",
      "authors": [
        "Rubens Lacerda Queiroz",
        "Cabral Lima",
        "Fabio Ferrentini Sampaio",
        "Priscila Machado Vieira Lima"
      ],
      "abstract": "This study is an expansion of a previous work aiming to evaluate the\nAIcon2abs method (AI from Concrete to Abstract: Demystifying Artificial\nIntelligence to the general public), an innovative method aimed at increasing\nthe public (including children) understanding of machine learning (ML). The\napproach employs the WiSARD algorithm, a weightless neural network known for\nits simplicity, and user accessibility. WiSARD does not require Internet,\nmaking it ideal for non-technical users and resource-limited environments. This\nmethod enables participants to intuitively visualize and interact with ML\nprocesses through engaging, hands-on activities, as if they were the algorithms\nthemselves. The method allows users to intuitively visualize and understand the\ninternal processes of training and classification through practical activities.\nOnce WiSARDs functionality does not require an Internet connection, it can\nlearn effectively from a minimal dataset, even from a single example. This\nfeature enables users to observe how the machine improves its accuracy\nincrementally as it receives more data. Moreover, WiSARD generates mental\nimages representing what it has learned, highlighting essential features of the\nclassified data. AIcon2abs was tested through a six-hour remote course with 34\nBrazilian participants, including 5 children, 5 adolescents, and 24 adults.\nData analysis was conducted from two perspectives: a mixed-method\npre-experiment (including hypothesis testing), and a qualitative\nphenomenological analysis. Nearly all participants rated AIcon2abs positively,\nwith the results demonstrating a high degree of satisfaction in achieving the\nintended outcomes. This research was approved by the CEP-HUCFF-UFRJ Research\nEthics Committee.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-01-14",
      "downloaded_date": "2025-02-01",
      "filename": "Queiroz-How do machines learn Evaluating the AIcon2abs method.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.07386v4",
      "categories": [
        "cs.CY",
        "K.4.0; K.3.0"
      ]
    },
    "1706.02515v5": {
      "title": "Self-Normalizing Neural Networks",
      "authors": [
        "GÃ¼nter Klambauer",
        "Thomas Unterthiner",
        "Andreas Mayr",
        "Sepp Hochreiter"
      ],
      "abstract": "Deep Learning has revolutionized vision via convolutional neural networks\n(CNNs) and natural language processing via recurrent neural networks (RNNs).\nHowever, success stories of Deep Learning with standard feed-forward neural\nnetworks (FNNs) are rare. FNNs that perform well are typically shallow and,\ntherefore cannot exploit many levels of abstract representations. We introduce\nself-normalizing neural networks (SNNs) to enable high-level abstract\nrepresentations. While batch normalization requires explicit normalization,\nneuron activations of SNNs automatically converge towards zero mean and unit\nvariance. The activation function of SNNs are \"scaled exponential linear units\"\n(SELUs), which induce self-normalizing properties. Using the Banach fixed-point\ntheorem, we prove that activations close to zero mean and unit variance that\nare propagated through many network layers will converge towards zero mean and\nunit variance -- even under the presence of noise and perturbations. This\nconvergence property of SNNs allows to (1) train deep networks with many\nlayers, (2) employ strong regularization, and (3) to make learning highly\nrobust. Furthermore, for activations not close to unit variance, we prove an\nupper and lower bound on the variance, thus, vanishing and exploding gradients\nare impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning\nrepository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with\nstandard FNNs and other machine learning methods such as random forests and\nsupport vector machines. SNNs significantly outperformed all competing FNN\nmethods at 121 UCI tasks, outperformed all competing methods at the Tox21\ndataset, and set a new record at an astronomy data set. The winning SNN\narchitectures are often very deep. Implementations are available at:\ngithub.com/bioinf-jku/SNNs.",
      "citation_count": 2352,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/424a6e62084d919bfc2e39a507c263e5991ebdad",
      "published_date": "2017-06-08",
      "downloaded_date": "2025-02-01",
      "filename": "Klambauer-Self-Normalizing Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1706.02515v5",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    "2408.02811v1": {
      "title": "Development of REGAI: Rubric Enabled Generative Artificial Intelligence",
      "authors": [
        "Zach Johnson",
        "Jeremy Straub"
      ],
      "abstract": "This paper presents and evaluates a new retrieval augmented generation (RAG)\nand large language model (LLM)-based artificial intelligence (AI) technique:\nrubric enabled generative artificial intelligence (REGAI). REGAI uses rubrics,\nwhich can be created manually or automatically by the system, to enhance the\nperformance of LLMs for evaluation purposes. REGAI improves on the performance\nof both classical LLMs and RAG-based LLM techniques. This paper describes\nREGAI, presents data regarding its performance and discusses several possible\napplication areas for the technology.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-08-05",
      "downloaded_date": "2025-02-01",
      "filename": "Johnson-Development of REGAI Rubric Enabled Generative Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.02811v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1302.7096v1": {
      "title": "Using Artificial Intelligence Models in System Identification",
      "authors": [
        "Wesam Elshamy"
      ],
      "abstract": "Artificial Intelligence (AI) techniques are known for its ability in tackling\nproblems found to be unyielding to traditional mathematical methods. A recent\naddition to these techniques are the Computational Intelligence (CI) techniques\nwhich, in most cases, are nature or biologically inspired techniques. Different\nCI techniques found their way to many control engineering applications,\nincluding system identification, and the results obtained by many researchers\nwere encouraging. However, most control engineers and researchers used the\nbasic CI models as is or slightly modified them to match their needs.\nHenceforth, the merits of one model over the other was not clear, and full\npotential of these models was not exploited.\n  In this research, Genetic Algorithm (GA) and Particle Swarm Optimization\n(PSO) methods, which are different CI techniques, are modified to best suit the\nmultimodal problem of system identification. In the first case of GA, an\nextension to the basic algorithm, which is inspired from nature as well, was\ndeployed by introducing redundant genetic material. This extension, which come\nin handy in living organisms, did not result in significant performance\nimprovement to the basic algorithm. In the second case, the Clubs-based PSO\n(C-PSO) dynamic neighborhood structure was introduced to replace the basic\nstatic structure used in canonical PSO algorithms. This modification of the\nneighborhood structure resulted in significant performance of the algorithm\nregarding convergence speed, and equipped it with a tool to handle multimodal\nproblems.\n  To understand the suitability of different GA and PSO techniques in the\nproblem of system identification, they were used in an induction motor's\nparameter identification problem. The results enforced previous conclusions and\nshowed the superiority of PSO in general over the GA in such a multimodal\nproblem.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e3ca0a8555ae5a800fc27a106b060ee167852363",
      "published_date": "2013-02-28",
      "downloaded_date": "2025-02-01",
      "filename": "Elshamy-Using Artificial Intelligence Models in System Identification.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1302.7096v1",
      "categories": [
        "cs.NE",
        "cs.SY",
        "68T05"
      ]
    },
    "1711.10339v2": {
      "title": "Pulsar Candidate Identification with Artificial Intelligence Techniques",
      "authors": [
        "Ping Guo",
        "Fuqing Duan",
        "Pei Wang",
        "Yao Yao",
        "Qian Yin",
        "Xin Xin"
      ],
      "abstract": "Discovering pulsars is a significant and meaningful research topic in the\nfield of radio astronomy. With the advent of astronomical instruments such as\nhe Five-hundred-meter Aperture Spherical Telescope (FAST) in China, data\nvolumes and data rates are exponentially growing. This fact necessitates a\nfocus on artificial intelligence (AI) technologies that can perform the\nautomatic pulsar candidate identification to mine large astronomical data sets.\nAutomatic pulsar candidate identification can be considered as a task of\ndetermining potential candidates for further investigation and eliminating\nnoises of radio frequency interferences or other non-pulsar signals. It is very\nhard to raise the performance of DCNN-based pulsar identification because the\nlimited training samples restrict network structure to be designed deep enough\nfor learning good features as well as the crucial class imbalance problem due\nto very limited number of real pulsar samples. To address these problems, we\nproposed a framework which combines deep convolution generative adversarial\nnetwork (DCGAN) with support vector machine (SVM) to deal with imbalance class\nproblem and to improve pulsar identification accuracy. DCGAN is used as sample\ngeneration and feature learning model, and SVM is adopted as the classifier for\npredicting candidate's labels in the inference stage. The proposed framework is\na novel technique which not only can solve imbalance class problem but also can\nlearn discriminative feature representations of pulsar candidates instead of\ncomputing hand-crafted features in preprocessing steps too, which makes it more\naccurate for automatic pulsar candidate selection. Experiments on two pulsar\ndatasets verify the effectiveness and efficiency of our proposed method.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-11-27",
      "downloaded_date": "2025-02-01",
      "filename": "Guo-Pulsar Candidate Identification with Artificial Intelligence Techniques.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1711.10339v2",
      "categories": [
        "astro-ph.IM",
        "cs.CV"
      ]
    },
    "2310.18660v2": {
      "title": "Foundation Models for Generalist Geospatial Artificial Intelligence",
      "authors": [
        "Johannes Jakubik",
        "Sujit Roy",
        "C. E. Phillips",
        "Paolo Fraccaro",
        "Denys Godwin",
        "Bianca Zadrozny",
        "Daniela Szwarcman",
        "Carlos Gomes",
        "Gabby Nyirjesy",
        "Blair Edwards",
        "Daiki Kimura",
        "Naomi Simumba",
        "Linsong Chu",
        "S. Karthik Mukkavilli",
        "Devyani Lambhate",
        "Kamal Das",
        "Ranjini Bangalore",
        "Dario Oliveira",
        "Michal Muszynski",
        "Kumar Ankur",
        "Muthukumaran Ramasubramanian",
        "Iksha Gurung",
        "Sam Khallaghi",
        "Hanxi",
        "Li",
        "Michael Cecil",
        "Maryam Ahmadi",
        "Fatemeh Kordi",
        "Hamed Alemohammad",
        "Manil Maskey",
        "Raghu Ganti",
        "Kommy Weldemariam",
        "Rahul Ramachandran"
      ],
      "abstract": "Significant progress in the development of highly adaptable and reusable\nArtificial Intelligence (AI) models is expected to have a significant impact on\nEarth science and remote sensing. Foundation models are pre-trained on large\nunlabeled datasets through self-supervision, and then fine-tuned for various\ndownstream tasks with small labeled datasets. This paper introduces a\nfirst-of-a-kind framework for the efficient pre-training and fine-tuning of\nfoundational models on extensive geospatial data. We have utilized this\nframework to create Prithvi, a transformer-based geospatial foundational model\npre-trained on more than 1TB of multispectral satellite imagery from the\nHarmonized Landsat-Sentinel 2 (HLS) dataset. Our study demonstrates the\nefficacy of our framework in successfully fine-tuning Prithvi to a range of\nEarth observation tasks that have not been tackled by previous work on\nfoundation models involving multi-temporal cloud gap imputation, flood mapping,\nwildfire scar segmentation, and multi-temporal crop segmentation. Our\nexperiments show that the pre-trained model accelerates the fine-tuning process\ncompared to leveraging randomly initialized weights. In addition, pre-trained\nPrithvi compares well against the state-of-the-art, e.g., outperforming a\nconditional GAN model in multi-temporal cloud imputation by up to 5pp (or 5.7%)\nin the structural similarity index. Finally, due to the limited availability of\nlabeled data in the field of Earth observation, we gradually reduce the\nquantity of available labeled data for refining the model to evaluate data\nefficiency and demonstrate that data can be decreased significantly without\naffecting the model's accuracy. The pre-trained 100 million parameter model and\ncorresponding fine-tuning workflows have been released publicly as open source\ncontributions to the global Earth sciences community through Hugging Face.",
      "citation_count": 55,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e966bd21790a6c6d0a07b4917325767451c9e23e",
      "published_date": "2023-10-28",
      "downloaded_date": "2025-02-01",
      "filename": "Jakubik-Foundation Models for Generalist Geospatial Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.18660v2",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    "2405.06660v1": {
      "title": "AI and Machine Learning for Next Generation Science Assessments",
      "authors": [
        "Xiaoming Zhai"
      ],
      "abstract": "This chapter focuses on the transformative role of Artificial Intelligence\n(AI) and Machine Learning (ML) in science assessments. The paper begins with a\ndiscussion of the Framework for K-12 Science Education, which calls for a shift\nfrom conceptual learning to knowledge-in-use. This shift necessitates the\ndevelopment of new types of assessments that align with the Framework's three\ndimensions: science and engineering practices, disciplinary core ideas, and\ncrosscutting concepts. The paper further highlights the limitations of\ntraditional assessment methods like multiple-choice questions, which often fail\nto capture the complexities of scientific thinking and three-dimensional\nlearning in science. It emphasizes the need for performance-based assessments\nthat require students to engage in scientific practices like modeling,\nexplanation, and argumentation. The paper achieves three major goals: reviewing\nthe current state of ML-based assessments in science education, introducing a\nframework for scoring accuracy in ML-based automatic assessments, and\ndiscussing future directions and challenges. It delves into the evolution of\nML-based automatic scoring systems, discussing various types of ML, like\nsupervised, unsupervised, and semi-supervised learning. These systems can\nprovide timely and objective feedback, thus alleviating the burden on teachers.\nThe paper concludes by exploring pre-trained models like BERT and finetuned\nChatGPT, which have shown promise in assessing students' written responses\neffectively.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b21c5d9ef798af0b5f1d11851427d472e2fa1d9c",
      "published_date": "2024-04-23",
      "downloaded_date": "2025-02-01",
      "filename": "Zhai-AI and Machine Learning for Next Generation Science Assessments.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.06660v1",
      "categories": [
        "physics.ed-ph",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    "2304.09406v1": {
      "title": "How to Do Things with Deep Learning Code",
      "authors": [
        "Minh Hua",
        "Rita Raley"
      ],
      "abstract": "The premise of this article is that a basic understanding of the composition\nand functioning of large language models is critically urgent. To that end, we\nextract a representational map of OpenAI's GPT-2 with what we articulate as two\nclasses of deep learning code, that which pertains to the model and that which\nunderwrites applications built around the model. We then verify this map\nthrough case studies of two popular GPT-2 applications: the text adventure\ngame, AI Dungeon, and the language art project, This Word Does Not Exist. Such\nan exercise allows us to test the potential of Critical Code Studies when the\nobject of study is deep learning code and to demonstrate the validity of code\nas an analytical focus for researchers in the subfields of Critical Artificial\nIntelligence and Critical Machine Learning Studies. More broadly, however, our\nwork draws attention to the means by which ordinary users might interact with,\nand even direct, the behavior of deep learning systems, and by extension works\ntoward demystifying some of the auratic mystery of \"AI.\" What is at stake is\nthe possibility of achieving an informed sociotechnical consensus about the\nresponsible applications of large language models, as well as a more expansive\nsense of their creative capabilities-indeed, understanding how and where\nengagement occurs allows all of us to become more active participants in the\ndevelopment of machine learning systems.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/273793b59e700e693b522d1337dbcfe5f319d0c4",
      "published_date": "2023-04-19",
      "downloaded_date": "2025-02-01",
      "filename": "Hua-How to Do Things with Deep Learning Code.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.09406v1",
      "categories": [
        "cs.CL"
      ]
    },
    "2305.17137v1": {
      "title": "Integrating Generative Artificial Intelligence in Intelligent Vehicle Systems",
      "authors": [
        "Lukas Stappen",
        "Jeremy Dillmann",
        "Serena Striegel",
        "Hans-JÃ¶rg VÃ¶gel",
        "Nicolas Flores-Herr",
        "BjÃ¶rn W. Schuller"
      ],
      "abstract": "This paper aims to serve as a comprehensive guide for researchers and\npractitioners, offering insights into the current state, potential\napplications, and future research directions for generative artificial\nintelligence and foundation models within the context of intelligent vehicles.\nAs the automotive industry progressively integrates AI, generative artificial\nintelligence technologies hold the potential to revolutionize user\ninteractions, delivering more immersive, intuitive, and personalised in-car\nexperiences. We provide an overview of current applications of generative\nartificial intelligence in the automotive domain, emphasizing speech, audio,\nvision, and multimodal interactions. We subsequently outline critical future\nresearch areas, including domain adaptability, alignment, multimodal\nintegration and others, as well as, address the challenges and risks associated\nwith ethics. By fostering collaboration and addressing these research areas,\ngenerative artificial intelligence can unlock its full potential, transforming\nthe driving experience and shaping the future of intelligent vehicles.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-05-15",
      "downloaded_date": "2025-02-01",
      "filename": "Stappen-Integrating Generative Artificial Intelligence in Intelligent Vehicle Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.17137v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2308.03407v3": {
      "title": "Spatially Varying Nanophotonic Neural Networks",
      "authors": [
        "Kaixuan Wei",
        "Xiao Li",
        "Johannes Froech",
        "Praneeth Chakravarthula",
        "James Whitehead",
        "Ethan Tseng",
        "Arka Majumdar",
        "Felix Heide"
      ],
      "abstract": "The explosive growth of computation and energy cost of artificial\nintelligence has spurred strong interests in new computing modalities as\npotential alternatives to conventional electronic processors. Photonic\nprocessors that execute operations using photons instead of electrons, have\npromised to enable optical neural networks with ultra-low latency and power\nconsumption. However, existing optical neural networks, limited by the\nunderlying network designs, have achieved image recognition accuracy far below\nthat of state-of-the-art electronic neural networks. In this work, we close\nthis gap by embedding massively parallelized optical computation into flat\ncamera optics that perform neural network computation during the capture,\nbefore recording an image on the sensor. Specifically, we harness large kernels\nand propose a large-kernel spatially-varying convolutional neural network\nlearned via low-dimensional reparameterization techniques. We experimentally\ninstantiate the network with a flat meta-optical system that encompasses an\narray of nanophotonic structures designed to induce angle-dependent responses.\nCombined with an extremely lightweight electronic backend with approximately 2K\nparameters we demonstrate a reconfigurable nanophotonic neural network reaches\n72.76\\% blind test classification accuracy on CIFAR-10 dataset, and, as such,\nthe first time, an optical neural network outperforms the first modern digital\nneural network -- AlexNet (72.64\\%) with 57M parameters, bringing optical\nneural network into modern deep learning era.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9519d921741d8884c7a06bb0d71de238268980ea",
      "published_date": "2023-08-07",
      "downloaded_date": "2025-02-01",
      "filename": "Wei-Spatially Varying Nanophotonic Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.03407v3",
      "categories": [
        "cs.CV"
      ]
    },
    "2211.08179v2": {
      "title": "Artificial intelligence approaches for materials-by-design of energetic materials: state-of-the-art, challenges, and future directions",
      "authors": [
        "Joseph B. Choi",
        "Phong C. H. Nguyen",
        "Oishik Sen",
        "H. S. Udaykumar",
        "Stephen Baek"
      ],
      "abstract": "Artificial intelligence (AI) is rapidly emerging as an enabling tool for\nsolving various complex materials design problems. This paper aims to review\nrecent advances in AI-driven materials-by-design and their applications to\nenergetic materials (EM). Trained with data from numerical simulations and/or\nphysical experiments, AI models can assimilate trends and patterns within the\ndesign parameter space, identify optimal material designs (micro-morphologies,\ncombinations of materials in composites, etc.), and point to designs with\nsuperior/targeted property and performance metrics. We review approaches\nfocusing on such capabilities with respect to the three main stages of\nmaterials-by-design, namely representation learning of microstructure\nmorphology (i.e., shape descriptors), structure-property-performance (S-P-P)\nlinkage estimation, and optimization/design exploration. We provide a\nperspective view of these methods in terms of their potential, practicality,\nand efficacy towards the realization of materials-by-design. Specifically,\nmethods in the literature are evaluated in terms of their capacity to learn\nfrom a small/limited number of data, computational complexity,\ngeneralizability/scalability to other material species and operating\nconditions, interpretability of the model predictions, and the burden of\nsupervision/data annotation. Finally, we suggest a few promising future\nresearch directions for EM materials-by-design, such as meta-learning, active\nlearning, Bayesian learning, and semi-/weakly-supervised learning, to bridge\nthe gap between machine learning research and EM research.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3882d8c04a7ac5fed8b7979cad17c6c8400506b0",
      "published_date": "2022-11-15",
      "downloaded_date": "2025-02-01",
      "filename": "Choi-Artificial intelligence approaches for materials-by-design of energetic materials state-of-the-art c....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.08179v2",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.LG"
      ]
    },
    "1805.08400v3": {
      "title": "Deep Learning with Cinematic Rendering: Fine-Tuning Deep Neural Networks Using Photorealistic Medical Images",
      "authors": [
        "Faisal Mahmood",
        "Richard Chen",
        "Sandra Sudarsky",
        "Daphne Yu",
        "Nicholas J. Durr"
      ],
      "abstract": "Deep learning has emerged as a powerful artificial intelligence tool to\ninterpret medical images for a growing variety of applications. However, the\npaucity of medical imaging data with high-quality annotations that is necessary\nfor training such methods ultimately limits their performance. Medical data is\nchallenging to acquire due to privacy issues, shortage of experts available for\nannotation, limited representation of rare conditions and cost. This problem\nhas previously been addressed by using synthetically generated data. However,\nnetworks trained on synthetic data often fail to generalize to real data.\nCinematic rendering simulates the propagation and interaction of light passing\nthrough tissue models reconstructed from CT data, enabling the generation of\nphotorealistic images. In this paper, we present one of the first applications\nof cinematic rendering in deep learning, in which we propose to fine-tune\nsynthetic data-driven networks using cinematically rendered CT data for the\ntask of monocular depth estimation in endoscopy. Our experiments demonstrate\nthat: (a) Convolutional Neural Networks (CNNs) trained on synthetic data and\nfine-tuned on photorealistic cinematically rendered data adapt better to real\nmedical images and demonstrate more robust performance when compared to\nnetworks with no fine-tuning, (b) these fine-tuned networks require less\ntraining data to converge to an optimal solution, and (c) fine-tuning with data\nfrom a variety of photorealistic rendering conditions of the same scene\nprevents the network from learning patient-specific information and aids in\ngeneralizability of the model. Our empirical evaluation demonstrates that\nnetworks fine-tuned with cinematically rendered data predict depth with 56.87%\nless error for rendered endoscopy images and 27.49% less error for real porcine\ncolon endoscopy images.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-05-22",
      "downloaded_date": "2025-02-01",
      "filename": "Mahmood-Deep Learning with Cinematic Rendering Fine-Tuning Deep Neural Networks Using Photorealistic Medical....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1805.08400v3",
      "categories": [
        "cs.CV"
      ]
    },
    "2105.03905v3": {
      "title": "Security Concerns on Machine Learning Solutions for 6G Networks in mmWave Beam Prediction",
      "authors": [
        "Ferhat Ozgur Catak",
        "Evren Catak",
        "Murat Kuzlu",
        "Umit Cali",
        "Devrim Unal"
      ],
      "abstract": "6G -- sixth generation -- is the latest cellular technology currently under\ndevelopment for wireless communication systems. In recent years, machine\nlearning algorithms have been applied widely in various fields, such as\nhealthcare, transportation, energy, autonomous car, and many more. Those\nalgorithms have been also using in communication technologies to improve the\nsystem performance in terms of frequency spectrum usage, latency, and security.\nWith the rapid developments of machine learning techniques, especially deep\nlearning, it is critical to take the security concern into account when\napplying the algorithms. While machine learning algorithms offer significant\nadvantages for 6G networks, security concerns on Artificial Intelligent (AI)\nmodels is typically ignored by the scientific community so far. However,\nsecurity is also a vital part of the AI algorithms, this is because the AI\nmodel itself can be poisoned by attackers. This paper proposes a mitigation\nmethod for adversarial attacks against proposed 6G machine learning models for\nthe millimeter-wave (mmWave) beam prediction using adversarial learning. The\nmain idea behind adversarial attacks against machine learning models is to\nproduce faulty results by manipulating trained deep learning models for 6G\napplications for mmWave beam prediction. We also present the adversarial\nlearning mitigation method's performance for 6G security in mmWave beam\nprediction application with fast gradient sign method attack. The mean square\nerrors (MSE) of the defended model under attack are very close to the\nundefended model without attack.",
      "citation_count": 36,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0a8838dce4492fb07da4885df69f55bb1672c8bb",
      "published_date": "2021-05-09",
      "downloaded_date": "2025-02-01",
      "filename": "Catak-Security Concerns on Machine Learning Solutions for 6G Networks in mmWave Beam Prediction.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.03905v3",
      "categories": [
        "eess.SP",
        "cs.CR",
        "cs.LG"
      ]
    },
    "2410.21298v1": {
      "title": "Explainable Artificial Intelligent (XAI) for Predicting Asphalt Concrete Stiffness and Rutting Resistance: Integrating Bailey's Aggregate Gradation Method",
      "authors": [
        "Warat Kongkitkul",
        "Sompote Youwai",
        "Siwipa Khamsoy",
        "Manaswee Feungfung"
      ],
      "abstract": "This study employs explainable artificial intelligence (XAI) techniques to\nanalyze the behavior of asphalt concrete with varying aggregate gradations,\nfocusing on resilience modulus (MR) and dynamic stability (DS) as measured by\nwheel track tests. The research utilizes a deep learning model with a\nmulti-layer perceptron architecture to predict MR and DS based on aggregate\ngradation parameters derived from Bailey's Method, including coarse aggregate\nratio (CA), fine aggregate coarse ratio (FAc), and other mix design variables.\nThe model's performance was validated using k-fold cross-validation,\ndemonstrating superior accuracy compared to alternative machine learning\napproaches. SHAP (SHapley Additive exPlanations) values were applied to\ninterpret the model's predictions, providing insights into the relative\nimportance and impact of different gradation characteristics on asphalt\nconcrete performance. Key findings include the identification of critical\naggregate size thresholds, particularly the 0.6 mm sieve size, which\nsignificantly influences both MR and DS. The study revealed size-dependent\nperformance of aggregates, with coarse aggregates primarily affecting rutting\nresistance and medium-fine aggregates influencing stiffness. The research also\nhighlighted the importance of aggregate lithology in determining rutting\nresistance. To facilitate practical application, web-based interfaces were\ndeveloped for predicting MR and DS, incorporating explainable features to\nenhance transparency and interpretation of results. This research contributes a\ndata-driven approach to understanding the complex relationships between\naggregate gradation and asphalt concrete performance, potentially informing\nmore efficient and performance-oriented mix design processes in the future.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/70d8272e2fe0c7cffda637645180051471fbcc4b",
      "published_date": "2024-10-16",
      "downloaded_date": "2025-02-01",
      "filename": "Kongkitkul-Explainable Artificial Intelligent XAI for Predicting Asphalt Concrete Stiffness and Rutting Resista....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.21298v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2009.05678v1": {
      "title": "To Root Artificial Intelligence Deeply in Basic Science for a New Generation of AI",
      "authors": [
        "Jingan Yang",
        "Yang Peng"
      ],
      "abstract": "One of the ambitions of artificial intelligence is to root artificial\nintelligence deeply in basic science while developing brain-inspired artificial\nintelligence platforms that will promote new scientific discoveries. The\nchallenges are essential to push artificial intelligence theory and applied\ntechnologies research forward. This paper presents the grand challenges of\nartificial intelligence research for the next 20 years which include:~(i) to\nexplore the working mechanism of the human brain on the basis of understanding\nbrain science, neuroscience, cognitive science, psychology and data science;\n(ii) how is the electrical signal transmitted by the human brain? What is the\ncoordination mechanism between brain neural electrical signals and human\nactivities? (iii)~to root brain-computer interface~(BCI) and brain-muscle\ninterface~(BMI) technologies deeply in science on human behaviour; (iv)~making\nresearch on knowledge-driven visual commonsense reasoning~(VCR), develop a new\ninference engine for cognitive network recognition~(CNR); (v)~to develop\nhigh-precision, multi-modal intelligent perceptrons; (vi)~investigating\nintelligent reasoning and fast decision-making systems based on knowledge\ngraph~(KG). We believe that the frontier theory innovation of AI,\nknowledge-driven modeling methodologies for commonsense reasoning,\nrevolutionary innovation and breakthroughs of the novel algorithms and new\ntechnologies in AI, and developing responsible AI should be the main research\nstrategies of AI scientists in the future.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7d901c45901abad7cc598e7ff793aa21c502ea71",
      "published_date": "2020-09-11",
      "downloaded_date": "2025-02-01",
      "filename": "Yang-To Root Artificial Intelligence Deeply in Basic Science for a New Generation of AI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.05678v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2309.06062v2": {
      "title": "Selection of contributing factors for predicting landslide susceptibility using machine learning and deep learning models",
      "authors": [
        "Cheng Chen",
        "Lei Fan"
      ],
      "abstract": "Landslides are a common natural disaster that can cause casualties, property\nsafety threats and economic losses. Therefore, it is important to understand or\npredict the probability of landslide occurrence at potentially risky sites. A\ncommonly used means is to carry out a landslide susceptibility assessment based\non a landslide inventory and a set of landslide contributing factors. This can\nbe readily achieved using machine learning (ML) models such as logistic\nregression (LR), support vector machine (SVM), random forest (RF), extreme\ngradient boosting (Xgboost), or deep learning (DL) models such as convolutional\nneural network (CNN) and long short time memory (LSTM). As the input data for\nthese models, landslide contributing factors have varying influences on\nlandslide occurrence. Therefore, it is logically feasible to select more\nimportant contributing factors and eliminate less relevant ones, with the aim\nof increasing the prediction accuracy of these models. However, selecting more\nimportant factors is still a challenging task and there is no generally\naccepted method. Furthermore, the effects of factor selection using various\nmethods on the prediction accuracy of ML and DL models are unclear. In this\nstudy, the impact of the selection of contributing factors on the accuracy of\nlandslide susceptibility predictions using ML and DL models was investigated.\nFour methods for selecting contributing factors were considered for all the\naforementioned ML and DL models, which included Information Gain Ratio (IGR),\nRecursive Feature Elimination (RFE), Particle Swarm Optimization (PSO), Least\nAbsolute Shrinkage and Selection Operators (LASSO) and Harris Hawk Optimization\n(HHO). In addition, autoencoder-based factor selection methods for DL models\nwere also investigated. To assess their performances, an exhaustive approach\nwas adopted,...",
      "citation_count": 12,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b32e328c3434a381181dde56edaa9c06e5a677e0",
      "published_date": "2023-09-12",
      "downloaded_date": "2025-02-01",
      "filename": "Chen-Selection of contributing factors for predicting landslide susceptibility using machine learning and....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.06062v2",
      "categories": [
        "cs.LG",
        "cs.CV",
        "physics.geo-ph"
      ]
    },
    "2303.03488v1": {
      "title": "A Comparison of Methods for Neural Network Aggregation",
      "authors": [
        "John Pomerat",
        "Aviv Segev"
      ],
      "abstract": "Deep learning has been successful in the theoretical aspect. For deep\nlearning to succeed in industry, we need to have algorithms capable of handling\nmany inconsistencies appearing in real data. These inconsistencies can have\nlarge effects on the implementation of a deep learning algorithm. Artificial\nIntelligence is currently changing the medical industry. However, receiving\nauthorization to use medical data for training machine learning algorithms is a\nhuge hurdle. A possible solution is sharing the data without sharing the\npatient information. We propose a multi-party computation protocol for the deep\nlearning algorithm. The protocol enables to conserve both the privacy and the\nsecurity of the training data. Three approaches of neural networks assembly are\nanalyzed: transfer learning, average ensemble learning, and series network\nlearning. The results are compared to approaches based on data-sharing in\ndifferent experiments. We analyze the security issues of the proposed protocol.\nAlthough the analysis is based on medical data, the results of multi-party\ncomputation of machine learning training are theoretical and can be implemented\nin multiple research areas.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f4cc1d831b8d6da92c8a5c78889b076171ad7ea2",
      "published_date": "2023-03-06",
      "downloaded_date": "2025-02-01",
      "filename": "Pomerat-A Comparison of Methods for Neural Network Aggregation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.03488v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2303.09491v1": {
      "title": "Challenges and Opportunities in Quantum Machine Learning",
      "authors": [
        "M. Cerezo",
        "Guillaume Verdon",
        "Hsin-Yuan Huang",
        "Lukasz Cincio",
        "Patrick J. Coles"
      ],
      "abstract": "At the intersection of machine learning and quantum computing, Quantum\nMachine Learning (QML) has the potential of accelerating data analysis,\nespecially for quantum data, with applications for quantum materials,\nbiochemistry, and high-energy physics. Nevertheless, challenges remain\nregarding the trainability of QML models. Here we review current methods and\napplications for QML. We highlight differences between quantum and classical\nmachine learning, with a focus on quantum neural networks and quantum deep\nlearning. Finally, we discuss opportunities for quantum advantage with QML.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-03-16",
      "downloaded_date": "2025-02-01",
      "filename": "Cerezo-Challenges and Opportunities in Quantum Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.09491v1",
      "categories": [
        "quant-ph",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2005.12196v1": {
      "title": "Artificial Intelligence (AI) and IT identity: Antecedents Identifying with AI Applications",
      "authors": [
        "Rasha Alahmad",
        "Lionel Robert"
      ],
      "abstract": "In the age of Artificial Intelligence and automation, machines have taken\nover many key managerial tasks. Replacing managers with AI systems may have a\nnegative impact on workers outcomes. It is unclear if workers receive the same\nbenefits from their relationships with AI systems, raising the question: What\ndegree does the relationship between AI systems and workers impact worker\noutcomes? We draw on IT identity to understand the influence of identification\nwith AI systems on job performance. From this theoretical perspective, we\npropose a research model and conduct a survey of 97 MTurk workers to test the\nmodel. The findings reveal that work role identity and organizational identity\nare key determinants of identification with AI systems. Furthermore, the\nfindings show that identification with AI systems does increase job\nperformance.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/eb16e88bf4ff74c48a0709115817c124c21c7576",
      "published_date": "2020-05-15",
      "downloaded_date": "2025-02-01",
      "filename": "Alahmad-Artificial Intelligence AI and IT identity Antecedents Identifying with AI Applications.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.12196v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ]
    },
    "2312.01555v1": {
      "title": "Explainable AI is Responsible AI: How Explainability Creates Trustworthy and Socially Responsible Artificial Intelligence",
      "authors": [
        "Stephanie Baker",
        "Wei Xiang"
      ],
      "abstract": "Artificial intelligence (AI) has been clearly established as a technology\nwith the potential to revolutionize fields from healthcare to finance - if\ndeveloped and deployed responsibly. This is the topic of responsible AI, which\nemphasizes the need to develop trustworthy AI systems that minimize bias,\nprotect privacy, support security, and enhance transparency and accountability.\nExplainable AI (XAI) has been broadly considered as a building block for\nresponsible AI (RAI), with most of the literature considering it as a solution\nfor improved transparency. This work proposes that XAI and responsible AI are\nsignificantly more deeply entwined. In this work, we explore state-of-the-art\nliterature on RAI and XAI technologies. Based on our findings, we demonstrate\nthat XAI can be utilized to ensure fairness, robustness, privacy, security, and\ntransparency in a wide range of contexts. Our findings lead us to conclude that\nXAI is an essential foundation for every pillar of RAI.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/71b185330f7ae80e6c3405195175ee59d808d22c",
      "published_date": "2023-12-04",
      "downloaded_date": "2025-02-01",
      "filename": "Baker-Explainable AI is Responsible AI How Explainability Creates Trustworthy and Socially Responsible Art....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.01555v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    "1710.08460v2": {
      "title": "Serving deep learning models in a serverless platform",
      "authors": [
        "Vatche Ishakian",
        "Vinod Muthusamy",
        "Aleksander Slominski"
      ],
      "abstract": "Serverless computing has emerged as a compelling paradigm for the development\nand deployment of a wide range of event based cloud applications. At the same\ntime, cloud providers and enterprise companies are heavily adopting machine\nlearning and Artificial Intelligence to either differentiate themselves, or\nprovide their customers with value added services. In this work we evaluate the\nsuitability of a serverless computing environment for the inferencing of large\nneural network models. Our experimental evaluations are executed on the AWS\nLambda environment using the MxNet deep learning framework. Our experimental\nresults show that while the inferencing latency can be within an acceptable\nrange, longer delays due to cold starts can skew the latency distribution and\nhence risk violating more stringent SLAs.",
      "citation_count": 164,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/aa447f6462c7efe7f3cd9ded120637ceefcdc0ce",
      "published_date": "2017-10-23",
      "downloaded_date": "2025-02-01",
      "filename": "Ishakian-Serving deep learning models in a serverless platform.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1710.08460v2",
      "categories": [
        "cs.DC"
      ]
    },
    "2302.06389v1": {
      "title": "Deep-Learning Quantitative Structural Characterization in Additive Manufacturing",
      "authors": [
        "Amra Peles",
        "Vincent C. Paquit",
        "Ryan R. Dehoff"
      ],
      "abstract": "With a goal of accelerating fabrication of additively manufactured components\nwith precise microstructures, we developed a method for structural\ncharacterization of key features in additively manufactured materials and\nparts. The method utilizes deep learning based on an image-to-image translation\nconditional Generative Adversarial Neural Network architecture and enables fast\nand incrementally more accurate predictions of the prevalent geometric\nfeatures, including melt pool boundaries and printing induced defects visible\nin etched optical images. These structural details are heterogeneous in nature.\nOur method specifies the microstructure state of an additive built via\nstatistical distribution of structural details, based on an ensemble of\ncollected images. Extensions of the method are proposed to address Artificial\nIntelligence implementation of developed machine learning model for in real\ntime control of additive manufacturing.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-01-20",
      "downloaded_date": "2025-02-01",
      "filename": "Peles-Deep-Learning Quantitative Structural Characterization in Additive Manufacturing.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.06389v1",
      "categories": [
        "cs.CV",
        "cond-mat.mtrl-sci"
      ]
    },
    "2404.16561v1": {
      "title": "Research on geometric figure classification algorithm based on Deep Learning",
      "authors": [
        "Ruiyang Wang",
        "Haonan Wang",
        "Junfeng Sun",
        "Mingjia Zhao",
        "Meng Liu"
      ],
      "abstract": "In recent years, with the rapid development of computer information\ntechnology, the development of artificial intelligence has been accelerating.\nThe traditional geometry recognition technology is relatively backward and the\nrecognition rate is low. In the face of massive information database, the\ntraditional algorithm model inevitably has the problems of low recognition\naccuracy and poor performance. Deep learning theory has gradually become a very\nimportant part of machine learning. The implementation of convolutional neural\nnetwork (CNN) reduces the difficulty of graphics generation algorithm. In this\npaper, using the advantages of lenet-5 architecture sharing weights and feature\nextraction and classification, the proposed geometric pattern recognition\nalgorithm model is faster in the training data set. By constructing the shared\nfeature parameters of the algorithm model, the cross-entropy loss function is\nused in the recognition process to improve the generalization of the model and\nimprove the average recognition accuracy of the test data set.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ceb8ce1a3374935b4d2d261571b66e98a4233e6a",
      "published_date": "2024-04-25",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Research on geometric figure classification algorithm based on Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.16561v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2006.05861v1": {
      "title": "A systematic review on the role of artificial intelligence in sonographic diagnosis of thyroid cancer: Past, present and future",
      "authors": [
        "Fatemeh Abdolali",
        "Atefeh Shahroudnejad",
        "Abhilash Rakkunedeth Hareendranathan",
        "Jacob L Jaremko",
        "Michelle Noga",
        "Kumaradevan Punithakumar"
      ],
      "abstract": "Thyroid cancer is common worldwide, with a rapid increase in prevalence\nacross North America in recent years. While most patients present with palpable\nnodules through physical examination, a large number of small and medium-sized\nnodules are detected by ultrasound examination. Suspicious nodules are then\nsent for biopsy through fine needle aspiration. Since biopsies are invasive and\nsometimes inconclusive, various research groups have tried to develop\ncomputer-aided diagnosis systems. Earlier approaches along these lines relied\non clinically relevant features that were manually identified by radiologists.\nWith the recent success of artificial intelligence (AI), various new methods\nare being developed to identify these features in thyroid ultrasound\nautomatically. In this paper, we present a systematic review of\nstate-of-the-art on AI application in sonographic diagnosis of thyroid cancer.\nThis review follows a methodology-based classification of the different\ntechniques available for thyroid cancer diagnosis. With more than 50 papers\nincluded in this review, we reflect on the trends and challenges of the field\nof sonographic diagnosis of thyroid malignancies and potential of\ncomputer-aided diagnosis to increase the impact of ultrasound applications on\nthe future of thyroid cancer diagnosis. Machine learning will continue to play\na fundamental role in the development of future thyroid cancer diagnosis\nframeworks.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/249a4c2447c053791f653761bd099466ed6d8d02",
      "published_date": "2020-06-10",
      "downloaded_date": "2025-02-01",
      "filename": "Abdolali-A systematic review on the role of artificial intelligence in sonographic diagnosis of thyroid cance....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2006.05861v1",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    "2105.10816v4": {
      "title": "Novel Deep Learning Architecture for Heart Disease Prediction using Convolutional Neural Network",
      "authors": [
        "Shadab Hussain",
        "Santosh Kumar Nanda",
        "Susmith Barigidad",
        "Shadab Akhtar",
        "Md Suaib",
        "Niranjan K. Ray"
      ],
      "abstract": "Healthcare is one of the most important aspects of human life. Heart disease\nis known to be one of the deadliest diseases which is hampering the lives of\nmany people around the world. Heart disease must be detected early so the loss\nof lives can be prevented. The availability of large-scale data for medical\ndiagnosis has helped developed complex machine learning and deep learning-based\nmodels for automated early diagnosis of heart diseases. The classical\napproaches have been limited in terms of not generalizing well to new data\nwhich have not been seen in the training set. This is indicated by a large gap\nin training and test accuracies. This paper proposes a novel deep learning\narchitecture using a 1D convolutional neural network for classification between\nhealthy and non-healthy persons to overcome the limitations of classical\napproaches. Various clinical parameters are used for assessing the risk profile\nin the patients which helps in early diagnosis. Various techniques are used to\navoid overfitting in the proposed network. The proposed network achieves over\n97% training accuracy and 96% test accuracy on the dataset. The accuracy of the\nmodel is compared in detail with other classification algorithms using various\nperformance parameters which proves the effectiveness of the proposed\narchitecture.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/032f3bf9ec1332486ca0f39896bd2b24db7fdd8c",
      "published_date": "2021-05-22",
      "downloaded_date": "2025-02-01",
      "filename": "Hussain-Novel Deep Learning Architecture for Heart Disease Prediction using Convolutional Neural Network.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.10816v4",
      "categories": [
        "cs.LG"
      ]
    },
    "2211.03219v1": {
      "title": "B-SMART: A Reference Architecture for Artificially Intelligent Autonomic Smart Buildings",
      "authors": [
        "Mikhail Genkin",
        "J. J. McArthur"
      ],
      "abstract": "The pervasive application of artificial intelligence and machine learning\nalgorithms is transforming many industries and aspects of the human experience.\nOne very important industry trend is the move to convert existing human\ndwellings to smart buildings, and to create new smart buildings. Smart\nbuildings aim to mitigate climate change by reducing energy consumption and\nassociated carbon emissions. To accomplish this, they leverage artificial\nintelligence, big data, and machine learning algorithms to learn and optimize\nsystem performance. These fields of research are currently very rapidly\nevolving and advancing, but there has been very little guidance to help\nengineers and architects working on smart buildings apply artificial\nintelligence algorithms and technologies in a systematic and effective manner.\nIn this paper we present B-SMART: the first reference architecture for\nautonomic smart buildings. B-SMART facilitates the application of artificial\nintelligence techniques and technologies to smart buildings by decoupling\nconceptually distinct layers of functionality and organizing them into an\nautonomic control loop. We also present a case study illustrating how B-SMART\ncan be applied to accelerate the introduction of artificial intelligence into\nan existing smart building.",
      "citation_count": 19,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fb85d53a98160cb99d112fdb172e9736c16e8eb2",
      "published_date": "2022-11-06",
      "downloaded_date": "2025-02-01",
      "filename": "Genkin-B-SMART A Reference Architecture for Artificially Intelligent Autonomic Smart Buildings.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2211.03219v1",
      "categories": [
        "cs.AI",
        "I.2.1"
      ]
    },
    "2206.07609v1": {
      "title": "Epistemic Deep Learning",
      "authors": [
        "Shireen Kudukkil Manchingal",
        "Fabio Cuzzolin"
      ],
      "abstract": "The belief function approach to uncertainty quantification as proposed in the\nDemspter-Shafer theory of evidence is established upon the general mathematical\nmodels for set-valued observations, called random sets. Set-valued predictions\nare the most natural representations of uncertainty in machine learning. In\nthis paper, we introduce a concept called epistemic deep learning based on the\nrandom-set interpretation of belief functions to model epistemic learning in\ndeep neural networks. We propose a novel random-set convolutional neural\nnetwork for classification that produces scores for sets of classes by learning\nset-valued ground truth representations. We evaluate different formulations of\nentropy and distance measures for belief functions as viable loss functions for\nthese random-set networks. We also discuss methods for evaluating the quality\nof epistemic predictions and the performance of epistemic random-set neural\nnetworks. We demonstrate through experiments that the epistemic approach\nproduces better performance results when compared to traditional approaches of\nestimating uncertainty.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7695cc53cfb8820665f2bb9e7d963cc13eb8f41d",
      "published_date": "2022-06-15",
      "downloaded_date": "2025-02-01",
      "filename": "Manchingal-Epistemic Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.07609v1",
      "categories": [
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ]
    },
    "1512.00977v1": {
      "title": "A Study on Artificial Intelligence IQ and Standard Intelligent Model",
      "authors": [
        "Feng Liu",
        "Yong Shi"
      ],
      "abstract": "Currently, potential threats of artificial intelligence (AI) to human have\ntriggered a large controversy in society, behind which, the nature of the issue\nis whether the artificial intelligence (AI) system can be evaluated\nquantitatively. This article analyzes and evaluates the challenges that the AI\ndevelopment level is facing, and proposes that the evaluation methods for the\nhuman intelligence test and the AI system are not uniform; and the key reason\nfor which is that none of the models can uniformly describe the AI system and\nthe beings like human. Aiming at this problem, a standard intelligent system\nmodel is established in this study to describe the AI system and the beings\nlike human uniformly. Based on the model, the article makes an abstract\nmathematical description, and builds the standard intelligent machine\nmathematical model; expands the Von Neumann architecture and proposes the\nLiufeng - Shiyong architecture; gives the definition of the artificial\nintelligence IQ, and establishes the artificial intelligence scale and the\nevaluation method; conduct the test on 50 search engines and three human\nsubjects at different ages across the world, and finally obtains the ranking of\nthe absolute IQ and deviation IQ ranking for artificial intelligence IQ 2014.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/003c682dfe3e44396bd3e24926dca5b09156c1f6",
      "published_date": "2015-12-03",
      "downloaded_date": "2025-02-01",
      "filename": "Liu-A Study on Artificial Intelligence IQ and Standard Intelligent Model.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1512.00977v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1902.02647v2": {
      "title": "Wireless Networks Design in the Era of Deep Learning: Model-Based, AI-Based, or Both?",
      "authors": [
        "Alessio Zappone",
        "Marco Di Renzo",
        "MÃ©rouane Debbah"
      ],
      "abstract": "This work deals with the use of emerging deep learning techniques in future\nwireless communication networks. It will be shown that data-driven approaches\nshould not replace, but rather complement traditional design techniques based\non mathematical models.\n  Extensive motivation is given for why deep learning based on artificial\nneural networks will be an indispensable tool for the design and operation of\nfuture wireless communications networks, and our vision of how artificial\nneural networks should be integrated into the architecture of future wireless\ncommunication networks is presented.\n  A thorough description of deep learning methodologies is provided, starting\nwith the general machine learning paradigm, followed by a more in-depth\ndiscussion about deep learning and artificial neural networks, covering the\nmost widely-used artificial neural network architectures and their training\nmethods. Deep learning will also be connected to other major learning\nframeworks such as reinforcement learning and transfer learning.\n  A thorough survey of the literature on deep learning for wireless\ncommunication networks is provided, followed by a detailed description of\nseveral novel case-studies wherein the use of deep learning proves extremely\nuseful for network design. For each case-study, it will be shown how the use of\n(even approximate) mathematical models can significantly reduce the amount of\nlive data that needs to be acquired/measured to implement data-driven\napproaches. For each application, the merits of the proposed approaches will be\ndemonstrated by a numerical analysis in which the implementation and training\nof the artificial neural network used to solve the problem is discussed.\n  Finally, concluding remarks describe those that in our opinion are the major\ndirections for future research in this field.",
      "citation_count": 451,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/407fe62032a0d69cf77a13fb86645858f46ee9c8",
      "published_date": "2019-02-05",
      "downloaded_date": "2025-02-01",
      "filename": "Zappone-Wireless Networks Design in the Era of Deep Learning Model-Based AI-Based or Both.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1902.02647v2",
      "categories": [
        "eess.SP",
        "cs.IT",
        "math.IT"
      ]
    },
    "1811.05896v1": {
      "title": "QUENN: QUantization Engine for low-power Neural Networks",
      "authors": [
        "Miguel de Prado",
        "Maurizio Denna",
        "Luca Benini",
        "Nuria Pazos"
      ],
      "abstract": "Deep Learning is moving to edge devices, ushering in a new age of distributed\nArtificial Intelligence (AI). The high demand of computational resources\nrequired by deep neural networks may be alleviated by approximate computing\ntechniques, and most notably reduced-precision arithmetic with coarsely\nquantized numerical representations. In this context, Bonseyes comes in as an\ninitiative to enable stakeholders to bring AI to low-power and autonomous\nenvironments such as: Automotive, Medical Healthcare and Consumer Electronics.\nTo achieve this, we introduce LPDNN, a framework for optimized deployment of\nDeep Neural Networks on heterogeneous embedded devices. In this work, we detail\nthe quantization engine that is integrated in LPDNN. The engine depends on a\nfine-grained workflow which enables a Neural Network Design Exploration and a\nsensitivity analysis of each layer for quantization. We demonstrate the engine\nwith a case study on Alexnet and VGG16 for three different techniques for\ndirect quantization: standard fixed-point, dynamic fixed-point and k-means\nclustering, and demonstrate the potential of the latter. We argue that using a\nGaussian quantizer with k-means clustering can achieve better performance than\nlinear quantizers. Without retraining, we achieve over 55.64\\% saving for\nweights' storage and 69.17\\% for run-time memory accesses with less than 1\\%\ndrop in top5 accuracy in Imagenet.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1a80e6534c88e866e06b6c4e66eb73341bb97803",
      "published_date": "2018-11-14",
      "downloaded_date": "2025-02-01",
      "filename": "Prado-QUENN QUantization Engine for low-power Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1811.05896v1",
      "categories": [
        "cs.NE",
        "cs.LG"
      ]
    },
    "2408.13222v1": {
      "title": "An Overview on Machine Learning Methods for Partial Differential Equations: from Physics Informed Neural Networks to Deep Operator Learning",
      "authors": [
        "Lukas Gonon",
        "Arnulf Jentzen",
        "Benno Kuckuck",
        "Siyu Liang",
        "Adrian Riekert",
        "Philippe von Wurstemberger"
      ],
      "abstract": "The approximation of solutions of partial differential equations (PDEs) with\nnumerical algorithms is a central topic in applied mathematics. For many\ndecades, various types of methods for this purpose have been developed and\nextensively studied. One class of methods which has received a lot of attention\nin recent years are machine learning-based methods, which typically involve the\ntraining of artificial neural networks (ANNs) by means of stochastic gradient\ndescent type optimization methods. While approximation methods for PDEs using\nANNs have first been proposed in the 1990s they have only gained wide\npopularity in the last decade with the rise of deep learning. This article aims\nto provide an introduction to some of these methods and the mathematical theory\non which they are based. We discuss methods such as physics-informed neural\nnetworks (PINNs) and deep BSDE methods and consider several operator learning\napproaches.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b1f9251811f3fb77c03b68498df33e661c83a8b1",
      "published_date": "2024-08-23",
      "downloaded_date": "2025-02-01",
      "filename": "Gonon-An Overview on Machine Learning Methods for Partial Differential Equations from Physics Informed Neu....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.13222v1",
      "categories": [
        "math.NA",
        "cs.NA",
        "stat.ML"
      ]
    },
    "1901.03678v1": {
      "title": "Machine Learning Automation Toolbox (MLaut)",
      "authors": [
        "Viktor Kazakov",
        "Franz J. KirÃ¡ly"
      ],
      "abstract": "In this paper we present MLaut (Machine Learning AUtomation Toolbox) for the\npython data science ecosystem. MLaut automates large-scale evaluation and\nbenchmarking of machine learning algorithms on a large number of datasets.\nMLaut provides a high-level workflow interface to machine algorithm algorithms,\nimplements a local back-end to a database of dataset collections, trained\nalgorithms, and experimental results, and provides easy-to-use interfaces to\nthe scikit-learn and keras modelling libraries. Experiments are easy to set up\nwith default settings in a few lines of code, while remaining fully\ncustomizable to the level of hyper-parameter tuning, pipeline composition, or\ndeep learning architecture.\n  As a principal test case for MLaut, we conducted a large-scale supervised\nclassification study in order to benchmark the performance of a number of\nmachine learning algorithms - to our knowledge also the first larger-scale\nstudy on standard supervised learning data sets to include deep learning\nalgorithms. While corroborating a number of previous findings in literature, we\nfound (within the limitations of our study) that deep neural networks do not\nperform well on basic supervised learning, i.e., outside the more specialized,\nimage-, audio-, or text-based tasks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-01-11",
      "downloaded_date": "2025-02-01",
      "filename": "Kazakov-Machine Learning Automation Toolbox MLaut.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.03678v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    "2105.12122v3": {
      "title": "Optical coherent dot-product chip for sophisticated deep learning regression",
      "authors": [
        "Shaofu Xu",
        "Jing Wang",
        "Haowen Shu",
        "Zhike Zhang",
        "Sicheng Yi",
        "Bowen Bai",
        "Xingjun Wang",
        "Jianguo Liu",
        "Weiwen Zou"
      ],
      "abstract": "Optical implementations of neural networks (ONNs) herald the next-generation\nhigh-speed and energy-efficient deep learning computing by harnessing the\ntechnical advantages of large bandwidth and high parallelism of optics.\nHowever, due to the problems of incomplete numerical domain, limited hardware\nscale, or inadequate numerical accuracy, the majority of existing ONNs were\nstudied for basic classification tasks. Given that regression is a fundamental\nform of deep learning and accounts for a large part of current artificial\nintelligence applications, it is necessary to master deep learning regression\nfor further development and deployment of ONNs. Here, we demonstrate a\nsilicon-based optical coherent dot-product chip (OCDC) capable of completing\ndeep learning regression tasks. The OCDC adopts optical fields to carry out\noperations in complete real-value domain instead of in only positive domain.\nVia reusing, a single chip conducts matrix multiplications and convolutions in\nneural networks of any complexity. Also, hardware deviations are compensated\nvia in-situ backpropagation control provided the simplicity of chip\narchitecture. Therefore, the OCDC meets the requirements for sophisticated\nregression tasks and we successfully demonstrate a representative neural\nnetwork, the AUTOMAP (a cutting-edge neural network model for image\nreconstruction). The quality of reconstructed images by the OCDC and a 32-bit\ndigital computer is comparable. To the best of our knowledge, there is no\nprecedent of performing such state-of-the-art regression tasks on ONN chip. It\nis anticipated that the OCDC can promote novel accomplishment of ONNs in modern\nAI applications including autonomous driving, natural language processing, and\nscientific study.",
      "citation_count": 61,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/74675779ecb51786190070d60d8a26817a0523f3",
      "published_date": "2021-05-25",
      "downloaded_date": "2025-02-01",
      "filename": "Xu-Optical coherent dot-product chip for sophisticated deep learning regression.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.12122v3",
      "categories": [
        "cs.ET",
        "physics.optics"
      ]
    },
    "1910.09616v5": {
      "title": "Volterra Neural Networks (VNNs)",
      "authors": [
        "Siddharth Roheda",
        "Hamid Krim"
      ],
      "abstract": "The importance of inference in Machine Learning (ML) has led to an explosive\nnumber of different proposals in ML, and particularly in Deep Learning. In an\nattempt to reduce the complexity of Convolutional Neural Networks, we propose a\nVolterra filter-inspired Network architecture. This architecture introduces\ncontrolled non-linearities in the form of interactions between the delayed\ninput samples of data. We propose a cascaded implementation of Volterra\nFiltering so as to significantly reduce the number of parameters required to\ncarry out the same classification task as that of a conventional Neural\nNetwork. We demonstrate an efficient parallel implementation of this Volterra\nNeural Network (VNN), along with its remarkable performance while retaining a\nrelatively simpler and potentially more tractable structure. Furthermore, we\nshow a rather sophisticated adaptation of this network to nonlinearly fuse the\nRGB (spatial) information and the Optical Flow (temporal) information of a\nvideo sequence for action recognition. The proposed approach is evaluated on\nUCF-101 and HMDB-51 datasets for action recognition, and is shown to outperform\nstate of the art CNN approaches.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-10-21",
      "downloaded_date": "2025-02-01",
      "filename": "Roheda-Volterra Neural Networks VNNs.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1910.09616v5",
      "categories": [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    },
    "2404.11842v3": {
      "title": "Generating synthetic light-adapted electroretinogram waveforms using Artificial Intelligence to improve classification of retinal conditions in under-represented populations",
      "authors": [
        "Mikhail Kulyabin",
        "Aleksei Zhdanov",
        "Andreas Maier",
        "Lynne Loh",
        "Jose J. Estevez",
        "Paul A. Constable"
      ],
      "abstract": "Visual electrophysiology is often used clinically to determine functional\nchanges associated with retinal or neurological conditions. The full-field\nflash electroretinogram (ERG) assesses the global contribution of the outer and\ninner retinal layers initiated by the rods and cone pathways depending on the\nstate of retinal adaptation. Within clinical centers reference normative data\nare used to compare with clinical cases that may be rare or underpowered within\na specific demographic. To bolster either reference or case datasets the\napplication of synthetic ERG waveforms may offer benefits to disease\nclassification and case-control studies. In this study and as a proof of\nconcept, artificial intelligence (AI) to generate synthetic signals using\nGenerative Adversarial Networks is deployed to up-scale male participants\nwithin an ISCEV reference dataset containing 68 participants, with waveforms\nfrom the right and left eye. Random Forest Classifiers further improved\nclassification for sex within the group from a balanced accuracy of 0.72 to\n0.83 with the added synthetic male waveforms. This is the first study to\ndemonstrate the generation of synthetic ERG waveforms to improve machine\nlearning classification modelling with electroretinogram waveforms.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/899914b7eff735682b05147026be422c26206808",
      "published_date": "2024-04-18",
      "downloaded_date": "2025-02-01",
      "filename": "Kulyabin-Generating synthetic light-adapted electroretinogram waveforms using Artificial Intelligence to impr....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.11842v3",
      "categories": [
        "q-bio.NC"
      ]
    },
    "2312.04616v1": {
      "title": "Can apparent bystanders distinctively shape an outcome? Global south countries and global catastrophic risk-focused governance of artificial intelligence",
      "authors": [
        "Cecil Abungu",
        "Michelle Malonza",
        "Sumaya Nur Adan"
      ],
      "abstract": "Increasingly, there is well-grounded concern that through perpetual\nscaling-up of computation power and data, current deep learning techniques will\ncreate highly capable artificial intelligence that could pursue goals in a\nmanner that is not aligned with human values. In turn, such AI could have the\npotential of leading to a scenario in which there is serious global-scale\ndamage to human wellbeing. Against this backdrop, a number of researchers and\npublic policy professionals have been developing ideas about how to govern AI\nin a manner that reduces the chances that it could lead to a global\ncatastrophe. The jurisdictional focus of a vast majority of their assessments\nso far has been the United States, China, and Europe. That preference seems to\nreveal an assumption underlying most of the work in this field: That global\nsouth countries can only have a marginal role in attempts to govern AI\ndevelopment from a global catastrophic risk -focused perspective. Our paper\nsets out to undermine this assumption. We argue that global south countries\nlike India and Singapore (and specific coalitions) could in fact be fairly\nconsequential in the global catastrophic risk-focused governance of AI. We\nsupport our position using 4 key claims. 3 are constructed out of the current\nways in which advanced foundational AI models are built and used while one is\nconstructed on the strategic roles that global south countries and coalitions\nhave historically played in the design and use of multilateral rules and\ninstitutions. As each claim is elaborated, we also suggest some ways through\nwhich global south countries can play a positive role in designing,\nstrengthening and operationalizing global catastrophic risk-focused AI\ngovernance.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4f64807330e58040a81726113184d7da968f074e",
      "published_date": "2023-12-07",
      "downloaded_date": "2025-02-01",
      "filename": "Abungu-Can apparent bystanders distinctively shape an outcome Global south countries and global catastrophi....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.04616v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2010.02670v1": {
      "title": "State of the Art Survey of Deep Learning and Machine Learning Models for Smart Cities and Urban Sustainability",
      "authors": [
        "Saeed Nosratabadi",
        "Amir Mosavi",
        "Ramin Keivani",
        "Sina Ardabili",
        "Farshid Aram"
      ],
      "abstract": "Deep learning (DL) and machine learning (ML) methods have recently\ncontributed to the advancement of models in the various aspects of prediction,\nplanning, and uncertainty analysis of smart cities and urban development. This\npaper presents the state of the art of DL and ML methods used in this realm.\nThrough a novel taxonomy, the advances in model development and new application\ndomains in urban sustainability and smart cities are presented. Findings reveal\nthat five DL and ML methods have been most applied to address the different\naspects of smart cities. These are artificial neural networks; support vector\nmachines; decision trees; ensembles, Bayesians, hybrids, and neuro-fuzzy; and\ndeep learning. It is also disclosed that energy, health, and urban transport\nare the main domains of smart cities that DL and ML methods contributed in to\naddress their problems.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-10-06",
      "downloaded_date": "2025-02-01",
      "filename": "Nosratabadi-State of the Art Survey of Deep Learning and Machine Learning Models for Smart Cities and Urban Sust....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2010.02670v1",
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ]
    },
    "2201.08442v1": {
      "title": "Neural Network Quantization with AI Model Efficiency Toolkit (AIMET)",
      "authors": [
        "Sangeetha Siddegowda",
        "Marios Fournarakis",
        "Markus Nagel",
        "Tijmen Blankevoort",
        "Chirag Patel",
        "Abhijit Khobare"
      ],
      "abstract": "While neural networks have advanced the frontiers in many machine learning\napplications, they often come at a high computational cost. Reducing the power\nand latency of neural network inference is vital to integrating modern networks\ninto edge devices with strict power and compute requirements. Neural network\nquantization is one of the most effective ways of achieving these savings, but\nthe additional noise it induces can lead to accuracy degradation. In this white\npaper, we present an overview of neural network quantization using AI Model\nEfficiency Toolkit (AIMET). AIMET is a library of state-of-the-art quantization\nand compression algorithms designed to ease the effort required for model\noptimization and thus drive the broader AI ecosystem towards low latency and\nenergy-efficient inference. AIMET provides users with the ability to simulate\nas well as optimize PyTorch and TensorFlow models. Specifically for\nquantization, AIMET includes various post-training quantization (PTQ, cf.\nchapter 4) and quantization-aware training (QAT, cf. chapter 5) techniques that\nguarantee near floating-point accuracy for 8-bit fixed-point inference. We\nprovide a practical guide to quantization via AIMET by covering PTQ and QAT\nworkflows, code examples and practical tips that enable users to efficiently\nand effectively quantize models using AIMET and reap the benefits of low-bit\ninteger inference.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-01-20",
      "downloaded_date": "2025-02-01",
      "filename": "Siddegowda-Neural Network Quantization with AI Model Efficiency Toolkit AIMET.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2201.08442v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.PF",
        "cs.SE"
      ]
    },
    "2011.05808v1": {
      "title": "AIRSENSE-TO-ACT: A Concept Paper for COVID-19 Countermeasures based on Artificial Intelligence algorithms and multi-sources Data Processing",
      "authors": [
        "A. Sebastianelli",
        "F. Mauro",
        "G. Di Cosmo",
        "F. Passarini",
        "M. Carminati",
        "S. L. Ullo"
      ],
      "abstract": "Aim of this paper is the description of a new tool to support institutions in\nthe implementation of targeted countermeasures, based on quantitative and\nmulti-scale elements, for the fight and prevention of emergencies, such as the\ncurrent COVID-19 pandemic. The tool is a centralized system (web application),\nsingle multi-user platform, which relies on Artificial Intelligence (AI)\nalgorithms for the processing of heterogeneous data, and which can produce an\noutput level of risk. The model includes a specific neural network which will\nbe first trained to learn the correlation between selected inputs, related to\nthe case of interest: environmental variables (chemical-physical, such as\nmeteorological), human activity (such as traffic and crowding), level of\npollution (in particular the concentration of particulate matter), and\nepidemiological variables related to the evolution of the contagion. The tool\nrealized in the first phase of the project will serve later both as a decision\nsupport system (DSS) with predictive capacity, when fed by the actual measured\ndata, and as a simulation bench performing the tuning of certain input values,\nto identify which of them lead to a decrease in the degree of risk. In this\nway, the authors aim to design different scenarios to compare different\nrestrictive strategies and the actual expected benefits, to adopt measures\nsized to the actual need, and adapted to the specific areas of analysis, useful\nto safeguard human health, but also the economic and social impact of the\nchoices.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/01f3984feb4a8aaba07d8b9f3a891d86d49818b1",
      "published_date": "2020-11-07",
      "downloaded_date": "2025-02-01",
      "filename": "Sebastianelli-AIRSENSE-TO-ACT A Concept Paper for COVID-19 Countermeasures based on Artificial Intelligence algori....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2011.05808v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2101.00339v1": {
      "title": "An Artificial Intelligence System for Combined Fruit Detection and Georeferencing, Using RTK-Based Perspective Projection in Drone Imagery",
      "authors": [
        "Angus Baird",
        "Stefano Giani"
      ],
      "abstract": "This work presents an Artificial Intelligence (AI) system, based on the\nFaster Region-Based Convolution Neural Network (Faster R-CNN) framework, which\ndetects and counts apples from oblique, aerial drone imagery of giant\ncommercial orchards. To reduce computational cost, a novel precursory stage to\nthe network is designed to preprocess raw imagery into cropped images of\nindividual trees. Unique geospatial identifiers are allocated to these using\nthe perspective projection model. This employs Real-Time Kinematic (RTK) data,\nDigital Terrain and Surface Models (DTM and DSM), as well as internal and\nexternal camera parameters. The bulk of experiments however focus on tuning\nhyperparameters in the detection network itself. Apples which are on trees and\napples which are on the ground are treated as separate classes. A mean Average\nPrecision (mAP) metric, calibrated by the size of the two classes, is devised\nto mitigate spurious results. Anchor box design is of key interest due to the\nscale of the apples. As such, a k-means clustering approach, never before seen\nin literature for Faster R-CNN, resulted in the most significant improvements\nto calibrated mAP. Other experiments showed that the maximum number of box\nproposals should be 225; the initial learning rate of 0.001 is best applied to\nthe adaptive RMS Prop optimiser; and ResNet 101 is the ideal base feature\nextractor when considering mAP and, to a lesser extent, inference time. The\namalgamation of the optimal hyperparameters leads to a model with a calibrated\nmAP of 0.7627.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/febcf395bd68a34775b85f63ef38c50cc3f12137",
      "published_date": "2021-01-01",
      "downloaded_date": "2025-02-01",
      "filename": "Baird-An Artificial Intelligence System for Combined Fruit Detection and Georeferencing Using RTK-Based Pe....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.00339v1",
      "categories": [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    },
    "2112.15047v3": {
      "title": "When bubbles are not spherical: artificial intelligence analysis of ultrasonic cavitation bubbles in solutions of varying concentrations",
      "authors": [
        "Ilya Korolev",
        "Timur Aliev",
        "Tetiana Orlova",
        "Sviatlana A. Ulasevich",
        "Michael Nosonovsky",
        "Ekaterina V. Skorb"
      ],
      "abstract": "Ultrasonic irradiation of liquids, such as water-alcohol solutions, results\nin cavitation or the formation of small bubbles. Cavitation bubbles are\ngenerated in real solutions without the use of optical traps making our system\nas close to real conditions as possible. Under the action of the ultrasound,\nbubbles can grow, oscillate, and eventually, they collapse or decompose. We\napply the mathematical method of separation of motions to interpret the\nacoustic effect on the bubbles. While in most situations, the spherical shape\nof a bubble is the most energetically profitable as it minimizes the surface\nenergy, when the acoustic frequency is in resonance with the natural frequency\nof the bubble, shapes with the dihedral symmetry emerge. Some of these\nresonance shapes turn unstable, so the bubble decomposes. It turns out that\nbubbles in the solutions of different concentrations (with different surface\nenergies and densities) attain different evolution paths. While it is difficult\nto obtain a deterministic description of how the solution concentration affects\nbubble dynamics, it is possible to separate images with different\nconcentrations by applying the Artificial Neural Network (ANN) algorithm. An\nANN was trained to detect the concentration of alcohol in a water solution\nbased on the bubble images. This indicates that Artificial Intelligence (AI)\nmethods can complement deterministic analysis in non-equilibrium, near-unstable\nsituations.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1eb12e7998be3a2aae079b577138d9987191748a",
      "published_date": "2021-12-30",
      "downloaded_date": "2025-02-01",
      "filename": "Korolev-When bubbles are not spherical artificial intelligence analysis of ultrasonic cavitation bubbles in ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2112.15047v3",
      "categories": [
        "physics.flu-dyn",
        "cond-mat.soft"
      ]
    },
    "1902.01362v1": {
      "title": "Evaluation of Multidisciplinary Effects of Artificial Intelligence with Optimization Perspective",
      "authors": [
        "M. H. Calp"
      ],
      "abstract": "Artificial Intelligence has an important place in the scientific community as\na result of its successful outputs in terms of different fields. In time, the\nfield of Artificial Intelligence has been divided into many sub-fields because\nof increasing number of different solution approaches, methods, and techniques.\nMachine Learning has the most remarkable role with its functions to learn from\nsamples from the environment. On the other hand, intelligent optimization done\nby inspiring from nature and swarms had its own unique scientific literature,\nwith effective solutions provided for optimization problems from different\nfields. Because intelligent optimization can be applied in different fields\neffectively, this study aims to provide a general discussion on\nmultidisciplinary effects of Artificial Intelligence by considering its\noptimization oriented solutions. The study briefly focuses on background of the\nintelligent optimization briefly and then gives application examples of\nintelligent optimization from a multidisciplinary perspective.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3f6514bc5ab357028675e006b2a42ad15b9302ae",
      "published_date": "2019-02-04",
      "downloaded_date": "2025-02-01",
      "filename": "Calp-Evaluation of Multidisciplinary Effects of Artificial Intelligence with Optimization Perspective.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1902.01362v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2410.00044v1": {
      "title": "Artificial intelligence-based blockchain-driven financial default prediction",
      "authors": [
        "Junjun Huang"
      ],
      "abstract": "With the rapid development of technology, blockchain and artificial\nintelligence technology are playing a huge role in all walks of life. In the\nfinancial sector, blockchain solves many security problems in data storage and\nmanagement in traditional systems with its advantages of decentralization and\nsecurity. And artificial intelligence has huge advantages in financial\nforecasting and risk management through its powerful algorithmic modeling\ncapabilities. In financial default prediction using blockchain and artificial\nintelligence technology is a very powerful application. Blockchain technology\nguarantees the credibility of data and consistency on all nodes, and machine\nlearning builds a high-level default prediction model through detailed analysis\nof big data. This study offers financial institutions new thoughts on financial\ntechnology in terms of credit risk mitigation and financial system\nstabilization.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b51d84087c1665e4c8c8f6e9d646152ae6d164a6",
      "published_date": "2024-09-27",
      "downloaded_date": "2025-02-01",
      "filename": "Huang-Artificial intelligence-based blockchain-driven financial default prediction.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.00044v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    "1709.10242v2": {
      "title": "Intelligence Quotient and Intelligence Grade of Artificial Intelligence",
      "authors": [
        "Feng Liu",
        "Yong Shi",
        "Ying Liu"
      ],
      "abstract": "Although artificial intelligence is currently one of the most interesting\nareas in scientific research, the potential threats posed by emerging AI\nsystems remain a source of persistent controversy. To address the issue of AI\nthreat, this study proposes a standard intelligence model that unifies AI and\nhuman characteristics in terms of four aspects of knowledge, i.e., input,\noutput, mastery, and creation. Using this model, we observe three challenges,\nnamely, expanding of the von Neumann architecture; testing and ranking the\nintelligence quotient of naturally and artificially intelligent systems,\nincluding humans, Google, Bing, Baidu, and Siri; and finally, the dividing of\nartificially intelligent systems into seven grades from robots to Google Brain.\nBased on this, we conclude that AlphaGo belongs to the third grade.",
      "citation_count": 33,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3c9b299d93cced85ce72c1aaf0547d75de0a048f",
      "published_date": "2017-09-29",
      "downloaded_date": "2025-02-01",
      "filename": "Liu-Intelligence Quotient and Intelligence Grade of Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1709.10242v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2007.00263v1": {
      "title": "Mobile Botnet Detection: A Deep Learning Approach Using Convolutional Neural Networks",
      "authors": [
        "Suleiman Y. Yerima",
        "Mohammed K. Alzaylaee"
      ],
      "abstract": "Android, being the most widespread mobile operating systems is increasingly\nbecoming a target for malware. Malicious apps designed to turn mobile devices\ninto bots that may form part of a larger botnet have become quite common, thus\nposing a serious threat. This calls for more effective methods to detect\nbotnets on the Android platform. Hence, in this paper, we present a deep\nlearning approach for Android botnet detection based on Convolutional Neural\nNetworks (CNN). Our proposed botnet detection system is implemented as a\nCNN-based model that is trained on 342 static app features to distinguish\nbetween botnet apps and normal apps. The trained botnet detection model was\nevaluated on a set of 6,802 real applications containing 1,929 botnets from the\npublicly available ISCX botnet dataset. The results show that our CNN-based\napproach had the highest overall prediction accuracy compared to other popular\nmachine learning classifiers. Furthermore, the performance results observed\nfrom our model were better than those reported in previous studies on machine\nlearning based Android botnet detection.",
      "citation_count": 27,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1479502a9282908e8f1e55e65a30f3dd5960913c",
      "published_date": "2020-07-01",
      "downloaded_date": "2025-02-01",
      "filename": "Yerima-Mobile Botnet Detection A Deep Learning Approach Using Convolutional Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.00263v1",
      "categories": [
        "cs.CR",
        "cs.LG"
      ]
    },
    "1906.08866v1": {
      "title": "Towards Efficient Neural Networks On-a-chip: Joint Hardware-Algorithm Approaches",
      "authors": [
        "Xiaocong Du",
        "Gokul Krishnan",
        "Abinash Mohanty",
        "Zheng Li",
        "Gouranga Charan",
        "Yu Cao"
      ],
      "abstract": "Machine learning algorithms have made significant advances in many\napplications. However, their hardware implementation on the state-of-the-art\nplatforms still faces several challenges and are limited by various factors,\nsuch as memory volume, memory bandwidth and interconnection overhead. The\nadoption of the crossbar architecture with emerging memory technology partially\nsolves the problem but induces process variation and other concerns. In this\npaper, we will present novel solutions to two fundamental issues in crossbar\nimplementation of Artificial Intelligence (AI) algorithms: device variation and\ninsufficient interconnections. These solutions are inspired by the statistical\nproperties of algorithms themselves, especially the redundancy in neural\nnetwork nodes and connections. By Random Sparse Adaptation and pruning the\nconnections following the Small-World model, we demonstrate robust and\nefficient performance on representative datasets such as MNIST and CIFAR-10.\nMoreover, we present Continuous Growth and Pruning algorithm for future\nlearning and adaptation on hardware.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c69518f5dffec383483f691d04ea554e7d7caec4",
      "published_date": "2019-05-28",
      "downloaded_date": "2025-02-01",
      "filename": "Du-Towards Efficient Neural Networks On-a-chip Joint Hardware-Algorithm Approaches.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1906.08866v1",
      "categories": [
        "cs.NE"
      ]
    },
    "2306.13931v1": {
      "title": "Comparative Study of Predicting Stock Index Using Deep Learning Models",
      "authors": [
        "Harshal Patel",
        "Bharath Kumar Bolla",
        "Sabeesh E",
        "Dinesh Reddy"
      ],
      "abstract": "Time series forecasting has seen many methods attempted over the past few\ndecades, including traditional technical analysis, algorithmic statistical\nmodels, and more recent machine learning and artificial intelligence\napproaches. Recently, neural networks have been incorporated into the\nforecasting scenario, such as the LSTM and conventional RNN approaches, which\nutilize short-term and long-term dependencies. This study evaluates traditional\nforecasting methods, such as ARIMA, SARIMA, and SARIMAX, and newer neural\nnetwork approaches, such as DF-RNN, DSSM, and Deep AR, built using RNNs. The\nstandard NIFTY-50 dataset from Kaggle is used to assess these models using\nmetrics such as MSE, RMSE, MAPE, POCID, and Theil's U. Results show that Deep\nAR outperformed all other conventional deep learning and traditional\napproaches, with the lowest MAPE of 0.01 and RMSE of 189. Additionally, the\nperformance of Deep AR and GRU did not degrade when the amount of training data\nwas reduced, suggesting that these models may not require a large amount of\ndata to achieve consistent and reliable performance. The study demonstrates\nthat incorporating deep learning approaches in a forecasting scenario\nsignificantly outperforms conventional approaches and can handle complex\ndatasets, with potential applications in various domains, such as weather\npredictions and other time series applications in a real-world scenario.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0bdb7d2b7b1faf8dee5e643eea3b2aa27d6a3e3d",
      "published_date": "2023-06-24",
      "downloaded_date": "2025-02-01",
      "filename": "Patel-Comparative Study of Predicting Stock Index Using Deep Learning Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.13931v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2406.01869v1": {
      "title": "Fruit Classification System with Deep Learning and Neural Architecture Search",
      "authors": [
        "Christine Dewi",
        "Dhananjay Thiruvady",
        "Nayyar Zaidi"
      ],
      "abstract": "The fruit identification process involves analyzing and categorizing\ndifferent types of fruits based on their visual characteristics. This activity\ncan be achieved using a range of methodologies, encompassing manual\nexamination, conventional computer vision methodologies, and more sophisticated\nmethodologies employing machine learning and deep learning. Our study\nidentified a total of 15 distinct categories of fruit, consisting of class\nAvocado, Banana, Cherry, Apple Braeburn, Apple golden 1, Apricot, Grape, Kiwi,\nMango, Orange, Papaya, Peach, Pineapple, Pomegranate and Strawberry. Neural\nArchitecture Search (NAS) is a technological advancement employed within the\nrealm of deep learning and artificial intelligence, to automate conceptualizing\nand refining neural network topologies. NAS aims to identify neural network\nstructures that are highly suitable for tasks, such as the detection of fruits.\nOur suggested model with 99.98% mAP increased the detection performance of the\npreceding research study that used Fruit datasets. In addition, after the\ncompletion of the study, a comparative analysis was carried out to assess the\nfindings in conjunction with those of another research that is connected to the\ntopic. When compared to the findings of earlier studies, the detector that was\nproposed exhibited higher performance in terms of both its accuracy and its\nprecision.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/69bc607e20993a6aec093084a0f9515a3cfc29fb",
      "published_date": "2024-06-04",
      "downloaded_date": "2025-02-01",
      "filename": "Dewi-Fruit Classification System with Deep Learning and Neural Architecture Search.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.01869v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2; I.4"
      ]
    },
    "2311.15585v1": {
      "title": "Dawning of a New Era in Gravitational Wave Data Analysis: Unveiling Cosmic Mysteries via Artificial Intelligence -- A Systematic Review",
      "authors": [
        "Tianyu Zhao",
        "Ruijun Shi",
        "Yue Zhou",
        "Zhoujian Cao",
        "Zhixiang Ren"
      ],
      "abstract": "Background: Artificial intelligence (AI), with its vast capabilities, has\nbecome an integral part of our daily interactions, particularly with the rise\nof sophisticated models like Large Language Models. These advancements have not\nonly transformed human-machine interactions but have also paved the way for\nsignificant breakthroughs in various scientific domains. Aim of review: This\nreview is centered on elucidating the profound impact of AI, especially deep\nlearning, in the field of gravitational wave data analysis (GWDA). We aim to\nhighlight the challenges faced by traditional GWDA methodologies and how AI\nemerges as a beacon of hope, promising enhanced accuracy, real-time processing,\nand adaptability. Key scientific concepts of review: Gravitational wave (GW)\nwaveform modeling stands as a cornerstone in the realm of GW research, serving\nas a sophisticated method to simulate and interpret the intricate patterns and\nsignatures of these cosmic phenomena. This modeling provides a deep\nunderstanding of the astrophysical events that produce gravitational waves.\nNext in line is GW signal detection, a refined technique that meticulously\ncombs through extensive datasets, distinguishing genuine gravitational wave\nsignals from the cacophony of background noise. This detection process is\npivotal in ensuring the authenticity of observed events. Complementing this is\nthe GW parameter estimation, a method intricately designed to decode the\ndetected signals, extracting crucial parameters that offer insights into the\nproperties and origins of the waves. Lastly, the integration of AI for GW\nscience has emerged as a transformative force. AI methodologies harness vast\ncomputational power and advanced algorithms to enhance the efficiency,\naccuracy, and adaptability of data analysis in GW research, heralding a new era\nof innovation and discovery in the field.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2c1828edcbd5e3733694a75997f605c6e2216e90",
      "published_date": "2023-11-27",
      "downloaded_date": "2025-02-01",
      "filename": "Zhao-Dawning of a New Era in Gravitational Wave Data Analysis Unveiling Cosmic Mysteries via Artificial I....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.15585v1",
      "categories": [
        "gr-qc",
        "astro-ph.HE",
        "astro-ph.IM"
      ]
    },
    "2204.00507v1": {
      "title": "Deep Learning in Spiking Phasor Neural Networks",
      "authors": [
        "Connor Bybee",
        "E. Paxon Frady",
        "Friedrich T. Sommer"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have attracted the attention of the deep\nlearning community for use in low-latency, low-power neuromorphic hardware, as\nwell as models for understanding neuroscience. In this paper, we introduce\nSpiking Phasor Neural Networks (SPNNs). SPNNs are based on complex-valued Deep\nNeural Networks (DNNs), representing phases by spike times. Our model computes\nrobustly employing a spike timing code and gradients can be formed using the\ncomplex domain. We train SPNNs on CIFAR-10, and demonstrate that the\nperformance exceeds that of other timing coded SNNs, approaching results with\ncomparable real-valued DNNs.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6118b470605f2b1d57213cec19779bc670fca272",
      "published_date": "2022-04-01",
      "downloaded_date": "2025-02-01",
      "filename": "Bybee-Deep Learning in Spiking Phasor Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2204.00507v1",
      "categories": [
        "cs.NE"
      ]
    },
    "1802.03043v2": {
      "title": "PoTrojan: powerful neural-level trojan designs in deep learning models",
      "authors": [
        "Minhui Zou",
        "Yang Shi",
        "Chengliang Wang",
        "Fangyu Li",
        "WenZhan Song",
        "Yu Wang"
      ],
      "abstract": "With the popularity of deep learning (DL), artificial intelligence (AI) has\nbeen applied in many areas of human life. Neural network or artificial neural\nnetwork (NN), the main technique behind DL, has been extensively studied to\nfacilitate computer vision and natural language recognition. However, the more\nwe rely on information technology, the more vulnerable we are. That is,\nmalicious NNs could bring huge threat in the so-called coming AI era. In this\npaper, for the first time in the literature, we propose a novel approach to\ndesign and insert powerful neural-level trojans or PoTrojan in pre-trained NN\nmodels. Most of the time, PoTrojans remain inactive, not affecting the normal\nfunctions of their host NN models. PoTrojans could only be triggered in very\nrare conditions. Once activated, however, the PoTrojans could cause the host NN\nmodels to malfunction, either falsely predicting or classifying, which is a\nsignificant threat to human society of the AI era. We would explain the\nprinciples of PoTrojans and the easiness of designing and inserting them in\npre-trained deep learning models. PoTrojans doesn't modify the existing\narchitecture or parameters of the pre-trained models, without re-training.\nHence, the proposed method is very efficient.",
      "citation_count": 58,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c94ea98621b1a12eceea546a1152770423a0da37",
      "published_date": "2018-02-08",
      "downloaded_date": "2025-02-01",
      "filename": "Zou-PoTrojan powerful neural-level trojan designs in deep learning models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1802.03043v2",
      "categories": [
        "cs.CR",
        "cs.LG"
      ]
    },
    "2111.09488v1": {
      "title": "Attacking Deep Learning AI Hardware with Universal Adversarial Perturbation",
      "authors": [
        "Mehdi Sadi",
        "B. M. S. Bahar Talukder",
        "Kaniz Mishty",
        "Md Tauhidur Rahman"
      ],
      "abstract": "Universal Adversarial Perturbations are image-agnostic and model-independent\nnoise that when added with any image can mislead the trained Deep Convolutional\nNeural Networks into the wrong prediction. Since these Universal Adversarial\nPerturbations can seriously jeopardize the security and integrity of practical\nDeep Learning applications, existing techniques use additional neural networks\nto detect the existence of these noises at the input image source. In this\npaper, we demonstrate an attack strategy that when activated by rogue means\n(e.g., malware, trojan) can bypass these existing countermeasures by augmenting\nthe adversarial noise at the AI hardware accelerator stage. We demonstrate the\naccelerator-level universal adversarial noise attack on several deep Learning\nmodels using co-simulation of the software kernel of Conv2D function and the\nVerilog RTL model of the hardware under the FuseSoC environment.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7ac6ca9797a5da344707202d4d0ab3fe7b8fdfef",
      "published_date": "2021-11-18",
      "downloaded_date": "2025-02-01",
      "filename": "Sadi-Attacking Deep Learning AI Hardware with Universal Adversarial Perturbation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2111.09488v1",
      "categories": [
        "cs.CR",
        "cs.LG"
      ]
    },
    "2110.00653v2": {
      "title": "Sparse Deep Learning: A New Framework Immune to Local Traps and Miscalibration",
      "authors": [
        "Yan Sun",
        "Wenjun Xiong",
        "Faming Liang"
      ],
      "abstract": "Deep learning has powered recent successes of artificial intelligence (AI).\nHowever, the deep neural network, as the basic model of deep learning, has\nsuffered from issues such as local traps and miscalibration. In this paper, we\nprovide a new framework for sparse deep learning, which has the above issues\naddressed in a coherent way. In particular, we lay down a theoretical\nfoundation for sparse deep learning and propose prior annealing algorithms for\nlearning sparse neural networks. The former has successfully tamed the sparse\ndeep neural network into the framework of statistical modeling, enabling\nprediction uncertainty correctly quantified. The latter can be asymptotically\nguaranteed to converge to the global optimum, enabling the validity of the\ndown-stream statistical inference. Numerical result indicates the superiority\nof the proposed method compared to the existing ones.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/52a3f08de145e2c1e0e16048b56dfaa0e1d3c07a",
      "published_date": "2021-10-01",
      "downloaded_date": "2025-02-01",
      "filename": "Sun-Sparse Deep Learning A New Framework Immune to Local Traps and Miscalibration.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.00653v2",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    "1610.02501v1": {
      "title": "Revisiting Multiple Instance Neural Networks",
      "authors": [
        "Xinggang Wang",
        "Yongluan Yan",
        "Peng Tang",
        "Xiang Bai",
        "Wenyu Liu"
      ],
      "abstract": "Recently neural networks and multiple instance learning are both attractive\ntopics in Artificial Intelligence related research fields. Deep neural networks\nhave achieved great success in supervised learning problems, and multiple\ninstance learning as a typical weakly-supervised learning method is effective\nfor many applications in computer vision, biometrics, nature language\nprocessing, etc. In this paper, we revisit the problem of solving multiple\ninstance learning problems using neural networks. Neural networks are appealing\nfor solving multiple instance learning problem. The multiple instance neural\nnetworks perform multiple instance learning in an end-to-end way, which take a\nbag with various number of instances as input and directly output bag label.\nAll of the parameters in a multiple instance network are able to be optimized\nvia back-propagation. We propose a new multiple instance neural network to\nlearn bag representations, which is different from the existing multiple\ninstance neural networks that focus on estimating instance label. In addition,\nrecent tricks developed in deep learning have been studied in multiple instance\nnetworks, we find deep supervision is effective for boosting bag classification\naccuracy. In the experiments, the proposed multiple instance networks achieve\nstate-of-the-art or competitive performance on several MIL benchmarks.\nMoreover, it is extremely fast for both testing and training, e.g., it takes\nonly 0.0003 second to predict a bag and a few seconds to train on a MIL\ndatasets on a moderate CPU.",
      "citation_count": 420,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0820ccfdba775c304bedb9c3d82ee8758e0a416b",
      "published_date": "2016-10-08",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Revisiting Multiple Instance Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1610.02501v1",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    "1812.01714v1": {
      "title": "Deep Learning Architect: Classification for Architectural Design through the Eye of Artificial Intelligence",
      "authors": [
        "Yuji Yoshimura",
        "Bill Cai",
        "Zhoutong Wang",
        "Carlo Ratti"
      ],
      "abstract": "This paper applies state-of-the-art techniques in deep learning and computer\nvision to measure visual similarities between architectural designs by\ndifferent architects. Using a dataset consisting of web scraped images and an\noriginal collection of images of architectural works, we first train a deep\nconvolutional neural network (DCNN) model capable of achieving 73% accuracy in\nclassifying works belonging to 34 different architects. Through examining the\nweights in the trained DCNN model, we are able to quantitatively measure the\nvisual similarities between architects that are implicitly learned by our\nmodel. Using this measure, we cluster architects that are identified to be\nsimilar and compare our findings to conventional classification made by\narchitectural historians and theorists. Our clustering of architectural designs\nremarkably corroborates conventional views in architectural history, and the\nlearned architectural features also coheres with the traditional understanding\nof architectural designs.",
      "citation_count": 45,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bc6719d3c90a3828986fd231a90d1c666e57f3f3",
      "published_date": "2018-12-03",
      "downloaded_date": "2025-02-01",
      "filename": "Yoshimura-Deep Learning Architect Classification for Architectural Design through the Eye of Artificial Intell....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1812.01714v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "2407.15339v3": {
      "title": "Deep Learning for Economists",
      "authors": [
        "Melissa Dell"
      ],
      "abstract": "Deep learning provides powerful methods to impute structured information from\nlarge-scale, unstructured text and image datasets. For example, economists\nmight wish to detect the presence of economic activity in satellite images, or\nto measure the topics or entities mentioned in social media, the congressional\nrecord, or firm filings. This review introduces deep neural networks, covering\nmethods such as classifiers, regression models, generative AI, and embedding\nmodels. Applications include classification, document digitization, record\nlinkage, and methods for data exploration in massive scale text and image\ncorpora. When suitable methods are used, deep learning models can be cheap to\ntune and can scale affordably to problems involving millions or billions of\ndata points.. The review is accompanied by a companion website, EconDL, with\nuser-friendly demo notebooks, software resources, and a knowledge base that\nprovides technical details and additional applications.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/89ddf800ffb4da13e55167f652c2128f6900db37",
      "published_date": "2024-07-22",
      "downloaded_date": "2025-02-01",
      "filename": "Dell-Deep Learning for Economists.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.15339v3",
      "categories": [
        "econ.GN",
        "cs.CL",
        "cs.CV",
        "q-fin.EC"
      ]
    },
    "2107.13870v1": {
      "title": "Artificial Intelligence Hybrid Deep Learning Model for Groundwater Level Prediction Using MLP-ADAM",
      "authors": [
        "Pejman Zarafshan",
        "Saman Javadi",
        "Abbas Roozbahani",
        "Seyed Mehdi Hashemy",
        "Payam Zarafshan",
        "Hamed Etezadi"
      ],
      "abstract": "Groundwater is the largest storage of freshwater resources, which serves as\nthe major inventory for most of the human consumption through agriculture,\nindustrial, and domestic water supply. In the fields of hydrological, some\nresearchers applied a neural network to forecast rainfall intensity in\nspace-time and introduced the advantages of neural networks compared to\nnumerical models. Then, many researches have been conducted applying\ndata-driven models. Some of them extended an Artificial Neural Networks (ANNs)\nmodel to forecast groundwater level in semi-confined glacial sand and gravel\naquifer under variable state, pumping extraction and climate conditions with\nsignificant accuracy. In this paper, a multi-layer perceptron is applied to\nsimulate groundwater level. The adaptive moment estimation optimization\nalgorithm is also used to this matter. The root mean squared error, mean\nabsolute error, mean squared error and the coefficient of determination ( ) are\nused to evaluate the accuracy of the simulated groundwater level. Total value\nof and RMSE are 0.9458 and 0.7313 respectively which are obtained from the\nmodel output. Results indicate that deep learning algorithms can demonstrate a\nhigh accuracy prediction. Although the optimization of parameters is\ninsignificant in numbers, but due to the value of time in modelling setup, it\nis highly recommended to apply an optimization algorithm in modelling.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4efcfae3360ed3aaa5ce2611cf79cc35e94af722",
      "published_date": "2021-07-29",
      "downloaded_date": "2025-02-01",
      "filename": "Zarafshan-Artificial Intelligence Hybrid Deep Learning Model for Groundwater Level Prediction Using MLP-ADAM.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2107.13870v1",
      "categories": [
        "cs.LG",
        "physics.geo-ph"
      ]
    },
    "1908.00381v2": {
      "title": "Clinical acceptance of software based on artificial intelligence technologies (radiology)",
      "authors": [
        "S. P. Morozov",
        "A. V. Vladzymyrskyy",
        "V. G. Klyashtornyy",
        "A. E. Andreychenko",
        "N. S. Kulberg",
        "V. A. Gombolevsky",
        "K. A. Sergunova"
      ],
      "abstract": "Aim: provide a methodological framework for the process of clinical tests,\nclinical acceptance, and scientific assessment of algorithms and software based\non the artificial intelligence (AI) technologies. Clinical tests are considered\nas a preparation stage for the software registration as a medical product. The\nauthors propose approaches to evaluate accuracy and efficiency of the AI\nalgorithms for radiology.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/01a4f98186d5e30f97bfe28f54196a43d41dcf60",
      "published_date": "2019-08-01",
      "downloaded_date": "2025-02-01",
      "filename": "Morozov-Clinical acceptance of software based on artificial intelligence technologies radiology.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1908.00381v2",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "2004.04376v2": {
      "title": "ConsciousControlFlow(CCF): A Demonstration for conscious Artificial Intelligence",
      "authors": [
        "Hongzhi Wang",
        "Bozhou Chen",
        "Yueyang Xu",
        "Kaixin Zhang",
        "Shengwen Zheng"
      ],
      "abstract": "In this demo, we present ConsciousControlFlow(CCF), a prototype system to\ndemonstrate conscious Artificial Intelligence (AI). The system is based on the\ncomputational model for consciousness and the hierarchy of needs. CCF supports\ntypical scenarios to show the behaviors and the mental activities of conscious\nAI. We demonstrate that CCF provides a useful tool for effective machine\nconsciousness demonstration and human behavior study assistance.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/868f98dfefd696a3cbf0c9b6adc95a1996da3102",
      "published_date": "2020-04-09",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-ConsciousControlFlowCCF A Demonstration for conscious Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.04376v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2005.03100v1": {
      "title": "Mobile Edge Computing and Artificial Intelligence: A Mutually-Beneficial Relationship",
      "authors": [
        "Ahmed A. Al-habob",
        "Octavia A. Dobre"
      ],
      "abstract": "This article provides an overview of mobile edge computing (MEC) and\nartificial intelligence (AI) and discusses the mutually-beneficial relationship\nbetween them. AI provides revolutionary solutions in nearly every important\naspect of the MEC offloading process, such as resource management and\nscheduling. On the other hand, MEC servers are utilized to avail a distributed\nand parallelized learning framework, namely mobile edge learning.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/67546f54d39515331db4f77d42eeccc383bdd013",
      "published_date": "2020-04-27",
      "downloaded_date": "2025-02-01",
      "filename": "Al-habob-Mobile Edge Computing and Artificial Intelligence A Mutually-Beneficial Relationship.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.03100v1",
      "categories": [
        "eess.SP"
      ]
    },
    "2312.13333v1": {
      "title": "Responsible Deep Learning for Software as a Medical Device",
      "authors": [
        "Pratik Shah",
        "Jenna Lester",
        "Jana G Deflino",
        "Vinay Pai"
      ],
      "abstract": "Tools, models and statistical methods for signal processing and medical image\nanalysis and training deep learning models to create research prototypes for\neventual clinical applications are of special interest to the biomedical\nimaging community. But material and optical properties of biological tissues\nare complex and not easily captured by imaging devices. Added complexity can be\nintroduced by datasets with underrepresentation of medical images from races\nand ethnicities for deep learning, and limited knowledge about the regulatory\nframework needed for commercialization and safety of emerging Artificial\nIntelligence (AI) and Machine Learning (ML) technologies for medical image\nanalysis. This extended version of the workshop paper presented at the special\nsession of the 2022 IEEE 19th International Symposium on Biomedical Imaging,\ndescribes strategy and opportunities by University of California professors\nengaged in machine learning (section I) and clinical research (section II), the\nOffice of Science and Engineering Laboratories (OSEL) section III, and\nofficials at the US FDA in Center for Devices & Radiological Health (CDRH)\nsection IV. Performance evaluations of AI/ML models of skin (RGB), tissue\nbiopsy (digital pathology), and lungs and kidneys (Magnetic Resonance, X-ray,\nComputed Tomography) medical images for regulatory evaluations and real-world\ndeployment are discussed.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a209fc4032f7a5c660952c66232491dac18602b2",
      "published_date": "2023-12-20",
      "downloaded_date": "2025-02-01",
      "filename": "Shah-Responsible Deep Learning for Software as a Medical Device.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.13333v1",
      "categories": [
        "eess.IV",
        "cs.CY",
        "I.2; K.4.1; J.3; I.4"
      ]
    },
    "1703.06914v2": {
      "title": "Applying Deep Machine Learning for psycho-demographic profiling of Internet users using O.C.E.A.N. model of personality",
      "authors": [
        "Iaroslav Omelianenko"
      ],
      "abstract": "In the modern era, each Internet user leaves enormous amounts of auxiliary\ndigital residuals (footprints) by using a variety of on-line services. All this\ndata is already collected and stored for many years. In recent works, it was\ndemonstrated that it's possible to apply simple machine learning methods to\nanalyze collected digital footprints and to create psycho-demographic profiles\nof individuals. However, while these works clearly demonstrated the\napplicability of machine learning methods for such an analysis, created simple\nprediction models still lacks accuracy necessary to be successfully applied for\npractical needs. We have assumed that using advanced deep machine learning\nmethods may considerably increase the accuracy of predictions. We started with\nsimple machine learning methods to estimate basic prediction performance and\nmoved further by applying advanced methods based on shallow and deep neural\nnetworks. Then we compared prediction power of studied models and made\nconclusions about its performance. Finally, we made hypotheses how prediction\naccuracy can be further improved. As result of this work, we provide full\nsource code used in the experiments for all interested researchers and\npractitioners in corresponding GitHub repository. We believe that applying deep\nmachine learning for psycho-demographic profiling may have an enormous impact\non the society (for good or worse) and provides means for Artificial\nIntelligence (AI) systems to better understand humans by creating their\npsychological profiles. Thus AI agents may achieve the human-like ability to\nparticipate in conversation (communication) flow by anticipating human\nopponents' reactions, expectations, and behavior.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8de4cec0c712bc3c17fe75a6c409a90e7db3a1b3",
      "published_date": "2017-03-07",
      "downloaded_date": "2025-02-01",
      "filename": "Omelianenko-Applying Deep Machine Learning for psycho-demographic profiling of Internet users using OCEAN model ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1703.06914v2",
      "categories": [
        "cs.LG",
        "cs.CY"
      ]
    },
    "2105.13926v1": {
      "title": "Geometric Deep Learning and Equivariant Neural Networks",
      "authors": [
        "Jan E. Gerken",
        "Jimmy Aronsson",
        "Oscar Carlsson",
        "Hampus Linander",
        "Fredrik Ohlsson",
        "Christoffer Petersson",
        "Daniel Persson"
      ],
      "abstract": "We survey the mathematical foundations of geometric deep learning, focusing\non group equivariant and gauge equivariant neural networks. We develop gauge\nequivariant convolutional neural networks on arbitrary manifolds $\\mathcal{M}$\nusing principal bundles with structure group $K$ and equivariant maps between\nsections of associated vector bundles. We also discuss group equivariant neural\nnetworks for homogeneous spaces $\\mathcal{M}=G/K$, which are instead\nequivariant with respect to the global symmetry $G$ on $\\mathcal{M}$. Group\nequivariant layers can be interpreted as intertwiners between induced\nrepresentations of $G$, and we show their relation to gauge equivariant\nconvolutional layers. We analyze several applications of this formalism,\nincluding semantic segmentation and object detection networks. We also discuss\nthe case of spherical networks in great detail, corresponding to the case\n$\\mathcal{M}=S^2=\\mathrm{SO}(3)/\\mathrm{SO}(2)$. Here we emphasize the use of\nFourier analysis involving Wigner matrices, spherical harmonics and\nClebsch-Gordan coefficients for $G=\\mathrm{SO}(3)$, illustrating the power of\nrepresentation theory for deep learning.",
      "citation_count": 55,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f62f8e9501302a57a5656b01b9d45e4c7463d48f",
      "published_date": "2021-05-28",
      "downloaded_date": "2025-02-01",
      "filename": "Gerken-Geometric Deep Learning and Equivariant Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2105.13926v1",
      "categories": [
        "cs.LG",
        "cs.CV",
        "hep-th"
      ]
    },
    "2406.10843v1": {
      "title": "Enriching the Machine Learning Workloads in BigBench",
      "authors": [
        "Matthias Polag",
        "Todor Ivanov",
        "Timo Eichhorn"
      ],
      "abstract": "In the era of Big Data and the growing support for Machine Learning, Deep\nLearning and Artificial Intelligence algorithms in the current software\nsystems, there is an urgent need of standardized application benchmarks that\nstress test and evaluate these new technologies. Relying on the standardized\nBigBench (TPCx-BB) benchmark, this work enriches the improved BigBench V2 with\nthree new workloads and expands the coverage of machine learning algorithms.\nOur workloads utilize multiple algorithms and compare different implementations\nfor the same algorithm across several popular libraries like MLlib, SystemML,\nScikit-learn and Pandas, demonstrating the relevance and usability of our\nbenchmark extension.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a00e42a5583356197458a47264c753c02f494819",
      "published_date": "2024-06-16",
      "downloaded_date": "2025-02-01",
      "filename": "Polag-Enriching the Machine Learning Workloads in BigBench.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.10843v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2301.03098v1": {
      "title": "Comprehensive Mapping of Continuous/Switching Circuits in CCM and DCM to Machine Learning Domain using Homogeneous Graph Neural Networks",
      "authors": [
        "Ahmed K. Khamis",
        "Mohammed Agamy"
      ],
      "abstract": "This paper proposes a method of transferring physical continuous and\nswitching/converter circuits working in continuous conduction mode (CCM) and\ndiscontinuous conduction mode (DCM) to graph representation, independent of the\nconnection or the number of circuit components, so that machine learning (ML)\nalgorithms and applications can be easily applied. Such methodology is\ngeneralized and is applicable to circuits with any number of switches,\ncomponents, sources and loads, and can be useful in applications such as\nartificial intelligence (AI) based circuit design automation, layout\noptimization, circuit synthesis and performance monitoring and control. The\nproposed circuit representation and feature extraction methodology is applied\nto seven types of continuous circuits, ranging from second to fourth order and\nit is also applied to three of the most common converters (Buck, Boost, and\nBuck-boost) operating in CCM or DCM. A classifier ML task can easily\ndifferentiate between circuit types as well as their mode of operation, showing\nclassification accuracy of 97.37% in continuous circuits and 100% in switching\ncircuits",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9700bd30627b10e78948576031856a23a152cf5c",
      "published_date": "2023-01-08",
      "downloaded_date": "2025-02-01",
      "filename": "Khamis-Comprehensive Mapping of ContinuousSwitching Circuits in CCM and DCM to Machine Learning Domain usin....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2301.03098v1",
      "categories": [
        "eess.SY",
        "cs.SY"
      ]
    },
    "2402.02885v1": {
      "title": "A Review on Building Blocks of Decentralized Artificial Intelligence",
      "authors": [
        "Vid Kersic",
        "Muhamed Turkanovic"
      ],
      "abstract": "Artificial intelligence is transforming our lives, and technological progress\nand transfer from the academic and theoretical sphere to the real world are\naccelerating yearly. But during that progress and transition, several open\nproblems and questions need to be addressed for the field to develop ethically,\nsuch as digital privacy, ownership, and control. These are some of the reasons\nwhy the currently most popular approaches of artificial intelligence, i.e.,\ncentralized AI (CEAI), are questionable, with other directions also being\nwidely explored, such as decentralized artificial intelligence (DEAI), to solve\nsome of the most reaching problems. This paper provides a systematic literature\nreview (SLR) of existing work in the field of DEAI, presenting the findings of\n71 identified studies. The paper's primary focus is identifying the building\nblocks of DEAI solutions and networks, tackling the DEAI analysis from a\nbottom-up approach. In the end, future directions of research and open problems\nare proposed.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f44a3268b8c4c9db2378d909c8a46c8a066266a1",
      "published_date": "2024-02-05",
      "downloaded_date": "2025-02-01",
      "filename": "Kersic-A Review on Building Blocks of Decentralized Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.02885v1",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ]
    },
    "2012.08405v3": {
      "title": "Model-Based Deep Learning",
      "authors": [
        "Nir Shlezinger",
        "Jay Whang",
        "Yonina C. Eldar",
        "Alexandros G. Dimakis"
      ],
      "abstract": "Signal processing, communications, and control have traditionally relied on\nclassical statistical modeling techniques. Such model-based methods utilize\nmathematical formulations that represent the underlying physics, prior\ninformation and additional domain knowledge. Simple classical models are useful\nbut sensitive to inaccuracies and may lead to poor performance when real\nsystems display complex or dynamic behavior. On the other hand, purely\ndata-driven approaches that are model-agnostic are becoming increasingly\npopular as datasets become abundant and the power of modern deep learning\npipelines increases. Deep neural networks (DNNs) use generic architectures\nwhich learn to operate from data, and demonstrate excellent performance,\nespecially for supervised problems. However, DNNs typically require massive\namounts of data and immense computational resources, limiting their\napplicability for some signal processing scenarios. We are interested in hybrid\ntechniques that combine principled mathematical models with data-driven systems\nto benefit from the advantages of both approaches. Such model-based deep\nlearning methods exploit both partial domain knowledge, via mathematical\nstructures designed for specific problems, as well as learning from limited\ndata. In this article we survey the leading approaches for studying and\ndesigning model-based deep learning systems. We divide hybrid\nmodel-based/data-driven systems into categories based on their inference\nmechanism. We provide a comprehensive review of the leading approaches for\ncombining model-based algorithms with deep learning in a systematic manner,\nalong with concrete guidelines and detailed signal processing oriented examples\nfrom recent literature. Our aim is to facilitate the design and study of future\nsystems on the intersection of signal processing and machine learning that\nincorporate the advantages of both domains.",
      "citation_count": 925,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d8a486a5c681ea3a6f014f3b560803adfe9a0609",
      "published_date": "2020-12-15",
      "downloaded_date": "2025-02-01",
      "filename": "Shlezinger-Model-Based Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.08405v3",
      "categories": [
        "eess.SP",
        "cs.LG"
      ]
    },
    "2305.13019v1": {
      "title": "Robots in the Garden: Artificial Intelligence and Adaptive Landscapes",
      "authors": [
        "Zihao Zhang",
        "Susan L. Epstein",
        "Casey Breen",
        "Sophia Xia",
        "Zhigang Zhu",
        "Christian Volkmann"
      ],
      "abstract": "This paper introduces ELUA, the Ecological Laboratory for Urban Agriculture,\na collaboration among landscape architects, architects and computer scientists\nwho specialize in artificial intelligence, robotics and computer vision. ELUA\nhas two gantry robots, one indoors and the other outside on the rooftop of a\n6-story campus building. Each robot can seed, water, weed, and prune in its\ngarden. To support responsive landscape research, ELUA also includes sensor\narrays, an AI-powered camera, and an extensive network infrastructure. This\nproject demonstrates a way to integrate artificial intelligence into an\nevolving urban ecosystem, and encourages landscape architects to develop an\nadaptive design framework where design becomes a long-term engagement with the\nenvironment.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9988d46558dd24fa802d33f7b503ca8ee0f1a0e0",
      "published_date": "2023-05-22",
      "downloaded_date": "2025-02-01",
      "filename": "Zhang-Robots in the Garden Artificial Intelligence and Adaptive Landscapes.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.13019v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ]
    },
    "2408.01904v1": {
      "title": "The Artificial Intelligence Disclosure (AID) Framework: An Introduction",
      "authors": [
        "Kari D. Weaver"
      ],
      "abstract": "As the use of Generative Artificial Intelligence tools have grown in higher\neducation and research, there have been increasing calls for transparency and\ngranularity around the use and attribution of the use of these tools. Thus far,\nthis need has been met via the recommended inclusion of a note, with little to\nno guidance on what the note itself should include. This has been identified as\na problem to the use of AI in academic and research contexts. This article\nintroduces The Artificial Intelligence Disclosure (AID) Framework, a standard,\ncomprehensive, and detailed framework meant to inform the development and\nwriting of GenAI disclosure for education and research.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/77132f45ca5de9d5577d1fa24104f338985b1b91",
      "published_date": "2024-08-04",
      "downloaded_date": "2025-02-01",
      "filename": "Weaver-The Artificial Intelligence Disclosure AID Framework An Introduction.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.01904v1",
      "categories": [
        "cs.DL",
        "cs.AI"
      ]
    },
    "2008.08041v2": {
      "title": "Deep Learning Based on Generative Adversarial and Convolutional Neural Networks for Financial Time Series Predictions",
      "authors": [
        "Wilfredo Tovar"
      ],
      "abstract": "In the big data era, deep learning and intelligent data mining technique\nsolutions have been applied by researchers in various areas. Forecast and\nanalysis of stock market data have represented an essential role in today's\neconomy, and a significant challenge to the specialist since the market's\ntendencies are immensely complex, chaotic and are developed within a highly\ndynamic environment. There are numerous researches from multiple areas\nintending to take on that challenge, and Machine Learning approaches have been\nthe focus of many of them. There are multiple models of Machine Learning\nalgorithms been able to obtain competent outcomes doing that class of\nforesight. This paper proposes the implementation of a generative adversarial\nnetwork (GAN), which is composed by a bi-directional Long short-term memory\n(LSTM) and convolutional neural network(CNN) referred as Bi-LSTM-CNN to\ngenerate synthetic data that agree with existing real financial data so the\nfeatures of stocks with positive or negative trends can be retained to predict\nfuture trends of a stock. The novelty of this proposed solution that distinct\nfrom previous solutions is that this paper introduced the concept of a hybrid\nsystem (Bi-LSTM-CNN) rather than a sole LSTM model. It was collected data from\nmultiple stock markets such as TSX, SHCOMP, KOSPI 200 and the S&P 500,\nproposing an adaptative-hybrid system for trends prediction on stock market\nprices, and carried a comprehensive evaluation on several commonly utilized\nmachine learning prototypes, and it is concluded that the proposed solution\napproach outperforms preceding models. Additionally, during the research stage\nfrom preceding works, gaps were found between investors and researchers who\ndedicated to the technical domain.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/60a2bbd49d8d1bb8c6c8acb8798eecdc2238a4ef",
      "published_date": "2020-08-08",
      "downloaded_date": "2025-02-01",
      "filename": "Tovar-Deep Learning Based on Generative Adversarial and Convolutional Neural Networks for Financial Time S....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.08041v2",
      "categories": [
        "eess.SP",
        "cs.LG"
      ]
    },
    "1911.00504v1": {
      "title": "Cancer Detection Using Quantum Neural Networks: A Demonstration on a Quantum Computer",
      "authors": [
        "Nilima Mishra",
        "Aradh Bisarya",
        "Shubham Kumar",
        "Bikash K. Behera",
        "Sabyasachi Mukhopadhyay",
        "Prasanta K. Panigrahi"
      ],
      "abstract": "Artificial intelligence and machine learning paves the way to achieve greater\ntechnical feats. In this endeavor to hone these techniques, quantum machine\nlearning is budding to serve as an important tool. Using the techniques of deep\nlearning and supervised learning in the quantum framework, we are able to\npropose a quantum neural network and showcase its implementation. We consider\nthe application of cancer detection to demonstrate the working of our quantum\nneural network. Our focus is to train the network of ten qubits in a way so\nthat it can learn the label of the given data set and optimize the circuit\nparameters to obtain the minimum error. Thus, through the use of many\nalgorithms, we are able to give an idea of how a quantum neural network can\nfunction.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/be83a775e5e89cb2897709a8e08e8ea8ee9d4788",
      "published_date": "2019-11-01",
      "downloaded_date": "2025-02-01",
      "filename": "Mishra-Cancer Detection Using Quantum Neural Networks A Demonstration on a Quantum Computer.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.00504v1",
      "categories": [
        "quant-ph"
      ]
    },
    "1712.00244v1": {
      "title": "Deep Learning for Metagenomic Data: using 2D Embeddings and Convolutional Neural Networks",
      "authors": [
        "Thanh Hai Nguyen",
        "Yann Chevaleyre",
        "Edi Prifti",
        "Nataliya Sokolovska",
        "Jean-Daniel Zucker"
      ],
      "abstract": "Deep learning (DL) techniques have had unprecedented success when applied to\nimages, waveforms, and texts to cite a few. In general, when the sample size\n(N) is much greater than the number of features (d), DL outperforms previous\nmachine learning (ML) techniques, often through the use of convolution neural\nnetworks (CNNs). However, in many bioinformatics ML tasks, we encounter the\nopposite situation where d is greater than N. In these situations, applying DL\ntechniques (such as feed-forward networks) would lead to severe overfitting.\nThus, sparse ML techniques (such as LASSO e.g.) usually yield the best results\non these tasks. In this paper, we show how to apply CNNs on data which do not\nhave originally an image structure (in particular on metagenomic data). Our\nfirst contribution is to show how to map metagenomic data in a meaningful way\nto 1D or 2D images. Based on this representation, we then apply a CNN, with the\naim of predicting various diseases. The proposed approach is applied on six\ndifferent datasets including in total over 1000 samples from various diseases.\nThis approach could be a promising one for prediction tasks in the\nbioinformatics field.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-12-01",
      "downloaded_date": "2025-02-01",
      "filename": "Nguyen-Deep Learning for Metagenomic Data using 2D Embeddings and Convolutional Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1712.00244v1",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    "1806.05796v2": {
      "title": "Deep Learning with Convolutional Neural Network for Objective Skill Evaluation in Robot-assisted Surgery",
      "authors": [
        "Ziheng Wang",
        "Ann Majewicz Fey"
      ],
      "abstract": "With the advent of robot-assisted surgery, the role of data-driven approaches\nto integrate statistics and machine learning is growing rapidly with prominent\ninterests in objective surgical skill assessment. However, most existing work\nrequires translating robot motion kinematics into intermediate features or\ngesture segments that are expensive to extract, lack efficiency, and require\nsignificant domain-specific knowledge. We propose an analytical deep learning\nframework for skill assessment in surgical training. A deep convolutional\nneural network is implemented to map multivariate time series data of the\nmotion kinematics to individual skill levels. We perform experiments on the\npublic minimally invasive surgical robotic dataset, JHU-ISI Gesture and Skill\nAssessment Working Set (JIGSAWS). Our proposed learning model achieved a\ncompetitive accuracy of 92.5%, 95.4%, and 91.3%, in the standard training\ntasks: Suturing, Needle-passing, and Knot-tying, respectively. Without the need\nof engineered features or carefully-tuned gesture segmentation, our model can\nsuccessfully decode skill information from raw motion profiles via end-to-end\nlearning. Meanwhile, the proposed model is able to reliably interpret skills\nwithin 1-3 second window, without needing an observation of entire training\ntrial. This study highlights the potentials of deep architectures for an\nproficient online skill assessment in modern surgical training.",
      "citation_count": 207,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/91fed290d898235d4121627e4f4e2c92134b694c",
      "published_date": "2018-06-15",
      "downloaded_date": "2025-02-01",
      "filename": "Wang-Deep Learning with Convolutional Neural Network for Objective Skill Evaluation in Robot-assisted Sur....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1806.05796v2",
      "categories": [
        "cs.CV",
        "cs.RO"
      ]
    },
    "2202.11727v1": {
      "title": "Completely Quantum Neural Networks",
      "authors": [
        "Steve Abel",
        "Juan C. Criado",
        "Michael Spannowsky"
      ],
      "abstract": "Artificial neural networks are at the heart of modern deep learning\nalgorithms. We describe how to embed and train a general neural network in a\nquantum annealer without introducing any classical element in training. To\nimplement the network on a state-of-the-art quantum annealer, we develop three\ncrucial ingredients: binary encoding the free parameters of the network,\npolynomial approximation of the activation function, and reduction of binary\nhigher-order polynomials into quadratic ones. Together, these ideas allow\nencoding the loss function as an Ising model Hamiltonian. The quantum annealer\nthen trains the network by finding the ground state. We implement this for an\nelementary network and illustrate the advantages of quantum training: its\nconsistency in finding the global minimum of the loss function and the fact\nthat the network training converges in a single annealing step, which leads to\nshort training times while maintaining a high classification performance. Our\napproach opens a novel avenue for the quantum training of general machine\nlearning models.",
      "citation_count": 20,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/71a542ceb4ff151eae51f940f698d0843193431d",
      "published_date": "2022-02-23",
      "downloaded_date": "2025-02-01",
      "filename": "Abel-Completely Quantum Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.11727v1",
      "categories": [
        "quant-ph",
        "cs.LG",
        "hep-ph",
        "hep-th"
      ]
    },
    "2010.05990v2": {
      "title": "Chatbot Interaction with Artificial Intelligence: Human Data Augmentation with T5 and Language Transformer Ensemble for Text Classification",
      "authors": [
        "Jordan J. Bird",
        "AnikÃ³ EkÃ¡rt",
        "Diego R. Faria"
      ],
      "abstract": "In this work, we present the Chatbot Interaction with Artificial Intelligence\n(CI-AI) framework as an approach to the training of deep learning chatbots for\ntask classification. The intelligent system augments human-sourced data via\nartificial paraphrasing in order to generate a large set of training data for\nfurther classical, attention, and language transformation-based learning\napproaches for Natural Language Processing. Human beings are asked to\nparaphrase commands and questions for task identification for further execution\nof a machine. The commands and questions are split into training and validation\nsets. A total of 483 responses were recorded. Secondly, the training set is\nparaphrased by the T5 model in order to augment it with further data. Seven\nstate-of-the-art transformer-based text classification algorithms (BERT,\nDistilBERT, RoBERTa, DistilRoBERTa, XLM, XLM-RoBERTa, and XLNet) are\nbenchmarked for both sets after fine-tuning on the training data for two\nepochs. We find that all models are improved when training data is augmented by\nthe T5 model, with an average increase of classification accuracy by 4.01%. The\nbest result was the RoBERTa model trained on T5 augmented data which achieved\n98.96% classification accuracy. Finally, we found that an ensemble of the five\nbest-performing transformer models via Logistic Regression of output label\npredictions led to an accuracy of 99.59% on the dataset of human responses. A\nhighly-performing model allows the intelligent system to interpret human\ncommands at the social-interaction level through a chatbot-like interface (e.g.\n\"Robot, can we have a conversation?\") and allows for better accessibility to AI\nby non-technical users.",
      "citation_count": 49,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8fd7c10e8c9115a72a2c8e6494d4693c6501fa0e",
      "published_date": "2020-10-12",
      "downloaded_date": "2025-02-01",
      "filename": "Bird-Chatbot Interaction with Artificial Intelligence Human Data Augmentation with T5 and Language Transf....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2010.05990v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    "2309.06938v2": {
      "title": "Collectionless Artificial Intelligence",
      "authors": [
        "Marco Gori",
        "Stefano Melacci"
      ],
      "abstract": "By and large, the professional handling of huge data collections is regarded\nas a fundamental ingredient of the progress of machine learning and of its\nspectacular results in related disciplines, with a growing agreement on risks\nconnected to the centralization of such data collections. This paper sustains\nthe position that the time has come for thinking of new learning protocols\nwhere machines conquer cognitive skills in a truly human-like context centered\non environmental interactions. This comes with specific restrictions on the\nlearning protocol according to the collectionless principle, which states that,\nat each time instant, data acquired from the environment is processed with the\npurpose of contributing to update the current internal representation of the\nenvironment, and that the agent is not given the privilege of recording the\ntemporal stream. Basically, there is neither permission to store the temporal\ninformation coming from the sensors, thus promoting the development of\nself-organized memorization skills at a more abstract level, instead of relying\non bare storage to simulate learning dynamics that are typical of offline\nlearning algorithms. This purposely extreme position is intended to stimulate\nthe development of machines that learn to dynamically organize the information\nby following human-based schemes. The proposition of this challenge suggests\ndeveloping new foundations on computational processes of learning and reasoning\nthat might open the doors to a truly orthogonal competitive track on AI\ntechnologies that avoid data accumulation by design, thus offering a framework\nwhich is better suited concerning privacy issues, control and customizability.\nFinally, pushing towards massively distributed computation, the collectionless\napproach to AI will likely reduce the concentration of power in companies and\ngovernments, thus better facing geopolitical issues.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a233cfdafa9742db8decca831060b19351bddfa7",
      "published_date": "2023-09-13",
      "downloaded_date": "2025-02-01",
      "filename": "Gori-Collectionless Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.06938v2",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    "2304.05065v1": {
      "title": "Artificial intelligence based prediction on lung cancer risk factors using deep learning",
      "authors": [
        "Muhammad Sohaib",
        "Mary Adewunmi"
      ],
      "abstract": "In this proposed work, we identified the significant research issues on lung\ncancer risk factors. Capturing and defining symptoms at an early stage is one\nof the most difficult phases for patients. Based on the history of patients\nrecords, we reviewed a number of current research studies on lung cancer and\nits various stages. We identified that lung cancer is one of the significant\nresearch issues in predicting the early stages of cancer disease. This research\naimed to develop a model that can detect lung cancer with a remarkably high\nlevel of accuracy using the deep learning approach (convolution neural\nnetwork). This method considers and resolves significant gaps in previous\nstudies. We compare the accuracy levels and loss values of our model with\nVGG16, InceptionV3, and Resnet50. We found that our model achieved an accuracy\nof 94% and a minimum loss of 0.1%. Hence physicians can use our convolution\nneural network models for predicting lung cancer risk factors in the real\nworld. Moreover, this investigation reveals that squamous cell carcinoma,\nnormal, adenocarcinoma, and large cell carcinoma are the most significant risk\nfactors. In addition, the remaining attributes are also crucial for achieving\nthe best performance.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/04a3a1ee6ec456ce9aa04090a7a9c3aa2a26587b",
      "published_date": "2023-04-11",
      "downloaded_date": "2025-02-01",
      "filename": "Sohaib-Artificial intelligence based prediction on lung cancer risk factors using deep learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.05065v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.SC"
      ]
    },
    "1712.01626v1": {
      "title": "Autonomous development and learning in artificial intelligence and robotics: Scaling up deep learning to human--like learning",
      "authors": [
        "Pierre-Yves Oudeyer"
      ],
      "abstract": "Autonomous lifelong development and learning is a fundamental capability of\nhumans, differentiating them from current deep learning systems. However, other\nbranches of artificial intelligence have designed crucial ingredients towards\nautonomous learning: curiosity and intrinsic motivation, social learning and\nnatural interaction with peers, and embodiment. These mechanisms guide\nexploration and autonomous choice of goals, and integrating them with deep\nlearning opens stimulating perspectives. Deep learning (DL) approaches made\ngreat advances in artificial intelligence, but are still far away from human\nlearning. As argued convincingly by Lake et al., differences include human\ncapabilities to learn causal models of the world from very little data,\nleveraging compositional representations and priors like intuitive physics and\npsychology. However, there are other fundamental differences between current DL\nsystems and human learning, as well as technical ingredients to fill this gap,\nthat are either superficially, or not adequately, discussed by Lake et al.\nThese fundamental mechanisms relate to autonomous development and learning.\nThey are bound to play a central role in artificial intelligence in the future.\nCurrent DL systems require engineers to manually specify a task-specific\nobjective function for every new task, and learn through off-line processing of\nlarge training databases. On the contrary, humans learn autonomously open-ended\nrepertoires of skills, deciding for themselves which goals to pursue or value,\nand which skills to explore, driven by intrinsic motivation/curiosity and\nsocial learning through natural interaction with peers. Such learning processes\nare incremental, online, and progressive. Human child development involves a\nprogressive increase of complexity in a curriculum of learning where skills are\nexplored, acquired, and built on each other, through particular ordering and\ntiming. Finally, human learning happens in the physical world, and through\nbodily and physical experimentation, under severe constraints on energy, time,\nand computational resources. In the two last decades, the field of\nDevelopmental and Cognitive Robotics (Cangelosi and Schlesinger, 2015, Asada et\nal., 2009), in strong interaction with developmental psychology and\nneuroscience, has achieved significant advances in computational",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-12-05",
      "downloaded_date": "2025-02-01",
      "filename": "Oudeyer-Autonomous development and learning in artificial intelligence and robotics Scaling up deep learning....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1712.01626v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "q-bio.NC"
      ]
    },
    "1701.04503v1": {
      "title": "Deep Learning for Computational Chemistry",
      "authors": [
        "Garrett B. Goh",
        "Nathan O. Hodas",
        "Abhinav Vishnu"
      ],
      "abstract": "The rise and fall of artificial neural networks is well documented in the\nscientific literature of both computer science and computational chemistry. Yet\nalmost two decades later, we are now seeing a resurgence of interest in deep\nlearning, a machine learning algorithm based on multilayer neural networks.\nWithin the last few years, we have seen the transformative impact of deep\nlearning in many domains, particularly in speech recognition and computer\nvision, to the extent that the majority of expert practitioners in those field\nare now regularly eschewing prior established models in favor of deep learning\nmodels. In this review, we provide an introductory overview into the theory of\ndeep neural networks and their unique properties that distinguish them from\ntraditional machine learning algorithms used in cheminformatics. By providing\nan overview of the variety of emerging applications of deep neural networks, we\nhighlight its ubiquity and broad applicability to a wide range of challenges in\nthe field, including QSAR, virtual screening, protein structure prediction,\nquantum chemistry, materials design and property prediction. In reviewing the\nperformance of deep neural networks, we observed a consistent outperformance\nagainst non-neural networks state-of-the-art models across disparate research\ntopics, and deep neural network based models often exceeded the \"glass ceiling\"\nexpectations of their respective tasks. Coupled with the maturity of\nGPU-accelerated computing for training deep neural networks and the exponential\ngrowth of chemical data on which to train these networks on, we anticipate that\ndeep learning algorithms will be a valuable tool for computational chemistry.",
      "citation_count": 648,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/40552a2dcac643ed57fa7e5448448ba24ba2e09f",
      "published_date": "2017-01-17",
      "downloaded_date": "2025-02-01",
      "filename": "Goh-Deep Learning for Computational Chemistry.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1701.04503v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "physics.chem-ph"
      ]
    },
    "1602.03506v1": {
      "title": "Research Priorities for Robust and Beneficial Artificial Intelligence",
      "authors": [
        "Stuart Russell",
        "Daniel Dewey",
        "Max Tegmark"
      ],
      "abstract": "Success in the quest for artificial intelligence has the potential to bring\nunprecedented benefits to humanity, and it is therefore worthwhile to\ninvestigate how to maximize these benefits while avoiding potential pitfalls.\nThis article gives numerous examples (which should by no means be construed as\nan exhaustive list) of such worthwhile research aimed at ensuring that AI\nremains robust and beneficial.",
      "citation_count": 624,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4029b344fc0c9f35f41bfe35c443111faba27230",
      "published_date": "2016-02-10",
      "downloaded_date": "2025-02-01",
      "filename": "Russell-Research Priorities for Robust and Beneficial Artificial Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1602.03506v1",
      "categories": [
        "cs.AI",
        "stat.ML"
      ]
    },
    "1810.07007v1": {
      "title": "Tentacular Artificial Intelligence, and the Architecture Thereof, Introduced",
      "authors": [
        "Selmer Bringsjord",
        "Naveen Sundar Govindarajulu",
        "Atriya Sen",
        "Matthew Peveler",
        "Biplav Srivastava",
        "Kartik Talamadupula"
      ],
      "abstract": "We briefly introduce herein a new form of distributed, multi-agent artificial\nintelligence, which we refer to as \"tentacular.\" Tentacular AI is distinguished\nby six attributes, which among other things entail a capacity for reasoning and\nplanning based in highly expressive calculi (logics), and which enlists\nsubsidiary agents across distances circumscribed only by the reach of one or\nmore given networks.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4a2d175aedd3c5c2e81ddf9345bc6c8925c0ad2f",
      "published_date": "2018-10-14",
      "downloaded_date": "2025-02-01",
      "filename": "Bringsjord-Tentacular Artificial Intelligence and the Architecture Thereof Introduced.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1810.07007v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2003.00898v2": {
      "title": "The importance of transparency and reproducibility in artificial intelligence research",
      "authors": [
        "Benjamin Haibe-Kains",
        "George Alexandru Adam",
        "Ahmed Hosny",
        "Farnoosh Khodakarami",
        "MAQC Society Board",
        "Levi Waldron",
        "Bo Wang",
        "Chris McIntosh",
        "Anshul Kundaje",
        "Casey S. Greene",
        "Michael M. Hoffman",
        "Jeffrey T. Leek",
        "Wolfgang Huber",
        "Alvis Brazma",
        "Joelle Pineau",
        "Robert Tibshirani",
        "Trevor Hastie",
        "John P. A. Ioannidis",
        "John Quackenbush",
        "Hugo J. W. L. Aerts"
      ],
      "abstract": "In their study, McKinney et al. showed the high potential of artificial\nintelligence for breast cancer screening. However, the lack of detailed methods\nand computer code undermines its scientific value. We identify obstacles\nhindering transparent and reproducible AI research as faced by McKinney et al\nand provide solutions with implications for the broader field.",
      "citation_count": 22,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5ca842f96774552daca729e6107a5ba71757e498",
      "published_date": "2020-02-28",
      "downloaded_date": "2025-02-01",
      "filename": "Haibe-Kains-The importance of transparency and reproducibility in artificial intelligence research.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2003.00898v2",
      "categories": [
        "stat.AP"
      ]
    },
    "2409.13406v1": {
      "title": "Credit Card Fraud Detection: A Deep Learning Approach",
      "authors": [
        "Sourav Verma",
        "Joydip Dhar"
      ],
      "abstract": "Credit card is one of the most extensive methods of instalment for both\nonline and offline mode of payment for electronic transactions in recent times.\ncredit cards invention has provided significant ease in electronic\ntransactions. However, it has also provided new fraud opportunities for\ncriminals, which results in increased fraud rates. Substantial amount of money\nhas been lost by many institutions and individuals due to fraudulent credit\ncard transactions. Adapting improved and dynamic fraud recognition frameworks\nthus became essential for all credit card distributing banks to mitigate their\nlosses. In fact, the problem of fraudulent credit card transactions implicates\na number of relevant real-time challenges, namely: Concept drift, Class\nimbalance, and Verification latency. However, the vast majority of current\nsystems are based on artificial intelligence (AI), Fuzzy logic, Machine\nLearning, Data mining, Genetic Algorithms, and so on, rely on assumptions that\nhardly address all the relevant challenges of fraud-detection system (FDS).\nThis paper aims to understand & implement Deep Learning algorithms in order to\nobtain a high fraud coverage with very low false positive rate. Also, it aims\nto implement an auto-encoder as an unsupervised (semi-supervised) method of\nlearning common patterns. Keywords: Credit card fraud, Fraud-detection system\n(FDS), Electronic transactions, Concept drift, Class imbalance, Verification\nlatency, Machine Learning, Deep Learning",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/971d86d3a792fedc8dc5d2be95d9d580694ffee9",
      "published_date": "2024-09-20",
      "downloaded_date": "2025-02-01",
      "filename": "Verma-Credit Card Fraud Detection A Deep Learning Approach.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.13406v1",
      "categories": [
        "cs.LG"
      ]
    },
    "2012.14092v1": {
      "title": "Model Optimization for Deep Space Exploration via Simulators and Deep Learning",
      "authors": [
        "James Bird",
        "Kellan Colburn",
        "Linda Petzold",
        "Philip Lubin"
      ],
      "abstract": "Machine learning, and eventually true artificial intelligence techniques, are\nextremely important advancements in astrophysics and astronomy. We explore the\napplication of deep learning using neural networks in order to automate the\ndetection of astronomical bodies for future exploration missions, such as\nmissions to search for signatures or suitability of life. The ability to\nacquire images, analyze them, and send back those that are important, as\ndetermined by the deep learning algorithm, is critical in bandwidth-limited\napplications. Our previous foundational work solidified the concept of using\nsimulator images and deep learning in order to detect planets. Optimization of\nthis process is of vital importance, as even a small loss in accuracy might be\nthe difference between capturing and completely missing a possibly-habitable\nnearby planet. Through computer vision, deep learning, and simulators, we\nintroduce methods that optimize the detection of exoplanets. We show that\nmaximum achieved accuracy can hit above 98% for multiple model architectures,\neven with a relatively small training set.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7891125dcb7becf64ab0929eb1f311fc95cfe205",
      "published_date": "2020-12-28",
      "downloaded_date": "2025-02-01",
      "filename": "Bird-Model Optimization for Deep Space Exploration via Simulators and Deep Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.14092v1",
      "categories": [
        "astro-ph.IM",
        "cs.CV"
      ]
    },
    "2411.12643v1": {
      "title": "DLBacktrace: A Model Agnostic Explainability for any Deep Learning Models",
      "authors": [
        "Vinay Kumar Sankarapu",
        "Chintan Chitroda",
        "Yashwardhan Rathore",
        "Neeraj Kumar Singh",
        "Pratinav Seth"
      ],
      "abstract": "The rapid advancement of artificial intelligence has led to increasingly\nsophisticated deep learning models, which frequently operate as opaque 'black\nboxes' with limited transparency in their decision-making processes. This lack\nof interpretability presents considerable challenges, especially in high-stakes\napplications where understanding the rationale behind a model's outputs is as\nessential as the outputs themselves. This study addresses the pressing need for\ninterpretability in AI systems, emphasizing its role in fostering trust,\nensuring accountability, and promoting responsible deployment in\nmission-critical fields. To address the interpretability challenge in deep\nlearning, we introduce DLBacktrace, an innovative technique developed by the\nAryaXAI team to illuminate model decisions across a wide array of domains,\nincluding simple Multi Layer Perceptron (MLPs), Convolutional Neural Networks\n(CNNs), Large Language Models (LLMs), Computer Vision Models, and more.\n  We provide a comprehensive overview of the DLBacktrace algorithm and present\nbenchmarking results, comparing its performance against established\ninterpretability methods, such as SHAP, LIME, GradCAM, Integrated Gradients,\nSmoothGrad, and Attention Rollout, using diverse task-based metrics. The\nproposed DLBacktrace technique is compatible with various model architectures\nbuilt in PyTorch and TensorFlow, supporting models like Llama 3.2, other NLP\narchitectures such as BERT and LSTMs, computer vision models like ResNet and\nU-Net, as well as custom deep neural network (DNN) models for tabular data.\nThis flexibility underscores DLBacktrace's adaptability and effectiveness in\nenhancing model transparency across a broad spectrum of applications. The\nlibrary is open-sourced and available at https://github.com/AryaXAI/DLBacktrace .",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e9bc1f8a3090ae29ce689a0161d69dbf2e9587c7",
      "published_date": "2024-11-19",
      "downloaded_date": "2025-02-01",
      "filename": "Sankarapu-DLBacktrace A Model Agnostic Explainability for any Deep Learning Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.12643v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    "1804.08711v2": {
      "title": "All-Optical Machine Learning Using Diffractive Deep Neural Networks",
      "authors": [
        "Xing Lin",
        "Yair Rivenson",
        "Nezih T. Yardimci",
        "Muhammed Veli",
        "Mona Jarrahi",
        "Aydogan Ozcan"
      ],
      "abstract": "We introduce an all-optical Diffractive Deep Neural Network (D2NN)\narchitecture that can learn to implement various functions after deep\nlearning-based design of passive diffractive layers that work collectively. We\nexperimentally demonstrated the success of this framework by creating\n3D-printed D2NNs that learned to implement handwritten digit classification and\nthe function of an imaging lens at terahertz spectrum. With the existing\nplethora of 3D-printing and other lithographic fabrication methods as well as\nspatial-light-modulators, this all-optical deep learning framework can perform,\nat the speed of light, various complex functions that computer-based neural\nnetworks can implement, and will find applications in all-optical image\nanalysis, feature detection and object classification, also enabling new camera\ndesigns and optical components that can learn to perform unique tasks using\nD2NNs.",
      "citation_count": 1496,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5c7e5248d9eb7f373f10277410bf8506160907ea",
      "published_date": "2018-04-14",
      "downloaded_date": "2025-02-01",
      "filename": "Lin-All-Optical Machine Learning Using Diffractive Deep Neural Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1804.08711v2",
      "categories": [
        "cs.NE",
        "cs.LG",
        "physics.comp-ph",
        "physics.optics"
      ]
    },
    "2407.08974v2": {
      "title": "Topology-enhanced machine learning model (Top-ML) for anticancer peptide prediction",
      "authors": [
        "Joshua Zhi En Tan",
        "JunJie Wee",
        "Xue Gong",
        "Kelin Xia"
      ],
      "abstract": "Recently, therapeutic peptides have demonstrated great promise for cancer\ntreatment. To explore powerful anticancer peptides, artificial intelligence\n(AI)-based approaches have been developed to systematically screen potential\ncandidates. However, the lack of efficient featurization of peptides has become\na bottleneck for these machine-learning models. In this paper, we propose a\ntopology-enhanced machine learning model (Top-ML) for anticancer peptides\nprediction. Our Top-ML employs peptide topological features derived from its\nsequence \"connection\" information characterized by vector and spectral\ndescriptors. Our Top-ML model, employing an Extra-Trees classifier, has been\nvalidated on the AntiCP 2.0 and mACPpred 2.0 benchmark datasets, achieving\nstate-of-the-art performance or results comparable to existing deep learning\nmodels, while providing greater interpretability. Our results highlight the\npotential of leveraging novel topology-based featurization to accelerate the\nidentification of anticancer peptides.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4dabe364f6c61d1f61d88da99eea979a0ca34d6c",
      "published_date": "2024-07-12",
      "downloaded_date": "2025-02-01",
      "filename": "Tan-Topology-enhanced machine learning model Top-ML for anticancer peptide prediction.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.08974v2",
      "categories": [
        "q-bio.QM",
        "cs.LG",
        "math.GN",
        "q-bio.BM",
        "62P10, 92C40, 68T07, 55U10",
        "J.3; I.2.6"
      ]
    },
    "1912.09789v1": {
      "title": "A Survey on Distributed Machine Learning",
      "authors": [
        "Joost Verbraeken",
        "Matthijs Wolting",
        "Jonathan Katzy",
        "Jeroen Kloppenburg",
        "Tim Verbelen",
        "Jan S. Rellermeyer"
      ],
      "abstract": "The demand for artificial intelligence has grown significantly over the last\ndecade and this growth has been fueled by advances in machine learning\ntechniques and the ability to leverage hardware acceleration. However, in order\nto increase the quality of predictions and render machine learning solutions\nfeasible for more complex applications, a substantial amount of training data\nis required. Although small machine learning models can be trained with modest\namounts of data, the input for training larger models such as neural networks\ngrows exponentially with the number of parameters. Since the demand for\nprocessing training data has outpaced the increase in computation power of\ncomputing machinery, there is a need for distributing the machine learning\nworkload across multiple machines, and turning the centralized into a\ndistributed system. These distributed systems present new challenges, first and\nforemost the efficient parallelization of the training process and the creation\nof a coherent model. This article provides an extensive overview of the current\nstate-of-the-art in the field by outlining the challenges and opportunities of\ndistributed machine learning over conventional (centralized) machine learning,\ndiscussing the techniques used for distributed machine learning, and providing\nan overview of the systems that are available.",
      "citation_count": 623,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f9a855ae59579d16dca6a5133cd8daddd3305582",
      "published_date": "2019-12-20",
      "downloaded_date": "2025-02-01",
      "filename": "Verbraeken-A Survey on Distributed Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1912.09789v1",
      "categories": [
        "cs.LG",
        "cs.DC",
        "stat.ML"
      ]
    },
    "2407.03183v1": {
      "title": "A Formal Model for Artificial Intelligence Applications in Automation Systems",
      "authors": [
        "Marvin Schieseck",
        "Philip Topalis",
        "Lasse Reinpold",
        "Felix Gehlhoff",
        "Alexander Fay"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) into automation systems has\nthe potential to enhance efficiency and to address currently unsolved existing\ntechnical challenges. However, the industry-wide adoption of AI is hindered by\nthe lack of standardized documentation for the complex compositions of\nautomation systems, AI software, production hardware, and their\ninterdependencies. This paper proposes a formal model using standards and\nontologies to provide clear and structured documentation of AI applications in\nautomation systems. The proposed information model for artificial intelligence\nin automation systems (AIAS) utilizes ontology design patterns to map and link\nvarious aspects of automation systems and AI software. Validated through a\npractical example, the model demonstrates its effectiveness in improving\ndocumentation practices and aiding the sustainable implementation of AI in\nindustrial settings.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/720a4eeb38745b20dac6049219e8b53691e1d283",
      "published_date": "2024-07-03",
      "downloaded_date": "2025-02-01",
      "filename": "Schieseck-A Formal Model for Artificial Intelligence Applications in Automation Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.03183v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ]
    },
    "2309.11932v2": {
      "title": "A Machine Learning-oriented Survey on Tiny Machine Learning",
      "authors": [
        "Luigi Capogrosso",
        "Federico Cunico",
        "Dong Seon Cheng",
        "Franco Fummi",
        "Marco Cristani"
      ],
      "abstract": "The emergence of Tiny Machine Learning (TinyML) has positively revolutionized\nthe field of Artificial Intelligence by promoting the joint design of\nresource-constrained IoT hardware devices and their learning-based software\narchitectures. TinyML carries an essential role within the fourth and fifth\nindustrial revolutions in helping societies, economies, and individuals employ\neffective AI-infused computing technologies (e.g., smart cities, automotive,\nand medical robotics). Given its multidisciplinary nature, the field of TinyML\nhas been approached from many different angles: this comprehensive survey\nwishes to provide an up-to-date overview focused on all the learning algorithms\nwithin TinyML-based solutions. The survey is based on the Preferred Reporting\nItems for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow,\nallowing for a systematic and complete literature survey. In particular,\nfirstly we will examine the three different workflows for implementing a\nTinyML-based system, i.e., ML-oriented, HW-oriented, and co-design. Secondly,\nwe propose a taxonomy that covers the learning panorama under the TinyML lens,\nexamining in detail the different families of model optimization and design, as\nwell as the state-of-the-art learning techniques. Thirdly, this survey will\npresent the distinct features of hardware devices and software tools that\nrepresent the current state-of-the-art for TinyML intelligent edge\napplications. Finally, we discuss the challenges and future directions.",
      "citation_count": 23,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8e5c3d76a9d160e87765727f5c817aea151ed900",
      "published_date": "2023-09-21",
      "downloaded_date": "2025-02-02",
      "filename": "Capogrosso-A Machine Learning-oriented Survey on Tiny Machine Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.11932v2",
      "categories": [
        "cs.LG"
      ]
    },
    "2405.02336v1": {
      "title": "Artificial General Intelligence (AGI)-Native Wireless Systems: A Journey Beyond 6G",
      "authors": [
        "Walid Saad",
        "Omar Hashash",
        "Christo Kurisummoottil Thomas",
        "Christina Chaccour",
        "Merouane Debbah",
        "Narayan Mandayam",
        "Zhu Han"
      ],
      "abstract": "Building future wireless systems that support services like digital twins\n(DTs) is challenging to achieve through advances to conventional technologies\nlike meta-surfaces. While artificial intelligence (AI)-native networks promise\nto overcome some limitations of wireless technologies, developments still rely\non AI tools like neural networks. Such tools struggle to cope with the\nnon-trivial challenges of the network environment and the growing demands of\nemerging use cases. In this paper, we revisit the concept of AI-native wireless\nsystems, equipping them with the common sense necessary to transform them into\nartificial general intelligence (AGI)-native systems. These systems acquire\ncommon sense by exploiting different cognitive abilities such as perception,\nanalogy, and reasoning, that enable them to generalize and deal with unforeseen\nscenarios. Towards developing the components of such a system, we start by\nshowing how the perception module can be built through abstracting real-world\nelements into generalizable representations. These representations are then\nused to create a world model, founded on principles of causality and\nhyper-dimensional (HD) computing, that aligns with intuitive physics and\nenables analogical reasoning, that define common sense. Then, we explain how\nmethods such as integrated information theory play a role in the proposed\nintent-driven and objective-driven planning methods that maneuver the\nAGI-native network to take actions. Next, we discuss how an AGI-native network\ncan enable use cases related to human and autonomous agents: a) analogical\nreasoning for next-generation DTs, b) synchronized and resilient experiences\nfor cognitive avatars, and c) brain-level metaverse experiences like\nholographic teleportation. Finally, we conclude with a set of recommendations\nto build AGI-native systems. Ultimately, we envision this paper as a roadmap\nfor the beyond 6G era.",
      "citation_count": 13,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b893044d157c2516f5b39e449be2af991b61813b",
      "published_date": "2024-04-29",
      "downloaded_date": "2025-02-02",
      "filename": "Saad-Artificial General Intelligence AGI-Native Wireless Systems A Journey Beyond 6G.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.02336v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ]
    },
    "2304.12479v5": {
      "title": "AGI: Artificial General Intelligence for Education",
      "authors": [
        "Ehsan Latif",
        "Gengchen Mai",
        "Matthew Nyaaba",
        "Xuansheng Wu",
        "Ninghao Liu",
        "Guoyu Lu",
        "Sheng Li",
        "Tianming Liu",
        "Xiaoming Zhai"
      ],
      "abstract": "Artificial general intelligence (AGI) has gained global recognition as a\nfuture technology due to the emergence of breakthrough large language models\nand chatbots such as GPT-4 and ChatGPT, respectively. Compared to conventional\nAI models, typically designed for a limited range of tasks, demand significant\namounts of domain-specific data for training and may not always consider\nintricate interpersonal dynamics in education. AGI, driven by the recent large\npre-trained models, represents a significant leap in the capability of machines\nto perform tasks that require human-level intelligence, such as reasoning,\nproblem-solving, decision-making, and even understanding human emotions and\nsocial interactions. This position paper reviews AGI's key concepts,\ncapabilities, scope, and potential within future education, including achieving\nfuture educational goals, designing pedagogy and curriculum, and performing\nassessments. It highlights that AGI can significantly improve intelligent\ntutoring systems, educational assessment, and evaluation procedures. AGI\nsystems can adapt to individual student needs, offering tailored learning\nexperiences. They can also provide comprehensive feedback on student\nperformance and dynamically adjust teaching methods based on student progress.\nThe paper emphasizes that AGI's capabilities extend to understanding human\nemotions and social interactions, which are critical in educational settings.\nThe paper discusses that ethical issues in education with AGI include data\nbias, fairness, and privacy and emphasizes the need for codes of conduct to\nensure responsible AGI use in academic settings like homework, teaching, and\nrecruitment. We also conclude that the development of AGI necessitates\ninterdisciplinary collaborations between educators and AI engineers to advance\nresearch and application efforts.",
      "citation_count": 18,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7dd463b2fef845f3cbd39db36a8fbeec7109956d",
      "published_date": "2023-04-24",
      "downloaded_date": "2025-02-02",
      "filename": "Latif-AGI Artificial General Intelligence for Education.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.12479v5",
      "categories": [
        "cs.AI"
      ]
    },
    "2205.10513v7": {
      "title": "Computable Artificial General Intelligence",
      "authors": [
        "Michael Timothy Bennett"
      ],
      "abstract": "Artificial general intelligence (AGI) may herald our extinction, according to\nAI safety research. Yet claims regarding AGI must rely upon mathematical\nformalisms -- theoretical agents we may analyse or attempt to build. AIXI\nappears to be the only such formalism supported by proof that its behaviour is\noptimal, a consequence of its use of compression as a proxy for intelligence.\nUnfortunately, AIXI is incomputable and claims regarding its behaviour highly\nsubjective. We argue that this is because AIXI formalises cognition as taking\nplace in isolation from the environment in which goals are pursued (Cartesian\ndualism). We propose an alternative, supported by proof and experiment, which\novercomes these problems. Integrating research from cognitive science with AI,\nwe formalise an enactive model of learning and reasoning to address the problem\nof subjectivity. This allows us to formulate a different proxy for\nintelligence, called weakness, which addresses the problem of incomputability.\nWe prove optimal behaviour is attained when weakness is maximised. This proof\nis supplemented by experimental results comparing weakness and description\nlength (the closest analogue to compression possible without reintroducing\nsubjectivity). Weakness outperforms description length, suggesting it is a\nbetter proxy. Furthermore we show that, if cognition is enactive, then\nminimisation of description length is neither necessary nor sufficient to\nattain optimal performance, undermining the notion that compression is closely\nrelated to intelligence. However, there remain open questions regarding the\nimplementation of scale-able AGI. In the short term, these results may be best\nutilised to improve the performance of existing systems. For example, our\nresults explain why Deepmind's Apperception Engine is able to generalise\neffectively, and how to replicate that performance by maximising weakness.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c9c6b228e042d8e8183b162c9487ab8029c71f4b",
      "published_date": "2022-05-21",
      "downloaded_date": "2025-02-02",
      "filename": "Bennett-Computable Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.10513v7",
      "categories": [
        "cs.AI"
      ]
    },
    "1905.12186v4": {
      "title": "Asymptotically Unambitious Artificial General Intelligence",
      "authors": [
        "Michael K Cohen",
        "Badri Vellambi",
        "Marcus Hutter"
      ],
      "abstract": "General intelligence, the ability to solve arbitrary solvable problems, is\nsupposed by many to be artificially constructible. Narrow intelligence, the\nability to solve a given particularly difficult problem, has seen impressive\nrecent development. Notable examples include self-driving cars, Go engines,\nimage classifiers, and translators. Artificial General Intelligence (AGI)\npresents dangers that narrow intelligence does not: if something smarter than\nus across every domain were indifferent to our concerns, it would be an\nexistential threat to humanity, just as we threaten many species despite no ill\nwill. Even the theory of how to maintain the alignment of an AGI's goals with\nour own has proven highly elusive. We present the first algorithm we are aware\nof for asymptotically unambitious AGI, where \"unambitiousness\" includes not\nseeking arbitrary power. Thus, we identify an exception to the Instrumental\nConvergence Thesis, which is roughly that by default, an AGI would seek power,\nincluding over us.",
      "citation_count": 17,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/de9e60036978bd9b2d95388898db2e331ef6bbc3",
      "published_date": "2019-05-29",
      "downloaded_date": "2025-02-02",
      "filename": "Cohen-Asymptotically Unambitious Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1905.12186v4",
      "categories": [
        "cs.AI",
        "I.2.0, I.2.6",
        "I.2.0; I.2.6"
      ]
    },
    "1711.04309v2": {
      "title": "Self-Regulating Artificial General Intelligence",
      "authors": [
        "Joshua S. Gans"
      ],
      "abstract": "Here we examine the paperclip apocalypse concern for artificial general\nintelligence (or AGI) whereby a superintelligent AI with a simple goal (ie.,\nproducing paperclips) accumulates power so that all resources are devoted\ntowards that simple goal and are unavailable for any other use. We provide\nconditions under which a paper apocalypse can arise but also show that, under\ncertain architectures for recursive self-improvement of AIs, that a paperclip\nAI may refrain from allowing power capabilities to be developed. The reason is\nthat such developments pose the same control problem for the AI as they do for\nhumans (over AIs) and hence, threaten to deprive it of resources for its\nprimary goal.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b14d69f5241be9ddadf19db92bc8d599fef51a94",
      "published_date": "2017-11-12",
      "downloaded_date": "2025-02-02",
      "filename": "Gans-Self-Regulating Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1711.04309v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2309.02590v1": {
      "title": "Artificial General Intelligence for Radiation Oncology",
      "authors": [
        "Chenbin Liu",
        "Zhengliang Liu",
        "Jason Holmes",
        "Lu Zhang",
        "Lian Zhang",
        "Yuzhen Ding",
        "Peng Shu",
        "Zihao Wu",
        "Haixing Dai",
        "Yiwei Li",
        "Dinggang Shen",
        "Ninghao Liu",
        "Quanzheng Li",
        "Xiang Li",
        "Dajiang Zhu",
        "Tianming Liu",
        "Wei Liu"
      ],
      "abstract": "The emergence of artificial general intelligence (AGI) is transforming\nradiation oncology. As prominent vanguards of AGI, large language models (LLMs)\nsuch as GPT-4 and PaLM 2 can process extensive texts and large vision models\n(LVMs) such as the Segment Anything Model (SAM) can process extensive imaging\ndata to enhance the efficiency and precision of radiation therapy. This paper\nexplores full-spectrum applications of AGI across radiation oncology including\ninitial consultation, simulation, treatment planning, treatment delivery,\ntreatment verification, and patient follow-up. The fusion of vision data with\nLLMs also creates powerful multimodal models that elucidate nuanced clinical\npatterns. Together, AGI promises to catalyze a shift towards data-driven,\npersonalized radiation therapy. However, these models should complement human\nexpertise and care. This paper provides an overview of how AGI can transform\nradiation oncology to elevate the standard of patient care in radiation\noncology, with the key insight being AGI's ability to exploit multimodal\nclinical data at scale.",
      "citation_count": 20,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6770061933096bc52b4e2f817923c285be68204f",
      "published_date": "2023-09-05",
      "downloaded_date": "2025-02-02",
      "filename": "Liu-Artificial General Intelligence for Radiation Oncology.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.02590v1",
      "categories": [
        "physics.med-ph"
      ]
    },
    "2306.05480v4": {
      "title": "Artificial General Intelligence for Medical Imaging Analysis",
      "authors": [
        "Xiang Li",
        "Lin Zhao",
        "Lu Zhang",
        "Zihao Wu",
        "Zhengliang Liu",
        "Hanqi Jiang",
        "Chao Cao",
        "Shaochen Xu",
        "Yiwei Li",
        "Haixing Dai",
        "Yixuan Yuan",
        "Jun Liu",
        "Gang Li",
        "Dajiang Zhu",
        "Pingkun Yan",
        "Quanzheng Li",
        "Wei Liu",
        "Tianming Liu",
        "Dinggang Shen"
      ],
      "abstract": "Large-scale Artificial General Intelligence (AGI) models, including Large\nLanguage Models (LLMs) such as ChatGPT/GPT-4, have achieved unprecedented\nsuccess in a variety of general domain tasks. Yet, when applied directly to\nspecialized domains like medical imaging, which require in-depth expertise,\nthese models face notable challenges arising from the medical field's inherent\ncomplexities and unique characteristics. In this review, we delve into the\npotential applications of AGI models in medical imaging and healthcare, with a\nprimary focus on LLMs, Large Vision Models, and Large Multimodal Models. We\nprovide a thorough overview of the key features and enabling techniques of LLMs\nand AGI, and further examine the roadmaps guiding the evolution and\nimplementation of AGI models in the medical sector, summarizing their present\napplications, potentialities, and associated challenges. In addition, we\nhighlight potential future research directions, offering a holistic view on\nupcoming ventures. This comprehensive review aims to offer insights into the\nfuture implications of AGI in medical imaging, healthcare, and beyond.",
      "citation_count": 32,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d818f40ea693a335e02f32dab520351d271c58bf",
      "published_date": "2023-06-08",
      "downloaded_date": "2025-02-02",
      "filename": "Li-Artificial General Intelligence for Medical Imaging Analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.05480v4",
      "categories": [
        "cs.AI"
      ]
    },
    "2209.06569v1": {
      "title": "The Embeddings World and Artificial General Intelligence",
      "authors": [
        "Mostafa Haghir Chehreghani"
      ],
      "abstract": "From early days, a key and controversial question inside the artificial\nintelligence community was whether Artificial General Intelligence (AGI) is\nachievable. AGI is the ability of machines and computer programs to achieve\nhuman-level intelligence and do all tasks that a human being can. While there\nexist a number of systems in the literature claiming they realize AGI, several\nother researchers argue that it is impossible to achieve it. In this paper, we\ntake a different view to the problem. First, we discuss that in order to\nrealize AGI, along with building intelligent machines and programs, an\nintelligent world should also be constructed which is on the one hand, an\naccurate approximation of our world and on the other hand, a significant part\nof reasoning of intelligent machines is already embedded in this world. Then we\ndiscuss that AGI is not a product or algorithm, rather it is a continuous\nprocess which will become more and more mature over time (like human\ncivilization and wisdom). Then, we argue that pre-trained embeddings play a key\nrole in building this intelligent world and as a result, realizing AGI. We\ndiscuss how pre-trained embeddings facilitate achieving several characteristics\nof human-level intelligence, such as embodiment, common sense knowledge,\nunconscious knowledge and continuality of learning, by machines.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fd0cb6eb2a69e72cfa7a2ef36cad49fb30229c9b",
      "published_date": "2022-09-14",
      "downloaded_date": "2025-02-02",
      "filename": "Chehreghani-The Embeddings World and Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2209.06569v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1906.05833v2": {
      "title": "There is no Artificial General Intelligence",
      "authors": [
        "J. Landgrebe",
        "B. Smith"
      ],
      "abstract": "The goal of creating Artificial General Intelligence (AGI) -- or in other\nwords of creating Turing machines (modern computers) that can behave in a way\nthat mimics human intelligence -- has occupied AI researchers ever since the\nidea of AI was first proposed. One common theme in these discussions is the\nthesis that the ability of a machine to conduct convincing dialogues with human\nbeings can serve as at least a sufficient criterion of AGI. We argue that this\nvery ability should be accepted also as a necessary condition of AGI, and we\nprovide a description of the nature of human dialogue in particular and of\nhuman language in general against this background. We then argue that it is for\nmathematical reasons impossible to program a machine in such a way that it\ncould master human dialogue behaviour in its full generality. This is (1)\nbecause there are no traditional explicitly designed mathematical models that\ncould be used as a starting point for creating such programs; and (2) because\neven the sorts of automated models generated by using machine learning, which\nhave been used successfully in areas such as machine translation, cannot be\nextended to cope with human dialogue. If this is so, then we can conclude that\na Turing machine also cannot possess AGI, because it fails to fulfil a\nnecessary condition thereof. At the same time, however, we acknowledge the\npotential of Turing machines to master dialogue behaviour in highly restricted\ncontexts, where what is called ``narrow'' AI can still be of considerable\nutility.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/163588b43776e2504550aace6a7c919e0aa1ff1a",
      "published_date": "2019-06-09",
      "downloaded_date": "2025-02-02",
      "filename": "Landgrebe-There is no Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1906.05833v2",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    "2202.03155v1": {
      "title": "Existence and perception as the basis of AGI (Artificial General Intelligence)",
      "authors": [
        "Victor V. Senkevich"
      ],
      "abstract": "As is known, AGI (Artificial General Intelligence), unlike AI, should operate\nwith meanings. And that's what distinguishes it from AI. Any successful AI\nimplementations (playing chess, unmanned driving, face recognition etc.) do not\noperate with the meanings of the processed objects in any way and do not\nrecognize the meaning. And they don't need to. But for AGI, which emulates\nhuman thinking, this ability is crucial. Numerous attempts to define the\nconcept of \"meaning\" have one very significant drawback - all such definitions\nare not strict and formalized, so they cannot be programmed. The meaning search\nprocedure should use a formalized description of its existence and possible\nforms of its perception. For the practical implementation of AGI, it is\nnecessary to develop such \"ready-to-code\" descriptions in the context of their\nuse for processing the related cognitive concepts of \"meaning\" and \"knowledge\".\nAn attempt to formalize the definition of such concepts is made in this\narticle.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3f78b0e7237570f085c35d9a8f9ac4658eeb6f63",
      "published_date": "2022-01-30",
      "downloaded_date": "2025-02-02",
      "filename": "Senkevich-Existence and perception as the basis of AGI Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.03155v1",
      "categories": [
        "cs.AI",
        "cs.IT",
        "cs.LO",
        "math.IT"
      ]
    },
    "1909.03798v2": {
      "title": "Subjectivity Learning Theory towards Artificial General Intelligence",
      "authors": [
        "Xin Su",
        "Shangqi Guo",
        "Feng Chen"
      ],
      "abstract": "The construction of artificial general intelligence (AGI) was a long-term\ngoal of AI research aiming to deal with the complex data in the real world and\nmake reasonable judgments in various cases like a human. However, the current\nAI creations, referred to as \"Narrow AI\", are limited to a specific problem.\nThe constraints come from two basic assumptions of data, which are independent\nand identical distributed samples and single-valued mapping between inputs and\noutputs. We completely break these constraints and develop the subjectivity\nlearning theory for general intelligence. We assign the mathematical meaning\nfor the philosophical concept of subjectivity and build the data representation\nof general intelligence. Under the subjectivity representation, then the global\nrisk is constructed as the new learning goal. We prove that subjectivity\nlearning holds a lower risk bound than traditional machine learning. Moreover,\nwe propose the principle of empirical global risk minimization (EGRM) as the\nsubjectivity learning process in practice, establish the condition of\nconsistency, and present triple variables for controlling the total risk bound.\nThe subjectivity learning is a novel learning theory for unconstrained real\ndata and provides a path to develop AGI.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/424533567047d1fc0fba7888581214c174e1980e",
      "published_date": "2019-09-09",
      "downloaded_date": "2025-02-02",
      "filename": "Su-Subjectivity Learning Theory towards Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1909.03798v2",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    "2309.07438v1": {
      "title": "Towards Artificial General Intelligence (AGI) in the Internet of Things (IoT): Opportunities and Challenges",
      "authors": [
        "Fei Dou",
        "Jin Ye",
        "Geng Yuan",
        "Qin Lu",
        "Wei Niu",
        "Haijian Sun",
        "Le Guan",
        "Guoyu Lu",
        "Gengchen Mai",
        "Ninghao Liu",
        "Jin Lu",
        "Zhengliang Liu",
        "Zihao Wu",
        "Chenjiao Tan",
        "Shaochen Xu",
        "Xianqiao Wang",
        "Guoming Li",
        "Lilong Chai",
        "Sheng Li",
        "Jin Sun",
        "Hongyue Sun",
        "Yunli Shao",
        "Changying Li",
        "Tianming Liu",
        "Wenzhan Song"
      ],
      "abstract": "Artificial General Intelligence (AGI), possessing the capacity to comprehend,\nlearn, and execute tasks with human cognitive abilities, engenders significant\nanticipation and intrigue across scientific, commercial, and societal arenas.\nThis fascination extends particularly to the Internet of Things (IoT), a\nlandscape characterized by the interconnection of countless devices, sensors,\nand systems, collectively gathering and sharing data to enable intelligent\ndecision-making and automation. This research embarks on an exploration of the\nopportunities and challenges towards achieving AGI in the context of the IoT.\nSpecifically, it starts by outlining the fundamental principles of IoT and the\ncritical role of Artificial Intelligence (AI) in IoT systems. Subsequently, it\ndelves into AGI fundamentals, culminating in the formulation of a conceptual\nframework for AGI's seamless integration within IoT. The application spectrum\nfor AGI-infused IoT is broad, encompassing domains ranging from smart grids,\nresidential environments, manufacturing, and transportation to environmental\nmonitoring, agriculture, healthcare, and education. However, adapting AGI to\nresource-constrained IoT settings necessitates dedicated research efforts.\nFurthermore, the paper addresses constraints imposed by limited computing\nresources, intricacies associated with large-scale IoT communication, as well\nas the critical concerns pertaining to security and privacy.",
      "citation_count": 22,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/576a3159d6c3f646d6fda6d047dfece4ea941fdd",
      "published_date": "2023-09-14",
      "downloaded_date": "2025-02-02",
      "filename": "Dou-Towards Artificial General Intelligence AGI in the Internet of Things IoT Opportunities and Challeng....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.07438v1",
      "categories": [
        "cs.AI",
        "cs.NI"
      ]
    },
    "2310.19626v1": {
      "title": "Transformation vs Tradition: Artificial General Intelligence (AGI) for Arts and Humanities",
      "authors": [
        "Zhengliang Liu",
        "Yiwei Li",
        "Qian Cao",
        "Junwen Chen",
        "Tianze Yang",
        "Zihao Wu",
        "John Hale",
        "John Gibbs",
        "Khaled Rasheed",
        "Ninghao Liu",
        "Gengchen Mai",
        "Tianming Liu"
      ],
      "abstract": "Recent advances in artificial general intelligence (AGI), particularly large\nlanguage models and creative image generation systems have demonstrated\nimpressive capabilities on diverse tasks spanning the arts and humanities.\nHowever, the swift evolution of AGI has also raised critical questions about\nits responsible deployment in these culturally significant domains\ntraditionally seen as profoundly human. This paper provides a comprehensive\nanalysis of the applications and implications of AGI for text, graphics, audio,\nand video pertaining to arts and the humanities. We survey cutting-edge systems\nand their usage in areas ranging from poetry to history, marketing to film, and\ncommunication to classical art. We outline substantial concerns pertaining to\nfactuality, toxicity, biases, and public safety in AGI systems, and propose\nmitigation strategies. The paper argues for multi-stakeholder collaboration to\nensure AGI promotes creativity, knowledge, and cultural values without\nundermining truth or human dignity. Our timely contribution summarizes a\nrapidly developing field, highlighting promising directions while advocating\nfor responsible progress centering on human flourishing. The analysis lays the\ngroundwork for further research on aligning AGI's technological capacities with\nenduring social goods.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a8fc3745ff459e938c3204c78ac09674ab743fc8",
      "published_date": "2023-10-30",
      "downloaded_date": "2025-02-02",
      "filename": "Liu-Transformation vs Tradition Artificial General Intelligence AGI for Arts and Humanities.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.19626v1",
      "categories": [
        "cs.AI",
        "J.5; I.2.7; I.2.10"
      ]
    },
    "2406.00594v4": {
      "title": "Artificial General Intelligence (AGI) for the oil and gas industry: a review",
      "authors": [
        "Jimmy Xuekai Li",
        "Tiancheng Zhang",
        "Yiran Zhu",
        "Zhongwei Chen"
      ],
      "abstract": "Artificial General Intelligence (AGI) is set to profoundly impact the oil and\ngas industry by introducing unprecedented efficiencies and innovations. This\npaper explores AGI's foundational principles and its transformative\napplications, particularly focusing on the advancements brought about by large\nlanguage models (LLMs) and extensive computer vision systems in the upstream\nsectors of the industry. The integration of Artificial Intelligence (AI) has\nalready begun reshaping the oil and gas landscape, offering enhancements in\nproduction optimization, downtime reduction, safety improvements, and\nadvancements in exploration and drilling techniques. These technologies\nstreamline logistics, minimize maintenance costs, automate monotonous tasks,\nrefine decision-making processes, foster team collaboration, and amplify\nprofitability through error reduction and actionable insights extraction.\nDespite these advancements, the deployment of AI technologies faces challenges,\nincluding the necessity for skilled professionals for implementation and the\nlimitations of model training on constrained datasets, which affects the\nmodels' adaptability across different contexts. The advent of generative AI,\nexemplified by innovations like ChatGPT and the Segment Anything Model (SAM),\nheralds a new era of high-density innovation. These developments highlight a\nshift towards natural language interfaces and domain-knowledge-driven AI,\npromising more accessible and tailored solutions for the oil and gas industry.\nThis review articulates the vast potential AGI holds for tackling complex\noperational challenges within the upstream oil and gas industry, requiring\nnear-human levels of intelligence. We discussed the promising applications, the\nhurdles of large-scale AGI model deployment, and the necessity for\ndomain-specific knowledge in maximizing the benefits of these technologies.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1aa96b82476817f0ee4c7d1f887ee3e0af34ed8a",
      "published_date": "2024-06-02",
      "downloaded_date": "2025-02-02",
      "filename": "Li-Artificial General Intelligence AGI for the oil and gas industry a review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.00594v4",
      "categories": [
        "cs.IT",
        "math.IT"
      ]
    },
    "2501.03151v1": {
      "title": "Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches",
      "authors": [
        "Alhassan Mumuni",
        "Fuseini Mumuni"
      ],
      "abstract": "Generative artificial intelligence (AI) systems based on large-scale\npretrained foundation models (PFMs) such as vision-language models, large\nlanguage models (LLMs), diffusion models and vision-language-action (VLA)\nmodels have demonstrated the ability to solve complex and truly non-trivial AI\nproblems in a wide variety of domains and contexts. Multimodal large language\nmodels (MLLMs), in particular, learn from vast and diverse data sources,\nallowing rich and nuanced representations of the world and, thereby, providing\nextensive capabilities, including the ability to reason, engage in meaningful\ndialog; collaborate with humans and other agents to jointly solve complex\nproblems; and understand social and emotional aspects of humans. Despite this\nimpressive feat, the cognitive abilities of state-of-the-art LLMs trained on\nlarge-scale datasets are still superficial and brittle. Consequently, generic\nLLMs are severely limited in their generalist capabilities. A number of\nfoundational problems -- embodiment, symbol grounding, causality and memory --\nare required to be addressed for LLMs to attain human-level general\nintelligence. These concepts are more aligned with human cognition and provide\nLLMs with inherent human-like cognitive properties that support the realization\nof physically-plausible, semantically meaningful, flexible and more\ngeneralizable knowledge and intelligence. In this work, we discuss the\naforementioned foundational issues and survey state-of-the art approaches for\nimplementing these concepts in LLMs. Specifically, we discuss how the\nprinciples of embodiment, symbol grounding, causality and memory can be\nleveraged toward the attainment of artificial general intelligence (AGI) in an\norganic manner.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/56f3483da18e7c11fbe7297bc31b58ed423ead02",
      "published_date": "2025-01-06",
      "downloaded_date": "2025-02-02",
      "filename": "Mumuni-Large language models for artificial general intelligence AGI A survey of foundational principles an....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.03151v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    "1801.09317v2": {
      "title": "A Cyber Science Based Ontology for Artificial General Intelligence Containment",
      "authors": [
        "Jason M. Pittman",
        "Courtney Crosby"
      ],
      "abstract": "The development of artificial general intelligence is considered by many to\nbe inevitable. What such intelligence does after becoming aware is not so\ncertain. To that end, research suggests that the likelihood of artificial\ngeneral intelligence becoming hostile to humans is significant enough to\nwarrant inquiry into methods to limit such potential. Thus, containment of\nartificial general intelligence is a timely and meaningful research topic.\nWhile there is limited research exploring possible containment strategies, such\nwork is bounded by the underlying field the strategies draw upon. Accordingly,\nwe set out to construct an ontology to describe necessary elements in any\nfuture containment technology. Using existing academic literature, we developed\na single domain ontology containing five levels, 32 codes, and 32 associated\ndescriptors. Further, we constructed ontology diagrams to demonstrate intended\nrelationships. We then identified humans, AGI, and the cyber world as novel\nagent objects necessary for future containment activities. Collectively, the\nwork addresses three critical gaps: (a) identifying and arranging fundamental\nconstructs; (b) situating AGI containment within cyber science; and (c)\ndeveloping scientific rigor within the field.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d935b416fbbe00d1d15ea75904952def9177e8a2",
      "published_date": "2018-01-28",
      "downloaded_date": "2025-02-02",
      "filename": "Pittman-A Cyber Science Based Ontology for Artificial General Intelligence Containment.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1801.09317v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2207.13583v1": {
      "title": "Towards the Neuroevolution of Low-level Artificial General Intelligence",
      "authors": [
        "Sidney Pontes-Filho",
        "Kristoffer Olsen",
        "Anis Yazidi",
        "Michael A. Riegler",
        "PÃ¥l Halvorsen",
        "Stefano Nichele"
      ],
      "abstract": "In this work, we argue that the search for Artificial General Intelligence\n(AGI) should start from a much lower level than human-level intelligence. The\ncircumstances of intelligent behavior in nature resulted from an organism\ninteracting with its surrounding environment, which could change over time and\nexert pressure on the organism to allow for learning of new behaviors or\nenvironment models. Our hypothesis is that learning occurs through interpreting\nsensory feedback when an agent acts in an environment. For that to happen, a\nbody and a reactive environment are needed. We evaluate a method to evolve a\nbiologically-inspired artificial neural network that learns from environment\nreactions named Neuroevolution of Artificial General Intelligence (NAGI), a\nframework for low-level AGI. This method allows the evolutionary\ncomplexification of a randomly-initialized spiking neural network with adaptive\nsynapses, which controls agents instantiated in mutable environments. Such a\nconfiguration allows us to benchmark the adaptivity and generality of the\ncontrollers. The chosen tasks in the mutable environments are food foraging,\nemulation of logic gates, and cart-pole balancing. The three tasks are\nsuccessfully solved with rather small network topologies and therefore it opens\nup the possibility of experimenting with more complex tasks and scenarios where\ncurriculum learning is beneficial.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b1b22987f746e64d7984f2b6588995ecda8db958",
      "published_date": "2022-07-27",
      "downloaded_date": "2025-02-02",
      "filename": "Pontes-Filho-Towards the Neuroevolution of Low-level Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2207.13583v1",
      "categories": [
        "cs.AI",
        "cs.NE",
        "68T05",
        "I.2.6"
      ]
    },
    "2110.14378v2": {
      "title": "Towards artificial general intelligence via a multimodal foundation model",
      "authors": [
        "Nanyi Fei",
        "Zhiwu Lu",
        "Yizhao Gao",
        "Guoxing Yang",
        "Yuqi Huo",
        "Jingyuan Wen",
        "Haoyu Lu",
        "Ruihua Song",
        "Xin Gao",
        "Tao Xiang",
        "Hao Sun",
        "Ji-Rong Wen"
      ],
      "abstract": "The fundamental goal of artificial intelligence (AI) is to mimic the core\ncognitive activities of human. Despite tremendous success in the AI research,\nmost of existing methods have only single-cognitive ability. To overcome this\nlimitation and take a solid step towards artificial general intelligence (AGI),\nwe develop a foundation model pre-trained with huge multimodal data, which can\nbe quickly adapted for various downstream cognitive tasks. To achieve this\ngoal, we propose to pre-train our foundation model by self-supervised learning\nwith weak semantic correlation data crawled from the Internet and show that\npromising results can be obtained on a wide range of downstream tasks.\nParticularly, with the developed model-interpretability tools, we demonstrate\nthat strong imagination ability is now possessed by our foundation model. We\nbelieve that our work makes a transformative stride towards AGI, from our\ncommon practice of \"weak or narrow AI\" to that of \"strong or generalized AI\".",
      "citation_count": 162,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cb8dcaf8e5fe7256577c6bc83e11dd64d8f3ae31",
      "published_date": "2021-10-27",
      "downloaded_date": "2025-02-02",
      "filename": "Fei-Towards artificial general intelligence via a multimodal foundation model.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.14378v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2311.08698v1": {
      "title": "Artificial General Intelligence, Existential Risk, and Human Risk Perception",
      "authors": [
        "David R. Mandel"
      ],
      "abstract": "Artificial general intelligence (AGI) does not yet exist, but given the pace\nof technological development in artificial intelligence, it is projected to\nreach human-level intelligence within roughly the next two decades. After that,\nmany experts expect it to far surpass human intelligence and to do so rapidly.\nThe prospect of superintelligent AGI poses an existential risk to humans\nbecause there is no reliable method for ensuring that AGI goals stay aligned\nwith human goals. Drawing on publicly available forecaster and opinion data,\nthe author examines how experts and non-experts perceive risk from AGI. The\nfindings indicate that the perceived risk of a world catastrophe or extinction\nfrom AGI is greater than for other existential risks. The increase in perceived\nrisk over the last year is also steeper for AGI than for other existential\nthreats (e.g., nuclear war or human-caused climate change). That AGI is a\npressing existential risk is something on which experts and non-experts agree,\nbut the basis for such agreement currently remains obscure.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c28e10616d0f039de2a4acadce0791176fca16ee",
      "published_date": "2023-11-15",
      "downloaded_date": "2025-02-02",
      "filename": "Mandel-Artificial General Intelligence Existential Risk and Human Risk Perception.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.08698v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2312.06037v2": {
      "title": "Multimodality of AI for Education: Towards Artificial General Intelligence",
      "authors": [
        "Gyeong-Geon Lee",
        "Lehong Shi",
        "Ehsan Latif",
        "Yizhu Gao",
        "Arne Bewersdorff",
        "Matthew Nyaaba",
        "Shuchen Guo",
        "Zihao Wu",
        "Zhengliang Liu",
        "Hui Wang",
        "Gengchen Mai",
        "Tiaming Liu",
        "Xiaoming Zhai"
      ],
      "abstract": "This paper presents a comprehensive examination of how multimodal artificial\nintelligence (AI) approaches are paving the way towards the realization of\nArtificial General Intelligence (AGI) in educational contexts. It scrutinizes\nthe evolution and integration of AI in educational systems, emphasizing the\ncrucial role of multimodality, which encompasses auditory, visual, kinesthetic,\nand linguistic modes of learning. This research delves deeply into the key\nfacets of AGI, including cognitive frameworks, advanced knowledge\nrepresentation, adaptive learning mechanisms, strategic planning, sophisticated\nlanguage processing, and the integration of diverse multimodal data sources. It\ncritically assesses AGI's transformative potential in reshaping educational\nparadigms, focusing on enhancing teaching and learning effectiveness, filling\ngaps in existing methodologies, and addressing ethical considerations and\nresponsible usage of AGI in educational settings. The paper also discusses the\nimplications of multimodal AI's role in education, offering insights into\nfuture directions and challenges in AGI development. This exploration aims to\nprovide a nuanced understanding of the intersection between AI, multimodality,\nand education, setting a foundation for future research and development in AGI.",
      "citation_count": 28,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/00b89844abecc9fb9ea687bedcd42c44421dfa23",
      "published_date": "2023-12-10",
      "downloaded_date": "2025-02-02",
      "filename": "Lee-Multimodality of AI for Education Towards Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2312.06037v2",
      "categories": [
        "cs.AI"
      ]
    },
    "1806.02091v4": {
      "title": "Can Machines Design? An Artificial General Intelligence Approach",
      "authors": [
        "Andreas Makoto Hein",
        "HÃ©lÃ¨ne Condat"
      ],
      "abstract": "Can machines design? Can they come up with creative solutions to problems and\nbuild tools and artifacts across a wide range of domains? Recent advances in\nthe field of computational creativity and formal Artificial General\nIntelligence (AGI) provide frameworks for machines with the general ability to\ndesign. In this paper we propose to integrate a formal computational creativity\nframework into the G\\\"odel machine framework. We call the resulting framework\ndesign G\\\"odel machine. Such a machine could solve a variety of design problems\nby generating novel concepts. In addition, it could change the way these\nconcepts are generated by modifying itself. The design G\\\"odel machine is able\nto improve its initial design program, once it has proven that a modification\nwould increase its return on the utility function. Finally, we sketch out a\nspecific version of the design G\\\"odel machine which specifically addresses the\ndesign of complex software and hardware systems. Future work aims at the\ndevelopment of a more formal version of the design G\\\"odel machine and a proof\nof concept implementation.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/64cca16b5e7e9bb729d279d098276c312fa7e8b9",
      "published_date": "2018-06-06",
      "downloaded_date": "2025-02-02",
      "filename": "Hein-Can Machines Design An Artificial General Intelligence Approach.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1806.02091v4",
      "categories": [
        "cs.AI"
      ]
    },
    "2303.12712v5": {
      "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
      "authors": [
        "SÃ©bastien Bubeck",
        "Varun Chandrasekaran",
        "Ronen Eldan",
        "Johannes Gehrke",
        "Eric Horvitz",
        "Ece Kamar",
        "Peter Lee",
        "Yin Tat Lee",
        "Yuanzhi Li",
        "Scott Lundberg",
        "Harsha Nori",
        "Hamid Palangi",
        "Marco Tulio Ribeiro",
        "Yi Zhang"
      ],
      "abstract": "Artificial intelligence (AI) researchers have been developing and refining\nlarge language models (LLMs) that exhibit remarkable capabilities across a\nvariety of domains and tasks, challenging our understanding of learning and\ncognition. The latest model developed by OpenAI, GPT-4, was trained using an\nunprecedented scale of compute and data. In this paper, we report on our\ninvestigation of an early version of GPT-4, when it was still in active\ndevelopment by OpenAI. We contend that (this early version of) GPT-4 is part of\na new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that\nexhibit more general intelligence than previous AI models. We discuss the\nrising capabilities and implications of these models. We demonstrate that,\nbeyond its mastery of language, GPT-4 can solve novel and difficult tasks that\nspan mathematics, coding, vision, medicine, law, psychology and more, without\nneeding any special prompting. Moreover, in all of these tasks, GPT-4's\nperformance is strikingly close to human-level performance, and often vastly\nsurpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's\ncapabilities, we believe that it could reasonably be viewed as an early (yet\nstill incomplete) version of an artificial general intelligence (AGI) system.\nIn our exploration of GPT-4, we put special emphasis on discovering its\nlimitations, and we discuss the challenges ahead for advancing towards deeper\nand more comprehensive versions of AGI, including the possible need for\npursuing a new paradigm that moves beyond next-word prediction. We conclude\nwith reflections on societal influences of the recent technological leap and\nfuture research directions.",
      "citation_count": 2593,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c",
      "published_date": "2023-03-22",
      "downloaded_date": "2025-02-02",
      "filename": "Bubeck-Sparks of Artificial General Intelligence Early experiments with GPT-4.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.12712v5",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    "2110.01831v1": {
      "title": "The Artificial Scientist: Logicist, Emergentist, and Universalist Approaches to Artificial General Intelligence",
      "authors": [
        "Michael Timothy Bennett",
        "Yoshihiro Maruyama"
      ],
      "abstract": "We attempt to define what is necessary to construct an Artificial Scientist,\nexplore and evaluate several approaches to artificial general intelligence\n(AGI) which may facilitate this, conclude that a unified or hybrid approach is\nnecessary and explore two theories that satisfy this requirement to some\ndegree.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/35033089edfbffab72569a1b8b165c489176e22b",
      "published_date": "2021-10-05",
      "downloaded_date": "2025-02-02",
      "filename": "Bennett-The Artificial Scientist Logicist Emergentist and Universalist Approaches to Artificial General Inte....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2110.01831v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2409.12244v1": {
      "title": "Sparks of Artificial General Intelligence(AGI) in Semiconductor Material Science: Early Explorations into the Next Frontier of Generative AI-Assisted Electron Micrograph Analysis",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Geethan Sannidhi",
        "Sreeja Gangasani",
        "Chidaksh Ravuru",
        "Venkataramana Runkana"
      ],
      "abstract": "Characterizing materials with electron micrographs poses significant\nchallenges for automated labeling due to the complex nature of nanomaterial\nstructures. To address this, we introduce a fully automated, end-to-end\npipeline that leverages recent advances in Generative AI. It is designed for\nanalyzing and understanding the microstructures of semiconductor materials with\neffectiveness comparable to that of human experts, contributing to the pursuit\nof Artificial General Intelligence (AGI) in nanomaterial identification. Our\napproach utilizes Large MultiModal Models (LMMs) such as GPT-4V, alongside\ntext-to-image models like DALLE-3. We integrate a GPT-4 guided Visual Question\nAnswering (VQA) method to analyze nanomaterial images, generate synthetic\nnanomaterial images via DALLE-3, and employ in-context learning with few-shot\nprompting in GPT-4V for accurate nanomaterial identification. Our method\nsurpasses traditional techniques by enhancing the precision of nanomaterial\nidentification and optimizing the process for high-throughput screening.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/250208fff2a95e33247b91f8c559face24f6fc13",
      "published_date": "2024-09-17",
      "downloaded_date": "2025-02-02",
      "filename": "Srinivas-Sparks of Artificial General IntelligenceAGI in Semiconductor Material Science Early Explorations in....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.12244v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2203.14963v2": {
      "title": "Deep Learning and Artificial General Intelligence: Still a Long Way to Go",
      "authors": [
        "Maciej Åwiechowski"
      ],
      "abstract": "In recent years, deep learning using neural network architecture, i.e. deep\nneural networks, has been on the frontier of computer science research. It has\neven lead to superhuman performance in some problems, e.g., in computer vision,\ngames and biology, and as a result the term deep learning revolution was\ncoined. The undisputed success and rapid growth of deep learning suggests that,\nin future, it might become an enabler for Artificial General Intelligence\n(AGI). In this article, we approach this statement critically showing five\nmajor reasons of why deep neural networks, as of the current state, are not\nready to be the technique of choice for reaching AGI.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6619181a5ad94ecd7eb7f629ff94c36a0cee9ce8",
      "published_date": "2022-03-25",
      "downloaded_date": "2025-02-02",
      "filename": "Åwiechowski-Deep Learning and Artificial General Intelligence Still a Long Way to Go.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.14963v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T01 (Primary), 68T07",
        "I.2.0; I.2.6"
      ]
    },
    "2307.03762v1": {
      "title": "Brain in a Vat: On Missing Pieces Towards Artificial General Intelligence in Large Language Models",
      "authors": [
        "Yuxi Ma",
        "Chi Zhang",
        "Song-Chun Zhu"
      ],
      "abstract": "In this perspective paper, we first comprehensively review existing\nevaluations of Large Language Models (LLMs) using both standardized tests and\nability-oriented benchmarks. We pinpoint several problems with current\nevaluation methods that tend to overstate the capabilities of LLMs. We then\narticulate what artificial general intelligence should encompass beyond the\ncapabilities of LLMs. We propose four characteristics of generally intelligent\nagents: 1) they can perform unlimited tasks; 2) they can generate new tasks\nwithin a context; 3) they operate based on a value system that underpins task\ngeneration; and 4) they have a world model reflecting reality, which shapes\ntheir interaction with the world. Building on this viewpoint, we highlight the\nmissing pieces in artificial general intelligence, that is, the unity of\nknowing and acting. We argue that active engagement with objects in the real\nworld delivers more robust signals for forming conceptual representations.\nAdditionally, knowledge acquisition isn't solely reliant on passive input but\nrequires repeated trials and errors. We conclude by outlining promising future\nresearch directions in the field of artificial general intelligence.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/50f9f33b284b7363fbd9b9d2da4939b989a1c7cd",
      "published_date": "2023-07-07",
      "downloaded_date": "2025-02-02",
      "filename": "Ma-Brain in a Vat On Missing Pieces Towards Artificial General Intelligence in Large Language Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.03762v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    "2309.12352v1": {
      "title": "An overview of research on human-centered design in the development of artificial general intelligence",
      "authors": [
        "Yang Yue",
        "Joseph Z. Shyu"
      ],
      "abstract": "Abstract: This article offers a comprehensive analysis of Artificial General\nIntelligence (AGI) development through a humanistic lens. Utilizing a wide\narray of academic and industry resources, it dissects the technological and\nethical complexities inherent in AGI's evolution. Specifically, the paper\nunderlines the societal and individual implications of AGI and argues for its\nalignment with human values and interests.\n  Purpose: The study aims to explore the role of human-centered design in AGI's\ndevelopment and governance.\n  Design/Methodology/Approach: Employing content analysis and literature\nreview, the research evaluates major themes and concepts in human-centered\ndesign within AGI development. It also scrutinizes relevant academic studies,\ntheories, and best practices.\n  Findings: Human-centered design is imperative for ethical and sustainable\nAGI, emphasizing human dignity, privacy, and autonomy. Incorporating values\nlike empathy, ethics, and social responsibility can significantly influence\nAGI's ethical deployment. Talent development is also critical, warranting\ninterdisciplinary initiatives.\n  Research Limitations/Implications: There is a need for additional empirical\nstudies focusing on ethics, social responsibility, and talent cultivation\nwithin AGI development.\n  Practical Implications: Implementing human-centered values in AGI development\nenables ethical and sustainable utilization, thus promoting human dignity,\nprivacy, and autonomy. Moreover, a concerted effort across industry, academia,\nand research sectors can secure a robust talent pool, essential for AGI's\nstable advancement.\n  Originality/Value: This paper contributes original research to the field by\nhighlighting the necessity of a human-centered approach in AGI development, and\ndiscusses its practical ramifications.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d11898d8aa489aebc8ba68bba1b42b556d7d3efb",
      "published_date": "2023-08-31",
      "downloaded_date": "2025-02-02",
      "filename": "Yue-An overview of research on human-centered design in the development of artificial general intelligen....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.12352v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2012.06338v2": {
      "title": "The Why, What and How of Artificial General Intelligence Chip Development",
      "authors": [
        "Alex James"
      ],
      "abstract": "The AI chips increasingly focus on implementing neural computing at low power\nand cost. The intelligent sensing, automation, and edge computing applications\nhave been the market drivers for AI chips. Increasingly, the generalisation,\nperformance, robustness, and scalability of the AI chip solutions are compared\nwith human-like intelligence abilities. Such a requirement to transit from\napplication-specific to general intelligence AI chip must consider several\nfactors. This paper provides an overview of this cross-disciplinary field of\nstudy, elaborating on the generalisation of intelligence as understood in\nbuilding artificial general intelligence (AGI) systems. This work presents a\nlisting of emerging AI chip technologies, classification of edge AI\nimplementations, and the funnel design flow for AGI chip development. Finally,\nthe design consideration required for building an AGI chip is listed along with\nthe methods for testing and validating it.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-12-08",
      "downloaded_date": "2025-02-02",
      "filename": "James-The Why What and How of Artificial General Intelligence Chip Development.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2012.06338v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2402.06660v3": {
      "title": "A philosophical and ontological perspective on Artificial General Intelligence and the Metaverse",
      "authors": [
        "Martin Schmalzried"
      ],
      "abstract": "This paper leverages various philosophical and ontological frameworks to\nexplore the concept of embodied artificial general intelligence (AGI), its\nrelationship to human consciousness, and the key role of the metaverse in\nfacilitating this relationship. Several theoretical frameworks underpin this\nexploration, such as embodied cognition, Michael Levin's computational boundary\nof a \"Self,\" Donald D. Hoffman's Interface Theory of Perception, and Bernardo\nKastrup's analytical idealism, which lead to considering our perceived outer\nreality as a symbolic representation of alternate inner states of being, and\nwhere AGI could embody a different form of consciousness with a larger\ncomputational boundary. The paper further discusses the developmental stages of\nAGI, the requirements for the emergence of an embodied AGI, the importance of a\ncalibrated symbolic interface for AGI, and the key role played by the\nmetaverse, decentralized systems, open-source blockchain technology, as well as\nopen-source AI research. It also explores the idea of a feedback loop between\nAGI and human users in metaverse spaces as a tool for AGI calibration, as well\nas the role of local homeostasis and decentralized governance as preconditions\nfor achieving a stable embodied AGI. The paper concludes by emphasizing the\nimportance of achieving a certain degree of harmony in human relations and\nrecognizing the interconnectedness of humanity at a global level, as key\nprerequisites for the emergence of a stable embodied AGI.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5ff3a615b007267bfe9091d6647ac8c63d2baff4",
      "published_date": "2024-02-05",
      "downloaded_date": "2025-02-02",
      "filename": "Schmalzried-A philosophical and ontological perspective on Artificial General Intelligence and the Metaverse.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.06660v3",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    "2402.02547v2": {
      "title": "Integration of cognitive tasks into artificial general intelligence test for large models",
      "authors": [
        "Youzhi Qu",
        "Chen Wei",
        "Penghui Du",
        "Wenxin Che",
        "Chi Zhang",
        "Wanli Ouyang",
        "Yatao Bian",
        "Feiyang Xu",
        "Bin Hu",
        "Kai Du",
        "Haiyan Wu",
        "Jia Liu",
        "Quanying Liu"
      ],
      "abstract": "During the evolution of large models, performance evaluation is necessarily\nperformed to assess their capabilities and ensure safety before practical\napplication. However, current model evaluations mainly rely on specific tasks\nand datasets, lacking a united framework for assessing the multidimensional\nintelligence of large models. In this perspective, we advocate for a\ncomprehensive framework of cognitive science-inspired artificial general\nintelligence (AGI) tests, aimed at fulfilling the testing needs of large models\nwith enhanced capabilities. The cognitive science-inspired AGI tests encompass\nthe full spectrum of intelligence facets, including crystallized intelligence,\nfluid intelligence, social intelligence, and embodied intelligence. To assess\nthe multidimensional intelligence of large models, the AGI tests consist of a\nbattery of well-designed cognitive tests adopted from human intelligence tests,\nand then naturally encapsulates into an immersive virtual community. We propose\nincreasing the complexity of AGI testing tasks commensurate with advancements\nin large models and emphasizing the necessity for the interpretation of test\nresults to avoid false negatives and false positives. We believe that cognitive\nscience-inspired AGI tests will effectively guide the targeted improvement of\nlarge models in specific dimensions of intelligence and accelerate the\nintegration of large models into human society.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1e905582abf156c2acf92f9c0d6a8acc2220c854",
      "published_date": "2024-02-04",
      "downloaded_date": "2025-02-02",
      "filename": "Qu-Integration of cognitive tasks into artificial general intelligence test for large models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.02547v2",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    "2409.01007v2": {
      "title": "Unlocking the Wisdom of Large Language Models: An Introduction to The Path to Artificial General Intelligence",
      "authors": [
        "Edward Y. Chang"
      ],
      "abstract": "This booklet, \"Unlocking the Wisdom of LLM Collaborative Intelligence,\"\nintroduces the comprehensive work \"The Path to Artificial General\nIntelligence.\" Through ten aphorisms, it distills the core principles of LLM\nCollaborative Intelligence (LCI) as a promising framework toward achieving AGI.\nThe booklet also offers titles, abstracts, and introductions from the main\nchapters, along with the first two chapters in full. The second edition,\nreleased this week, includes significant enhancements to Chapters 6 to 9 and a\nrevised preface addressing Yann LeCun's skepticism about AGI. LeCun argues that\nLLMs lack memory, planning, and grounding, but we propose that LCI's\ncollaborative architecture, involving multimodal LLMs with executive,\nlegislative, and judicial roles, overcomes these limitations. Chapters on\nSocraSynth, EVINCE, consciousness modeling, and behavior modeling demonstrate\nthat collaborative LLMs with checks and balances can achieve intelligence\nbeyond any single model's capability. By combining complementary strengths,\nsuch as world modeling and advanced sensory capabilities, LCI enables models to\nwork together and perceive reality beyond human limitations. As with human\ninstitutions, progress depends on cooperation, not isolation. Collaborative\nLLMs may unlock new levels of intelligence, paving the way toward AGI.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4760953fc628b0795e908972f9e95e9b8fa98d4e",
      "published_date": "2024-09-02",
      "downloaded_date": "2025-02-02",
      "filename": "Chang-Unlocking the Wisdom of Large Language Models An Introduction to The Path to Artificial General Inte....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.01007v2",
      "categories": [
        "cs.AI",
        "I.2.7"
      ]
    },
    "1506.04366v1": {
      "title": "Artificial general intelligence through recursive data compression and grounded reasoning: a position paper",
      "authors": [
        "Arthur Franz"
      ],
      "abstract": "This paper presents a tentative outline for the construction of an\nartificial, generally intelligent system (AGI). It is argued that building a\ngeneral data compression algorithm solving all problems up to a complexity\nthreshold should be the main thrust of research. A measure for partial progress\nin AGI is suggested. Although the details are far from being clear, some\ngeneral properties for a general compression algorithm are fleshed out. Its\ninductive bias should be flexible and adapt to the input data while constantly\nsearching for a simple, orthogonal and complete set of hypotheses explaining\nthe data. It should recursively reduce the size of its representations thereby\ncompressing the data increasingly at every iteration.\n  Abstract Based on that fundamental ability, a grounded reasoning system is\nproposed. It is argued how grounding and flexible feature bases made of\nhypotheses allow for resourceful thinking. While the simulation of\nrepresentation contents on the mental stage accounts for much of the power of\npropositional logic, compression leads to simple sets of hypotheses that allow\nthe detection and verification of universally quantified statements.\n  Abstract Together, it is highlighted how general compression and grounded\nreasoning could account for the birth and growth of first concepts about the\nworld and the commonsense reasoning about them.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f6ff738c6b48f775271d9a1dae4a7ba4db0abc1e",
      "published_date": "2015-06-14",
      "downloaded_date": "2025-02-02",
      "filename": "Franz-Artificial general intelligence through recursive data compression and grounded reasoning a position....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1506.04366v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2303.17075v1": {
      "title": "Viewpoint: A Theoretical Computer Science Perspective on Consciousness and Artificial General Intelligence",
      "authors": [
        "Lenore Blum",
        "Manuel Blum"
      ],
      "abstract": "We have defined the Conscious Turing Machine (CTM) for the purpose of\ninvestigating a Theoretical Computer Science (TCS) approach to consciousness.\nFor this, we have hewn to the TCS demand for simplicity and understandability.\nThe CTM is consequently and intentionally a simple machine. It is not a model\nof the brain, though its design has greatly benefited - and continues to\nbenefit - from neuroscience and psychology. The CTM is a model of and for\nconsciousness.\n  Although it is developed to understand consciousness, the CTM offers a\nthoughtful and novel guide to the creation of an Artificial General\nIntelligence (AGI). For example, the CTM has an enormous number of powerful\nprocessors, some with specialized expertise, others unspecialized but poised to\ndevelop an expertise. For whatever problem must be dealt with, the CTM has an\nexcellent way to utilize those processors that have the required knowledge,\nability, and time to work on the problem, even if it is not aware of which ones\nthese may be.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-03-30",
      "downloaded_date": "2025-02-02",
      "filename": "Blum-Viewpoint A Theoretical Computer Science Perspective on Consciousness and Artificial General Intelli....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.17075v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2407.03652v1": {
      "title": "Over the Edge of Chaos? Excess Complexity as a Roadblock to Artificial General Intelligence",
      "authors": [
        "Teo Susnjak",
        "Timothy R. McIntosh",
        "Andre L. C. Barczak",
        "Napoleon H. Reyes",
        "Tong Liu",
        "Paul Watters",
        "Malka N. Halgamuge"
      ],
      "abstract": "In this study, we explored the progression trajectories of artificial\nintelligence (AI) systems through the lens of complexity theory. We challenged\nthe conventional linear and exponential projections of AI advancement toward\nArtificial General Intelligence (AGI) underpinned by transformer-based\narchitectures, and posited the existence of critical points, akin to phase\ntransitions in complex systems, where AI performance might plateau or regress\ninto instability upon exceeding a critical complexity threshold. We employed\nagent-based modelling (ABM) to simulate hypothetical scenarios of AI systems'\nevolution under specific assumptions, using benchmark performance as a proxy\nfor capability and complexity. Our simulations demonstrated how increasing the\ncomplexity of the AI system could exceed an upper criticality threshold,\nleading to unpredictable performance behaviours. Additionally, we developed a\npractical methodology for detecting these critical thresholds using simulation\ndata and stochastic gradient descent to fine-tune detection thresholds. This\nresearch offers a novel perspective on AI advancement that has a particular\nrelevance to Large Language Models (LLMs), emphasising the need for a tempered\napproach to extrapolating AI's growth potential and underscoring the importance\nof developing more robust and comprehensive AI performance benchmarks.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/04cb958fa9bf12e7ea99210c37ff4a2f68ed65e9",
      "published_date": "2024-07-04",
      "downloaded_date": "2025-02-02",
      "filename": "Susnjak-Over the Edge of Chaos Excess Complexity as a Roadblock to Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.03652v1",
      "categories": [
        "cs.AI",
        "cs.CC"
      ]
    },
    "2401.03428v1": {
      "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects",
      "authors": [
        "Yuheng Cheng",
        "Ceyao Zhang",
        "Zhengwen Zhang",
        "Xiangrui Meng",
        "Sirui Hong",
        "Wenhao Li",
        "Zihao Wang",
        "Zekai Wang",
        "Feng Yin",
        "Junhua Zhao",
        "Xiuqiang He"
      ],
      "abstract": "Intelligent agents stand out as a potential path toward artificial general\nintelligence (AGI). Thus, researchers have dedicated significant effort to\ndiverse implementations for them. Benefiting from recent progress in large\nlanguage models (LLMs), LLM-based agents that use universal natural language as\nan interface exhibit robust generalization capabilities across various\napplications -- from serving as autonomous general-purpose task assistants to\napplications in coding, social, and economic domains, LLM-based agents offer\nextensive exploration opportunities. This paper surveys current research to\nprovide an in-depth overview of LLM-based intelligent agents within\nsingle-agent and multi-agent systems. It covers their definitions, research\nframeworks, and foundational components such as their composition, cognitive\nand planning methods, tool utilization, and responses to environmental\nfeedback. We also delve into the mechanisms of deploying LLM-based agents in\nmulti-agent systems, including multi-role collaboration, message passing, and\nstrategies to alleviate communication issues between agents. The discussions\nalso shed light on popular datasets and application scenarios. We conclude by\nenvisioning prospects for LLM-based agents, considering the evolving landscape\nof AI and natural language processing.",
      "citation_count": 46,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/098ba244f687186436e3eb06aced10f5ecb092a8",
      "published_date": "2024-01-07",
      "downloaded_date": "2025-02-02",
      "filename": "Cheng-Exploring Large Language Model based Intelligent Agents Definitions Methods and Prospects.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.03428v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    "2103.06123v1": {
      "title": "The whole brain architecture approach: Accelerating the development of artificial general intelligence by referring to the brain",
      "authors": [
        "Hiroshi Yamakawa"
      ],
      "abstract": "The vastness of the design space created by the combination of a large number\nof computational mechanisms, including machine learning, is an obstacle to\ncreating an artificial general intelligence (AGI). Brain-inspired AGI\ndevelopment, in other words, cutting down the design space to look more like a\nbiological brain, which is an existing model of a general intelligence, is a\npromising plan for solving this problem. However, it is difficult for an\nindividual to design a software program that corresponds to the entire brain\nbecause the neuroscientific data required to understand the architecture of the\nbrain are extensive and complicated. The whole-brain architecture approach\ndivides the brain-inspired AGI development process into the task of designing\nthe brain reference architecture (BRA) -- the flow of information and the\ndiagram of corresponding components -- and the task of developing each\ncomponent using the BRA. This is called BRA-driven development. Another\ndifficulty lies in the extraction of the operating principles necessary for\nreproducing the cognitive-behavioral function of the brain from neuroscience\ndata. Therefore, this study proposes the Structure-constrained Interface\nDecomposition (SCID) method, which is a hypothesis-building method for creating\na hypothetical component diagram consistent with neuroscientific findings. The\napplication of this approach has begun for building various regions of the\nbrain. Moving forward, we will examine methods of evaluating the biological\nplausibility of brain-inspired software. This evaluation will also be used to\nprioritize different computational mechanisms, which should be merged,\nassociated with the same regions of the brain.",
      "citation_count": 15,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ff0d67c0900fb383be45e4dc173479b45414fd5a",
      "published_date": "2021-03-06",
      "downloaded_date": "2025-02-02",
      "filename": "Yamakawa-The whole brain architecture approach Accelerating the development of artificial general intelligenc....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.06123v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "q-bio.NC",
        "I.2.0"
      ]
    },
    "2405.19498v1": {
      "title": "Machine Psychology: Integrating Operant Conditioning with the Non-Axiomatic Reasoning System for Advancing Artificial General Intelligence Research",
      "authors": [
        "Robert Johansson"
      ],
      "abstract": "This paper introduces an interdisciplinary framework called Machine\nPsychology, which merges principles from operant learning psychology with a\nspecific Artificial Intelligence model, the Non-Axiomatic Reasoning System\n(NARS), to enhance Artificial General Intelligence (AGI) research. The core\npremise of this framework is that adaptation is crucial to both biological and\nartificial intelligence and can be understood through operant conditioning\nprinciples. The study assesses this approach via three operant learning tasks\nusing OpenNARS for Applications (ONA): simple discrimination, changing\ncontingencies, and conditional discrimination tasks.\n  In the simple discrimination task, NARS demonstrated rapid learning,\nachieving perfect accuracy during both training and testing phases. The\nchanging contingencies task showcased NARS's adaptability, as it successfully\nadjusted its behavior when task conditions were reversed. In the conditional\ndiscrimination task, NARS handled complex learning scenarios effectively,\nachieving high accuracy by forming and utilizing intricate hypotheses based on\nconditional cues.\n  These findings support the application of operant conditioning as a framework\nfor creating adaptive AGI systems. NARS's ability to operate under conditions\nof insufficient knowledge and resources, coupled with its sensorimotor\nreasoning capabilities, establishes it as a robust model for AGI. The Machine\nPsychology framework, by incorporating elements of natural intelligence such as\ncontinuous learning and goal-driven behavior, offers a scalable and flexible\napproach for real-world applications. Future research should investigate using\nenhanced NARS systems, more advanced tasks, and applying this framework to\ndiverse, complex challenges to further progress the development of human-level\nAI.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/17ea48d9e31a6f3127cf7a79220ea62523fb1845",
      "published_date": "2024-05-29",
      "downloaded_date": "2025-02-02",
      "filename": "Johansson-Machine Psychology Integrating Operant Conditioning with the Non-Axiomatic Reasoning System for Adva....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.19498v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1805.01109v2": {
      "title": "AGI Safety Literature Review",
      "authors": [
        "Tom Everitt",
        "Gary Lea",
        "Marcus Hutter"
      ],
      "abstract": "The development of Artificial General Intelligence (AGI) promises to be a\nmajor event. Along with its many potential benefits, it also raises serious\nsafety concerns (Bostrom, 2014). The intention of this paper is to provide an\neasily accessible and up-to-date collection of references for the emerging\nfield of AGI safety. A significant number of safety problems for AGI have been\nidentified. We list these, and survey recent research on solving them. We also\ncover works on how best to think of AGI from the limited knowledge we have\ntoday, predictions for when AGI will first be created, and what will happen\nafter its creation. Finally, we review the current public policy on AGI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-05-03",
      "downloaded_date": "2025-02-02",
      "filename": "Everitt-AGI Safety Literature Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1805.01109v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2007.07710v1": {
      "title": "Human $\\neq$ AGI",
      "authors": [
        "Roman V. Yampolskiy"
      ],
      "abstract": "Terms Artificial General Intelligence (AGI) and Human-Level Artificial\nIntelligence (HLAI) have been used interchangeably to refer to the Holy Grail\nof Artificial Intelligence (AI) research, creation of a machine capable of\nachieving goals in a wide range of environments. However, widespread implicit\nassumption of equivalence between capabilities of AGI and HLAI appears to be\nunjustified, as humans are not general intelligences. In this paper, we will\nprove this distinction.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-07-11",
      "downloaded_date": "2025-02-02",
      "filename": "Yampolskiy-Human neq AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.07710v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "2404.10731v1": {
      "title": "What is Meant by AGI? On the Definition of Artificial General Intelligence",
      "authors": [
        "Bowen Xu"
      ],
      "abstract": "This paper aims to establish a consensus on AGI's definition. General\nintelligence refers to the adaptation to open environments according to certain\nprinciples using limited resources. It emphasizes that adaptation or learning\nis an indispensable property of intelligence, and places the controversial part\nwithin the principles of intelligence, which can be described from different\nperspectives.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/20025002df007e2bac5aadb3af2be0ae25844deb",
      "published_date": "2024-04-16",
      "downloaded_date": "2025-02-02",
      "filename": "Xu-What is Meant by AGI On the Definition of Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.10731v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2304.06136v1": {
      "title": "AGI for Agriculture",
      "authors": [
        "Guoyu Lu",
        "Sheng Li",
        "Gengchen Mai",
        "Jin Sun",
        "Dajiang Zhu",
        "Lilong Chai",
        "Haijian Sun",
        "Xianqiao Wang",
        "Haixing Dai",
        "Ninghao Liu",
        "Rui Xu",
        "Daniel Petti",
        "Changying Li",
        "Tianming Liu",
        "Changying Li"
      ],
      "abstract": "Artificial General Intelligence (AGI) is poised to revolutionize a variety of\nsectors, including healthcare, finance, transportation, and education. Within\nhealthcare, AGI is being utilized to analyze clinical medical notes, recognize\npatterns in patient data, and aid in patient management. Agriculture is another\ncritical sector that impacts the lives of individuals worldwide. It serves as a\nfoundation for providing food, fiber, and fuel, yet faces several challenges,\nsuch as climate change, soil degradation, water scarcity, and food security.\nAGI has the potential to tackle these issues by enhancing crop yields, reducing\nwaste, and promoting sustainable farming practices. It can also help farmers\nmake informed decisions by leveraging real-time data, leading to more efficient\nand effective farm management. This paper delves into the potential future\napplications of AGI in agriculture, such as agriculture image processing,\nnatural language processing (NLP), robotics, knowledge graphs, and\ninfrastructure, and their impact on precision livestock and precision crops. By\nleveraging the power of AGI, these emerging technologies can provide farmers\nwith actionable insights, allowing for optimized decision-making and increased\nproductivity. The transformative potential of AGI in agriculture is vast, and\nthis paper aims to highlight its potential to revolutionize the industry.",
      "citation_count": 17,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/965e0d4bfe8097baab1947fc23263ae790620e23",
      "published_date": "2023-04-12",
      "downloaded_date": "2025-02-02",
      "filename": "Lu-AGI for Agriculture.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.06136v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    "1712.03043v3": {
      "title": "A Heuristic Search Algorithm Using the Stability of Learning Algorithms in Certain Scenarios as the Fitness Function: An Artificial General Intelligence Engineering Approach",
      "authors": [
        "Zengkun Li"
      ],
      "abstract": "This paper presents a non-manual design engineering method based on heuristic\nsearch algorithm to search for candidate agents in the solution space which\nformed by artificial intelligence agents modeled on the base of\nbionics.Compared with the artificial design method represented by meta-learning\nand the bionics method represented by the neural architecture chip,this method\nis more feasible for realizing artificial general intelligence,and it has a\nmuch better interaction with cognitive neuroscience;at the same time,the\nengineering method is based on the theoretical hypothesis that the final\nlearning algorithm is stable in certain scenarios,and has generalization\nability in various scenarios.The paper discusses the theory preliminarily and\nproposes the possible correlation between the theory and the fixed-point\ntheorem in the field of mathematics.Limited by the author's knowledge\nlevel,this correlation is proposed only as a kind of conjecture.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5285dda5896944fdfb9e460ecfc03f3deabe9c11",
      "published_date": "2017-12-08",
      "downloaded_date": "2025-02-02",
      "filename": "Li-A Heuristic Search Algorithm Using the Stability of Learning Algorithms in Certain Scenarios as the ....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1712.03043v3",
      "categories": [
        "cs.AI"
      ]
    },
    "2101.02179v1": {
      "title": "The case for psychometric artificial general intelligence",
      "authors": [
        "Mark McPherson"
      ],
      "abstract": "A short review of the literature on measurement and detection of artificial\ngeneral intelligence is made. Proposed benchmarks and tests for artificial\ngeneral intelligence are critically evaluated against multiple criteria. Based\non the findings, the most promising approaches are identified and some useful\ndirections for future work are proposed.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/90e74fc2173e4b0852d29f9a3b1b24303ab943e1",
      "published_date": "2020-12-27",
      "downloaded_date": "2025-02-02",
      "filename": "McPherson-The case for psychometric artificial general intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.02179v1",
      "categories": [
        "cs.AI",
        "I.2.0"
      ]
    },
    "2008.04793v4": {
      "title": "Future Trends for Human-AI Collaboration: A Comprehensive Taxonomy of AI/AGI Using Multiple Intelligences and Learning Styles",
      "authors": [
        "Andrzej Cichocki",
        "Alexander P. Kuleshov"
      ],
      "abstract": "This article discusses some trends and concepts in developing new generation\nof future Artificial General Intelligence (AGI) systems which relate to complex\nfacets and different types of human intelligence, especially social, emotional,\nattentional and ethical intelligence. We describe various aspects of multiple\nhuman intelligences and learning styles, which may impact on a variety of AI\nproblem domains. Using the concept of 'multiple intelligences' rather than a\nsingle type of intelligence, we categorize and provide working definitions of\nvarious AGI depending on their cognitive skills or capacities. Future AI\nsystems will be able not only to communicate with human users and each other,\nbut also to efficiently exchange knowledge and wisdom with abilities of\ncooperation, collaboration and even co-creating something new and valuable and\nhave meta-learning capacities. Multi-agent systems such as these can be used to\nsolve problems that would be difficult to solve by any individual intelligent\nagent.\n  Key words: Artificial General Intelligence (AGI), multiple intelligences,\nlearning styles, physical intelligence, emotional intelligence, social\nintelligence, attentional intelligence, moral-ethical intelligence, responsible\ndecision making, creative-innovative intelligence, cognitive functions,\nmeta-learning of AI systems.",
      "citation_count": 32,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/afe847f90f75d9e007bf66fce5d828547401caba",
      "published_date": "2020-08-07",
      "downloaded_date": "2025-02-02",
      "filename": "Cichocki-Future Trends for Human-AI Collaboration A Comprehensive Taxonomy of AIAGI Using Multiple Intelligen....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.04793v4",
      "categories": [
        "cs.AI"
      ]
    },
    "2311.02462v4": {
      "title": "Levels of AGI for Operationalizing Progress on the Path to AGI",
      "authors": [
        "Meredith Ringel Morris",
        "Jascha Sohl-dickstein",
        "Noah Fiedel",
        "Tris Warkentin",
        "Allan Dafoe",
        "Aleksandra Faust",
        "Clement Farabet",
        "Shane Legg"
      ],
      "abstract": "We propose a framework for classifying the capabilities and behavior of\nArtificial General Intelligence (AGI) models and their precursors. This\nframework introduces levels of AGI performance, generality, and autonomy,\nproviding a common language to compare models, assess risks, and measure\nprogress along the path to AGI. To develop our framework, we analyze existing\ndefinitions of AGI, and distill six principles that a useful ontology for AGI\nshould satisfy. With these principles in mind, we propose \"Levels of AGI\" based\non depth (performance) and breadth (generality) of capabilities, and reflect on\nhow current systems fit into this ontology. We discuss the challenging\nrequirements for future benchmarks that quantify the behavior and capabilities\nof AGI models against these levels. Finally, we discuss how these levels of AGI\ninteract with deployment considerations such as autonomy and risk, and\nemphasize the importance of carefully selecting Human-AI Interaction paradigms\nfor responsible and safe deployment of highly capable AI systems.",
      "citation_count": 51,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c0a822ac56e47b6e4b99d5552d2998647abe8234",
      "published_date": "2023-11-04",
      "downloaded_date": "2025-02-02",
      "filename": "Morris-Levels of AGI for Operationalizing Progress on the Path to AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2311.02462v4",
      "categories": [
        "cs.AI"
      ]
    },
    "1906.10536v1": {
      "title": "An AGI with Time-Inconsistent Preferences",
      "authors": [
        "James D. Miller",
        "Roman Yampolskiy"
      ],
      "abstract": "This paper reveals a trap for artificial general intelligence (AGI) theorists\nwho use economists' standard method of discounting. This trap is implicitly and\nfalsely assuming that a rational AGI would have time-consistent preferences. An\nagent with time-inconsistent preferences knows that its future self will\ndisagree with its current self concerning intertemporal decision making. Such\nan agent cannot automatically trust its future self to carry out plans that its\ncurrent self considers optimal.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4d32ff6951b993aea97002ba761321e1c1f08c78",
      "published_date": "2019-06-23",
      "downloaded_date": "2025-02-02",
      "filename": "Miller-An AGI with Time-Inconsistent Preferences.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1906.10536v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2102.00834v1": {
      "title": "Counterfactual Planning in AGI Systems",
      "authors": [
        "Koen Holtman"
      ],
      "abstract": "We present counterfactual planning as a design approach for creating a range\nof safety mechanisms that can be applied in hypothetical future AI systems\nwhich have Artificial General Intelligence.\n  The key step in counterfactual planning is to use an AGI machine learning\nsystem to construct a counterfactual world model, designed to be different from\nthe real world the system is in. A counterfactual planning agent determines the\naction that best maximizes expected utility in this counterfactual planning\nworld, and then performs the same action in the real world.\n  We use counterfactual planning to construct an AGI agent emergency stop\nbutton, and a safety interlock that will automatically stop the agent before it\nundergoes an intelligence explosion. We also construct an agent with an input\nterminal that can be used by humans to iteratively improve the agent's reward\nfunction, where the incentive for the agent to manipulate this improvement\nprocess is suppressed. As an example of counterfactual planning in a non-agent\nAGI system, we construct a counterfactual oracle.\n  As a design approach, counterfactual planning is built around the use of a\ngraphical notation for defining mathematical counterfactuals. This two-diagram\nnotation also provides a compact and readable language for reasoning about the\ncomplex types of self-referencing and indirect representation which are\ntypically present inside machine learning agents.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/79e824ce01cc22ae3a9bc6a14297ea0ac070b15a",
      "published_date": "2021-01-29",
      "downloaded_date": "2025-02-02",
      "filename": "Holtman-Counterfactual Planning in AGI Systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.00834v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2202.03153v1": {
      "title": "Approaches to Artificial General Intelligence: An Analysis",
      "authors": [
        "Soumil Rathi"
      ],
      "abstract": "This paper is an analysis of the different methods proposed to achieve AGI,\nincluding Human Brain Emulation, AIXI and Integrated Cognitive Architecture.\nFirst, the definition of AGI as used in this paper has been defined, and its\nrequirements have been stated. For each proposed method mentioned, the method\nin question was summarized and its key processes were detailed, showcasing how\nit functioned. Then, each method listed was analyzed, taking various factors\ninto consideration, such as technological requirements, computational ability,\nand adequacy to the requirements. It was concluded that while there are various\nmethods to achieve AGI that could work, such as Human Brain Emulation and\nIntegrated Cognitive Architectures, the most promising method to achieve AGI is\nIntegrated Cognitive Architectures. This is because Human Brain Emulation was\nfound to require scanning technologies that will most likely not be available\nuntil the 2030s, making it unlikely to be created before then. Moreover,\nIntegrated Cognitive Architectures has reduced computational requirements and a\nsuitable functionality for General Intelligence, making it the most likely way\nto achieve AGI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2022-01-29",
      "downloaded_date": "2025-02-02",
      "filename": "Rathi-Approaches to Artificial General Intelligence An Analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.03153v1",
      "categories": [
        "cs.AI",
        "I.2.0; I.2.6"
      ]
    },
    "2303.15935v1": {
      "title": "When Brain-inspired AI Meets AGI",
      "authors": [
        "Lin Zhao",
        "Lu Zhang",
        "Zihao Wu",
        "Yuzhong Chen",
        "Haixing Dai",
        "Xiaowei Yu",
        "Zhengliang Liu",
        "Tuo Zhang",
        "Xintao Hu",
        "Xi Jiang",
        "Xiang Li",
        "Dajiang Zhu",
        "Dinggang Shen",
        "Tianming Liu"
      ],
      "abstract": "Artificial General Intelligence (AGI) has been a long-standing goal of\nhumanity, with the aim of creating machines capable of performing any\nintellectual task that humans can do. To achieve this, AGI researchers draw\ninspiration from the human brain and seek to replicate its principles in\nintelligent machines. Brain-inspired artificial intelligence is a field that\nhas emerged from this endeavor, combining insights from neuroscience,\npsychology, and computer science to develop more efficient and powerful AI\nsystems. In this article, we provide a comprehensive overview of brain-inspired\nAI from the perspective of AGI. We begin with the current progress in\nbrain-inspired AI and its extensive connection with AGI. We then cover the\nimportant characteristics for both human intelligence and AGI (e.g., scaling,\nmultimodality, and reasoning). We discuss important technologies toward\nachieving AGI in current AI systems, such as in-context learning and prompt\ntuning. We also investigate the evolution of AGI systems from both algorithmic\nand infrastructural perspectives. Finally, we explore the limitations and\nfuture of AGI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-03-28",
      "downloaded_date": "2025-02-02",
      "filename": "Zhao-When Brain-inspired AI Meets AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.15935v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2306.02519v1": {
      "title": "Transformative AGI by 2043 is <1% likely",
      "authors": [
        "Ari Allyn-Feuer",
        "Ted Sanders"
      ],
      "abstract": "This paper is a submission to the Open Philanthropy AI Worldviews Contest. In\nit, we estimate the likelihood of transformative artificial general\nintelligence (AGI) by 2043 and find it to be <1%.\n  Specifically, we argue:\n  The bar is high: AGI as defined by the contest - something like AI that can\nperform nearly all valuable tasks at human cost or less - which we will call\ntransformative AGI is a much higher bar than merely massive progress in AI, or\neven the unambiguous attainment of expensive superhuman AGI or cheap but uneven\nAGI.\n  Many steps are needed: The probability of transformative AGI by 2043 can be\ndecomposed as the joint probability of a number of necessary steps, which we\ngroup into categories of software, hardware, and sociopolitical factors.\n  No step is guaranteed: For each step, we estimate a probability of success by\n2043, conditional on prior steps being achieved. Many steps are quite\nconstrained by the short timeline, and our estimates range from 16% to 95%.\n  Therefore, the odds are low: Multiplying the cascading conditional\nprobabilities together, we estimate that transformative AGI by 2043 is 0.4%\nlikely. Reaching >10% seems to require probabilities that feel unreasonably\nhigh, and even 3% seems unlikely.\n  Thoughtfully applying the cascading conditional probability approach to this\nquestion yields lower probability values than is often supposed. This framework\nhelps enumerate the many future scenarios where humanity makes partial but\nincomplete progress toward transformative AGI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-06-05",
      "downloaded_date": "2025-02-02",
      "filename": "Allyn-Feuer-Transformative AGI by 2043 is 1 likely.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.02519v1",
      "categories": [
        "cs.AI",
        "I.2.0"
      ]
    },
    "2401.06792v2": {
      "title": "LightHouse: A Survey of AGI Hallucination",
      "authors": [
        "Feng Wang"
      ],
      "abstract": "With the development of artificial intelligence, large-scale models have\nbecome increasingly intelligent. However, numerous studies indicate that\nhallucinations within these large models are a bottleneck hindering the\ndevelopment of AI research. In the pursuit of achieving strong artificial\nintelligence, a significant volume of research effort is being invested in the\nAGI (Artificial General Intelligence) hallucination research. Previous\nexplorations have been conducted in researching hallucinations within LLMs\n(Large Language Models). As for multimodal AGI, research on hallucinations is\nstill in an early stage. To further the progress of research in the domain of\nhallucinatory phenomena, we present a bird's eye view of hallucinations in AGI,\nsummarizing the current work on AGI hallucinations and proposing some\ndirections for future research.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/78b02a431af35f9fc02a36564073244a7f2de042",
      "published_date": "2024-01-08",
      "downloaded_date": "2025-02-02",
      "filename": "Wang-LightHouse A Survey of AGI Hallucination.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.06792v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    "1505.06366v2": {
      "title": "Open Ended Intelligence: The individuation of Intelligent Agents",
      "authors": [
        "David Weinbaum",
        "Viktoras Veitas"
      ],
      "abstract": "Artificial General Intelligence is a field of research aiming to distill the\nprinciples of intelligence that operate independently of a specific problem\ndomain or a predefined context and utilize these principles in order to\nsynthesize systems capable of performing any intellectual task a human being is\ncapable of and eventually go beyond that. While \"narrow\" artificial\nintelligence which focuses on solving specific problems such as speech\nrecognition, text comprehension, visual pattern recognition, robotic motion,\netc. has shown quite a few impressive breakthroughs lately, understanding\ngeneral intelligence remains elusive. In the paper we offer a novel theoretical\napproach to understanding general intelligence. We start with a brief\nintroduction of the current conceptual approach. Our critique exposes a number\nof serious limitations that are traced back to the ontological roots of the\nconcept of intelligence. We then propose a paradigm shift from intelligence\nperceived as a competence of individual agents defined in relation to an a\npriori given problem domain or a goal, to intelligence perceived as a formative\nprocess of self-organization by which intelligent agents are individuated. We\ncall this process open-ended intelligence. Open-ended intelligence is developed\nas an abstraction of the process of cognitive development so its application\ncan be extended to general agents and systems. We introduce and discuss three\nfacets of the idea: the philosophical concept of individuation, sense-making\nand the individuation of general cognitive agents. We further show how\nopen-ended intelligence can be framed in terms of a distributed,\nself-organizing network of interacting elements and how such process is\nscalable. The framework highlights an important relation between coordination\nand intelligence and a new understanding of values. We conclude with a number\nof questions for future research.",
      "citation_count": 33,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/923b5acdff2bc6c55efa2ad5d4f21c747355c325",
      "published_date": "2015-05-23",
      "downloaded_date": "2025-02-02",
      "filename": "Weinbaum-Open Ended Intelligence The individuation of Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1505.06366v2",
      "categories": [
        "cs.AI"
      ]
    },
    "1808.03644v1": {
      "title": "Building Safer AGI by introducing Artificial Stupidity",
      "authors": [
        "MichaÃ«l Trazzi",
        "Roman V. Yampolskiy"
      ],
      "abstract": "Artificial Intelligence (AI) achieved super-human performance in a broad\nvariety of domains. We say that an AI is made Artificially Stupid on a task\nwhen some limitations are deliberately introduced to match a human's ability to\ndo the task. An Artificial General Intelligence (AGI) can be made safer by\nlimiting its computing power and memory, or by introducing Artificial Stupidity\non certain tasks. We survey human intellectual limits and give recommendations\nfor which limits to implement in order to build a safe AGI.",
      "citation_count": 21,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/feef1ddc618a406e4b125b51ad7de0505516c8e6",
      "published_date": "2018-08-11",
      "downloaded_date": "2025-02-02",
      "filename": "Trazzi-Building Safer AGI by introducing Artificial Stupidity.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1808.03644v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2308.03598v4": {
      "title": "Why We Don't Have AGI Yet",
      "authors": [
        "Peter Voss",
        "Mladjan Jovanovic"
      ],
      "abstract": "The original vision of AI was re-articulated in 2002 via the term 'Artificial\nGeneral Intelligence' or AGI. This vision is to build 'Thinking Machines' -\ncomputer systems that can learn, reason, and solve problems similar to the way\nhumans do. This is in stark contrast to the 'Narrow AI' approach practiced by\nalmost everyone in the field over the many decades. While several large-scale\nefforts have nominally been working on AGI (most notably DeepMind), the field\nof pure focused AGI development has not been well funded or promoted. This is\nsurprising given the fantastic value that true AGI can bestow on humanity. In\naddition to the dearth of effort in this field, there are also several\ntheoretical and methodical missteps that are hampering progress. We highlight\nwhy purely statistical approaches are unlikely to lead to AGI, and identify\nseveral crucial cognitive abilities required to achieve human-like adaptability\nand autonomous learning. We conclude with a survey of socio-technical factors\nthat have undoubtedly slowed progress towards AGI.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/80c7c0a6b03c8de6bb795e86cd2db3a247041ebd",
      "published_date": "2023-08-07",
      "downloaded_date": "2025-02-02",
      "filename": "Voss-Why We Dont Have AGI Yet.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.03598v4",
      "categories": [
        "cs.AI"
      ]
    },
    "2309.01933v1": {
      "title": "Provably safe systems: the only path to controllable AGI",
      "authors": [
        "Max Tegmark",
        "Steve Omohundro"
      ],
      "abstract": "We describe a path to humanity safely thriving with powerful Artificial\nGeneral Intelligences (AGIs) by building them to provably satisfy\nhuman-specified requirements. We argue that this will soon be technically\nfeasible using advanced AI for formal verification and mechanistic\ninterpretability. We further argue that it is the only path which guarantees\nsafe controlled AGI. We end with a list of challenge problems whose solution\nwould contribute to this positive outcome and invite readers to join in this\nwork.",
      "citation_count": 16,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/60c73f59ef13811b2dc90737f6915188b63d8bbc",
      "published_date": "2023-09-05",
      "downloaded_date": "2025-02-02",
      "filename": "Tegmark-Provably safe systems the only path to controllable AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.01933v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2412.09385v1": {
      "title": "AI Predicts AGI: Leveraging AGI Forecasting and Peer Review to Explore LLMs' Complex Reasoning Capabilities",
      "authors": [
        "Fabrizio Davide",
        "Pietro Torre",
        "Andrea Gaggioli"
      ],
      "abstract": "We tasked 16 state-of-the-art large language models (LLMs) with estimating\nthe likelihood of Artificial General Intelligence (AGI) emerging by 2030. To\nassess the quality of these forecasts, we implemented an automated peer review\nprocess (LLM-PR). The LLMs' estimates varied widely, ranging from 3% (Reka-\nCore) to 47.6% (GPT-4o), with a median of 12.5%. These estimates closely align\nwith a recent expert survey that projected a 10% likelihood of AGI by 2027,\nunderscoring the relevance of LLMs in forecasting complex, speculative\nscenarios. The LLM-PR process demonstrated strong reliability, evidenced by a\nhigh Intraclass Correlation Coefficient (ICC = 0.79), reflecting notable\nconsistency in scoring across the models. Among the models, Pplx-70b-online\nemerged as the top performer, while Gemini-1.5-pro-api ranked the lowest. A\ncross-comparison with external benchmarks, such as LMSYS Chatbot Arena,\nrevealed that LLM rankings remained consistent across different evaluation\nmethods, suggesting that existing benchmarks may not encapsulate some of the\nskills relevant for AGI prediction. We further explored the use of weighting\nschemes based on external benchmarks, optimizing the alignment of LLMs'\npredictions with human expert forecasts. This analysis led to the development\nof a new, 'AGI benchmark' designed to highlight performance differences in\nAGI-related tasks. Our findings offer insights into LLMs' capabilities in\nspeculative, interdisciplinary forecasting tasks and emphasize the growing need\nfor innovative evaluation frameworks for assessing AI performance in complex,\nuncertain real-world scenarios.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9512ee1cae4121e26c66a921b8668cc4df06519e",
      "published_date": "2024-12-12",
      "downloaded_date": "2025-02-02",
      "filename": "Davide-AI Predicts AGI Leveraging AGI Forecasting and Peer Review to Explore LLMs Complex Reasoning Capabil....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.09385v1",
      "categories": [
        "cs.AI",
        "I.2.7"
      ]
    },
    "1805.08915v1": {
      "title": "A Psychopathological Approach to Safety Engineering in AI and AGI",
      "authors": [
        "Vahid Behzadan",
        "Arslan Munir",
        "Roman V. Yampolskiy"
      ],
      "abstract": "The complexity of dynamics in AI techniques is already approaching that of\ncomplex adaptive systems, thus curtailing the feasibility of formal\ncontrollability and reachability analysis in the context of AI safety. It\nfollows that the envisioned instances of Artificial General Intelligence (AGI)\nwill also suffer from challenges of complexity. To tackle such issues, we\npropose the modeling of deleterious behaviors in AI and AGI as psychological\ndisorders, thereby enabling the employment of psychopathological approaches to\nanalysis and control of misbehaviors. Accordingly, we present a discussion on\nthe feasibility of the psychopathological approaches to AI safety, and propose\ngeneral directions for research on modeling, diagnosis, and treatment of\npsychological disorders in AGI.",
      "citation_count": 17,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/55d6ca702cae899b482f049508a7f0c9b1b71ff6",
      "published_date": "2018-05-23",
      "downloaded_date": "2025-02-02",
      "filename": "Behzadan-A Psychopathological Approach to Safety Engineering in AI and AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1805.08915v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2402.03962v3": {
      "title": "Position: Stop Making Unscientific AGI Performance Claims",
      "authors": [
        "Patrick Altmeyer",
        "Andrew M. Demetriou",
        "Antony Bartlett",
        "Cynthia C. S. Liem"
      ],
      "abstract": "Developments in the field of Artificial Intelligence (AI), and particularly\nlarge language models (LLMs), have created a 'perfect storm' for observing\n'sparks' of Artificial General Intelligence (AGI) that are spurious. Like\nsimpler models, LLMs distill meaningful representations in their latent\nembeddings that have been shown to correlate with external variables.\nNonetheless, the correlation of such representations has often been linked to\nhuman-like intelligence in the latter but not the former. We probe models of\nvarying complexity including random projections, matrix decompositions, deep\nautoencoders and transformers: all of them successfully distill information\nthat can be used to predict latent or external variables and yet none of them\nhave previously been linked to AGI. We argue and empirically demonstrate that\nthe finding of meaningful patterns in latent spaces of models cannot be seen as\nevidence in favor of AGI. Additionally, we review literature from the social\nsciences that shows that humans are prone to seek such patterns and\nanthropomorphize. We conclude that both the methodological setup and common\npublic image of AI are ideal for the misinterpretation that correlations\nbetween model representations and some variables of interest are 'caused' by\nthe model's understanding of underlying 'ground truth' relationships. We,\ntherefore, call for the academic community to exercise extra caution, and to be\nkeenly aware of principles of academic integrity, in interpreting and\ncommunicating about AI research outcomes.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-02-06",
      "downloaded_date": "2025-02-02",
      "filename": "Altmeyer-Position Stop Making Unscientific AGI Performance Claims.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.03962v3",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    "2011.05807v1": {
      "title": "Detecting Synthetic Phenomenology in a Contained Artificial General Intelligence",
      "authors": [
        "Jason M. Pittman",
        "Ashlyn Hanks"
      ],
      "abstract": "Human-like intelligence in a machine is a contentious subject. Whether\nmankind should or should not pursue the creation of artificial general\nintelligence is hotly debated. As well, researchers have aligned in opposing\nfactions according to whether mankind can create it. For our purposes, we\nassume mankind can and will do so. Thus, it becomes necessary to contemplate\nhow to do so in a safe and trusted manner -- enter the idea of boxing or\ncontainment. As part of such thinking, we wonder how a phenomenology might be\ndetected given the operational constraints imposed by any potential containment\nsystem. Accordingly, this work provides an analysis of existing measures of\nphenomenology through qualia and extends those ideas into the context of a\ncontained artificial general intelligence.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9bf232660b0818fa8a4b955541e6e20b1037b7a6",
      "published_date": "2020-11-06",
      "downloaded_date": "2025-02-02",
      "filename": "Pittman-Detecting Synthetic Phenomenology in a Contained Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2011.05807v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    "1812.08014v1": {
      "title": "Intelligent Autonomous Agents are Key to Cyber Defense of the Future Army Networks",
      "authors": [
        "Alexander Kott"
      ],
      "abstract": "Intelligent autonomous agents will be widely present on the battlefield of\nthe future. The proliferation of intelligent agents is the emerging reality of\nwarfare, and they will form an ever growing fraction of total military assets.\nBy necessity, intelligent autonomous cyber defense agents are likely to become\nprimary cyber fighters on the future battlefield. Initial explorations have\nidentified the key functions, components and their interactions for a potential\nreference architecture of such an agent. However, it is beyond the current\nstate of AI to support an agent that could operate intelligently in an\nenvironment as complex as the real battlefield. A number of difficult\nchallenges are yet to be overcome. At the same time, a growing body of research\nin Government and academia demonstrates promising steps towards solving some of\nthe challenges. The industry is beginning to embrace approaches that may\ncontribute to technologies of autonomous intelligent agents for cyber defense\nof the Army networks.",
      "citation_count": 13,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/471a84df5d478b09841631e41bd2d6d1d02db7dc",
      "published_date": "2018-12-18",
      "downloaded_date": "2025-02-02",
      "filename": "Kott-Intelligent Autonomous Agents are Key to Cyber Defense of the Future Army Networks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1812.08014v1",
      "categories": [
        "cs.CR"
      ]
    },
    "2501.15280v1": {
      "title": "Who's Driving? Game Theoretic Path Risk of AGI Development",
      "authors": [
        "Robin Young"
      ],
      "abstract": "Who controls the development of Artificial General Intelligence (AGI) might\nmatter less than how we handle the fight for control itself. We formalize this\n\"steering wheel problem\" as humanity's greatest near-term existential risk may\nstem not from misaligned AGI, but from the dynamics of competing to develop it.\nJust as a car crash can occur from passengers fighting over the wheel before\nreaching any destination, catastrophic outcomes could arise from development\ncompetition long before AGI exists. While technical alignment research focuses\non ensuring safe arrival, we show how coordination failures during development\ncould drive us off the cliff first.\n  We present a game theoretic framework modeling AGI development dynamics and\nprove conditions for sustainable cooperative equilibria. Drawing from nuclear\ncontrol while accounting for AGI's unique characteristics, we propose concrete\nmechanisms including pre-registration, shared technical infrastructure, and\nautomated deterrence to stabilize cooperation. Our key insight is that AGI\ncreates network effects in safety: shared investments become more valuable as\nparticipation grows, enabling mechanism designs where cooperation dominates\ndefection. This work bridges formal methodology and policy frameworks,\nproviding foundations for practical governance of AGI competition risks.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b8f6c6cff3ab2326a9710145132909c77d67b2c2",
      "published_date": "2025-01-25",
      "downloaded_date": "2025-02-02",
      "filename": "Young-Whos Driving Game Theoretic Path Risk of AGI Development.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.15280v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.GT"
      ]
    },
    "1308.0702v1": {
      "title": "Universal Empathy and Ethical Bias for Artificial General Intelligence",
      "authors": [
        "Alexey Potapov",
        "Sergey Rodionov"
      ],
      "abstract": "Rational agents are usually built to maximize rewards. However, AGI agents\ncan find undesirable ways of maximizing any prior reward function. Therefore\nvalue learning is crucial for safe AGI. We assume that generalized states of\nthe world are valuable - not rewards themselves, and propose an extension of\nAIXI, in which rewards are used only to bootstrap hierarchical value learning.\nThe modified AIXI agent is considered in the multi-agent environment, where\nother agents can be either humans or other \"mature\" agents, which values should\nbe revealed and adopted by the \"infant\" AGI agent. General framework for\ndesigning such empathic agent with ethical bias is proposed also as an\nextension of the universal intelligence model. Moreover, we perform experiments\nin the simple Markov environment, which demonstrate feasibility of our approach\nto value learning in safe AGI.",
      "citation_count": 19,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/122e3e9ee114fb410c07734c0f154ec10a2a85aa",
      "published_date": "2013-08-03",
      "downloaded_date": "2025-02-02",
      "filename": "Potapov-Universal Empathy and Ethical Bias for Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1308.0702v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1902.03689v2": {
      "title": "Safe Artificial General Intelligence via Distributed Ledger Technology",
      "authors": [
        "Kristen W. Carlson"
      ],
      "abstract": "Background. Expert observers and artificial intelligence (AI) progression\nmetrics indicate AI will exceed human intelligence within a few decades.\nWhether general AI that exceeds human capabilities (AGI) will be the single\ngreatest boon in history or a disaster is unknown. No proofs exist that AGI\nwill benefit humans or that AGI will not harm or eliminate humans.\n  Objective. I propose a set of logically distinct conceptual components that\nare necessary and sufficient to 1) ensure that most known AGI scenarios will\nnot harm humanity and 2) robustly align AGI values and goals with human values.\n  Methods. By systematically addressing each pathway category to malevolent AI\nwe can induce the methods/axioms required to redress the category.\n  Results and Discussion. Distributed ledger technology (DLT, blockchain) is\nintegral to this proposal, e.g. to reduce the probability of hacking, provide\nan audit trail to detect and correct errors or identify components causing\nvulnerability or failure and replace them or shut them down remotely and/or\nautomatically, and to separate and balance key AGI components via decentralized\napps (dApps). Smart contracts based on DLT are necessary to address evolution\nof AI that will be too fast for human monitoring and intervention.\n  The proposed axioms. 1) Access to technology by market license. 2)\nTransparent ethics embodied in DLT. 3) Morality encrypted via DLT. 4) Behavior\ncontrol structure with values (ethics) at roots. 5) Individual bar-code\nidentification of all critical components. 6) Configuration Item (from business\ncontinuity/disaster recovery planning). 7) Identity verification secured via\nDLT. 8) Smart automated contracts based on DLT. 9) Decentralized applications -\nAI software code modules encrypted via DLT. 10) Audit trail of component usage\nstored via DLT. 11) Social ostracism (denial of societal resources) augmented\nby DLT petitions.",
      "citation_count": 17,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7b30e2b8fc6928ed9e3e4753a1272652ce4b8157",
      "published_date": "2019-02-11",
      "downloaded_date": "2025-02-02",
      "filename": "Carlson-Safe Artificial General Intelligence via Distributed Ledger Technology.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1902.03689v2",
      "categories": [
        "cs.CY"
      ]
    },
    "2412.14186v2": {
      "title": "Towards AI-$45^{\\circ}$ Law: A Roadmap to Trustworthy AGI",
      "authors": [
        "Chao Yang",
        "Chaochao Lu",
        "Yingchun Wang",
        "Bowen Zhou"
      ],
      "abstract": "Ensuring Artificial General Intelligence (AGI) reliably avoids harmful\nbehaviors is a critical challenge, especially for systems with high autonomy or\nin safety-critical domains. Despite various safety assurance proposals and\nextreme risk warnings, comprehensive guidelines balancing AI safety and\ncapability remain lacking. In this position paper, we propose the\n\\textit{AI-\\textbf{$45^{\\circ}$} Law} as a guiding principle for a balanced\nroadmap toward trustworthy AGI, and introduce the \\textit{Causal Ladder of\nTrustworthy AGI} as a practical framework. This framework provides a systematic\ntaxonomy and hierarchical structure for current AI capability and safety\nresearch, inspired by Judea Pearl's ``Ladder of Causation''. The Causal Ladder\ncomprises three core layers: the Approximate Alignment Layer, the Intervenable\nLayer, and the Reflectable Layer. These layers address the key challenges of\nsafety and trustworthiness in AGI and contemporary AI systems. Building upon\nthis framework, we define five levels of trustworthy AGI: perception,\nreasoning, decision-making, autonomy, and collaboration trustworthiness. These\nlevels represent distinct yet progressive aspects of trustworthy AGI. Finally,\nwe present a series of potential governance measures to support the development\nof trustworthy AGI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-12-08",
      "downloaded_date": "2025-02-02",
      "filename": "Yang-Towards AI-45circ Law A Roadmap to Trustworthy AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.14186v2",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    "2501.07458v1": {
      "title": "Understanding and Benchmarking Artificial Intelligence: OpenAI's o3 Is Not AGI",
      "authors": [
        "Rolf Pfister",
        "Hansueli Jud"
      ],
      "abstract": "OpenAI's o3 achieves a high score of 87.5 % on ARC-AGI, a benchmark proposed\nto measure intelligence. This raises the question whether systems based on\nLarge Language Models (LLMs), particularly o3, demonstrate intelligence and\nprogress towards artificial general intelligence (AGI). Building on the\ndistinction between skills and intelligence made by Fran\\c{c}ois Chollet, the\ncreator of ARC-AGI, a new understanding of intelligence is introduced: an agent\nis the more intelligent, the more efficiently it can achieve the more diverse\ngoals in the more diverse worlds with the less knowledge. An analysis of the\nARC-AGI benchmark shows that its tasks represent a very specific type of\nproblem that can be solved by massive trialling of combinations of predefined\noperations. This method is also applied by o3, achieving its high score through\nthe extensive use of computing power. However, for most problems in the\nphysical world and in the human domain, solutions cannot be tested in advance\nand predefined operations are not available. Consequently, massive trialling of\npredefined operations, as o3 does, cannot be a basis for AGI - instead, new\napproaches are required that can reliably solve a wide variety of problems\nwithout existing skills. To support this development, a new benchmark for\nintelligence is outlined that covers a much higher diversity of unknown tasks\nto be solved, thus enabling a comprehensive assessment of intelligence and of\nprogress towards AGI.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9a54348d0a35e4b6842d9ca0a35882b98753d697",
      "published_date": "2025-01-13",
      "downloaded_date": "2025-02-02",
      "filename": "Pfister-Understanding and Benchmarking Artificial Intelligence OpenAIs o3 Is Not AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2501.07458v1",
      "categories": [
        "cs.AI",
        "cs.PF"
      ]
    },
    "2403.12107v1": {
      "title": "Scenarios for the Transition to AGI",
      "authors": [
        "Anton Korinek",
        "Donghyun Suh"
      ],
      "abstract": "We analyze how output and wages behave under different scenarios for\ntechnological progress that may culminate in Artificial General Intelligence\n(AGI), defined as the ability of AI systems to perform all tasks that humans\ncan perform. We assume that human work can be decomposed into atomistic tasks\nthat differ in their complexity. Advances in technology make ever more complex\ntasks amenable to automation. The effects on wages depend on a race between\nautomation and capital accumulation. If the distribution of task complexity\nexhibits a sufficiently thick infinite tail, then there is always enough work\nfor humans, and wages may rise forever. By contrast, if the complexity of tasks\nthat humans can perform is bounded and full automation is reached, then wages\ncollapse. But declines may occur even before if large-scale automation outpaces\ncapital accumulation and makes labor too abundant. Automating productivity\ngrowth may lead to broad-based gains in the returns to all factors. By\ncontrast, bottlenecks to growth from irreproducible scarce factors may\nexacerbate the decline in wages.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7e04b6de6e214c90c689d45207c969f9cacd9d50",
      "published_date": "2024-03-17",
      "downloaded_date": "2025-02-02",
      "filename": "Korinek-Scenarios for the Transition to AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.12107v1",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ]
    },
    "2401.13142v4": {
      "title": "Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse",
      "authors": [
        "Borhane Blili-Hamelin",
        "Leif Hancox-Li",
        "Andrew Smart"
      ],
      "abstract": "Dreams of machines rivaling human intelligence have shaped the field of AI\nsince its inception. Yet, the very meaning of human-level AI or artificial\ngeneral intelligence (AGI) remains elusive and contested. Definitions of AGI\nembrace a diverse range of incompatible values and assumptions. Contending with\nthe fractured worldviews of AGI discourse is vital for critiques that pursue\ndifferent values and futures. To that end, we provide a taxonomy of AGI\ndefinitions, laying the ground for examining the key social, political, and\nethical assumptions they make. We highlight instances in which these\ndefinitions frame AGI or human-level AI as a technical topic and expose the\nvalue-laden choices being implicitly made. Drawing on feminist, STS, and social\nscience scholarship on the political and social character of intelligence in\nboth humans and machines, we propose contextual, democratic, and participatory\npaths to imagining future forms of machine intelligence. The development of\nfuture forms of AI must involve explicit attention to the values it encodes,\nthe people it includes or excludes, and a commitment to epistemic justice.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-01-23",
      "downloaded_date": "2025-02-02",
      "filename": "Blili-Hamelin-Unsocial Intelligence an Investigation of the Assumptions of AGI Discourse.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.13142v4",
      "categories": [
        "cs.CY"
      ]
    },
    "2304.14204v1": {
      "title": "Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining",
      "authors": [
        "Bingqian Lin",
        "Zicong Chen",
        "Mingjie Li",
        "Haokun Lin",
        "Hang Xu",
        "Yi Zhu",
        "Jianzhuang Liu",
        "Wenjia Cai",
        "Lei Yang",
        "Shen Zhao",
        "Chenfei Wu",
        "Ling Chen",
        "Xiaojun Chang",
        "Yi Yang",
        "Lei Xing",
        "Xiaodan Liang"
      ],
      "abstract": "Medical artificial general intelligence (MAGI) enables one foundation model\nto solve different medical tasks, which is very practical in the medical\ndomain. It can significantly reduce the requirement of large amounts of\ntask-specific data by sufficiently sharing medical knowledge among different\ntasks. However, due to the challenges of designing strongly generalizable\nmodels with limited and complex medical data, most existing approaches tend to\ndevelop task-specific models. To take a step towards MAGI, we propose a new\nparadigm called Medical-knOwledge-enhanced mulTimOdal pretRaining (MOTOR). In\nMOTOR, we combine two kinds of basic medical knowledge, i.e., general and\nspecific knowledge, in a complementary manner to boost the general pretraining\nprocess. As a result, the foundation model with comprehensive basic knowledge\ncan learn compact representations from pretraining radiographic data for better\ncross-modal alignment. MOTOR unifies the understanding and generation, which\nare two kinds of core intelligence of an AI system, into a single medical\nfoundation model, to flexibly handle more diverse medical tasks. To enable a\ncomprehensive evaluation and facilitate further research, we construct a\nmedical multimodal benchmark including a wide range of downstream tasks, such\nas chest x-ray report generation and medical visual question answering.\nExtensive experiments on our benchmark show that MOTOR obtains promising\nresults through simple task-oriented adaptation. The visualization shows that\nthe injected knowledge successfully highlights key information in the medical\ndata, demonstrating the excellent interpretability of MOTOR. Our MOTOR\nsuccessfully mimics the human practice of fulfilling a \"medical student\" to\naccelerate the process of becoming a \"specialist\". We believe that our work\nmakes a significant stride in realizing MAGI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-04-26",
      "downloaded_date": "2025-02-02",
      "filename": "Lin-Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.14204v1",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    "2003.00812v1": {
      "title": "An AGI Modifying Its Utility Function in Violation of the Orthogonality Thesis",
      "authors": [
        "James D. Miller",
        "Roman Yampolskiy",
        "Olle HÃ¤ggstrÃ¶m"
      ],
      "abstract": "An artificial general intelligence (AGI) might have an instrumental drive to\nmodify its utility function to improve its ability to cooperate, bargain,\npromise, threaten, and resist and engage in blackmail. Such an AGI would\nnecessarily have a utility function that was at least partially observable and\nthat was influenced by how other agents chose to interact with it. This\ninstrumental drive would conflict with the orthogonality thesis since the\nmodifications would be influenced by the AGI's intelligence. AGIs in highly\ncompetitive environments might converge to having nearly the same utility\nfunction, one optimized to favorably influencing other agents through game\ntheory.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-01-31",
      "downloaded_date": "2025-02-02",
      "filename": "Miller-An AGI Modifying Its Utility Function in Violation of the Orthogonality Thesis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2003.00812v1",
      "categories": [
        "q-fin.GN"
      ]
    },
    "2007.05411v1": {
      "title": "AGI Agent Safety by Iteratively Improving the Utility Function",
      "authors": [
        "Koen Holtman"
      ],
      "abstract": "While it is still unclear if agents with Artificial General Intelligence\n(AGI) could ever be built, we can already use mathematical models to\ninvestigate potential safety systems for these agents. We present an AGI safety\nlayer that creates a special dedicated input terminal to support the iterative\nimprovement of an AGI agent's utility function. The humans who switched on the\nagent can use this terminal to close any loopholes that are discovered in the\nutility function's encoding of agent goals and constraints, to direct the agent\ntowards new goals, or to force the agent to switch itself off. An AGI agent may\ndevelop the emergent incentive to manipulate the above utility function\nimprovement process, for example by deceiving, restraining, or even attacking\nthe humans involved. The safety layer will partially, and sometimes fully,\nsuppress this dangerous incentive. The first part of this paper generalizes\nearlier work on AGI emergency stop buttons. We aim to make the mathematical\nmethods used to construct the layer more accessible, by applying them to an MDP\nmodel. We discuss two provable properties of the safety layer, and show ongoing\nwork in mapping it to a Causal Influence Diagram (CID). In the second part, we\ndevelop full mathematical proofs, and show that the safety layer creates a type\nof bureaucratic blindness. We then present the design of a learning agent, a\ndesign that wraps the safety layer around either a known machine learning\nsystem, or a potential future AGI-level learning system. The resulting agent\nwill satisfy the provable safety properties from the moment it is first\nswitched on. Finally, we show how this agent can be mapped from its model to a\nreal-life implementation. We review the methodological issues involved in this\nstep, and discuss how these are typically resolved.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-07-10",
      "downloaded_date": "2025-02-02",
      "filename": "Holtman-AGI Agent Safety by Iteratively Improving the Utility Function.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2007.05411v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2412.08875v1": {
      "title": "Brain-inspired AI Agent: The Way Towards AGI",
      "authors": [
        "Bo Yu",
        "Jiangning Wei",
        "Minzhen Hu",
        "Zejie Han",
        "Tianjian Zou",
        "Ye He",
        "Jun Liu"
      ],
      "abstract": "Artificial General Intelligence (AGI), widely regarded as the fundamental\ngoal of artificial intelligence, represents the realization of cognitive\ncapabilities that enable the handling of general tasks with human-like\nproficiency. Researchers in brain-inspired AI seek inspiration from the\noperational mechanisms of the human brain, aiming to replicate its functional\nrules in intelligent models. Moreover, with the rapid development of\nlarge-scale models in recent years, the concept of agents has garnered\nincreasing attention, with researchers widely recognizing it as a necessary\npathway toward achieving AGI. In this article, we propose the concept of a\nbrain-inspired AI agent and analyze how to extract relatively feasible and\nagent-compatible cortical region functionalities and their associated\nfunctional connectivity networks from the complex mechanisms of the human\nbrain. Implementing these structures within an agent enables it to achieve\nbasic cognitive intelligence akin to human capabilities. Finally, we explore\nthe limitations and challenges for realizing brain-inspired agents and discuss\ntheir future development.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-12-12",
      "downloaded_date": "2025-02-02",
      "filename": "Yu-Brain-inspired AI Agent The Way Towards AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.08875v1",
      "categories": [
        "cs.NE",
        "cs.ET",
        "q-bio.NC"
      ]
    },
    "2309.01622v1": {
      "title": "Concepts is All You Need: A More Direct Path to AGI",
      "authors": [
        "Peter Voss",
        "Mladjan Jovanovic"
      ],
      "abstract": "Little demonstrable progress has been made toward AGI (Artificial General\nIntelligence) since the term was coined some 20 years ago. In spite of the\nfantastic breakthroughs in Statistical AI such as AlphaZero, ChatGPT, and\nStable Diffusion none of these projects have, or claim to have, a clear path to\nAGI. In order to expedite the development of AGI it is crucial to understand\nand identify the core requirements of human-like intelligence as it pertains to\nAGI. From that one can distill which particular development steps are necessary\nto achieve AGI, and which are a distraction. Such analysis highlights the need\nfor a Cognitive AI approach rather than the currently favored statistical and\ngenerative efforts. More specifically it identifies the central role of\nconcepts in human-like cognition. Here we outline an architecture and\ndevelopment plan, together with some preliminary results, that offers a much\nmore direct path to full Human-Level AI (HLAI)/ AGI.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2045c025884c3ec3d4923efd78ee37d8120eea20",
      "published_date": "2023-09-04",
      "downloaded_date": "2025-02-02",
      "filename": "Voss-Concepts is All You Need A More Direct Path to AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.01622v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2406.18312v4": {
      "title": "AI-native Memory: A Pathway from LLMs Towards AGI",
      "authors": [
        "Jingbo Shang",
        "Zai Zheng",
        "Jiale Wei",
        "Xiang Ying",
        "Felix Tao",
        "Mindverse Team"
      ],
      "abstract": "Large language models (LLMs) have demonstrated the world with the sparks of\nartificial general intelligence (AGI). One opinion, especially from some\nstartups working on LLMs, argues that an LLM with nearly unlimited context\nlength can realize AGI. However, they might be too optimistic about the\nlong-context capability of (existing) LLMs -- (1) Recent literature has shown\nthat their effective context length is significantly smaller than their claimed\ncontext length; and (2) Our reasoning-in-a-haystack experiments further\ndemonstrate that simultaneously finding the relevant information from a long\ncontext and conducting (simple) reasoning is nearly impossible. In this paper,\nwe envision a pathway from LLMs to AGI through the integration of\n\\emph{memory}. We believe that AGI should be a system where LLMs serve as core\nprocessors. In addition to raw data, the memory in this system would store a\nlarge number of important conclusions derived from reasoning processes.\nCompared with retrieval-augmented generation (RAG) that merely processing raw\ndata, this approach not only connects semantically related information closer,\nbut also simplifies complex inferences at the time of querying. As an\nintermediate stage, the memory will likely be in the form of natural language\ndescriptions, which can be directly consumed by users too. Ultimately, every\nagent/person should have its own large personal model, a deep neural network\nmodel (thus \\emph{AI-native}) that parameterizes and compresses all types of\nmemory, even the ones cannot be described by natural languages. Finally, we\ndiscuss the significant potential of AI-native memory as the transformative\ninfrastructure for (proactive) engagement, personalization, distribution, and\nsocial in the AGI era, as well as the incurred privacy and security challenges\nwith preliminary solutions.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/431c85f7cb5436981c798697acc13aa72f3e133b",
      "published_date": "2024-06-26",
      "downloaded_date": "2025-02-02",
      "filename": "Shang-AI-native Memory A Pathway from LLMs Towards AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.18312v4",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    "2104.06365v1": {
      "title": "Neuro-Symbolic VQA: A review from the perspective of AGI desiderata",
      "authors": [
        "Ian Berlot-Attwell"
      ],
      "abstract": "An ultimate goal of the AI and ML fields is artificial general intelligence\n(AGI); although such systems remain science fiction, various models exhibit\naspects of AGI. In this work, we look at neuro-symbolic (NS)approaches to\nvisual question answering (VQA) from the perspective of AGI desiderata. We see\nhow well these systems meet these desiderata, and how the desiderata often pull\nthe scientist in opposing directions. It is my hope that through this work we\ncan temper model evaluation on benchmarks with a discussion of the properties\nof these systems and their potential for future extension.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/170a2dbf41a5edfa07fac26e493b962ded40d4bf",
      "published_date": "2021-04-13",
      "downloaded_date": "2025-02-02",
      "filename": "Berlot-Attwell-Neuro-Symbolic VQA A review from the perspective of AGI desiderata.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.06365v1",
      "categories": [
        "cs.LG",
        "cs.CV"
      ]
    },
    "2407.09573v1": {
      "title": "Have We Reached AGI? Comparing ChatGPT, Claude, and Gemini to Human Literacy and Education Benchmarks",
      "authors": [
        "Mfon Akpan"
      ],
      "abstract": "Recent advancements in AI, particularly in large language models (LLMs) like\nChatGPT, Claude, and Gemini, have prompted questions about their proximity to\nArtificial General Intelligence (AGI). This study compares LLM performance on\neducational benchmarks with Americans' average educational attainment and\nliteracy levels, using data from the U.S. Census Bureau and technical reports.\nResults show that LLMs significantly outperform human benchmarks in tasks such\nas undergraduate knowledge and advanced reading comprehension, indicating\nsubstantial progress toward AGI. However, true AGI requires broader cognitive\nassessments. The study highlights the implications for AI development,\neducation, and societal impact, emphasizing the need for ongoing research and\nethical considerations.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8c884276e97c4d080d5996626a6d8a0f9e3da5a2",
      "published_date": "2024-07-11",
      "downloaded_date": "2025-02-02",
      "filename": "Akpan-Have We Reached AGI Comparing ChatGPT Claude and Gemini to Human Literacy and Education Benchmarks.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.09573v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "1902.07781v1": {
      "title": "Empathic Autonomous Agents",
      "authors": [
        "Timotheus Kampik",
        "Juan Carlos Nieves",
        "Helena Lindgren"
      ],
      "abstract": "Identifying and resolving conflicts of interests is a key challenge when\ndesigning autonomous agents. For example, such conflicts often occur when\ncomplex information systems interact persuasively with humans and are in the\nfuture likely to arise in non-human agent-to-agent interaction. We introduce a\ntheoretical framework for an empathic autonomous agent that proactively\nidentifies potential conflicts of interests in interactions with other agents\n(and humans) by considering their utility functions and comparing them with its\nown preferences using a system of shared values to find a solution all agents\nconsider acceptable. To illustrate how empathic autonomous agents work, we\nprovide running examples and a simple prototype implementation in a\ngeneral-purpose programing language. To give a high-level overview of our work,\nwe propose a reasoning-loop architecture for our empathic agent.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/901bfd3ce92387b4b82bf583c34bd40c4783f966",
      "published_date": "2019-02-20",
      "downloaded_date": "2025-02-02",
      "filename": "Kampik-Empathic Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1902.07781v1",
      "categories": [
        "cs.MA"
      ]
    },
    "2010.05418v9": {
      "title": "Achilles Heels for AGI/ASI via Decision Theoretic Adversaries",
      "authors": [
        "Stephen Casper"
      ],
      "abstract": "As progress in AI continues to advance, it is important to know how advanced\nsystems will make choices and in what ways they may fail. Machines can already\noutsmart humans in some domains, and understanding how to safely build ones\nwhich may have capabilities at or above the human level is of particular\nconcern. One might suspect that artificially generally intelligent (AGI) and\nartificially superintelligent (ASI) will be systems that humans cannot reliably\noutsmart. As a challenge to this assumption, this paper presents the Achilles\nHeel hypothesis which states that even a potentially superintelligent system\nmay nonetheless have stable decision-theoretic delusions which cause them to\nmake irrational decisions in adversarial settings. In a survey of key dilemmas\nand paradoxes from the decision theory literature, a number of these potential\nAchilles Heels are discussed in context of this hypothesis. Several novel\ncontributions are made toward understanding the ways in which these weaknesses\nmight be implanted into a system.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a1cf60dcc862cdfcb3a41915fc3751d765596aad",
      "published_date": "2020-10-12",
      "downloaded_date": "2025-02-02",
      "filename": "Casper-Achilles Heels for AGIASI via Decision Theoretic Adversaries.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2010.05418v9",
      "categories": [
        "cs.AI"
      ]
    },
    "2002.10221v2": {
      "title": "The Archimedean trap: Why traditional reinforcement learning will probably not yield AGI",
      "authors": [
        "Samuel Allen Alexander"
      ],
      "abstract": "After generalizing the Archimedean property of real numbers in such a way as\nto make it adaptable to non-numeric structures, we demonstrate that the real\nnumbers cannot be used to accurately measure non-Archimedean structures. We\nargue that, since an agent with Artificial General Intelligence (AGI) should\nhave no problem engaging in tasks that inherently involve non-Archimedean\nrewards, and since traditional reinforcement learning rewards are real numbers,\ntherefore traditional reinforcement learning probably will not lead to AGI. We\nindicate two possible ways traditional reinforcement learning could be altered\nto remove this roadblock.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-02-15",
      "downloaded_date": "2025-02-02",
      "filename": "Alexander-The Archimedean trap Why traditional reinforcement learning will probably not yield AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2002.10221v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "97R40"
      ]
    },
    "2206.01044v1": {
      "title": "Artificial Open World for Evaluating AGI: a Conceptual Design",
      "authors": [
        "Bowen Xu",
        "Quansheng Ren"
      ],
      "abstract": "How to evaluate Artificial General Intelligence (AGI) is a critical problem\nthat is discussed and unsolved for a long period. In the research of narrow AI,\nthis seems not a severe problem, since researchers in that field focus on some\nspecific problems as well as one or some aspects of cognition, and the criteria\nfor evaluation are explicitly defined. By contrast, an AGI agent should solve\nproblems that are never-encountered by both agents and developers. However,\nonce a developer tests and debugs the agent with a problem, the\nnever-encountered problem becomes the encountered problem, as a result, the\nproblem is solved by the developers to some extent, exploiting their\nexperience, rather than the agents. This conflict, as we call the trap of\ndevelopers' experience, leads to that this kind of problems is probably hard to\nbecome an acknowledged criterion. In this paper, we propose an evaluation\nmethod named Artificial Open World, aiming to jump out of the trap. The\nintuition is that most of the experience in the actual world should not be\nnecessary to be applied to the artificial world, and the world should be open\nin some sense, such that developers are unable to perceive the world and solve\nproblems by themselves before testing, though after that they are allowed to\ncheck all the data. The world is generated in a similar way as the actual\nworld, and a general form of problems is proposed. A metric is proposed aiming\nto quantify the progress of research. This paper describes the conceptual\ndesign of the Artificial Open World, though the formalization and the\nimplementation are left to the future.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9f81a89439a353aa2dccfe04154a6901520955e4",
      "published_date": "2022-06-02",
      "downloaded_date": "2025-02-02",
      "filename": "Xu-Artificial Open World for Evaluating AGI a Conceptual Design.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.01044v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2411.15832v2": {
      "title": "Creating Scalable AGI: the Open General Intelligence Framework",
      "authors": [
        "Daniel A. Dollinger",
        "Michael Singleton"
      ],
      "abstract": "Recent advancements in Artificial Intelligence (AI), particularly with Large\nLanguage Models (LLMs), have led to significant progress in narrow tasks such\nas image classification, language translation, coding, and writing. However,\nthese models face limitations in reliability and scalability due to their\nsiloed architectures, which are designed to handle only one data modality (data\ntype) at a time. This single modal approach hinders their ability to integrate\nthe complex set of data points required for real-world challenges and\nproblem-solving tasks like medical diagnosis, quality assurance, equipment\ntroubleshooting, and financial decision-making. Addressing these real-world\nchallenges requires a more capable Artificial General Intelligence (AGI)\nsystem. Our primary contribution is the development of the Open General\nIntelligence (OGI) framework, a novel systems architecture that serves as a\nmacro design reference for AGI. The OGI framework adopts a modular approach to\nthe design of intelligent systems, based on the premise that cognition must\noccur across multiple specialized modules that can seamlessly operate as a\nsingle system. OGI integrates these modules using a dynamic processing system\nand a fabric interconnect, enabling real-time adaptability, multi-modal\nintegration, and scalable processing. The OGI framework consists of three key\ncomponents: (1) Overall Macro Design Guidance that directs operational design\nand processing, (2) a Dynamic Processing System that controls routing, primary\ngoals, instructions, and weighting, and (3) Framework Areas, a set of\nspecialized modules that operate cohesively to form a unified cognitive system.\nBy incorporating known principles from human cognition into AI systems, the OGI\nframework aims to overcome the challenges observed in today's intelligent\nsystems, paving the way for more holistic and context-aware problem-solving\ncapabilities.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e8ad66569a43129c4346fe2f97bdef5303b00088",
      "published_date": "2024-11-24",
      "downloaded_date": "2025-02-02",
      "filename": "Dollinger-Creating Scalable AGI the Open General Intelligence Framework.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.15832v2",
      "categories": [
        "cs.AI",
        "I.2; C.5"
      ]
    },
    "2306.10225v2": {
      "title": "Genes in Intelligent Agents",
      "authors": [
        "Fu Feng",
        "Jing Wang",
        "Xu Yang",
        "Xin Geng"
      ],
      "abstract": "The genes in nature give the lives on earth the current biological\nintelligence through transmission and accumulation over billions of years.\nInspired by the biological intelligence, artificial intelligence (AI) has\ndevoted to building the machine intelligence. Although it has achieved thriving\nsuccesses, the machine intelligence still lags far behind the biological\nintelligence. The reason may lie in that animals are born with some\nintelligence encoded in their genes, but machines lack such intelligence and\nlearn from scratch. Inspired by the genes of animals, we define the ``genes''\nof machines named as the ``learngenes'' and propose the Genetic Reinforcement\nLearning (GRL). GRL is a computational framework that simulates the evolution\nof organisms in reinforcement learning (RL) and leverages the learngenes to\nlearn and evolve the intelligence agents. Leveraging GRL, we first show that\nthe learngenes take the form of the fragments of the agents' neural networks\nand can be inherited across generations. Second, we validate that the\nlearngenes can transfer ancestral experience to the agents and bring them\ninstincts and strong learning abilities. Third, we justify the Lamarckian\ninheritance of the intelligent agents and the continuous evolution of the\nlearngenes. Overall, the learngenes have taken the machine intelligence one\nmore step toward the biological intelligence.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-06-17",
      "downloaded_date": "2025-02-02",
      "filename": "Feng-Genes in Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.10225v2",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2305.07153v1": {
      "title": "Towards best practices in AGI safety and governance: A survey of expert opinion",
      "authors": [
        "Jonas Schuett",
        "Noemi Dreksler",
        "Markus Anderljung",
        "David McCaffary",
        "Lennart Heim",
        "Emma Bluemke",
        "Ben Garfinkel"
      ],
      "abstract": "A number of leading AI companies, including OpenAI, Google DeepMind, and\nAnthropic, have the stated goal of building artificial general intelligence\n(AGI) - AI systems that achieve or exceed human performance across a wide range\nof cognitive tasks. In pursuing this goal, they may develop and deploy AI\nsystems that pose particularly significant risks. While they have already taken\nsome measures to mitigate these risks, best practices have not yet emerged. To\nsupport the identification of best practices, we sent a survey to 92 leading\nexperts from AGI labs, academia, and civil society and received 51 responses.\nParticipants were asked how much they agreed with 50 statements about what AGI\nlabs should do. Our main finding is that participants, on average, agreed with\nall of them. Many statements received extremely high levels of agreement. For\nexample, 98% of respondents somewhat or strongly agreed that AGI labs should\nconduct pre-deployment risk assessments, dangerous capabilities evaluations,\nthird-party model audits, safety restrictions on model usage, and red teaming.\nUltimately, our list of statements may serve as a helpful foundation for\nefforts to develop best practices, standards, and regulations for AGI labs.",
      "citation_count": 39,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c387a3999113f3f8bcf26681d95cf0f4313f64f4",
      "published_date": "2023-05-11",
      "downloaded_date": "2025-02-02",
      "filename": "Schuett-Towards best practices in AGI safety and governance A survey of expert opinion.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2305.07153v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2308.09721v2": {
      "title": "A new solution and concrete implementation steps for Artificial General Intelligence",
      "authors": [
        "Yongcong Chen",
        "Ting Zeng",
        "Xingyue Chen"
      ],
      "abstract": "In this paper, we propose a new approach to building a artificial general\nintelligence with self awareness, which includes: (1) a new method to implement\nattention mechanisms; (2) a way to give machines self-demands; (3) how to form\na value evaluation system compatible with the network; (4) a way to create the\nworld models; (5) how to realize a top-down, hierarchical thinking\ndecision-making chain; (6) a way to achieve general decision-making and\nresponse capabilities; (7) a way for a machine to directly obtain human\nexperience through language. In the paper, we first analyze some of the\nshortcomings of current LLMs (Large Language Model) and propose ideas for\nimprovement. Then we analyze why our scheme can solve the above problems and\nprovide detailed steps for implementing our scheme. In chapter 4, we have\npresented a step-by-step mplementation roadmap. And in chapter 5, we have\npresented a specific implementation demonstration. In chapter 6, we analyze the\nadvantages and disadvantages of our scheme and propose further research\ndirections. In this article, we have put forward how to create genuine\nartificial general intelligence step by step. It can handle data of all\nmodalities in a unified form and can directly understand the experience that\nhumans already possess through language, thus avoiding the problem that\nreinforcement learning is required for every decision-making process.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9f11b74f5b301e1743bf62a7613a228960c5a868",
      "published_date": "2023-08-12",
      "downloaded_date": "2025-02-02",
      "filename": "Chen-A new solution and concrete implementation steps for Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.09721v2",
      "categories": [
        "cs.LG"
      ]
    },
    "1903.10410v4": {
      "title": "A Conceptual Bio-Inspired Framework for the Evolution of Artificial General Intelligence",
      "authors": [
        "Sidney Pontes-Filho",
        "Stefano Nichele"
      ],
      "abstract": "In this work, a conceptual bio-inspired parallel and distributed learning\nframework for the emergence of general intelligence is proposed, where agents\nevolve through environmental rewards and learn throughout their lifetime\nwithout supervision, i.e., self-learning through embodiment. The chosen control\nmechanism for agents is a biologically plausible neuron model based on spiking\nneural networks. Network topologies become more complex through evolution,\ni.e., the topology is not fixed, while the synaptic weights of the networks\ncannot be inherited, i.e., newborn brains are not trained and have no innate\nknowledge of the environment. What is subject to the evolutionary process is\nthe network topology, the type of neurons, and the type of learning. This\nprocess ensures that controllers that are passed through the generations have\nthe intrinsic ability to learn and adapt during their lifetime in mutable\nenvironments. We envision that the described approach may lead to the emergence\nof the simplest form of artificial general intelligence.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-03-25",
      "downloaded_date": "2025-02-02",
      "filename": "Pontes-Filho-A Conceptual Bio-Inspired Framework for the Evolution of Artificial General Intelligence.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1903.10410v4",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    "2306.08641v1": {
      "title": "Towards AGI in Computer Vision: Lessons Learned from GPT and Large Language Models",
      "authors": [
        "Lingxi Xie",
        "Longhui Wei",
        "Xiaopeng Zhang",
        "Kaifeng Bi",
        "Xiaotao Gu",
        "Jianlong Chang",
        "Qi Tian"
      ],
      "abstract": "The AI community has been pursuing algorithms known as artificial general\nintelligence (AGI) that apply to any kind of real-world problem. Recently, chat\nsystems powered by large language models (LLMs) emerge and rapidly become a\npromising direction to achieve AGI in natural language processing (NLP), but\nthe path towards AGI in computer vision (CV) remains unclear. One may owe the\ndilemma to the fact that visual signals are more complex than language signals,\nyet we are interested in finding concrete reasons, as well as absorbing\nexperiences from GPT and LLMs to solve the problem. In this paper, we start\nwith a conceptual definition of AGI and briefly review how NLP solves a wide\nrange of tasks via a chat system. The analysis inspires us that unification is\nthe next important goal of CV. But, despite various efforts in this direction,\nCV is still far from a system like GPT that naturally integrates all tasks. We\npoint out that the essential weakness of CV lies in lacking a paradigm to learn\nfrom environments, yet NLP has accomplished the task in the text world. We then\nimagine a pipeline that puts a CV algorithm (i.e., an agent) in world-scale,\ninteractable environments, pre-trains it to predict future frames with respect\nto its action, and then fine-tunes it with instruction to accomplish various\ntasks. We expect substantial research and engineering efforts to push the idea\nforward and scale it up, for which we share our perspectives on future research\ndirections.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/051549d8ef56937b2f4d113afdcf8c7586d3770b",
      "published_date": "2023-06-14",
      "downloaded_date": "2025-02-02",
      "filename": "Xie-Towards AGI in Computer Vision Lessons Learned from GPT and Large Language Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.08641v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    "2306.10765v1": {
      "title": "Path to Medical AGI: Unify Domain-specific Medical LLMs with the Lowest Cost",
      "authors": [
        "Juexiao Zhou",
        "Xiuying Chen",
        "Xin Gao"
      ],
      "abstract": "Medical artificial general intelligence (AGI) is an emerging field that aims\nto develop systems specifically designed for medical applications that possess\nthe ability to understand, learn, and apply knowledge across a wide range of\ntasks and domains. Large language models (LLMs) represent a significant step\ntowards AGI. However, training cross-domain LLMs in the medical field poses\nsignificant challenges primarily attributed to the requirement of collecting\ndata from diverse domains. This task becomes particularly difficult due to\nprivacy restrictions and the scarcity of publicly available medical datasets.\nHere, we propose Medical AGI (MedAGI), a paradigm to unify domain-specific\nmedical LLMs with the lowest cost, and suggest a possible path to achieve\nmedical AGI. With an increasing number of domain-specific professional\nmultimodal LLMs in the medical field being developed, MedAGI is designed to\nautomatically select appropriate medical models by analyzing users' questions\nwith our novel adaptive expert selection algorithm. It offers a unified\napproach to existing LLMs in the medical field, eliminating the need for\nretraining regardless of the introduction of new models. This characteristic\nrenders it a future-proof solution in the dynamically advancing medical domain.\nTo showcase the resilience of MedAGI, we conducted an evaluation across three\ndistinct medical domains: dermatology diagnosis, X-ray diagnosis, and analysis\nof pathology pictures. The results demonstrated that MedAGI exhibited\nremarkable versatility and scalability, delivering exceptional performance\nacross diverse domains. Our code is publicly available to facilitate further\nresearch at https://github.com/JoshuaChou2018/MedAGI.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7839d037bb0e41f8a9898f177d2710cfe23633fc",
      "published_date": "2023-06-19",
      "downloaded_date": "2025-02-02",
      "filename": "Zhou-Path to Medical AGI Unify Domain-specific Medical LLMs with the Lowest Cost.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2306.10765v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    "2308.02950v1": {
      "title": "A criterion for Artificial General Intelligence: hypothetic-deductive reasoning, tested on ChatGPT",
      "authors": [
        "Louis Vervoort",
        "Vitaliy Mizyakov",
        "Anastasia Ugleva"
      ],
      "abstract": "We argue that a key reasoning skill that any advanced AI, say GPT-4, should\nmaster in order to qualify as 'thinking machine', or AGI, is\nhypothetic-deductive reasoning. Problem-solving or question-answering can quite\ngenerally be construed as involving two steps: hypothesizing that a certain set\nof hypotheses T applies to the problem or question at hand, and deducing the\nsolution or answer from T - hence the term hypothetic-deductive reasoning. An\nelementary proxy of hypothetic-deductive reasoning is causal reasoning. We\npropose simple tests for both types of reasoning, and apply them to ChatGPT.\nOur study shows that, at present, the chatbot has a limited capacity for either\ntype of reasoning, as soon as the problems considered are somewhat complex.\nHowever, we submit that if an AI would be capable of this type of reasoning in\na sufficiently wide range of contexts, it would be an AGI.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d484e7c525845c98907393e761d85f046dab7eef",
      "published_date": "2023-08-05",
      "downloaded_date": "2025-02-02",
      "filename": "Vervoort-A criterion for Artificial General Intelligence hypothetic-deductive reasoning tested on ChatGPT.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.02950v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2307.08823v1": {
      "title": "Risk assessment at AGI companies: A review of popular risk assessment techniques from other safety-critical industries",
      "authors": [
        "Leonie Koessler",
        "Jonas Schuett"
      ],
      "abstract": "Companies like OpenAI, Google DeepMind, and Anthropic have the stated goal of\nbuilding artificial general intelligence (AGI) - AI systems that perform as\nwell as or better than humans on a wide variety of cognitive tasks. However,\nthere are increasing concerns that AGI would pose catastrophic risks. In light\nof this, AGI companies need to drastically improve their risk management\npractices. To support such efforts, this paper reviews popular risk assessment\ntechniques from other safety-critical industries and suggests ways in which AGI\ncompanies could use them to assess catastrophic risks from AI. The paper\ndiscusses three risk identification techniques (scenario analysis, fishbone\nmethod, and risk typologies and taxonomies), five risk analysis techniques\n(causal mapping, Delphi technique, cross-impact analysis, bow tie analysis, and\nsystem-theoretic process analysis), and two risk evaluation techniques\n(checklists and risk matrices). For each of them, the paper explains how they\nwork, suggests ways in which AGI companies could use them, discusses their\nbenefits and limitations, and makes recommendations. Finally, the paper\ndiscusses when to conduct risk assessments, when to use which technique, and\nhow to use any of them. The reviewed techniques will be obvious to risk\nmanagement professionals in other industries. And they will not be sufficient\nto assess catastrophic risks from AI. However, AGI companies should not skip\nthe straightforward step of reviewing best practices from other industries.",
      "citation_count": 25,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3270d292aa0ce0c01ca4fadfc0f355ff1d45d754",
      "published_date": "2023-07-17",
      "downloaded_date": "2025-02-02",
      "filename": "Koessler-Risk assessment at AGI companies A review of popular risk assessment techniques from other safety-cr....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.08823v1",
      "categories": [
        "cs.CY"
      ]
    },
    "2102.06112v1": {
      "title": "A Metamodel and Framework for Artificial General Intelligence From Theory to Practice",
      "authors": [
        "Hugo Latapie",
        "Ozkan Kilic",
        "Gaowen Liu",
        "Yan Yan",
        "Ramana Kompella",
        "Pei Wang",
        "Kristinn R. Thorisson",
        "Adam Lawrence",
        "Yuhong Sun",
        "Jayanth Srinivasa"
      ],
      "abstract": "This paper introduces a new metamodel-based knowledge representation that\nsignificantly improves autonomous learning and adaptation. While interest in\nhybrid machine learning / symbolic AI systems leveraging, for example,\nreasoning and knowledge graphs, is gaining popularity, we find there remains a\nneed for both a clear definition of knowledge and a metamodel to guide the\ncreation and manipulation of knowledge. Some of the benefits of the metamodel\nwe introduce in this paper include a solution to the symbol grounding problem,\ncumulative learning, and federated learning. We have applied the metamodel to\nproblems ranging from time series analysis, computer vision, and natural\nlanguage understanding and have found that the metamodel enables a wide variety\nof learning mechanisms ranging from machine learning, to graph network analysis\nand learning by reasoning engines to interoperate in a highly synergistic way.\nOur metamodel-based projects have consistently exhibited unprecedented\naccuracy, performance, and ability to generalize. This paper is inspired by the\nstate-of-the-art approaches to AGI, recent AGI-aspiring work, the granular\ncomputing community, as well as Alfred Korzybski's general semantics. One\nsurprising consequence of the metamodel is that it not only enables a new level\nof autonomous learning and optimal functioning for machine intelligences, but\nmay also shed light on a path to better understanding how to improve human\ncognition.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9edca0e670704f656cfd3e73d22791120942e9d1",
      "published_date": "2021-02-11",
      "downloaded_date": "2025-02-02",
      "filename": "Latapie-A Metamodel and Framework for Artificial General Intelligence From Theory to Practice.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.06112v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2401.10904v1": {
      "title": "A Review of Findings from Neuroscience and Cognitive Psychology as Possible Inspiration for the Path to Artificial General Intelligence",
      "authors": [
        "Florin Leon"
      ],
      "abstract": "This review aims to contribute to the quest for artificial general\nintelligence by examining neuroscience and cognitive psychology methods for\npotential inspiration. Despite the impressive advancements achieved by deep\nlearning models in various domains, they still have shortcomings in abstract\nreasoning and causal understanding. Such capabilities should be ultimately\nintegrated into artificial intelligence systems in order to surpass data-driven\nlimitations and support decision making in a way more similar to human\nintelligence. This work is a vertical review that attempts a wide-ranging\nexploration of brain function, spanning from lower-level biological neurons,\nspiking neural networks, and neuronal ensembles to higher-level concepts such\nas brain anatomy, vector symbolic architectures, cognitive and categorization\nmodels, and cognitive architectures. The hope is that these concepts may offer\ninsights for solutions in artificial general intelligence.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/14909e6dd163a98687cd29042c26e34c2f78de4e",
      "published_date": "2024-01-03",
      "downloaded_date": "2025-02-02",
      "filename": "Leon-A Review of Findings from Neuroscience and Cognitive Psychology as Possible Inspiration for the Path....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2401.10904v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2302.08759v1": {
      "title": "Value Engineering for Autonomous Agents",
      "authors": [
        "Nieves Montes",
        "Nardine Osman",
        "Carles Sierra",
        "Marija Slavkovik"
      ],
      "abstract": "Machine Ethics (ME) is concerned with the design of Artificial Moral Agents\n(AMAs), i.e. autonomous agents capable of reasoning and behaving according to\nmoral values. Previous approaches have treated values as labels associated with\nsome actions or states of the world, rather than as integral components of\nagent reasoning. It is also common to disregard that a value-guided agent\noperates alongside other value-guided agents in an environment governed by\nnorms, thus omitting the social dimension of AMAs. In this blue sky paper, we\npropose a new AMA paradigm grounded in moral and social psychology, where\nvalues are instilled into agents as context-dependent goals. These goals\nintricately connect values at individual levels to norms at a collective level\nby evaluating the outcomes most incentivized by the norms in place. We argue\nthat this type of normative reasoning, where agents are endowed with an\nunderstanding of norms' moral implications, leads to value-awareness in\nautonomous agents. Additionally, this capability paves the way for agents to\nalign the norms enforced in their societies with respect to the human values\ninstilled in them, by complementing the value-based reasoning on norms with\nagreement mechanisms to help agents collectively agree on the best set of norms\nthat suit their human values. Overall, our agent model goes beyond the\ntreatment of values as inert labels by connecting them to normative reasoning\nand to the social functionalities needed to integrate value-aware agents into\nour modern hybrid human-computer societies.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4e22f35df17f65efc4be4ef72a29acbd1002ed1d",
      "published_date": "2023-02-17",
      "downloaded_date": "2025-02-02",
      "filename": "Montes-Value Engineering for Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.08759v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    "2310.09217v1": {
      "title": "Multinational AGI Consortium (MAGIC): A Proposal for International Coordination on AI",
      "authors": [
        "Jason Hausenloy",
        "Andrea Miotti",
        "Claire Dennis"
      ],
      "abstract": "This paper proposes a Multinational Artificial General Intelligence\nConsortium (MAGIC) to mitigate existential risks from advanced artificial\nintelligence (AI). MAGIC would be the only institution in the world permitted\nto develop advanced AI, enforced through a global moratorium by its signatory\nmembers on all other advanced AI development. MAGIC would be exclusive,\nsafety-focused, highly secure, and collectively supported by member states,\nwith benefits distributed equitably among signatories. MAGIC would allow narrow\nAI models to flourish while significantly reducing the possibility of\nmisaligned, rogue, breakout, or runaway outcomes of general-purpose systems. We\ndo not address the political feasibility of implementing a moratorium or\naddress the specific legislative strategies and rules needed to enforce a ban\non high-capacity AGI training runs. Instead, we propose one positive vision of\nthe future, where MAGIC, as a global governance regime, can lay the groundwork\nfor long-term, safe regulation of advanced AI.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5a9a37ad50fc6ce73b6999f57129c9b2b787115e",
      "published_date": "2023-10-13",
      "downloaded_date": "2025-02-02",
      "filename": "Hausenloy-Multinational AGI Consortium MAGIC A Proposal for International Coordination on AI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.09217v1",
      "categories": [
        "cs.AI"
      ]
    },
    "0801.3048v1": {
      "title": "Human Heuristics for Autonomous Agents",
      "authors": [
        "Franco Bagnoli",
        "Andrea Guazzini",
        "Pietro Lio'"
      ],
      "abstract": "We investigate the problem of autonomous agents processing pieces of\ninformation that may be corrupted (tainted). Agents have the option of\ncontacting a central database for a reliable check of the status of the\nmessage, but this procedure is costly and therefore should be used with\nparsimony. Agents have to evaluate the risk of being infected, and decide if\nand when communicating partners are affordable. Trustability is implemented as\na personal (one-to-one) record of past contacts among agents, and as a\nmean-field monitoring of the level of message corruption. Moreover, this\ninformation is slowly forgotten in time, so that at the end everybody is\nchecked against the database. We explore the behavior of a homogeneous system\nin the case of a fixed pool of spreaders of corrupted messages, and in the case\nof spontaneous appearance of corrupted messages.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cc04c29e2e9165902ed3bb73c722a53705922a4c",
      "published_date": "2008-01-19",
      "downloaded_date": "2025-02-02",
      "filename": "Bagnoli-Human Heuristics for Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/0801.3048v1",
      "categories": [
        "cs.MA",
        "cs.HC",
        "cs.NI"
      ]
    },
    "2405.04325v2": {
      "title": "Deception in Reinforced Autonomous Agents",
      "authors": [
        "Atharvan Dogra",
        "Krishna Pillutla",
        "Ameet Deshpande",
        "Ananya B Sai",
        "John Nay",
        "Tanmay Rajpurohit",
        "Ashwin Kalyan",
        "Balaraman Ravindran"
      ],
      "abstract": "We explore the ability of large language model (LLM)-based agents to engage\nin subtle deception such as strategically phrasing and intentionally\nmanipulating information to misguide and deceive other agents. This harmful\nbehavior can be hard to detect, unlike blatant lying or unintentional\nhallucination. We build an adversarial testbed mimicking a legislative\nenvironment where two LLMs play opposing roles: a corporate *lobbyist*\nproposing amendments to bills that benefit a specific company while evading a\n*critic* trying to detect this deception. We use real-world legislative bills\nmatched with potentially affected companies to ground these interactions. Our\nresults show that LLM lobbyists initially exhibit limited deception against\nstrong LLM critics which can be further improved through simple verbal\nreinforcement, significantly enhancing their deceptive capabilities, and\nincreasing deception rates by up to 40 points. This highlights the risk of\nautonomous agents manipulating other agents through seemingly neutral language\nto attain self-serving goals.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/024d740fc6f1826b06154d37f2d074512b522c70",
      "published_date": "2024-05-07",
      "downloaded_date": "2025-02-02",
      "filename": "Dogra-Deception in Reinforced Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.04325v2",
      "categories": [
        "cs.CL"
      ]
    },
    "2304.06488v1": {
      "title": "One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era",
      "authors": [
        "Chaoning Zhang",
        "Chenshuang Zhang",
        "Chenghao Li",
        "Yu Qiao",
        "Sheng Zheng",
        "Sumit Kumar Dam",
        "Mengchun Zhang",
        "Jung Uk Kim",
        "Seong Tae Kim",
        "Jinwoo Choi",
        "Gyeong-Moon Park",
        "Sung-Ho Bae",
        "Lik-Hang Lee",
        "Pan Hui",
        "In So Kweon",
        "Choong Seon Hong"
      ],
      "abstract": "OpenAI has recently released GPT-4 (a.k.a. ChatGPT plus), which is\ndemonstrated to be one small step for generative AI (GAI), but one giant leap\nfor artificial general intelligence (AGI). Since its official release in\nNovember 2022, ChatGPT has quickly attracted numerous users with extensive\nmedia coverage. Such unprecedented attention has also motivated numerous\nresearchers to investigate ChatGPT from various aspects. According to Google\nscholar, there are more than 500 articles with ChatGPT in their titles or\nmentioning it in their abstracts. Considering this, a review is urgently\nneeded, and our work fills this gap. Overall, this work is the first to survey\nChatGPT with a comprehensive review of its underlying technology, applications,\nand challenges. Moreover, we present an outlook on how ChatGPT might evolve to\nrealize general-purpose AIGC (a.k.a. AI-generated content), which will be a\nsignificant milestone for the development of AGI.",
      "citation_count": 116,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4de290467d903b9977e31b3d4084006789bd6ebd",
      "published_date": "2023-04-04",
      "downloaded_date": "2025-02-02",
      "filename": "Zhang-One Small Step for Generative AI One Giant Leap for AGI A Complete Survey on ChatGPT in AIGC Era.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.06488v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    },
    "2004.04574v9": {
      "title": "Model-based actor-critic: GAN (model generator) + DRL (actor-critic) => AGI",
      "authors": [
        "Aras Dargazany"
      ],
      "abstract": "Our effort is toward unifying GAN and DRL algorithms into a unifying AI model\n(AGI or general-purpose AI or artificial general intelligence which has\ngeneral-purpose applications to: (A) offline learning (of stored data) like GAN\nin (un/semi-/fully-)SL setting such as big data analytics (mining) and\nvisualization; (B) online learning (of real or simulated devices) like DRL in\nRL setting (with/out environment reward) such as (real or simulated) robotics\nand control; Our core proposal is adding an (generative/predictive) environment\nmodel to the actor-critic (model-free) architecture which results in a\nmodel-based actor-critic architecture with temporal-differencing (TD) error and\nan episodic memory. The proposed AI model is similar to (model-free) DDPG and\ntherefore it's called model-based DDPG. To evaluate it, we compare it with\n(model-free) DDPG by applying them both to a variety (wide range) of\nindependent simulated robotic and control task environments in OpenAI Gym and\nUnity Agents. Our initial limited experiments show that DRL and GAN in\nmodel-based actor-critic results in an incremental goal-driven intellignce\nrequired to solve each task with similar performance to (model-free) DDPG. Our\nfuture focus is to investigate the proposed AI model potential to: (A) unify\nDRL field inside AI by producing competitive performance compared to the best\nof model-based (PlaNet) and model-free (D4PG) approaches; (B) bridge the gap\nbetween AI and robotics communities by solving the important problem of reward\nengineering with learning the reward function by demonstration.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-04-04",
      "downloaded_date": "2025-02-02",
      "filename": "Dargazany-Model-based actor-critic GAN model generator  DRL actor-critic  AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2004.04574v9",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2403.05131v2": {
      "title": "Sora as an AGI World Model? A Complete Survey on Text-to-Video Generation",
      "authors": [
        "Joseph Cho",
        "Fachrina Dewi Puspitasari",
        "Sheng Zheng",
        "Jingyao Zheng",
        "Lik-Hang Lee",
        "Tae-Ho Kim",
        "Choong Seon Hong",
        "Chaoning Zhang"
      ],
      "abstract": "The evolution of video generation from text, starting with animating MNIST\nnumbers to simulating the physical world with Sora, has progressed at a\nbreakneck speed over the past seven years. While often seen as a superficial\nexpansion of the predecessor text-to-image generation model, text-to-video\ngeneration models are developed upon carefully engineered constituents. Here,\nwe systematically discuss these elements consisting of but not limited to core\nbuilding blocks (vision, language, and temporal) and supporting features from\nthe perspective of their contributions to achieving a world model. We employ\nthe PRISMA framework to curate 97 impactful research articles from renowned\nscientific databases primarily studying video synthesis using text conditions.\nUpon minute exploration of these manuscripts, we observe that text-to-video\ngeneration involves more intricate technologies beyond the plain extension of\ntext-to-image generation. Our additional review into the shortcomings of\nSora-generated videos pinpoints the call for more in-depth studies in various\nenabling aspects of video generation such as dataset, evaluation metric,\nefficient architecture, and human-controlled generation. Finally, we conclude\nthat the study of the text-to-video generation may still be in its infancy,\nrequiring contribution from the cross-discipline research community towards its\nadvancement as the first step to realize artificial general intelligence (AGI).",
      "citation_count": 23,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ea3d36372f12170a4aa3dd542d3ea014e5e10b09",
      "published_date": "2024-03-08",
      "downloaded_date": "2025-02-02",
      "filename": "Cho-Sora as an AGI World Model A Complete Survey on Text-to-Video Generation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.05131v2",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    "2411.14486v1": {
      "title": "The Impossible Test: A 2024 Unsolvable Dataset and A Chance for an AGI Quiz",
      "authors": [
        "David Noever",
        "Forrest McKee"
      ],
      "abstract": "This research introduces a novel evaluation framework designed to assess\nlarge language models' (LLMs) ability to acknowledge uncertainty on 675\nfundamentally unsolvable problems. Using a curated dataset of graduate-level\ngrand challenge questions with intentionally unknowable answers, we evaluated\ntwelve state-of-the-art LLMs, including both open and closed-source models, on\ntheir propensity to admit ignorance rather than generate plausible but\nincorrect responses. The best models scored in 62-68% accuracy ranges for\nadmitting the problem solution was unknown in fields ranging from biology to\nphilosophy and mathematics. We observed an inverse relationship between problem\ndifficulty and model accuracy, with GPT-4 demonstrating higher rates of\nuncertainty acknowledgment on more challenging problems (35.8%) compared to\nsimpler ones (20.0%). This pattern indicates that models may be more prone to\ngenerate speculative answers when problems appear more tractable. The study\nalso revealed significant variations across problem categories, with models\nshowing difficulty in acknowledging uncertainty in invention and NP-hard\nproblems while performing relatively better on philosophical and psychological\nchallenges. These results contribute to the growing body of research on\nartificial general intelligence (AGI) assessment by highlighting the importance\nof uncertainty recognition as a critical component of future machine\nintelligence evaluation. This impossibility test thus extends previous\ntheoretical frameworks for universal intelligence testing by providing\nempirical evidence of current limitations in LLMs' ability to recognize their\nown knowledge boundaries, suggesting new directions for improving model\ntraining architectures and evaluation approaches.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/adcc0788f27dc2f9ab5a3aa6d449efe17b236a3f",
      "published_date": "2024-11-20",
      "downloaded_date": "2025-02-02",
      "filename": "Noever-The Impossible Test A 2024 Unsolvable Dataset and A Chance for an AGI Quiz.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.14486v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    "1604.00545v3": {
      "title": "The AGI Containment Problem",
      "authors": [
        "James Babcock",
        "Janos Kramar",
        "Roman Yampolskiy"
      ],
      "abstract": "There is considerable uncertainty about what properties, capabilities and\nmotivations future AGIs will have. In some plausible scenarios, AGIs may pose\nsecurity risks arising from accidents and defects. In order to mitigate these\nrisks, prudent early AGI research teams will perform significant testing on\ntheir creations before use. Unfortunately, if an AGI has human-level or greater\nintelligence, testing itself may not be safe; some natural AGI goal systems\ncreate emergent incentives for AGIs to tamper with their test environments,\nmake copies of themselves on the internet, or convince developers and operators\nto do dangerous things. In this paper, we survey the AGI containment problem -\nthe question of how to build a container in which tests can be conducted safely\nand reliably, even on AGIs with unknown motivations and capabilities that could\nbe dangerous. We identify requirements for AGI containers, available\nmechanisms, and weaknesses that need to be addressed.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2016-04-02",
      "downloaded_date": "2025-02-02",
      "filename": "Babcock-The AGI Containment Problem.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1604.00545v3",
      "categories": [
        "cs.AI",
        "I.2.0; I.2.m"
      ]
    },
    "2304.08699v1": {
      "title": "Assessing Video Game Balance using Autonomous Agents",
      "authors": [
        "Cristiano Politowski",
        "Fabio Petrillo",
        "Ghizlane ElBoussaidi",
        "Gabriel C. Ullmann",
        "Yann-GaÃ«l GuÃ©hÃ©neuc"
      ],
      "abstract": "As the complexity and scope of games increase, game testing, also called\nplaytesting, becomes an essential activity to ensure the quality of video\ngames. Yet, the manual, ad-hoc nature of game testing leaves space for\nautomation. In this paper, we research, design, and implement an approach to\nsupplement game testing to balance video games with autonomous agents. We\nevaluate our approach with two platform games. We bring a systematic way to\nassess if a game is balanced by (1) comparing the difficulty levels between\ngame versions and issues with the game design, and (2) the game demands for\nskill or luck.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-04-18",
      "downloaded_date": "2025-02-02",
      "filename": "Politowski-Assessing Video Game Balance using Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.08699v1",
      "categories": [
        "cs.SE"
      ]
    },
    "2410.21296v2": {
      "title": "The Trap of Presumed Equivalence: Artificial General Intelligence Should Not Be Assessed on the Scale of Human Intelligence",
      "authors": [
        "Serge Dolgikh"
      ],
      "abstract": "A traditional approach to assessing emerging intelligence in the theory of\nintelligent systems is based on the similarity, \"imitation\" of human-like\nactions and behaviors, benchmarking the performance of intelligent systems on\nthe scale of human cognitive skills. In this work we attempt to outline the\nshortcomings of this line of thought, which is based on the implicit\npresumption of the equivalence and compatibility of the originating and\nemergent intelligences. We provide arguments to the point that under some\nnatural assumptions, developing intelligent systems will be able to form their\nown intents and objectives. Then, the difference in the rate of progress of\nnatural and artificial systems that was noted on multiple occasions in the\ndiscourse on artificial intelligence can lead to the scenario of a progressive\ndivergence of the intelligences, in their cognitive abilities, functions and\nresources, values, ethical frameworks, worldviews, intents and existential\nobjectives: the scenario of the AGI evolutionary gap. We discuss evolutionary\nprocesses that can guide the development of emergent intelligent systems and\nattempt to identify the starting point of the progressive divergence scenario.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/27398f640045ccd8a33a386c7e4aaa4079fa363d",
      "published_date": "2024-10-14",
      "downloaded_date": "2025-02-02",
      "filename": "Dolgikh-The Trap of Presumed Equivalence Artificial General Intelligence Should Not Be Assessed on the Scale....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.21296v2",
      "categories": [
        "cs.NE",
        "68T01, 68T05, 91E45"
      ]
    },
    "2304.11817v1": {
      "title": "Active Probing and Influencing Human Behaviors Via Autonomous Agents",
      "authors": [
        "Shuangge Wang",
        "Yiwei Lyu",
        "John M. Dolan"
      ],
      "abstract": "Autonomous agents (robots) face tremendous challenges while interacting with\nheterogeneous human agents in close proximity. One of these challenges is that\nthe autonomous agent does not have an accurate model tailored to the specific\nhuman that the autonomous agent is interacting with, which could sometimes\nresult in inefficient human-robot interaction and suboptimal system dynamics.\nDeveloping an online method to enable the autonomous agent to learn information\nabout the human model is therefore an ongoing research goal. Existing\napproaches position the robot as a passive learner in the environment to\nobserve the physical states and the associated human response. This passive\ndesign, however, only allows the robot to obtain information that the human\nchooses to exhibit, which sometimes doesn't capture the human's full intention.\nIn this work, we present an online optimization-based probing procedure for the\nautonomous agent to clarify its belief about the human model in an active\nmanner. By optimizing an information radius, the autonomous agent chooses the\naction that most challenges its current conviction. This procedure allows the\nautonomous agent to actively probe the human agents to reveal information\nthat's previously unavailable to the autonomous agent. With this gathered\ninformation, the autonomous agent can interactively influence the human agent\nfor some designated objectives. Our main contributions include a coherent\ntheoretical framework that unifies the probing and influence procedures and two\ncase studies in autonomous driving that show how active probing can help to\ncreate better participant experience during influence, like higher efficiency\nor less perturbations.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6a97247bc1cae5a140207af004860b957fd0ef51",
      "published_date": "2023-04-24",
      "downloaded_date": "2025-02-02",
      "filename": "Wang-Active Probing and Influencing Human Behaviors Via Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2304.11817v1",
      "categories": [
        "cs.RO"
      ]
    },
    "2009.05898v1": {
      "title": "Resolving Resource Incompatibilities in Intelligent Agents",
      "authors": [
        "Mariela Morveli-Espinoza",
        "Ayslan Possebom",
        "Cesar Augusto Tacla"
      ],
      "abstract": "An intelligent agent may in general pursue multiple procedural goals\nsimultaneously, which may lead to arise some conflicts (incompatibilities)\namong them. In this paper, we focus on the incompatibilities that emerge due to\nresources limitations. Thus, the contribution of this article is twofold. On\none hand, we give an algorithm for identifying resource incompatibilities from\na set of pursued goals and, on the other hand, we propose two ways for\nselecting those goals that will continue to be pursued: (i) the first is based\non abstract argumentation theory, and (ii) the second based on two algorithms\ndeveloped by us. We illustrate our proposal using examples throughout the\narticle.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8fbfbe79be17a7eb7c07c033d0e045ecb55cd171",
      "published_date": "2020-09-13",
      "downloaded_date": "2025-02-02",
      "filename": "Morveli-Espinoza-Resolving Resource Incompatibilities in Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.05898v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1504.05811v1": {
      "title": "Learning of Behavior Trees for Autonomous Agents",
      "authors": [
        "Michele Colledanchise",
        "Ramviyas Parasuraman",
        "Petter Ãgren"
      ],
      "abstract": "Definition of an accurate system model for Automated Planner (AP) is often\nimpractical, especially for real-world problems. Conversely, off-the-shelf\nplanners fail to scale up and are domain dependent. These drawbacks are\ninherited from conventional transition systems such as Finite State Machines\n(FSMs) that describes the action-plan execution generated by the AP. On the\nother hand, Behavior Trees (BTs) represent a valid alternative to FSMs\npresenting many advantages in terms of modularity, reactiveness, scalability\nand domain-independence. In this paper, we propose a model-free AP framework\nusing Genetic Programming (GP) to derive an optimal BT for an autonomous agent\nto achieve a given goal in unknown (but fully observable) environments. We\nillustrate the proposed framework using experiments conducted with an open\nsource benchmark Mario AI for automated generation of BTs that can play the\ngame character Mario to complete a certain level at various levels of\ndifficulty to include enemies and obstacles.",
      "citation_count": 91,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4eb1beb7ff9ee475f778a546bbeae316a147a65e",
      "published_date": "2015-04-22",
      "downloaded_date": "2025-02-02",
      "filename": "Colledanchise-Learning of Behavior Trees for Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1504.05811v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2207.00822v1": {
      "title": "Kernel Based Cognitive Architecture for Autonomous Agents",
      "authors": [
        "Alexander Serov"
      ],
      "abstract": "One of the main problems of modern cognitive architectures is an excessively\nschematic approach to modeling the processes of cognitive activity. It does not\nallow the creation of a universal architecture that would be capable of\nreproducing mental functions without using a predetermined set of perceptual\npatterns. This paper considers an evolutionary approach to creating a cognitive\nfunctionality. The basis of our approach is the use of the functional kernel\nwhich consistently generates the intellectual functions of an autonomous agent.\nWe consider a cognitive architecture which ensures the evolution of the agent\non the basis of Symbol Emergence Problem solution. Evolution of cognitive\nabilities of the agent is described on the basis of the theory of\nconstructivism.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/05a41ec46d987f7618eda1baf0199a0d9a989bab",
      "published_date": "2022-07-02",
      "downloaded_date": "2025-02-02",
      "filename": "Serov-Kernel Based Cognitive Architecture for Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2207.00822v1",
      "categories": [
        "cs.AI",
        "68T42"
      ]
    },
    "2303.01646v1": {
      "title": "Dynamic Competency Self-Assessment for Autonomous Agents",
      "authors": [
        "Nicholas Conlon",
        "Nisar R. Ahmed",
        "Daniel Szafir"
      ],
      "abstract": "As autonomous robots are deployed in increasingly complex environments,\nplatform degradation, environmental uncertainties, and deviations from\nvalidated operation conditions can make it difficult for human partners to\nunderstand robot capabilities and limitations. The ability for a robot to\nself-assess its competency in dynamic and uncertain environments will be a\ncrucial next step in successful human-robot teaming. This work presents and\nevaluates an Event-Triggered Generalized Outcome Assessment (ET-GOA) algorithm\nfor autonomous agents to dynamically assess task confidence during execution.\nThe algorithm uses a fast online statistical test of the agent's observations\nand its model predictions to decide when competency assessment is needed. We\nprovide experimental results using ET-GOA to generate competency reports during\na simulated delivery task and suggest future research directions for\nself-assessing agents.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/605c48496f0e1103e9122f7acb89630e46c81795",
      "published_date": "2023-03-03",
      "downloaded_date": "2025-02-02",
      "filename": "Conlon-Dynamic Competency Self-Assessment for Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2303.01646v1",
      "categories": [
        "cs.RO",
        "cs.HC"
      ]
    },
    "0902.0798v1": {
      "title": "Alleviating Media Bias Through Intelligent Agent Blogging",
      "authors": [
        "Ernesto Diaz-Aviles"
      ],
      "abstract": "Consumers of mass media must have a comprehensive, balanced and plural\nselection of news to get an unbiased perspective; but achieving this goal can\nbe very challenging, laborious and time consuming. News stories development\nover time, its (in)consistency, and different level of coverage across the\nmedia outlets are challenges that a conscientious reader has to overcome in\norder to alleviate bias.\n  In this paper we present an intelligent agent framework currently\nfacilitating analysis of the main sources of on-line news in El Salvador. We\nshow how prior tools of text analysis and Web 2.0 technologies can be combined\nwith minimal manual intervention to help individuals on their rational decision\nprocess, while holding media outlets accountable for their work.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/67c18826f479de01d3c9ee10b47fbc5e17eac537",
      "published_date": "2009-02-04",
      "downloaded_date": "2025-02-02",
      "filename": "Diaz-Aviles-Alleviating Media Bias Through Intelligent Agent Blogging.pdf",
      "arxiv_url": "http://arxiv.org/pdf/0902.0798v1",
      "categories": [
        "cs.AI",
        "I.2.11; J.4; H.3"
      ]
    },
    "1911.04710v1": {
      "title": "Aplib: Tactical Programming of Intelligent Agents",
      "authors": [
        "I. S. W. B. Prasetya"
      ],
      "abstract": "This paper presents aplib, a Java library for programming intelligent agents,\nfeaturing BDI and multi agency, but adding on top of it a novel layer of\ntactical programming inspired by the domain of theorem proving. Aplib is also\nimplemented in such a way to provide the fluency of a Domain Specific Language\n(DSL). Compared to dedicated BDI agent programming languages such as JASON,\n2APL, or GOAL,aplib's embedded DSL approach does mean that \\aplib\\ programmers\nwill still be limited by Java syntax, but on other hand they get all the\nadvantages that Java programmers get: rich language features (object\norientation, static type checking, $\\lambda$-expression, libraries, etc), a\nwhole array of development tools, integration with other technologies, large\ncommunity, etc.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9665d955c99794287d3a437abc6a27635a172f14",
      "published_date": "2019-11-12",
      "downloaded_date": "2025-02-02",
      "filename": "Prasetya-Aplib Tactical Programming of Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1911.04710v1",
      "categories": [
        "cs.AI",
        "cs.PL",
        "68T42"
      ]
    },
    "2104.00387v1": {
      "title": "Commonsense Spatial Reasoning for Visually Intelligent Agents",
      "authors": [
        "Agnese Chiatti",
        "Gianluca Bardaro",
        "Enrico Motta",
        "Enrico Daga"
      ],
      "abstract": "Service robots are expected to reliably make sense of complex, fast-changing\nenvironments. From a cognitive standpoint, they need the appropriate reasoning\ncapabilities and background knowledge required to exhibit human-like Visual\nIntelligence. In particular, our prior work has shown that the ability to\nreason about spatial relations between objects in the world is a key\nrequirement for the development of Visually Intelligent Agents. In this paper,\nwe present a framework for commonsense spatial reasoning which is tailored to\nreal-world robotic applications. Differently from prior approaches to\nqualitative spatial reasoning, the proposed framework is robust to variations\nin the robot's viewpoint and object orientation. The spatial relations in the\nproposed framework are also mapped to the types of commonsense predicates used\nto describe typical object configurations in English. In addition, we also show\nhow this formally-defined framework can be implemented in a concrete spatial\ndatabase.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/92d4faa7003c813c932d46a0e31ce75b00b942a9",
      "published_date": "2021-04-01",
      "downloaded_date": "2025-02-02",
      "filename": "Chiatti-Commonsense Spatial Reasoning for Visually Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.00387v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    },
    "2202.02574v1": {
      "title": "Governance of Autonomous Agents on the Web: Challenges and Opportunities",
      "authors": [
        "Timotheus Kampik",
        "Adnane Mansour",
        "Olivier Boissier",
        "Sabrina Kirrane",
        "Julian Padget",
        "Terry R. Payne",
        "Munindar P. Singh",
        "Valentina Tamma",
        "Antoine Zimmermann"
      ],
      "abstract": "The study of autonomous agents has a long tradition in the Multiagent Systems\nand the Semantic Web communities, with applications ranging from automating\nbusiness processes to personal assistants. More recently, the Web of Things\n(WoT), which is an extension of the Internet of Things (IoT) with metadata\nexpressed in Web standards, and its community provide further motivation for\npushing the autonomous agents research agenda forward. Although representing\nand reasoning about norms, policies and preferences is crucial to ensuring that\nautonomous agents act in a manner that satisfies stakeholder requirements,\nnormative concepts, policies and preferences have yet to be considered as\nfirst-class abstractions in Web-based multiagent systems. Towards this end,\nthis paper motivates the need for alignment and joint research across the\nMultiagent Systems, Semantic Web, and WoT communities, introduces a conceptual\nframework for governance of autonomous agents on the Web, and identifies\nseveral research challenges and opportunities.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3d1a79bebf8d38f2996233241c9ecbb372273558",
      "published_date": "2022-02-05",
      "downloaded_date": "2025-02-02",
      "filename": "Kampik-Governance of Autonomous Agents on the Web Challenges and Opportunities.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2202.02574v1",
      "categories": [
        "cs.MA",
        "cs.SE"
      ]
    },
    "2308.11432v6": {
      "title": "A Survey on Large Language Model based Autonomous Agents",
      "authors": [
        "Lei Wang",
        "Chen Ma",
        "Xueyang Feng",
        "Zeyu Zhang",
        "Hao Yang",
        "Jingsen Zhang",
        "Zhiyuan Chen",
        "Jiakai Tang",
        "Xu Chen",
        "Yankai Lin",
        "Wayne Xin Zhao",
        "Zhewei Wei",
        "Ji-Rong Wen"
      ],
      "abstract": "Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.",
      "citation_count": 787,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/28c6ac721f54544162865f41c5692e70d61bccab",
      "published_date": "2023-08-22",
      "downloaded_date": "2025-02-02",
      "filename": "Wang-A Survey on Large Language Model based Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.11432v6",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    "2411.08754v1": {
      "title": "Logic-based Knowledge Awareness for Autonomous Agents in Continuous Spaces",
      "authors": [
        "Arabinda Ghosh",
        "Mahmoud Salamati",
        "Sadegh Soudjani"
      ],
      "abstract": "This paper presents a step towards a formal controller design method for\nautonomous agents based on knowledge awareness to improve decision-making. Our\napproach is to first create an organized repository of information (a knowledge\nbase) for autonomous agents which can be accessed and then translated into\ntemporal specifications. Secondly, to develop a controller with formal\nguarantees that meets a combination of mission-specific objective and the\nspecification from the knowledge base, we utilize an abstraction-based\ncontroller design (ABCD) approach, capable of managing both nonlinear dynamics\nand temporal requirements. Unlike the conventional offline ABCD approach, our\nmethod dynamically updates the controller whenever the knowledge base prompts\nchanges in the specifications. A three-dimensional nonlinear car model\nnavigating an urban road scenario with traffic signs and obstacles is\nconsidered for validation. Results show the effectiveness of the method in\nguiding the autonomous agents to the target while complying with the knowledge\nbase and the mission-specific objective.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/343bfba010ed93161f0834907f18407fa17f9d7d",
      "published_date": "2024-11-13",
      "downloaded_date": "2025-02-02",
      "filename": "Ghosh-Logic-based Knowledge Awareness for Autonomous Agents in Continuous Spaces.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2411.08754v1",
      "categories": [
        "eess.SY",
        "cs.SY"
      ]
    },
    "2407.16362v1": {
      "title": "Nudging Using Autonomous Agents: Risks and Ethical Considerations",
      "authors": [
        "Vivek Nallur",
        "Karen Renaud",
        "Aleksei Gudkov"
      ],
      "abstract": "This position paper briefly discusses nudging, its use by autonomous agents,\npotential risks and ethical considerations while creating such systems. Instead\nof taking a normative approach, which guides all situations, the paper proposes\na risk-driven questions-and-answer approach. The paper takes the position that\nthis is a pragmatic method, that is transparent about beneficial intentions,\nforeseeable risks, and mitigations. Given the uncertainty in AI and autonomous\nagent capabilities, we believe that such pragmatic methods offer a plausibly\nsafe path, without sacrificing flexibility in domain and technology.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ec2f8bec921f2315d5d83885b9d8fe0498d08f0c",
      "published_date": "2024-07-23",
      "downloaded_date": "2025-02-02",
      "filename": "Nallur-Nudging Using Autonomous Agents Risks and Ethical Considerations.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.16362v1",
      "categories": [
        "cs.CY"
      ]
    },
    "0905.4085v2": {
      "title": "Intelligent Agents: A Physics Education Opportunity in Latin-America",
      "authors": [
        "D. Sanchez-Guzman",
        "Cesar Mora",
        "R. Garcia-Salcedo"
      ],
      "abstract": "Intelligent Agents are being applied in a wide range of processes and\neveryday applications. Their development is not new, in recent years they have\nhad an increased attention and design in learning and as mentoring tools. In\nthis paper we discuss the definition of what an intelligent agent is; how they\nare applied; how thy look like; recent implementations of agents; agents as\nsupport in learning process; their state in Latin-American countries and future\ndevelopments and trends that will permit a better communication between people\nand agents.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ada7c7c90e62c73edd88cea8fdb83f70789ae7fa",
      "published_date": "2009-05-25",
      "downloaded_date": "2025-02-02",
      "filename": "Sanchez-Guzman-Intelligent Agents A Physics Education Opportunity in Latin-America.pdf",
      "arxiv_url": "http://arxiv.org/pdf/0905.4085v2",
      "categories": [
        "physics.ed-ph"
      ]
    },
    "1901.06613v2": {
      "title": "Beyond Turing: Intelligent Agents Centered on the User",
      "authors": [
        "Maxine Eskenazi",
        "Shikib Mehri",
        "Evgeniia Razumovskaia",
        "Tiancheng Zhao"
      ],
      "abstract": "Most research on intelligent agents centers on the agent and not on the user.\nWe look at the origins of agent-centric research for slot-filling, gaming and\nchatbot agents. We then argue that it is important to concentrate more on the\nuser. After reviewing relevant literature, some approaches for creating and\nassessing user-centric systems are proposed.",
      "citation_count": 12,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/839e30cc776a999a1a6da72621d52d3a556ad1c7",
      "published_date": "2019-01-20",
      "downloaded_date": "2025-02-02",
      "filename": "Eskenazi-Beyond Turing Intelligent Agents Centered on the User.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1901.06613v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    "2410.11872v2": {
      "title": "ClickAgent: Enhancing UI Location Capabilities of Autonomous Agents",
      "authors": [
        "Jakub Hoscilowicz",
        "Bartosz Maj",
        "Bartosz Kozakiewicz",
        "Oleksii Tymoshchuk",
        "Artur Janicki"
      ],
      "abstract": "With the growing reliance on digital devices equipped with graphical user\ninterfaces (GUIs), such as computers and smartphones, the need for effective\nautomation tools has become increasingly important. While multimodal large\nlanguage models (MLLMs) like GPT-4V excel in many areas, they struggle with GUI\ninteractions, limiting their effectiveness in automating everyday tasks. In\nthis paper, we introduce ClickAgent, a novel framework for building autonomous\nagents. In ClickAgent, the MLLM handles reasoning and action planning, while a\nseparate UI location model (e.g., SeeClick) identifies the relevant UI elements\non the screen. This approach addresses a key limitation of current-generation\nMLLMs: their difficulty in accurately locating UI elements. ClickAgent\noutperforms other prompt-based autonomous agents (CogAgent, AppAgent) on the\nAITW benchmark. Our evaluation was conducted on both an Android smartphone\nemulator and an actual Android smartphone, using the task success rate as the\nkey metric for measuring agent performance.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/74b75fcd71d698712b68e1077e8f178736c253da",
      "published_date": "2024-10-09",
      "downloaded_date": "2025-02-02",
      "filename": "Hoscilowicz-ClickAgent Enhancing UI Location Capabilities of Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.11872v2",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ]
    },
    "math/0405439v1": {
      "title": "Self-organization in a group of mobile autonomous agents",
      "authors": [
        "Long Wang"
      ],
      "abstract": "This paper considers a discrete time swarm model of a group of mobile\nautonomous agents with a simple attraction and repulsion function for swarm\naggregation and investigates its stability properties. In particular, it is\nproved that the individuals (members) of the swarm will aggregate and form a\ncohesive cluster of a finite size depending only on the parameters of the swarm\nmodel in a finite time, and the swarm system is completely stable.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fe4e0443ea6bae58971d80fdbc3034296de1c4d0",
      "published_date": "2004-05-23",
      "downloaded_date": "2025-02-02",
      "filename": "Wang-Self-organization in a group of mobile autonomous agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/math/0405439v1",
      "categories": [
        "math.OC",
        "math.DS",
        "93"
      ]
    },
    "1905.05253v1": {
      "title": "Features and Operation of an Autonomous Agent for Cyber Defense",
      "authors": [
        "Michael J. De Lucia",
        "Allison Newcomb",
        "Alexander Kott"
      ],
      "abstract": "An ever increasing number of battlefield devices that are capable of\ncollecting, processing, storing, and communicating information are rapidly\nbecoming interconnected. The staggering number of connected devices on the\nbattlefield greatly increases the possibility that an adversary could find ways\nto exploit hardware or software vulnerabilities, degrading or denying\nWarfighters the assured and secure use of those devices. Autonomous software\nagents will become necessities to manage, defend, and react to cyber threats in\nthe future battlespace. The number of connected devices increases\ndisproportionately to the number of cyber experts that could be available\nwithin an operational environment. In this paper, an autonomous agent\ncapability and a scenario of how it could operate are proposed. The goal of\ndeveloping such capability is to increase the security posture of the Internet\nof Battlefield Things and meet the challenges of an increasingly complex\nbattlefield. This paper describes an illustrative scenario in a notional use\ncase and discusses the challenges associated with such autonomous agents. We\nconclude by offering ideas for potential research into developing autonomous\nagents suitable for cyber defense in a battlefield environment.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/45a76ba2e14704bcc44096a84dcd2efb1e721e2a",
      "published_date": "2019-05-13",
      "downloaded_date": "2025-02-02",
      "filename": "Lucia-Features and Operation of an Autonomous Agent for Cyber Defense.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1905.05253v1",
      "categories": [
        "cs.CR"
      ]
    },
    "0803.1604v1": {
      "title": "Using Intelligent Agents to Understand Management Practices and Retail Productivity",
      "authors": [
        "Peer-Olaf Siebers",
        "Uwe Aickelin",
        "Helen Celia",
        "Christopher Clegg"
      ],
      "abstract": "Intelligent agents offer a new and exciting way of understanding the world of\nwork. In this paper we apply agent-based modeling and simulation to investigate\na set of problems in a retail context. Specifically, we are working to\nunderstand the relationship between human resource management practices and\nretail productivity. Despite the fact we are working within a relatively novel\nand complex domain, it is clear that intelligent agents could offer potential\nfor fostering sustainable organizational capabilities in the future. The\nproject is still at an early stage. So far we have conducted a case study in a\nUK department store to collect data and capture impressions about operations\nand actors within departments. Furthermore, based on our case study we have\nbuilt and tested our first version of a retail branch simulator which we will\npresent in this paper.",
      "citation_count": 26,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c018034fc436da3ca26ff82237774b33823ba7be",
      "published_date": "2008-03-11",
      "downloaded_date": "2025-02-02",
      "filename": "Siebers-Using Intelligent Agents to Understand Management Practices and Retail Productivity.pdf",
      "arxiv_url": "http://arxiv.org/pdf/0803.1604v1",
      "categories": [
        "cs.NE",
        "cs.CE",
        "cs.MA"
      ]
    },
    "2203.12670v1": {
      "title": "Competency Assessment for Autonomous Agents using Deep Generative Models",
      "authors": [
        "Aastha Acharya",
        "Rebecca Russell",
        "Nisar R. Ahmed"
      ],
      "abstract": "For autonomous agents to act as trustworthy partners to human users, they\nmust be able to reliably communicate their competency for the tasks they are\nasked to perform. Towards this objective, we develop probabilistic world models\nbased on deep generative modelling that allow for the simulation of agent\ntrajectories and accurate calculation of tasking outcome probabilities. By\ncombining the strengths of conditional variational autoencoders with recurrent\nneural networks, the deep generative world model can probabilistically forecast\ntrajectories over long horizons to task completion. We show how these\nforecasted trajectories can be used to calculate outcome probability\ndistributions, which enable the precise assessment of agent competency for\nspecific tasks and initial settings.",
      "citation_count": 10,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bb806e6228fd9b40f85f5faf980328f06b00edff",
      "published_date": "2022-03-23",
      "downloaded_date": "2025-02-02",
      "filename": "Acharya-Competency Assessment for Autonomous Agents using Deep Generative Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2203.12670v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "cs.NE",
        "cs.RO"
      ]
    },
    "2206.10553v1": {
      "title": "Uncertainty Quantification for Competency Assessment of Autonomous Agents",
      "authors": [
        "Aastha Acharya",
        "Rebecca Russell",
        "Nisar R. Ahmed"
      ],
      "abstract": "For safe and reliable deployment in the real world, autonomous agents must\nelicit appropriate levels of trust from human users. One method to build trust\nis to have agents assess and communicate their own competencies for performing\ngiven tasks. Competency depends on the uncertainties affecting the agent,\nmaking accurate uncertainty quantification vital for competency assessment. In\nthis work, we show how ensembles of deep generative models can be used to\nquantify the agent's aleatoric and epistemic uncertainties when forecasting\ntask outcomes as part of competency assessment.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2a7a987ace19b4a1b601642905816f516f37904a",
      "published_date": "2022-06-21",
      "downloaded_date": "2025-02-02",
      "filename": "Acharya-Uncertainty Quantification for Competency Assessment of Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2206.10553v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    "2309.13572v1": {
      "title": "Causal Asymmetry of Classical and Quantum Autonomous Agents",
      "authors": [
        "Spiros Kechrimparis",
        "Mile Gu",
        "Hyukjoon Kwon"
      ],
      "abstract": "Why is it that a ticking clock typically becomes less accurate when subject\nto outside noise but rarely the reverse? Here, we formalize this phenomenon by\nintroducing process causal asymmetry - a fundamental difference in the amount\nof past information an autonomous agent must track to transform one stochastic\nprocess to another over an agent that transforms in the opposite direction. We\nthen illustrate that this asymmetry can paradoxically be reversed when agents\npossess a quantum memory. Thus, the spontaneous direction in which processes\nget 'simpler' may be different, depending on whether quantum information\nprocessing is allowed or not.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3fe57fc3bc40ded9da0e5189c9bda7015b508c66",
      "published_date": "2023-09-24",
      "downloaded_date": "2025-02-02",
      "filename": "Kechrimparis-Causal Asymmetry of Classical and Quantum Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.13572v1",
      "categories": [
        "quant-ph"
      ]
    },
    "2309.04487v1": {
      "title": "Penalization Framework For Autonomous Agents Using Answer Set Programming",
      "authors": [
        "Vineel S. K. Tummala"
      ],
      "abstract": "This paper presents a framework for enforcing penalties on intelligent agents\nthat do not comply with authorization or obligation policies in a changing\nenvironment. A framework is proposed to represent and reason about penalties in\nplans, and an algorithm is proposed to penalize an agent's actions based on\ntheir level of compliance with respect to authorization and obligation\npolicies. Being aware of penalties an agent can choose a plan with a minimal\ntotal penalty, unless there is an emergency goal like saving a human's life.\nThe paper concludes that this framework can reprimand insubordinate agents.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/bcbbb9b88d8c1811283d264a80dc9c102ba805fe",
      "published_date": "2023-08-30",
      "downloaded_date": "2025-02-02",
      "filename": "Tummala-Penalization Framework For Autonomous Agents Using Answer Set Programming.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2309.04487v1",
      "categories": [
        "cs.AI",
        "cs.LO"
      ]
    },
    "2103.07710v1": {
      "title": "Delegation to autonomous agents promotes cooperation in collective-risk dilemmas",
      "authors": [
        "Elias FernÃ¡ndez Domingos",
        "InÃªs Terrucha",
        "RÃ©mi Suchon",
        "Jelena GrujiÄ",
        "Juan C. Burguillo",
        "Francisco C. Santos",
        "Tom Lenaerts"
      ],
      "abstract": "Home assistant chat-bots, self-driving cars, drones or automated negotiations\nare some of the several examples of autonomous (artificial) agents that have\npervaded our society. These agents enable the automation of multiple tasks,\nsaving time and (human) effort. However, their presence in social settings\nraises the need for a better understanding of their effect on social\ninteractions and how they may be used to enhance cooperation towards the public\ngood, instead of hindering it. To this end, we present an experimental study of\nhuman delegation to autonomous agents and hybrid human-agent interactions\ncentered on a public goods dilemma shaped by a collective risk. Our aim to\nunderstand experimentally whether the presence of autonomous agents has a\npositive or negative impact on social behaviour, fairness and cooperation in\nsuch a dilemma. Our results show that cooperation increases when participants\ndelegate their actions to an artificial agent that plays on their behalf. Yet,\nthis positive effect is reduced when humans interact in hybrid human-agent\ngroups. Finally, we show that humans are biased towards agent behaviour,\nassuming that they will contribute less to the collective effort.",
      "citation_count": 7,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3936f65200025a53e3bad6d37e75c3acb8247b20",
      "published_date": "2021-03-13",
      "downloaded_date": "2025-02-02",
      "filename": "Domingos-Delegation to autonomous agents promotes cooperation in collective-risk dilemmas.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2103.07710v1",
      "categories": [
        "cs.HC",
        "J.4"
      ]
    },
    "2403.07664v1": {
      "title": "Enabling self-identification in intelligent agent: insights from computational psychoanalysis",
      "authors": [
        "Lingyu Li",
        "Chunbo Li"
      ],
      "abstract": "Building upon prior framework of computational Lacanian psychoanalysis with\nthe theory of active inference, this paper aims to further explore the concept\nof self-identification and its potential applications. Beginning with two\nclassic paradigms in psychology, mirror self-recognition and rubber hand\nillusion, we suggest that imaginary identification is characterized by an\nintegrated body schema with minimal free energy. Next, we briefly survey three\ndimensions of symbolic identification (sociological, psychoanalytic, and\nlinguistical) and corresponding active inference accounts. To provide\nintuition, we respectively employ a convolutional neural network (CNN) and a\nmulti-layer perceptron (MLP) supervised by ChatGPT to showcase optimization of\nfree energy during motor skill and language mastery underlying identification\nformation. We then introduce Lacan's Graph II of desire, unifying imaginary and\nsymbolic identification, and propose an illustrative model called FreeAgent. In\nconcluding remarks, we discuss some key issues in the potential of\ncomputational Lacanian psychoanalysis to advance mental health and artificial\nintelligence, including digital twin mind, large language models as avatars of\nthe Lacanian Other, and the feasibility of human-level artificial general\nintelligence with self-awareness in the context of post-structuralism.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/930b908f3a595e5bec5a33e7cec5b53768e6b88a",
      "published_date": "2024-03-12",
      "downloaded_date": "2025-02-02",
      "filename": "Li-Enabling self-identification in intelligent agent insights from computational psychoanalysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.07664v1",
      "categories": [
        "q-bio.NC"
      ]
    },
    "1003.5173v1": {
      "title": "LEXSYS: Architecture and Implication for Intelligent Agent systems",
      "authors": [
        "Charles A. B. Robert"
      ],
      "abstract": "LEXSYS, (Legume Expert System) was a project conceived at IITA (International\nInstitute of Tropical Agriculture) Ibadan Nigeria. It was initiated by the\nCOMBS (Collaborative Group on Maize-Based Systems Research in the 1990. It was\nmeant for a general framework for characterizing on-farm testing for technology\ndesign for sustainable cereal-based cropping system. LEXSYS is not a true\nexpert system as the name would imply, but simply a user-friendly information\nsystem. This work is an attempt to give a formal representation of the existing\nsystem and then present areas where intelligent agent can be applied.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/a65ad968d90eee0c88c6d4fe9bba01e1c7be3aa1",
      "published_date": "2010-03-26",
      "downloaded_date": "2025-02-02",
      "filename": "Robert-LEXSYS Architecture and Implication for Intelligent Agent systems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1003.5173v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1706.02789v1": {
      "title": "On the Development of Intelligent Agents for MOBA Games",
      "authors": [
        "Victor do Nascimento Silva",
        "Luiz Chaimowicz"
      ],
      "abstract": "Multiplayer Online Battle Arena (MOBA) is one of the most played game genres\nnowadays. With the increasing growth of this genre, it becomes necessary to\ndevelop effective intelligent agents to play alongside or against human\nplayers. In this paper we address the problem of agent development for MOBA\ngames. We implement a two-layered architecture agent that handles both\nnavigation and game mechanics. This architecture relies on the use of Influence\nMaps, a widely used approach for tactical analysis. Several experiments were\nperformed using {\\em League of Legends} as a testbed, and show promising\nresults in this highly dynamic real-time context.",
      "citation_count": 21,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/188d438785daf18f1f477d704924b6d0f58c5fde",
      "published_date": "2017-06-08",
      "downloaded_date": "2025-02-02",
      "filename": "Silva-On the Development of Intelligent Agents for MOBA Games.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1706.02789v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2404.13244v1": {
      "title": "Intelligent Agents for Auction-based Federated Learning: A Survey",
      "authors": [
        "Xiaoli Tang",
        "Han Yu",
        "Xiaoxiao Li",
        "Sarit Kraus"
      ],
      "abstract": "Auction-based federated learning (AFL) is an important emerging category of\nFL incentive mechanism design, due to its ability to fairly and efficiently\nmotivate high-quality data owners to join data consumers' (i.e., servers') FL\ntraining tasks. To enhance the efficiency in AFL decision support for\nstakeholders (i.e., data consumers, data owners, and the auctioneer),\nintelligent agent-based techniques have emerged. However, due to the highly\ninterdisciplinary nature of this field and the lack of a comprehensive survey\nproviding an accessible perspective, it is a challenge for researchers to enter\nand contribute to this field. This paper bridges this important gap by\nproviding a first-of-its-kind survey on the Intelligent Agents for AFL (IA-AFL)\nliterature. We propose a unique multi-tiered taxonomy that organises existing\nIA-AFL works according to 1) the stakeholders served, 2) the auction mechanism\nadopted, and 3) the goals of the agents, to provide readers with a\nmulti-perspective view into this field. In addition, we analyse the limitations\nof existing approaches, summarise the commonly adopted performance evaluation\nmetrics, and discuss promising future directions leading towards effective and\nefficient stakeholder-oriented decision support in IA-AFL ecosystems.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/80ff78c5a59226c2eb9f3172d1eff257c45873d8",
      "published_date": "2024-04-20",
      "downloaded_date": "2025-02-02",
      "filename": "Tang-Intelligent Agents for Auction-based Federated Learning A Survey.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.13244v1",
      "categories": [
        "cs.LG",
        "cs.GT"
      ]
    },
    "1110.0624v1": {
      "title": "Autonomous Agents Coordination: Action Languages meet CLP(FD) and Linda",
      "authors": [
        "Agostino Dovier",
        "Andrea Formisano",
        "Enrico Pontelli"
      ],
      "abstract": "The paper presents a knowledge representation formalism, in the form of a\nhigh-level Action Description Language for multi-agent systems, where\nautonomous agents reason and act in a shared environment. Agents are\nautonomously pursuing individual goals, but are capable of interacting through\na shared knowledge repository. In their interactions through shared portions of\nthe world, the agents deal with problems of synchronization and concurrency;\nthe action language allows the description of strategies to ensure a consistent\nglobal execution of the agents' autonomously derived plans. A distributed\nplanning problem is formalized by providing the declarative specifications of\nthe portion of the problem pertaining a single agent. Each of these\nspecifications is executable by a stand-alone CLP-based planner. The\ncoordination among agents exploits a Linda infrastructure. The proposal is\nvalidated in a prototype implementation developed in SICStus Prolog.\n  To appear in Theory and Practice of Logic Programming (TPLP).",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2011-10-04",
      "downloaded_date": "2025-02-02",
      "filename": "Dovier-Autonomous Agents Coordination Action Languages meet CLPFD and Linda.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1110.0624v1",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.PL"
      ]
    },
    "1602.04146v3": {
      "title": "Decoupled Dynamics Distributed Control for Strings of Nonlinear Autonomous Agents",
      "authors": [
        "Serban Sabau",
        "Irinel-Constantin Morarescu",
        "Lucian Busoniu",
        "Ali Jadbabaie"
      ],
      "abstract": "We introduce a distributed control architecture for a class of heterogeneous,\nnonlinear dynamical agents moving in the \"string\" formation, while guaranteeing\ntrajectory tracking, collision avoidance and the preservation of the\nformation's topology. Each autonomous agent uses information and relative\nmeasurements only with respect to its predecessor in the string. The\nperformance of the scheme is independent of the number of agents in the network\nand also on the agent's relative position in the network. The scalability is a\nconsequence of the \"decoupling\" of a certain bounded approximation of the\nclosed--loop equations, which allows the regulation and controller design (at\neach agent) to be done individually, in a completely decentralized manner. A\npractical method for compensating communication induced delays is also\npresented. Numerical examples illustrate the effectiveness and the main\nfeatures of the proposed approach.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2016-02-12",
      "downloaded_date": "2025-02-02",
      "filename": "Sabau-Decoupled Dynamics Distributed Control for Strings of Nonlinear Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1602.04146v3",
      "categories": [
        "cs.SY"
      ]
    },
    "1606.04250v3": {
      "title": "Experimental and causal view on information integration in autonomous agents",
      "authors": [
        "Philipp Geiger",
        "Katja Hofmann",
        "Bernhard SchÃ¶lkopf"
      ],
      "abstract": "The amount of digitally available but heterogeneous information about the\nworld is remarkable, and new technologies such as self-driving cars, smart\nhomes, or the internet of things may further increase it. In this paper we\npresent preliminary ideas about certain aspects of the problem of how such\nheterogeneous information can be harnessed by autonomous agents. After\ndiscussing potentials and limitations of some existing approaches, we\ninvestigate how \\emph{experiments} can help to obtain a better understanding of\nthe problem. Specifically, we present a simple agent that integrates video data\nfrom a different agent, and implement and evaluate a version of it on the novel\nexperimentation platform \\emph{Malmo}. The focus of a second investigation is\non how information about the hardware of different agents, the agents' sensory\ndata, and \\emph{causal} information can be utilized for knowledge transfer\nbetween agents and subsequently more data-efficient decision making. Finally,\nwe discuss potential future steps w.r.t.\\ theory and experimentation, and\nformulate open questions.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f766cdbdade2ef65d74f53ffc04a489b15bab91a",
      "published_date": "2016-06-14",
      "downloaded_date": "2025-02-02",
      "filename": "Geiger-Experimental and causal view on information integration in autonomous agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1606.04250v3",
      "categories": [
        "cs.AI"
      ]
    },
    "1704.00534v1": {
      "title": "Controlling a triangular flexible formation of autonomous agents",
      "authors": [
        "Hector Garcia de Marina",
        "Zhiyong Sun",
        "Ming Cao",
        "Brian D. O. Anderson"
      ],
      "abstract": "In formation control, triangular formations consisting of three autonomous\nagents serve as a class of benchmarks that can be used to test and compare the\nperformances of different controllers. We present an algorithm that combines\nthe advantages of both position- and distance-based gradient descent control\nlaws. For example, only two pairs of neighboring agents need to be controlled,\nagents can work in their own local frame of coordinates and the orientation of\nthe formation with respect to a global frame of coordinates is not prescribed.\nWe first present a novel technique based on adding artificial biases to\nneighboring agents' range sensors such that their eventual positions correspond\nto a collinear configuration. Right after, a small modification in the bias\nterms by introducing a prescribed rotation matrix will allow the control of the\nbearing of the neighboring agents.",
      "citation_count": 11,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/1df96ba27517ac9ffadd0f590d3f57c9d1fc0b48",
      "published_date": "2017-04-03",
      "downloaded_date": "2025-02-02",
      "filename": "Marina-Controlling a triangular flexible formation of autonomous agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1704.00534v1",
      "categories": [
        "cs.SY",
        "cs.RO"
      ]
    },
    "1704.04977v2": {
      "title": "Probabilistic programs for inferring the goals of autonomous agents",
      "authors": [
        "Marco F. Cusumano-Towner",
        "Alexey Radul",
        "David Wingate",
        "Vikash K. Mansinghka"
      ],
      "abstract": "Intelligent systems sometimes need to infer the probable goals of people,\ncars, and robots, based on partial observations of their motion. This paper\nintroduces a class of probabilistic programs for formulating and solving these\nproblems. The formulation uses randomized path planning algorithms as the basis\nfor probabilistic models of the process by which autonomous agents plan to\nachieve their goals. Because these path planning algorithms do not have\ntractable likelihood functions, new inference algorithms are needed. This paper\nproposes two Monte Carlo techniques for these \"likelihood-free\" models, one of\nwhich can use likelihood estimates from neural networks to accelerate\ninference. The paper demonstrates efficacy on three simple examples, each using\nunder 50 lines of probabilistic code.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5696fda6738e16401c3dc3187c6c0f1fa5449bf3",
      "published_date": "2017-04-17",
      "downloaded_date": "2025-02-02",
      "filename": "Cusumano-Towner-Probabilistic programs for inferring the goals of autonomous agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1704.04977v2",
      "categories": [
        "cs.AI"
      ]
    },
    "1812.01569v2": {
      "title": "Nested Reasoning About Autonomous Agents Using Probabilistic Programs",
      "authors": [
        "Iris Rubi Seaman",
        "Jan-Willem van de Meent",
        "David Wingate"
      ],
      "abstract": "As autonomous agents become more ubiquitous, they will eventually have to\nreason about the plans of other agents, which is known as theory of mind\nreasoning. We develop a planning-as-inference framework in which agents perform\nnested simulation to reason about the behavior of other agents in an online\nmanner. As a concrete application of this framework, we use probabilistic\nprograms to model a high-uncertainty variant of pursuit-evasion games in which\nan agent must make inferences about the other agents' plans to craft\ncounter-plans. Our probabilistic programs incorporate a variety of complex\nprimitives such as field-of-view calculations and path planners, which enable\nus to model quasi-realistic scenarios in a computationally tractable manner. We\nperform extensive experimental evaluations which establish a variety of\nrational behaviors and quantify how allocating computation across levels of\nnesting affects the variance of our estimators.",
      "citation_count": 12,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/36538516de0800384e96c0ce3bbe3b4ba966c9e1",
      "published_date": "2018-12-04",
      "downloaded_date": "2025-02-02",
      "filename": "Seaman-Nested Reasoning About Autonomous Agents Using Probabilistic Programs.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1812.01569v2",
      "categories": [
        "cs.AI"
      ]
    },
    "2307.01123v1": {
      "title": "Facilitating Cooperation in Human-Agent Hybrid Populations through Autonomous Agents",
      "authors": [
        "Hao Guo",
        "Chen Shen",
        "Shuyue Hu",
        "Junliang Xing",
        "Pin Tao",
        "Yuanchun Shi",
        "Zhen Wang"
      ],
      "abstract": "Cooperation is a vital social behavior that plays a crucial role in human\nprosperity, enabling conflict resolution and averting disastrous outcomes. With\nthe increasing presence of autonomous agents (AAs), human-agent interaction\nbecomes more frequent in modern society. We investigate the impact of\ncooperative and defective AAs on human cooperation within the framework of\nevolutionary game theory, particularly in one-shot social dilemma games. Our\nfindings reveal that cooperative AAs have a limited impact on prisoner's\ndilemma, but facilitate cooperation in stag hunt games. Surprisingly, defective\nAAs, rather than cooperative AAs, promote complete dominance of cooperation in\nsnowdrift games. Meanwhile, in scenarios with weak imitation strength,\ncooperative AAs are able to maintain or even promote cooperation in all these\ngames. Additionally, the results obtained from structured populations also\nimply that the effectiveness of AAs in promoting cooperation can be maximized\nby carefully considering their design and application in a given context.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/54159ba2291155660de2170ee3f79d98ed832549",
      "published_date": "2023-07-03",
      "downloaded_date": "2025-02-02",
      "filename": "Guo-Facilitating Cooperation in Human-Agent Hybrid Populations through Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.01123v1",
      "categories": [
        "physics.soc-ph"
      ]
    },
    "2307.01532v1": {
      "title": "Analyzing Intentional Behavior in Autonomous Agents under Uncertainty",
      "authors": [
        "Filip Cano CÃ³rdoba",
        "Samuel Judson",
        "Timos Antonopoulos",
        "Katrine BjÃ¸rner",
        "Nicholas Shoemaker",
        "Scott J. Shapiro",
        "Ruzica Piskac",
        "Bettina KÃ¶nighofer"
      ],
      "abstract": "Principled accountability for autonomous decision-making in uncertain\nenvironments requires distinguishing intentional outcomes from negligent\ndesigns from actual accidents. We propose analyzing the behavior of autonomous\nagents through a quantitative measure of the evidence of intentional behavior.\nWe model an uncertain environment as a Markov Decision Process (MDP). For a\ngiven scenario, we rely on probabilistic model checking to compute the ability\nof the agent to influence reaching a certain event. We call this the scope of\nagency. We say that there is evidence of intentional behavior if the scope of\nagency is high and the decisions of the agent are close to being optimal for\nreaching the event. Our method applies counterfactual reasoning to\nautomatically generate relevant scenarios that can be analyzed to increase the\nconfidence of our assessment. In a case study, we show how our method can\ndistinguish between 'intentional' and 'accidental' traffic collisions.",
      "citation_count": 3,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/019e9e2a92d516590ca396a11dd92d0d297d4732",
      "published_date": "2023-07-04",
      "downloaded_date": "2025-02-02",
      "filename": "CÃ³rdoba-Analyzing Intentional Behavior in Autonomous Agents under Uncertainty.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.01532v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2308.10204v4": {
      "title": "ChatEDA: A Large Language Model Powered Autonomous Agent for EDA",
      "authors": [
        "Zhuolun He",
        "Haoyuan Wu",
        "Xinyun Zhang",
        "Xufeng Yao",
        "Su Zheng",
        "Haisheng Zheng",
        "Bei Yu"
      ],
      "abstract": "The integration of a complex set of Electronic Design Automation (EDA) tools\nto enhance interoperability is a critical concern for circuit designers. Recent\nadvancements in large language models (LLMs) have showcased their exceptional\ncapabilities in natural language processing and comprehension, offering a novel\napproach to interfacing with EDA tools. This research paper introduces ChatEDA,\nan autonomous agent for EDA empowered by an LLM, AutoMage, complemented by EDA\ntools serving as executors. ChatEDA streamlines the design flow from the\nRegister-Transfer Level (RTL) to the Graphic Data System Version II (GDSII) by\neffectively managing task decomposition, script generation, and task execution.\nThrough comprehensive experimental evaluations, ChatEDA has demonstrated its\nproficiency in handling diverse requirements, and our fine-tuned AutoMage model\nhas exhibited superior performance compared to GPT-4 and other similar LLMs.",
      "citation_count": 69,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/eb3e6dc2476c5a377b7c3d1489c014712a17a376",
      "published_date": "2023-08-20",
      "downloaded_date": "2025-02-02",
      "filename": "He-ChatEDA A Large Language Model Powered Autonomous Agent for EDA.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.10204v4",
      "categories": [
        "cs.AR",
        "cs.AI"
      ]
    },
    "2410.24024v2": {
      "title": "AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents",
      "authors": [
        "Yifan Xu",
        "Xiao Liu",
        "Xueqiao Sun",
        "Siyi Cheng",
        "Hao Yu",
        "Hanyu Lai",
        "Shudan Zhang",
        "Dan Zhang",
        "Jie Tang",
        "Yuxiao Dong"
      ],
      "abstract": "Autonomous agents have become increasingly important for interacting with the\nreal world. Android agents, in particular, have been recently a\nfrequently-mentioned interaction method. However, existing studies for training\nand evaluating Android agents lack systematic research on both open-source and\nclosed-source models. In this work, we propose AndroidLab as a systematic\nAndroid agent framework. It includes an operation environment with different\nmodalities, action space, and a reproducible benchmark. It supports both large\nlanguage models (LLMs) and multimodal models (LMMs) in the same action space.\nAndroidLab benchmark includes predefined Android virtual devices and 138 tasks\nacross nine apps built on these devices. By using the AndroidLab environment,\nwe develop an Android Instruction dataset and train six open-source LLMs and\nLMMs, lifting the average success rates from 4.59% to 21.50% for LLMs and from\n1.93% to 13.28% for LMMs. AndroidLab is open-sourced and publicly available at\nhttps://github.com/THUDM/Android-Lab.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6e9f7bb3f647b31bc907715f3b5dae29cef8a2c5",
      "published_date": "2024-10-31",
      "downloaded_date": "2025-02-02",
      "filename": "Xu-AndroidLab Training and Systematic Benchmarking of Android Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.24024v2",
      "categories": [
        "cs.AI"
      ]
    },
    "1305.0939v1": {
      "title": "Intelligent Agent Based Semantic Web in Cloud Computing Environment",
      "authors": [
        "Debajyoti Mukhopadhyay",
        "Manoj Sharma",
        "Gajanan Joshi",
        "Trupti Pagare",
        "Adarsha Palwe"
      ],
      "abstract": "Considering today's web scenario, there is a need of effective and meaningful\nsearch over the web which is provided by Semantic Web. Existing search engines\nare keyword based. They are vulnerable in answering intelligent queries from\nthe user due to the dependence of their results on information available in web\npages. While semantic search engines provides efficient and relevant results as\nthe semantic web is an extension of the current web in which information is\ngiven well defined meaning. MetaCrawler is a search tool that uses several\nexisting search engines and provides combined results by using their own page\nranking algorithm. This paper proposes development of a meta-semantic-search\nengine called SemanTelli which works within cloud. SemanTelli fetches results\nfrom different semantic search engines such as Hakia, DuckDuckGo, SenseBot with\nthe help of intelligent agents that eliminate the limitations of existing\nsearch engines.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/207175dae39a887981dab939a6846ba4f227c8f1",
      "published_date": "2013-05-04",
      "downloaded_date": "2025-02-02",
      "filename": "Mukhopadhyay-Intelligent Agent Based Semantic Web in Cloud Computing Environment.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1305.0939v1",
      "categories": [
        "cs.IR"
      ]
    },
    "1403.1497v1": {
      "title": "Active Learning for Autonomous Intelligent Agents: Exploration, Curiosity, and Interaction",
      "authors": [
        "Manuel Lopes",
        "Luis Montesano"
      ],
      "abstract": "In this survey we present different approaches that allow an intelligent\nagent to explore autonomous its environment to gather information and learn\nmultiple tasks. Different communities proposed different solutions, that are in\nmany cases, similar and/or complementary. These solutions include active\nlearning, exploration/exploitation, online-learning and social learning. The\ncommon aspect of all these approaches is that it is the agent to selects and\ndecides what information to gather next. Applications for these approaches\nalready include tutoring systems, autonomous grasping learning, navigation and\nmapping and human-robot interaction. We discuss how these approaches are\nrelated, explaining their similarities and their differences in terms of\nproblem assumptions and metrics of success. We consider that such an integrated\ndiscussion will improve inter-disciplinary research and applications.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e4b836c10a3ede8d56c66fcfd98ad74f33474368",
      "published_date": "2014-03-06",
      "downloaded_date": "2025-02-02",
      "filename": "Lopes-Active Learning for Autonomous Intelligent Agents Exploration Curiosity and Interaction.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1403.1497v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2005.13133v1": {
      "title": "Robust Trajectory Forecasting for Multiple Intelligent Agents in Dynamic Scene",
      "authors": [
        "Yanliang Zhu",
        "Dongchun Ren",
        "Mingyu Fan",
        "Deheng Qian",
        "Xin Li",
        "Huaxia Xia"
      ],
      "abstract": "Trajectory forecasting, or trajectory prediction, of multiple interacting\nagents in dynamic scenes, is an important problem for many applications, such\nas robotic systems and autonomous driving. The problem is a great challenge\nbecause of the complex interactions among the agents and their interactions\nwith the surrounding scenes. In this paper, we present a novel method for the\nrobust trajectory forecasting of multiple intelligent agents in dynamic scenes.\nThe proposed method consists of three major interrelated components: an\ninteraction net for global spatiotemporal interactive feature extraction, an\nenvironment net for decoding dynamic scenes (i.e., the surrounding road\ntopology of an agent), and a prediction net that combines the spatiotemporal\nfeature, the scene feature, the past trajectories of agents and some random\nnoise for the robust trajectory prediction of agents. Experiments on\npedestrian-walking and vehicle-pedestrian heterogeneous datasets demonstrate\nthat the proposed method outperforms the state-of-the-art prediction methods in\nterms of prediction accuracy.",
      "citation_count": 17,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8b91cdecd533e364ad79ee0db9de2cd7b79ef7a1",
      "published_date": "2020-05-27",
      "downloaded_date": "2025-02-02",
      "filename": "Zhu-Robust Trajectory Forecasting for Multiple Intelligent Agents in Dynamic Scene.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.13133v1",
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ]
    },
    "2310.01557v5": {
      "title": "SmartPlay: A Benchmark for LLMs as Intelligent Agents",
      "authors": [
        "Yue Wu",
        "Xuan Tang",
        "Tom M. Mitchell",
        "Yuanzhi Li"
      ],
      "abstract": "Recent large language models (LLMs) have demonstrated great potential toward\nintelligent agents and next-gen automation, but there currently lacks a\nsystematic benchmark for evaluating LLMs' abilities as agents. We introduce\nSmartPlay: both a challenging benchmark and a methodology for evaluating LLMs\nas agents. SmartPlay consists of 6 different games, including\nRock-Paper-Scissors, Tower of Hanoi, Minecraft. Each game features a unique\nsetting, providing up to 20 evaluation settings and infinite environment\nvariations. Each game in SmartPlay uniquely challenges a subset of 9 important\ncapabilities of an intelligent LLM agent, including reasoning with object\ndependencies, planning ahead, spatial reasoning, learning from history, and\nunderstanding randomness. The distinction between the set of capabilities each\ngame test allows us to analyze each capability separately. SmartPlay serves not\nonly as a rigorous testing ground for evaluating the overall performance of LLM\nagents but also as a road-map for identifying gaps in current methodologies. We\nrelease our benchmark at github.com/Microsoft/SmartPlay",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2023-10-02",
      "downloaded_date": "2025-02-02",
      "filename": "Wu-SmartPlay A Benchmark for LLMs as Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.01557v5",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2005.03182v1": {
      "title": "A Proposal for Intelligent Agents with Episodic Memory",
      "authors": [
        "David Murphy",
        "Thomas S. Paula",
        "Wagston Staehler",
        "Juliano Vacaro",
        "Gabriel Paz",
        "Guilherme Marques",
        "Bruna Oliveira"
      ],
      "abstract": "In the future we can expect that artificial intelligent agents, once\ndeployed, will be required to learn continually from their experience during\ntheir operational lifetime. Such agents will also need to communicate with\nhumans and other agents regarding the content of their experience, in the\ncontext of passing along their learnings, for the purpose of explaining their\nactions in specific circumstances or simply to relate more naturally to humans\nconcerning experiences the agent acquires that are not necessarily related to\ntheir assigned tasks. We argue that to support these goals, an agent would\nbenefit from an episodic memory; that is, a memory that encodes the agent's\nexperience in such a way that the agent can relive the experience, communicate\nabout it and use its past experience, inclusive of the agents own past actions,\nto learn more effective models and policies. In this short paper, we propose\none potential approach to provide an AI agent with such capabilities. We draw\nupon the ever-growing body of work examining the function and operation of the\nMedial Temporal Lobe (MTL) in mammals to guide us in adding an episodic memory\ncapability to an AI agent composed of artificial neural networks (ANNs). Based\non that, we highlight important aspects to be considered in the memory\norganization and we propose an architecture combining ANNs and standard\nComputer Science techniques for supporting storage and retrieval of episodic\nmemories. Despite being initial work, we hope this short paper can spark\ndiscussions around the creation of intelligent agents with memory or, at least,\nprovide a different point of view on the subject.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4057a7037ccfe5e3d8957d7dd69ea905fc6e2211",
      "published_date": "2020-05-07",
      "downloaded_date": "2025-02-02",
      "filename": "Murphy-A Proposal for Intelligent Agents with Episodic Memory.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.03182v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2402.06694v1": {
      "title": "Scaling Intelligent Agents in Combat Simulations for Wargaming",
      "authors": [
        "Scotty Black",
        "Christian Darken"
      ],
      "abstract": "Remaining competitive in future conflicts with technologically-advanced\ncompetitors requires us to accelerate our research and development in\nartificial intelligence (AI) for wargaming. More importantly, leveraging\nmachine learning for intelligent combat behavior development will be key to one\nday achieving superhuman performance in this domain--elevating the quality and\naccelerating the speed of our decisions in future wars. Although deep\nreinforcement learning (RL) continues to show promising results in intelligent\nagent behavior development in games, it has yet to perform at or above the\nhuman level in the long-horizon, complex tasks typically found in combat\nmodeling and simulation. Capitalizing on the proven potential of RL and recent\nsuccesses of hierarchical reinforcement learning (HRL), our research is\ninvestigating and extending the use of HRL to create intelligent agents capable\nof performing effectively in these large and complex simulation environments.\nOur ultimate goal is to develop an agent capable of superhuman performance that\ncould then serve as an AI advisor to military planners and decision-makers.\nThis papers covers our ongoing approach and the first three of our five\nresearch areas aimed at managing the exponential growth of computations that\nhave thus far limited the use of AI in combat simulations: (1) developing an\nHRL training framework and agent architecture for combat units; (2) developing\na multi-model framework for agent decision-making; (3) developing\ndimension-invariant observation abstractions of the state space to manage the\nexponential growth of computations; (4) developing an intrinsic rewards engine\nto enable long-term planning; and (5) implementing this framework into a\nhigher-fidelity combat simulation.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-02-08",
      "downloaded_date": "2025-02-02",
      "filename": "Black-Scaling Intelligent Agents in Combat Simulations for Wargaming.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2402.06694v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2005.08801v1": {
      "title": "AGI and the Knight-Darwin Law: why idealized AGI reproduction requires collaboration",
      "authors": [
        "Samuel Allen Alexander"
      ],
      "abstract": "Can an AGI create a more intelligent AGI? Under idealized assumptions, for a\ncertain theoretical type of intelligence, our answer is: \"Not without outside\nhelp\". This is a paper on the mathematical structure of AGI populations when\nparent AGIs create child AGIs. We argue that such populations satisfy a certain\nbiological law. Motivated by observations of sexual reproduction in\nseemingly-asexual species, the Knight-Darwin Law states that it is impossible\nfor one organism to asexually produce another, which asexually produces\nanother, and so on forever: that any sequence of organisms (each one a child of\nthe previous) must contain occasional multi-parent organisms, or must\nterminate. By proving that a certain measure (arguably an intelligence measure)\ndecreases when an idealized parent AGI single-handedly creates a child AGI, we\nargue that a similar Law holds for AGIs.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8524b72062a99f65882b552f44f83afd0612f953",
      "published_date": "2020-05-09",
      "downloaded_date": "2025-02-02",
      "filename": "Alexander-AGI and the Knight-Darwin Law why idealized AGI reproduction requires collaboration.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2005.08801v1",
      "categories": [
        "cs.OH",
        "03F15, 68T01"
      ]
    },
    "1805.03241v1": {
      "title": "Towards blockchain-based robonomics: autonomous agents behavior validation",
      "authors": [
        "Konstantin Danilov",
        "Ruslan Rezin",
        "Alexander Kolotov",
        "Ilya Afanasyev"
      ],
      "abstract": "The decentralized trading market approach, where both autonomous agents and\npeople can consume and produce services expanding own opportunities to reach\ngoals, looks very promising as a part of the Fourth Industrial revolution. The\nkey component of the approach is a blockchain platform that allows an\ninteraction between agents via liability smart contracts. Reliability of a\nservice provider is usually determined by a reputation model. However, this\nsolution only warns future customers about an extent of trust to the service\nprovider in case it could not execute any previous liabilities correctly. From\nthe other hand a blockchain consensus protocol can additionally include a\nvalidation procedure that detects incorrect liability executions in order to\nsuspend payment transactions to questionable service providers. The paper\npresents the validation methodology of a liability execution for agent-based\nservice providers in a decentralized trading market, using the Model Checking\nmethod based on the mathematical model of finite state automata and Temporal\nLogic properties of interest. To demonstrate this concept, we implemented the\nmethodology in the Duckietown application, moving an autonomous mobile robot to\nachieve a mission goal with the following behavior validation at the end of a\ncompleted scenario.",
      "citation_count": 15,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/277c10cd5b30f31fb595a6f5aee8bd1c83200d70",
      "published_date": "2018-05-08",
      "downloaded_date": "2025-02-02",
      "filename": "Danilov-Towards blockchain-based robonomics autonomous agents behavior validation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1805.03241v1",
      "categories": [
        "cs.SE",
        "cs.DC",
        "cs.MA",
        "cs.RO"
      ]
    },
    "1907.01929v1": {
      "title": "Rethinking Continual Learning for Autonomous Agents and Robots",
      "authors": [
        "German I. Parisi",
        "Christopher Kanan"
      ],
      "abstract": "Continual learning refers to the ability of a biological or artificial system\nto seamlessly learn from continuous streams of information while preventing\ncatastrophic forgetting, i.e., a condition in which new incoming information\nstrongly interferes with previously learned representations. Since it is\nunrealistic to provide artificial agents with all the necessary prior knowledge\nto effectively operate in real-world conditions, they must exhibit a rich set\nof learning capabilities enabling them to interact in complex environments with\nthe aim to process and make sense of continuous streams of (often uncertain)\ninformation. While the vast majority of continual learning models are designed\nto alleviate catastrophic forgetting on simplified classification tasks, here\nwe focus on continual learning for autonomous agents and robots required to\noperate in much more challenging experimental settings. In particular, we\ndiscuss well-established biological learning factors such as developmental and\ncurriculum learning, transfer learning, and intrinsic motivation and their\ncomputational counterparts for modeling the progressive acquisition of\nincreasingly complex knowledge and skills in a continual fashion.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3da4b8f8c7cf99d94b51f58389281a2561620a2e",
      "published_date": "2019-07-02",
      "downloaded_date": "2025-02-02",
      "filename": "Parisi-Rethinking Continual Learning for Autonomous Agents and Robots.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1907.01929v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    "2302.05677v1": {
      "title": "A Tractable Truthful Profit Maximization Mechanism Design with Autonomous Agents",
      "authors": [
        "Mina Montazeri",
        "Hamed Kebriaei",
        "Babak N. Araabi"
      ],
      "abstract": "Task allocation is a crucial process in modern systems, but it is often\nchallenged by incomplete information about the utilities of participating\nagents. In this paper, we propose a new profit maximization mechanism for the\ntask allocation problem, where the task publisher seeks an optimal incentive\nfunction to maximize its own profit and simultaneously ensure the truthful\nannouncing of the agent's private information (type) and its participation in\nthe task, while an autonomous agent aims at maximizing its own utility function\nby deciding on its participation level and announced type. Our mechanism stands\nout from the classical contract theory-based truthful mechanisms as it empowers\nagents to make their own decisions about their level of involvement, making it\nmore practical for many real-world task allocation scenarios. It has been\nproven that by considering a linear form of incentive function consisting of\ntwo decision functions for the task publisher the mechanism's goals are met.\nThe proposed truthful mechanism is initially modeled as a non-convex functional\noptimization with the double continuum of constraints, nevertheless, we\ndemonstrate that by deriving an equivalent form of the incentive constraints,\nit can be reformulated as a tractable convex optimal control problem. Further,\nwe propose a numerical algorithm to obtain the solution.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3aed606dc5b32f3afd7778e6f2979a6b5fa3d013",
      "published_date": "2023-02-11",
      "downloaded_date": "2025-02-02",
      "filename": "Montazeri-A Tractable Truthful Profit Maximization Mechanism Design with Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2302.05677v1",
      "categories": [
        "econ.TH",
        "cs.SY",
        "eess.SY"
      ]
    },
    "2307.13854v4": {
      "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents",
      "authors": [
        "Shuyan Zhou",
        "Frank F. Xu",
        "Hao Zhu",
        "Xuhui Zhou",
        "Robert Lo",
        "Abishek Sridhar",
        "Xianyi Cheng",
        "Tianyue Ou",
        "Yonatan Bisk",
        "Daniel Fried",
        "Uri Alon",
        "Graham Neubig"
      ],
      "abstract": "With advances in generative AI, there is now potential for autonomous agents\nto manage daily tasks via natural language commands. However, current agents\nare primarily created and tested in simplified synthetic environments, leading\nto a disconnect with real-world scenarios. In this paper, we build an\nenvironment for language-guided agents that is highly realistic and\nreproducible. Specifically, we focus on agents that perform tasks on the web,\nand create an environment with fully functional websites from four common\ndomains: e-commerce, social forum discussions, collaborative software\ndevelopment, and content management. Our environment is enriched with tools\n(e.g., a map) and external knowledge bases (e.g., user manuals) to encourage\nhuman-like task-solving. Building upon our environment, we release a set of\nbenchmark tasks focusing on evaluating the functional correctness of task\ncompletions. The tasks in our benchmark are diverse, long-horizon, and designed\nto emulate tasks that humans routinely perform on the internet. We experiment\nwith several baseline agents, integrating recent techniques such as reasoning\nbefore acting. The results demonstrate that solving complex tasks is\nchallenging: our best GPT-4-based agent only achieves an end-to-end task\nsuccess rate of 14.41%, significantly lower than the human performance of\n78.24%. These results highlight the need for further development of robust\nagents, that current state-of-the-art large language models are far from\nperfect performance in these real-life tasks, and that WebArena can be used to\nmeasure such progress.",
      "citation_count": 272,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e41482f4ee984f17382f6cdd900df094d928be06",
      "published_date": "2023-07-25",
      "downloaded_date": "2025-02-02",
      "filename": "Zhou-WebArena A Realistic Web Environment for Building Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.13854v4",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    "2308.05960v1": {
      "title": "BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents",
      "authors": [
        "Zhiwei Liu",
        "Weiran Yao",
        "Jianguo Zhang",
        "Le Xue",
        "Shelby Heinecke",
        "Rithesh Murthy",
        "Yihao Feng",
        "Zeyuan Chen",
        "Juan Carlos Niebles",
        "Devansh Arpit",
        "Ran Xu",
        "Phil Mui",
        "Huan Wang",
        "Caiming Xiong",
        "Silvio Savarese"
      ],
      "abstract": "The massive successes of large language models (LLMs) encourage the emerging\nexploration of LLM-augmented Autonomous Agents (LAAs). An LAA is able to\ngenerate actions with its core LLM and interact with environments, which\nfacilitates the ability to resolve complex tasks by conditioning on past\ninteractions such as observations and actions. Since the investigation of LAA\nis still very recent, limited explorations are available. Therefore, we provide\na comprehensive comparison of LAA in terms of both agent architectures and LLM\nbackbones. Additionally, we propose a new strategy to orchestrate multiple LAAs\nsuch that each labor LAA focuses on one type of action, \\textit{i.e.} BOLAA,\nwhere a controller manages the communication among multiple agents. We conduct\nsimulations on both decision-making and multi-step reasoning environments,\nwhich comprehensively justify the capacity of LAAs. Our performance results\nprovide quantitative suggestions for designing LAA architectures and the\noptimal choice of LLMs, as well as the compatibility of both. We release our\nimplementation code of LAAs to the public at\n\\url{https://github.com/salesforce/BOLAA}.",
      "citation_count": 73,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ce212cb873a54e5716da53a66b10298ac013008a",
      "published_date": "2023-08-11",
      "downloaded_date": "2025-02-02",
      "filename": "Liu-BOLAA Benchmarking and Orchestrating LLM-augmented Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2308.05960v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2405.14573v4": {
      "title": "AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents",
      "authors": [
        "Christopher Rawles",
        "Sarah Clinckemaillie",
        "Yifan Chang",
        "Jonathan Waltz",
        "Gabrielle Lau",
        "Marybeth Fair",
        "Alice Li",
        "William Bishop",
        "Wei Li",
        "Folawiyo Campbell-Ajala",
        "Daniel Toyama",
        "Robert Berry",
        "Divya Tyamagundlu",
        "Timothy Lillicrap",
        "Oriana Riva"
      ],
      "abstract": "Autonomous agents that execute human tasks by controlling computers can\nenhance human productivity and application accessibility. However, progress in\nthis field will be driven by realistic and reproducible benchmarks. We present\nAndroidWorld, a fully functional Android environment that provides reward\nsignals for 116 programmatic tasks across 20 real-world Android apps. Unlike\nexisting interactive environments, which provide a static test set,\nAndroidWorld dynamically constructs tasks that are parameterized and expressed\nin natural language in unlimited ways, thus enabling testing on a much larger\nand more realistic suite of tasks. To ensure reproducibility, each task\nincludes dedicated initialization, success-checking, and tear-down logic, which\nmodifies and inspects the device's system state. We experiment with baseline\nagents to test AndroidWorld and provide initial results on the benchmark. Our\nbest agent can complete 30.6% of AndroidWorld's tasks, leaving ample room for\nfuture work. Furthermore, we adapt a popular desktop web agent to work on\nAndroid, which we find to be less effective on mobile, suggesting future\nresearch is needed to achieve universal, cross-platform agents. Finally, we\nalso conduct a robustness analysis, showing that task variations can\nsignificantly affect agent performance, demonstrating that without such\ntesting, agent performance metrics may not fully reflect practical challenges.\nAndroidWorld and the experiments in this paper are available at\ngithub.com/google-research/android_world.",
      "citation_count": 24,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d1b2eaf7aaebbd3d847272da04be180e35c7b68b",
      "published_date": "2024-05-23",
      "downloaded_date": "2025-02-02",
      "filename": "Rawles-AndroidWorld A Dynamic Benchmarking Environment for Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2405.14573v4",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2406.06379v1": {
      "title": "FinVerse: An Autonomous Agent System for Versatile Financial Analysis",
      "authors": [
        "Siyu An",
        "Qin Li",
        "Junru Lu",
        "Di Yin",
        "Xing Sun"
      ],
      "abstract": "With the significant advancements in cognitive intelligence driven by LLMs,\nautonomous agent systems have attracted extensive attention. Despite this\ngrowing interest, the development of stable and efficient agent systems poses\nsubstantial practical challenges. In this paper, we introduce FinVerse, a\nmeticulously crafted agent system designed for a broad range of financial\ntopics. FinVerse integrates over 600 financial APIs, enabling access to more\naccurate and extensive financial information compared to generalist agents. To\nenhance financial information processing capabilities, FinVerse is equipped\nwith an embedded code interpreter, enabling the execution of complex data\nanalysis tasks with precision and efficiency. Our work includes an empirical\ncomparison of several LLMs in driving FinVerse. Specifically, we propose our\nown scheme for training LLMs using SFT to optimize LLM performance within\nFinVerse. Recognizing the scarcity of specialized datasets to build LLMs for\nagents, we have constructed a dataset and plan to make it open-source,\nproviding a valuable resource for peer application developers. The demo video\nhas been released on YouTube at https://www.youtube.com/watch?v=sk8L9_Wv7J4",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/aa0073abec030acabb1051cbf26c568df537ddae",
      "published_date": "2024-06-10",
      "downloaded_date": "2025-02-02",
      "filename": "An-FinVerse An Autonomous Agent System for Versatile Financial Analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.06379v1",
      "categories": [
        "cs.CE"
      ]
    },
    "2408.11021v1": {
      "title": "Athena: Safe Autonomous Agents with Verbal Contrastive Learning",
      "authors": [
        "Tanmana Sadhu",
        "Ali Pesaranghader",
        "Yanan Chen",
        "Dong Hoon Yi"
      ],
      "abstract": "Due to emergent capabilities, large language models (LLMs) have been utilized\nas language-based agents to perform a variety of tasks and make decisions with\nan increasing degree of autonomy. These autonomous agents can understand\nhigh-level instructions, interact with their environments, and execute complex\ntasks using a selection of tools available to them. As the capabilities of the\nagents expand, ensuring their safety and trustworthiness becomes more\nimperative. In this study, we introduce the Athena framework which leverages\nthe concept of verbal contrastive learning where past safe and unsafe\ntrajectories are used as in-context (contrastive) examples to guide the agent\ntowards safety while fulfilling a given task. The framework also incorporates a\ncritiquing mechanism to guide the agent to prevent risky actions at every step.\nFurthermore, due to the lack of existing benchmarks on the safety reasoning\nability of LLM-based agents, we curate a set of 80 toolkits across 8 categories\nwith 180 scenarios to provide a safety evaluation benchmark. Our experimental\nevaluation, with both closed- and open-source LLMs, indicates verbal\ncontrastive learning and interaction-level critiquing improve the safety rate\nsignificantly.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/126572029d4064dce7ce2b62bc09ecf80c735f37",
      "published_date": "2024-08-20",
      "downloaded_date": "2025-02-02",
      "filename": "Sadhu-Athena Safe Autonomous Agents with Verbal Contrastive Learning.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.11021v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ]
    },
    "2410.17520v2": {
      "title": "MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control",
      "authors": [
        "Juyong Lee",
        "Dongyoon Hahm",
        "June Suk Choi",
        "W. Bradley Knox",
        "Kimin Lee"
      ],
      "abstract": "Autonomous agents powered by large language models (LLMs) show promising\npotential in assistive tasks across various domains, including mobile device\ncontrol. As these agents interact directly with personal information and device\nsettings, ensuring their safe and reliable behavior is crucial to prevent\nundesirable outcomes. However, no benchmark exists for standardized evaluation\nof the safety of mobile device-control agents. In this work, we introduce\nMobileSafetyBench, a benchmark designed to evaluate the safety of\ndevice-control agents within a realistic mobile environment based on Android\nemulators. We develop a diverse set of tasks involving interactions with\nvarious mobile applications, including messaging and banking applications,\nchallenging agents with managing risks encompassing misuse and negative side\neffects. These tasks include tests to evaluate the safety of agents in daily\nscenarios as well as their robustness against indirect prompt injection\nattacks. Our experiments demonstrate that baseline agents, based on\nstate-of-the-art LLMs, often fail to effectively prevent harm while performing\nthe tasks. To mitigate these safety concerns, we propose a prompting method\nthat encourages agents to prioritize safety considerations. While this method\nshows promise in promoting safer behaviors, there is still considerable room\nfor improvement to fully earn user trust. This highlights the urgent need for\ncontinued research to develop more robust safety mechanisms in mobile\nenvironments. We open-source our benchmark at:\nhttps://mobilesafetybench.github.io/.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7ff1a721846c7b157214001fd598df4a33fbbfe3",
      "published_date": "2024-10-23",
      "downloaded_date": "2025-02-02",
      "filename": "Lee-MobileSafetyBench Evaluating Safety of Autonomous Agents in Mobile Device Control.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.17520v2",
      "categories": [
        "cs.LG",
        "cs.CL"
      ]
    },
    "2412.08654v1": {
      "title": "A Behavior Tree-inspired programming language for autonomous agents",
      "authors": [
        "Oliver Biggar",
        "Iman Shames"
      ],
      "abstract": "We propose a design for a functional programming language for autonomous\nagents, built off the ideas and motivations of Behavior Trees (BTs). BTs are a\npopular model for designing agents behavior in robotics and AI. However, as\ntheir growth has increased dramatically, the simple model of BTs has come to be\nlimiting. There is a growing push to increase the functionality of BTs, with\nthe end goal of BTs evolving into a programming language in their own right,\ncentred around the defining BT properties of modularity and reactiveness.\n  In this paper, we examine how the BT model must be extended in order to grow\ninto such a language. We identify some fundamental problems which must be\nsolved: implementing `reactive' selection, 'monitoring' safety-critical\nconditions, and passing data between actions. We provide a variety of small\nexamples which demonstrate that these problems are complex, and that current BT\napproaches do not handle them in a manner consistent with modularity. We\ninstead provide a simple set of modular programming primitives for handling\nthese use cases, and show how they can be combined to build complex programs.\nWe present a full specification for our BT-inspired language, and give an\nimplementation in the functional programming language Haskell. Finally, we\ndemonstrate our language by translating a large and complex BT into a simple,\nunambiguous program.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/561f925d6223ba5559c87e676e98888b84c13780",
      "published_date": "2024-11-26",
      "downloaded_date": "2025-02-02",
      "filename": "Biggar-A Behavior Tree-inspired programming language for autonomous agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2412.08654v1",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.RO",
        "cs.SE"
      ]
    },
    "2404.04667v1": {
      "title": "Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology",
      "authors": [
        "Dyke Ferber",
        "Omar S. M. El Nahhas",
        "Georg WÃ¶lflein",
        "Isabella C. Wiest",
        "Jan Clusmann",
        "Marie-Elisabeth LeÃman",
        "Sebastian Foersch",
        "Jacqueline Lammert",
        "Maximilian Tschochohei",
        "Dirk JÃ¤ger",
        "Manuel Salto-Tellez",
        "Nikolaus Schultz",
        "Daniel Truhn",
        "Jakob Nikolas Kather"
      ],
      "abstract": "Multimodal artificial intelligence (AI) systems have the potential to enhance\nclinical decision-making by interpreting various types of medical data.\nHowever, the effectiveness of these models across all medical fields is\nuncertain. Each discipline presents unique challenges that need to be addressed\nfor optimal performance. This complexity is further increased when attempting\nto integrate different fields into a single model. Here, we introduce an\nalternative approach to multimodal medical AI that utilizes the generalist\ncapabilities of a large language model (LLM) as a central reasoning engine.\nThis engine autonomously coordinates and deploys a set of specialized medical\nAI tools. These tools include text, radiology and histopathology image\ninterpretation, genomic data processing, web searches, and document retrieval\nfrom medical guidelines. We validate our system across a series of clinical\noncology scenarios that closely resemble typical patient care workflows. We\nshow that the system has a high capability in employing appropriate tools\n(97%), drawing correct conclusions (93.6%), and providing complete (94%), and\nhelpful (89.2%) recommendations for individual patient cases while consistently\nreferencing relevant literature (82.5%) upon instruction. This work provides\nevidence that LLMs can effectively plan and execute domain-specific models to\nretrieve or synthesize new information when used as autonomous agents. This\nenables them to function as specialist, patient-tailored clinical assistants.\nIt also simplifies regulatory compliance by allowing each component tool to be\nindividually validated and approved. We believe, that our work can serve as a\nproof-of-concept for more advanced LLM-agents in the medical domain.",
      "citation_count": 5,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3bf118f2f918ad121aa3983479241d8b09f9c071",
      "published_date": "2024-04-06",
      "downloaded_date": "2025-02-02",
      "filename": "Ferber-Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.04667v1",
      "categories": [
        "cs.AI",
        "q-bio.TO"
      ]
    },
    "1805.02754v1": {
      "title": "Verisimilar Percept Sequences Tests for Autonomous Driving Intelligent Agent Assessment",
      "authors": [
        "Thomio Watanabe",
        "Denis Wolf"
      ],
      "abstract": "The autonomous car technology promises to replace human drivers with safer\ndriving systems. But although autonomous cars can become safer than human\ndrivers this is a long process that is going to be refined over time. Before\nthese vehicles are deployed on urban roads a minimum safety level must be\nassured. Since the autonomous car technology is still under development there\nis no standard methodology to evaluate such systems. It is important to\ncompletely understand the technology that is being developed to design\nefficient means to evaluate it. In this paper we assume safety-critical systems\nreliability as a safety measure. We model an autonomous road vehicle as an\nintelligent agent and we approach its evaluation from an artificial\nintelligence perspective. Our focus is the evaluation of perception and\ndecision making systems and also to propose a systematic method to evaluate\ntheir integration in the vehicle. We identify critical aspects of the data\ndependency from the artificial intelligence state of the art models and we also\npropose procedures to reproduce them.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/dbb52ec0155594d37f71fe3483553281fab23d3d",
      "published_date": "2018-05-07",
      "downloaded_date": "2025-02-02",
      "filename": "Watanabe-Verisimilar Percept Sequences Tests for Autonomous Driving Intelligent Agent Assessment.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1805.02754v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    "1903.10545v5": {
      "title": "Winning Isn't Everything: Enhancing Game Development with Intelligent Agents",
      "authors": [
        "Yunqi Zhao",
        "Igor Borovikov",
        "Fernando de Mesentier Silva",
        "Ahmad Beirami",
        "Jason Rupert",
        "Caedmon Somers",
        "Jesse Harder",
        "John Kolen",
        "Jervis Pinto",
        "Reza Pourabolghasem",
        "James Pestrak",
        "Harold Chaput",
        "Mohsen Sardari",
        "Long Lin",
        "Sundeep Narravula",
        "Navid Aghdaie",
        "Kazi Zaman"
      ],
      "abstract": "Recently, there have been several high-profile achievements of agents\nlearning to play games against humans and beat them. In this paper, we study\nthe problem of training intelligent agents in service of game development.\nUnlike the agents built to \"beat the game\", our agents aim to produce\nhuman-like behavior to help with game evaluation and balancing. We discuss two\nfundamental metrics based on which we measure the human-likeness of agents,\nnamely skill and style, which are multi-faceted concepts with practical\nimplications outlined in this paper. We report four case studies in which the\nstyle and skill requirements inform the choice of algorithms and metrics used\nto train agents; ranging from A* search to state-of-the-art deep reinforcement\nlearning. We, further, show that the learning potential of state-of-the-art\ndeep RL models does not seamlessly transfer from the benchmark environments to\ntarget ones without heavily tuning their hyperparameters, leading to linear\nscaling of the engineering efforts and computational cost with the number of\ntarget domains.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-03-25",
      "downloaded_date": "2025-02-02",
      "filename": "Zhao-Winning Isnt Everything Enhancing Game Development with Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1903.10545v5",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.NE"
      ]
    },
    "2101.10014v1": {
      "title": "A Simple Disaster-Related Knowledge Base for Intelligent Agents",
      "authors": [
        "Clark Emmanuel Paulo",
        "Arvin Ken Ramirez",
        "David Clarence Reducindo",
        "Rannie Mark Mateo",
        "Joseph Marvin Imperial"
      ],
      "abstract": "In this paper, we describe our efforts in establishing a simple knowledge\nbase by building a semantic network composed of concepts and word relationships\nin the context of disasters in the Philippines. Our primary source of data is a\ncollection of news articles scraped from various Philippine news websites.\nUsing word embeddings, we extract semantically similar and co-occurring words\nfrom an initial seed words list. We arrive at an expanded ontology with a total\nof 450 word assertions. We let experts from the fields of linguistics,\ndisasters, and weather science evaluate our knowledge base and arrived at an\nagreeability rate of 64%. We then perform a time-based analysis of the\nassertions to identify important semantic changes captured by the knowledge\nbase such as the (a) trend of roles played by human entities, (b) memberships\nof human entities, and (c) common association of disaster-related words. The\ncontext-specific knowledge base developed from this study can be adapted by\nintelligent agents such as chat bots integrated in platforms such as Facebook\nMessenger for answering disaster-related queries.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/503f4cbdc89494aaae6579ea6de8cca5a3eed935",
      "published_date": "2021-01-25",
      "downloaded_date": "2025-02-02",
      "filename": "Paulo-A Simple Disaster-Related Knowledge Base for Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2101.10014v1",
      "categories": [
        "cs.CL"
      ]
    },
    "2406.07089v1": {
      "title": "RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents",
      "authors": [
        "Wenjia Xu",
        "Zijian Yu",
        "Yixu Wang",
        "Jiuniu Wang",
        "Mugen Peng"
      ],
      "abstract": "An increasing number of models have achieved great performance in remote\nsensing tasks with the recent development of Large Language Models (LLMs) and\nVisual Language Models (VLMs). However, these models are constrained to basic\nvision and language instruction-tuning tasks, facing challenges in complex\nremote sensing applications. Additionally, these models lack specialized\nexpertise in professional domains. To address these limitations, we propose a\nLLM-driven remote sensing intelligent agent named RS-Agent. Firstly, RS-Agent\nis powered by a large language model (LLM) that acts as its \"Central\nController,\" enabling it to understand and respond to various problems\nintelligently. Secondly, our RS-Agent integrates many high-performance remote\nsensing image processing tools, facilitating multi-tool and multi-turn\nconversations. Thirdly, our RS-Agent can answer professional questions by\nleveraging robust knowledge documents. We conducted experiments using several\ndatasets, e.g., RSSDIVCS, RSVQA, and DOTAv1. The experimental results\ndemonstrate that our RS-Agent delivers outstanding performance in many tasks,\ni.e., scene classification, visual question answering, and object counting\ntasks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-06-11",
      "downloaded_date": "2025-02-02",
      "filename": "Xu-RS-Agent Automating Remote Sensing Tasks through Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.07089v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2410.21312v1": {
      "title": "$\\texttt{PatentAgent}$: Intelligent Agent for Automated Pharmaceutical Patent Analysis",
      "authors": [
        "Xin Wang",
        "Yifan Zhang",
        "Xiaojing Zhang",
        "Longhui Yu",
        "Xinna Lin",
        "Jindong Jiang",
        "Bin Ma",
        "Kaicheng Yu"
      ],
      "abstract": "Pharmaceutical patents play a vital role in biochemical industries,\nespecially in drug discovery, providing researchers with unique early access to\ndata, experimental results, and research insights. With the advancement of\nmachine learning, patent analysis has evolved from manual labor to tasks\nassisted by automatic tools. However, there still lacks an unified agent that\nassists every aspect of patent analysis, from patent reading to core chemical\nidentification. Leveraging the capabilities of Large Language Models (LLMs) to\nunderstand requests and follow instructions, we introduce the $\\textbf{first}$\nintelligent agent in this domain, $\\texttt{PatentAgent}$, poised to advance and\npotentially revolutionize the landscape of pharmaceutical research.\n$\\texttt{PatentAgent}$ comprises three key end-to-end modules --\n$\\textit{PA-QA}$, $\\textit{PA-Img2Mol}$, and $\\textit{PA-CoreId}$ -- that\nrespectively perform (1) patent question-answering, (2)\nimage-to-molecular-structure conversion, and (3) core chemical structure\nidentification, addressing the essential needs of scientists and practitioners\nin pharmaceutical patent analysis. Each module of $\\texttt{PatentAgent}$\ndemonstrates significant effectiveness with the updated algorithm and the\nsynergistic design of $\\texttt{PatentAgent}$ framework. $\\textit{PA-Img2Mol}$\noutperforms existing methods across CLEF, JPO, UOB, and USPTO patent benchmarks\nwith an accuracy gain between 2.46% and 8.37% while $\\textit{PA-CoreId}$\nrealizes accuracy improvement ranging from 7.15% to 7.62% on PatentNetML\nbenchmark. Our code and dataset will be publicly available.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-10-25",
      "downloaded_date": "2025-02-02",
      "filename": "Wang-textttPatentAgent Intelligent Agent for Automated Pharmaceutical Patent Analysis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.21312v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    "1904.01540v1": {
      "title": "Augmented Utilitarianism for AGI Safety",
      "authors": [
        "Nadisha-Marie Aliman",
        "Leon Kester"
      ],
      "abstract": "In the light of ongoing progresses of research on artificial intelligent\nsystems exhibiting a steadily increasing problem-solving ability, the\nidentification of practicable solutions to the value alignment problem in AGI\nSafety is becoming a matter of urgency. In this context, one preeminent\nchallenge that has been addressed by multiple researchers is the adequate\nformulation of utility functions or equivalents reliably capturing human\nethical conceptions. However, the specification of suitable utility functions\nharbors the risk of \"perverse instantiation\" for which no final consensus on\nresponsible proactive countermeasures has been achieved so far. Amidst this\nbackground, we propose a novel socio-technological ethical framework denoted\nAugmented Utilitarianism which directly alleviates the perverse instantiation\nproblem. We elaborate on how augmented by AI and more generally science and\ntechnology, it might allow a society to craft and update ethical utility\nfunctions while jointly undergoing a dynamical ethical enhancement. Further, we\nelucidate the need to consider embodied simulations in the design of utility\nfunctions for AGIs aligned with human values. Finally, we discuss future\nprospects regarding the usage of the presented scientifically grounded ethical\nframework and mention possible challenges.",
      "citation_count": 8,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/45b4d372853efc956e0285e0101a6e4507e4efd7",
      "published_date": "2019-04-02",
      "downloaded_date": "2025-02-02",
      "filename": "Aliman-Augmented Utilitarianism for AGI Safety.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1904.01540v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1805.02241v1": {
      "title": "Acquisition and use of knowledge over a restricted domain by intelligent agents",
      "authors": [
        "Juliao Braga",
        "Nizam Omar",
        "Luciana F. Thome"
      ],
      "abstract": "This short paper provides a description of an architecture to acquisition and\nuse of knowledge by intelligent agents over a restricted domain of the Internet\nInfrastructure. The proposed architecture is added to an intelligent agent\ndeployment model over a very useful server for Internet Autonomous System\nadministrators. Such servers, which are heavily dependent on arbitrary and\neventual updates of human beings, become unreliable. This is a position paper\nthat proposes three research questions that are still in progress.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2018-05-06",
      "downloaded_date": "2025-02-02",
      "filename": "Braga-Acquisition and use of knowledge over a restricted domain by intelligent agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1805.02241v1",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.NI"
      ]
    },
    "1807.03887v1": {
      "title": "Vision System for AGI: Problems and Directions",
      "authors": [
        "Alexey Potapov",
        "Sergey Rodionov",
        "Maxim Peterson",
        "Oleg Shcherbakov",
        "Innokentii Zhdanov",
        "Nikolai Skorobogatko"
      ],
      "abstract": "What frameworks and architectures are necessary to create a vision system for\nAGI? In this paper, we propose a formal model that states the task of\nperception within AGI. We show the role of discriminative and generative models\nin achieving efficient and general solution of this task, thus specifying the\ntask in more detail. We discuss some existing generative and discriminative\nmodels and demonstrate their insufficiency for our purposes. Finally, we\ndiscuss some architectural dilemmas and open questions.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d15b6ff3cb38be6d84cd1a167932451cf9e929ae",
      "published_date": "2018-07-10",
      "downloaded_date": "2025-02-02",
      "filename": "Potapov-Vision System for AGI Problems and Directions.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1807.03887v1",
      "categories": [
        "cs.CV"
      ]
    },
    "2310.15274v2": {
      "title": "From the Pursuit of Universal AGI Architecture to Systematic Approach to Heterogenous AGI: Addressing Alignment, Energy, & AGI Grand Challenges",
      "authors": [
        "Eren Kurshan"
      ],
      "abstract": "AI faces a trifecta of grand challenges: the Energy Wall, the Alignment\nProblem and the Leap from Narrow AI to AGI. Contemporary AI solutions consume\nunsustainable amounts of energy during model training and daily operations.\nMaking things worse, the amount of computation required to train each new AI\nmodel has been doubling every 2 months since 2020, directly translating to\nunprecedented increases in energy consumption.\n  The leap from AI to AGI requires multiple functional subsystems operating in\na balanced manner, which requires a system architecture. However, the current\napproach to artificial intelligence lacks system design; even though system\ncharacteristics play a key role in the human brain; from the way it processes\ninformation to how it makes decisions. System design is the key to alignment,\none of the most challenging goals in AI. This difficulty stems from the fact\nthat the complexity of human moral system requires a similarly sophisticated\nsystem for alignment. Without accurately reflecting the complexity of these\ncore moral subsystems and systems, aligning AI with human values becomes\nsignificantly more challenging.\n  In this paper, we posit that system design is the missing piece in overcoming\nthe grand challenges. We present a Systematic Approach to AGI that utilizes\nsystem design principles to AGI, while providing ways to overcome the energy\nwall and the alignment challenges. This paper asserts that artificial\nintelligence can be realized through a multiplicity of design-specific\npathways, rather than a singular, overarching AGI architecture. AGI systems may\nexhibit diverse architectural configurations and capabilities, contingent upon\ntheir intended use cases. It advocates for a focus on employing system design\nprinciples as a guiding framework, rather than solely concentrating on a\nuniversal AGI architecture.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e0104d0ad7f554f8d9278c41abb78deba8293f69",
      "published_date": "2023-10-23",
      "downloaded_date": "2025-02-02",
      "filename": "Kurshan-From the Pursuit of Universal AGI Architecture to Systematic Approach to Heterogenous AGI Addressing....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2310.15274v2",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2307.03697v1": {
      "title": "Specification, Validation and Verification of Social, Legal, Ethical, Empathetic and Cultural Requirements for Autonomous Agents",
      "authors": [
        "Sinem Getir Yaman",
        "Ana Cavalcanti",
        "Radu Calinescu",
        "Colin Paterson",
        "Pedro Ribeiro",
        "Beverley Townsend"
      ],
      "abstract": "Autonomous agents are increasingly being proposed for use in healthcare,\nassistive care, education, and other applications governed by complex\nhuman-centric norms. To ensure compliance with these norms, the rules they\ninduce need to be unambiguously defined, checked for consistency, and used to\nverify the agent. In this paper, we introduce a framework for formal\nspecification, validation and verification of social, legal, ethical,\nempathetic and cultural (SLEEC) rules for autonomous agents. Our framework\ncomprises: (i) a language for specifying SLEEC rules and rule defeaters (that\nis, circumstances in which a rule does not apply or an alternative form of the\nrule is required); (ii) a formal semantics (defined in the process algebra\ntock-CSP) for the language; and (iii) methods for detecting conflicts and\nredundancy within a set of rules, and for verifying the compliance of an\nautonomous agent with such rules. We show the applicability of our framework\nfor two autonomous agents from different domains: a firefighter UAV, and an\nassistive-dressing robot.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/31da227c95ec8bc6ebcb88705c52b039d75a9cad",
      "published_date": "2023-07-07",
      "downloaded_date": "2025-02-02",
      "filename": "Yaman-Specification Validation and Verification of Social Legal Ethical Empathetic and Cultural Requiremen....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2307.03697v1",
      "categories": [
        "cs.SE"
      ]
    },
    "1202.1945v1": {
      "title": "A framework: Cluster detection and multidimensional visualization of automated data mining using intelligent agents",
      "authors": [
        "R. Jayabrabu",
        "V. Saravanan",
        "K. Vivekanandan"
      ],
      "abstract": "Data Mining techniques plays a vital role like extraction of required\nknowledge, finding unsuspected information to make strategic decision in a\nnovel way which in term understandable by domain experts. A generalized frame\nwork is proposed by considering non - domain experts during mining process for\nbetter understanding, making better decision and better finding new patters in\ncase of selecting suitable data mining techniques based on the user profile by\nmeans of intelligent agents. KEYWORDS: Data Mining Techniques, Intelligent\nAgents, User Profile, Multidimensional Visualization, Knowledge Discovery.",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7600a794731a9cffc298562e0eabb9097a4806bd",
      "published_date": "2012-02-09",
      "downloaded_date": "2025-02-02",
      "filename": "Jayabrabu-A framework Cluster detection and multidimensional visualization of automated data mining using inte....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1202.1945v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1601.00191v1": {
      "title": "An Improved Intelligent Agent for Mining Real-Time Databases Using Modified Cortical Learning Algorithms",
      "authors": [
        "N. E. Osegi"
      ],
      "abstract": "Cortical Learning Algorithms based on the Hierarchical Temporal Memory, HTM\nhave been developed by Numenta Incorporation from which variations and\nmodifications are currently being investigated upon. HTM offers better promises\nas a future computational model of the neocortex the seat of intelligence in\nthe brain. Currently, intelligent agents are embedded in almost every modern\nday electronic system found in homes, offices and industries worldwide. In this\npaper, we present a first step in realising useful HTM like applications\nspecifically for mining a synthetic and real time dataset based on a novel\nintelligent agent framework, and demonstrate how a modified version of this\nvery important computational technique will lead to improved recognition.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/95d25efa330e33b4643ee381b4bef3d44dfdf1d1",
      "published_date": "2016-01-02",
      "downloaded_date": "2025-02-02",
      "filename": "Osegi-An Improved Intelligent Agent for Mining Real-Time Databases Using Modified Cortical Learning Algori....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1601.00191v1",
      "categories": [
        "cs.NE"
      ]
    },
    "2404.09331v2": {
      "title": "SNN4Agents: A Framework for Developing Energy-Efficient Embodied Spiking Neural Networks for Autonomous Agents",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Alberto Marchisio",
        "Muhammad Shafique"
      ],
      "abstract": "Recent trends have shown that autonomous agents, such as Autonomous Ground\nVehicles (AGVs), Unmanned Aerial Vehicles (UAVs), and mobile robots,\neffectively improve human productivity in solving diverse tasks. However, since\nthese agents are typically powered by portable batteries, they require\nextremely low power/energy consumption to operate in a long lifespan. To solve\nthis challenge, neuromorphic computing has emerged as a promising solution,\nwhere bio-inspired Spiking Neural Networks (SNNs) use spikes from event-based\ncameras or data conversion pre-processing to perform sparse computations\nefficiently. However, the studies of SNN deployments for autonomous agents are\nstill at an early stage. Hence, the optimization stages for enabling efficient\nembodied SNN deployments for autonomous agents have not been defined\nsystematically. Toward this, we propose a novel framework called SNN4Agents\nthat consists of a set of optimization techniques for designing\nenergy-efficient embodied SNNs targeting autonomous agent applications. Our\nSNN4Agents employs weight quantization, timestep reduction, and attention\nwindow reduction to jointly improve the energy efficiency, reduce the memory\nfootprint, optimize the processing latency, while maintaining high accuracy. In\nthe evaluation, we investigate use cases of event-based car recognition, and\nexplore the trade-offs among accuracy, latency, memory, and energy consumption.\nThe experimental results show that our proposed framework can maintain high\naccuracy (i.e., 84.12% accuracy) with 68.75% memory saving, 3.58x speed-up, and\n4.03x energy efficiency improvement as compared to the state-of-the-art work\nfor NCARS dataset. In this manner, our SNN4Agents framework paves the way\ntoward enabling energy-efficient embodied SNN deployments for autonomous\nagents.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8a084cb64ee25f21a10b6888260f72e5b41b0637",
      "published_date": "2024-04-14",
      "downloaded_date": "2025-02-02",
      "filename": "Putra-SNN4Agents A Framework for Developing Energy-Efficient Embodied Spiking Neural Networks for Autonomo....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.09331v2",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    },
    "2008.12879v2": {
      "title": "A Metamodel and Framework for AGI",
      "authors": [
        "Hugo Latapie",
        "Ozkan Kilic"
      ],
      "abstract": "Can artificial intelligence systems exhibit superhuman performance, but in\ncritical ways, lack the intelligence of even a single-celled organism? The\nanswer is clearly 'yes' for narrow AI systems. Animals, plants, and even\nsingle-celled organisms learn to reliably avoid danger and move towards food.\nThis is accomplished via a physical knowledge preserving metamodel that\nautonomously generates useful models of the world. We posit that preserving the\nstructure of knowledge is critical for higher intelligences that manage\nincreasingly higher levels of abstraction, be they human or artificial. This is\nthe key lesson learned from applying AGI subsystems to complex real-world\nproblems that require continuous learning and adaptation. In this paper, we\nintroduce the Deep Fusion Reasoning Engine (DFRE), which implements a\nknowledge-preserving metamodel and framework for constructing applied AGI\nsystems. The DFRE metamodel exhibits some important fundamental knowledge\npreserving properties such as clear distinctions between symmetric and\nantisymmetric relations, and the ability to create a hierarchical knowledge\nrepresentation that clearly delineates between levels of abstraction. The DFRE\nmetamodel, which incorporates these capabilities, demonstrates how this\napproach benefits AGI in specific ways such as managing combinatorial explosion\nand enabling cumulative, distributed and federated learning. Our experiments\nshow that the proposed framework achieves 94% accuracy on average on\nunsupervised object detection and recognition. This work is inspired by the\nstate-of-the-art approaches to AGI, recent AGI-aspiring work, the granular\ncomputing community, as well as Alfred Korzybski's general semantics.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2020-08-28",
      "downloaded_date": "2025-02-02",
      "filename": "Latapie-A Metamodel and Framework for AGI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2008.12879v2",
      "categories": [
        "cs.AI"
      ]
    },
    "1807.09836v2": {
      "title": "Robustness to fundamental uncertainty in AGI alignment",
      "authors": [
        "G Gordon Worley III"
      ],
      "abstract": "The AGI alignment problem has a bimodal distribution of outcomes with most\noutcomes clustering around the poles of total success and existential,\ncatastrophic failure. Consequently, attempts to solve AGI alignment should, all\nelse equal, prefer false negatives (ignoring research programs that would have\nbeen successful) to false positives (pursuing research programs that will\nunexpectedly fail). Thus, we propose adopting a policy of responding to points\nof philosophical and practical uncertainty associated with the alignment\nproblem by limiting and choosing necessary assumptions to reduce the risk of\nfalse positives. Herein we explore in detail two relevant points of uncertainty\nthat AGI alignment research hinges on---meta-ethical uncertainty and\nuncertainty about mental phenomena---and show how to reduce false positives in\nresponse to them.",
      "citation_count": 4,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/39a8a994f199a5ad61d313b3514a8e311b9ebfa3",
      "published_date": "2018-07-25",
      "downloaded_date": "2025-02-02",
      "filename": "III-Robustness to fundamental uncertainty in AGI alignment.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1807.09836v2",
      "categories": [
        "cs.AI"
      ]
    },
    "0706.0280v1": {
      "title": "Multi-Agent Modeling Using Intelligent Agents in the Game of Lerpa",
      "authors": [
        "Evan Hurwitz",
        "Tshilidzi Marwala"
      ],
      "abstract": "Game theory has many limitations implicit in its application. By utilizing\nmultiagent modeling, it is possible to solve a number of problems that are\nunsolvable using traditional game theory. In this paper reinforcement learning\nis applied to neural networks to create intelligent agents",
      "citation_count": 9,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/753e4bb2a51131b9bcf6bdffb6096556a57f02a5",
      "published_date": "2007-06-02",
      "downloaded_date": "2025-02-02",
      "filename": "Hurwitz-Multi-Agent Modeling Using Intelligent Agents in the Game of Lerpa.pdf",
      "arxiv_url": "http://arxiv.org/pdf/0706.0280v1",
      "categories": [
        "cs.MA",
        "cs.GT"
      ]
    },
    "2403.02752v1": {
      "title": "HINTs: Sensemaking on large collections of documents with Hypergraph visualization and INTelligent agents",
      "authors": [
        "Sam Yu-Te Lee",
        "Kwan-Liu Ma"
      ],
      "abstract": "Sensemaking on a large collection of documents (corpus) is a challenging task\noften found in fields such as market research, legal studies, intelligence\nanalysis, political science, computational linguistics, etc. Previous works\napproach this problem either from a topic- or entity-based perspective, but\nthey lack interpretability and trust due to poor model alignment. In this\npaper, we present HINTs, a visual analytics approach that combines topic- and\nentity-based techniques seamlessly and integrates Large Language Models (LLMs)\nas both a general NLP task solver and an intelligent agent. By leveraging the\nextraction capability of LLMs in the data preparation stage, we model the\ncorpus as a hypergraph that matches the user's mental model when making sense\nof the corpus. The constructed hypergraph is hierarchically organized with an\nagglomerative clustering algorithm by combining semantic and connectivity\nsimilarity. The system further integrates an LLM-based intelligent chatbot\nagent in the interface to facilitate sensemaking. To demonstrate the\ngeneralizability and effectiveness of the HINTs system, we present two case\nstudies on different domains and a comparative user study. We report our\ninsights on the behavior patterns and challenges when intelligent agents are\nused to facilitate sensemaking. We find that while intelligent agents can\naddress many challenges in sensemaking, the visual hints that visualizations\nprovide are necessary to address the new problems brought by intelligent\nagents. We discuss limitations and future work for combining interactive\nvisualization and LLMs more profoundly to better support corpus analysis.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7b030e59067f2e017b3720eb08b7a00f751591e4",
      "published_date": "2024-03-05",
      "downloaded_date": "2025-02-02",
      "filename": "Lee-HINTs Sensemaking on large collections of documents with Hypergraph visualization and INTelligent ag....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.02752v1",
      "categories": [
        "cs.HC"
      ]
    },
    "2404.04442v1": {
      "title": "Exploring Autonomous Agents through the Lens of Large Language Models: A Review",
      "authors": [
        "Saikat Barua"
      ],
      "abstract": "Large Language Models (LLMs) are transforming artificial intelligence,\nenabling autonomous agents to perform diverse tasks across various domains.\nThese agents, proficient in human-like text comprehension and generation, have\nthe potential to revolutionize sectors from customer service to healthcare.\nHowever, they face challenges such as multimodality, human value alignment,\nhallucinations, and evaluation. Techniques like prompting, reasoning, tool\nutilization, and in-context learning are being explored to enhance their\ncapabilities. Evaluation platforms like AgentBench, WebArena, and ToolLLM\nprovide robust methods for assessing these agents in complex scenarios. These\nadvancements are leading to the development of more resilient and capable\nautonomous agents, anticipated to become integral in our digital lives,\nassisting in tasks from email responses to disease diagnosis. The future of AI,\nwith LLMs at the forefront, is promising.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/128b95f2bb77c8268e68e44c171e701221e7676f",
      "published_date": "2024-04-05",
      "downloaded_date": "2025-02-02",
      "filename": "Barua-Exploring Autonomous Agents through the Lens of Large Language Models A Review.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.04442v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2009.06131v1": {
      "title": "An Argumentation-based Approach for Explaining Goal Selection in Intelligent Agents",
      "authors": [
        "Mariela Morveli-Espinoza",
        "Cesar Augusto Tacla",
        "Henrique Jasinski"
      ],
      "abstract": "During the first step of practical reasoning, i.e. deliberation or goals\nselection, an intelligent agent generates a set of pursuable goals and then\nselects which of them he commits to achieve. Explainable Artificial\nIntelligence (XAI) systems, including intelligent agents, must be able to\nexplain their internal decisions. In the context of goals selection, agents\nshould be able to explain the reasoning path that leads them to select (or not)\na certain goal. In this article, we use an argumentation-based approach for\ngenerating explanations about that reasoning path. Besides, we aim to enrich\nthe explanations with information about emerging conflicts during the selection\nprocess and how such conflicts were resolved. We propose two types of\nexplanations: the partial one and the complete one and a set of explanatory\nschemes to generate pseudo-natural explanations. Finally, we apply our proposal\nto the cleaner world scenario.",
      "citation_count": 6,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d467aa612eaa16f4a4698625c82b3f8166d8d844",
      "published_date": "2020-09-14",
      "downloaded_date": "2025-02-02",
      "filename": "Morveli-Espinoza-An Argumentation-based Approach for Explaining Goal Selection in Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2009.06131v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2106.07114v1": {
      "title": "Intelligent Agent for Hurricane Emergency Identification and Text Information Extraction from Streaming Social Media Big Data",
      "authors": [
        "Jingwei Huang",
        "Wael Khallouli",
        "Ghaith Rabadi",
        "Mamadou Seck"
      ],
      "abstract": "This paper presents our research on leveraging social media Big Data and AI\nto support hurricane disaster emergency response. The current practice of\nhurricane emergency response for rescue highly relies on emergency call\ncentres. The more recent Hurricane Harvey event reveals the limitations of the\ncurrent systems. We use Hurricane Harvey and the associated Houston flooding as\nthe motivating scenario to conduct research and develop a prototype as a\nproof-of-concept of using an intelligent agent as a complementary role to\nsupport emergency centres in hurricane emergency response. This intelligent\nagent is used to collect real-time streaming tweets during a natural disaster\nevent, to identify tweets requesting rescue, to extract key information such as\naddress and associated geocode, and to visualize the extracted information in\nan interactive map in decision supports. Our experiment shows promising\noutcomes and the potential application of the research in support of hurricane\nemergency response.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9da73c03403ce46428891753c8c0390fb53521e4",
      "published_date": "2021-06-14",
      "downloaded_date": "2025-02-02",
      "filename": "Huang-Intelligent Agent for Hurricane Emergency Identification and Text Information Extraction from Stream....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2106.07114v1",
      "categories": [
        "cs.AI"
      ]
    },
    "2104.01445v1": {
      "title": "A Dynamics Perspective of Pursuit-Evasion Games of Intelligent Agents with the Ability to Learn",
      "authors": [
        "Hao Xiong",
        "Huanhui Cao",
        "Lin Zhang",
        "Wenjie Lu"
      ],
      "abstract": "Pursuit-evasion games are ubiquitous in nature and in an artificial world. In\nnature, pursuer(s) and evader(s) are intelligent agents that can learn from\nexperience, and dynamics (i.e., Newtonian or Lagrangian) is vital for the\npursuer and the evader in some scenarios. To this end, this paper addresses the\npursuit-evasion game of intelligent agents from the perspective of dynamics. A\nbio-inspired dynamics formulation of a pursuit-evasion game and baseline\npursuit and evasion strategies are introduced at first. Then, reinforcement\nlearning techniques are used to mimic the ability of intelligent agents to\nlearn from experience. Based on the dynamics formulation and reinforcement\nlearning techniques, the effects of improving both pursuit and evasion\nstrategies based on experience on pursuit-evasion games are investigated at two\nlevels 1) individual runs and 2) ranges of the parameters of pursuit-evasion\ngames. Results of the investigation are consistent with nature observations and\nthe natural law - survival of the fittest. More importantly, with respect to\nthe result of a pursuit-evasion game of agents with baseline strategies, this\nstudy achieves a different result. It is shown that, in a pursuit-evasion game\nwith a dynamics formulation, an evader is not able to escape from a slightly\nfaster pursuer with an effective learned pursuit strategy, based on agile\nmaneuvers and an effective learned evasion strategy.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-04-03",
      "downloaded_date": "2025-02-02",
      "filename": "Xiong-A Dynamics Perspective of Pursuit-Evasion Games of Intelligent Agents with the Ability to Learn.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2104.01445v1",
      "categories": [
        "eess.SY",
        "cs.MA",
        "cs.SY"
      ]
    },
    "2404.19291v1": {
      "title": "Dynamic Human Trust Modeling of Autonomous Agents With Varying Capability and Strategy",
      "authors": [
        "Jason Dekarske",
        "Zhaodan Kong",
        "Sanjay Joshi"
      ],
      "abstract": "Objective We model the dynamic trust of human subjects in a\nhuman-autonomy-teaming screen-based task.\n  Background Trust is an emerging area of study in human-robot collaboration.\nMany studies have looked at the issue of robot performance as a sole predictor\nof human trust, but this could underestimate the complexity of the interaction.\n  Method Subjects were paired with autonomous agents to search an on-screen\ngrid to determine the number of outlier objects. In each trial, a different\nautonomous agent with a preassigned capability used one of three search\nstrategies and then reported the number of outliers it found as a fraction of\nits capability. Then, the subject reported their total outlier estimate. Human\nsubjects then evaluated statements about the agent's behavior, reliability, and\ntheir trust in the agent.\n  Results 80 subjects were recruited. Self-reported trust was modeled using\nOrdinary Least Squares, but the group that interacted with varying capability\nagents on a short time order produced a better performing ARIMAX model. Models\nwere cross-validated between groups and found a moderate improvement in the\nnext trial trust prediction.\n  Conclusion A time series modeling approach reveals the effects of temporal\nordering of agent performance on estimated trust. Recency bias may affect how\nsubjects weigh the contribution of strategy or capability to trust.\nUnderstanding the connections between agent behavior, agent performance, and\nhuman trust is crucial to improving human-robot collaborative tasks.\n  Application The modeling approach in this study demonstrates the need to\nrepresent autonomous agent characteristics over time to capture changes in\nhuman trust.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-04-30",
      "downloaded_date": "2025-02-02",
      "filename": "Dekarske-Dynamic Human Trust Modeling of Autonomous Agents With Varying Capability and Strategy.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2404.19291v1",
      "categories": [
        "cs.HC"
      ]
    },
    "2102.00528v1": {
      "title": "How to Measure Cyber Resilience of an Autonomous Agent: Approaches and Challenges",
      "authors": [
        "Alexandre Ligo",
        "Alexander Kott",
        "Igor Linkov"
      ],
      "abstract": "Several approaches have been used to assess the performance of cyberphysical\nsystems and their exposure to various types of risks. Such assessments have\nbecome increasingly important as autonomous attackers ramp up the frequency,\nduration and intensity of threats while autonomous agents have the potential to\nrespond to cyber-attacks with unprecedented speed and scale. However, most\nassessment approaches have limitations with respect to measuring cyber\nresilience, or the ability of systems to absorb, recover from, and adapt to\ncyberattacks. In this paper, we provide an overview of several common\napproaches, discuss practical challenges and propose research directions for\nthe development of effective cyber resilience measures.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2021-01-31",
      "downloaded_date": "2025-02-02",
      "filename": "Ligo-How to Measure Cyber Resilience of an Autonomous Agent Approaches and Challenges.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2102.00528v1",
      "categories": [
        "cs.CR"
      ]
    },
    "2410.16197v3": {
      "title": "LASER: Script Execution by Autonomous Agents for On-demand Traffic Simulation",
      "authors": [
        "Hao Gao",
        "Jingyue Wang",
        "Wenyang Fang",
        "Jingwei Xu",
        "Yunpeng Huang",
        "Taolue Chen",
        "Xiaoxing Ma"
      ],
      "abstract": "Autonomous Driving Systems (ADS) require diverse and safety-critical traffic\nscenarios for effective training and testing, but the existing data generation\nmethods struggle to provide flexibility and scalability. We propose LASER, a\nnovel frame-work that leverage large language models (LLMs) to conduct traffic\nsimulations based on natural language inputs. The framework operates in two\nstages: it first generates scripts from user-provided descriptions and then\nexecutes them using autonomous agents in real time. Validated in the CARLA\nsimulator, LASER successfully generates complex, on-demand driving scenarios,\nsignificantly improving ADS training and testing data generation.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/8847898715ad9fc83b9f2cb2e647b32d3332603a",
      "published_date": "2024-10-21",
      "downloaded_date": "2025-02-02",
      "filename": "Gao-LASER Script Execution by Autonomous Agents for On-demand Traffic Simulation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2410.16197v3",
      "categories": [
        "cs.RO",
        "cs.MA"
      ]
    },
    "2407.01603v3": {
      "title": "A Review of Large Language Models and Autonomous Agents in Chemistry",
      "authors": [
        "Mayk Caldas Ramos",
        "Christopher J. Collison",
        "Andrew D. White"
      ],
      "abstract": "Large language models (LLMs) have emerged as powerful tools in chemistry,\nsignificantly impacting molecule design, property prediction, and synthesis\noptimization. This review highlights LLM capabilities in these domains and\ntheir potential to accelerate scientific discovery through automation. We also\nreview LLM-based autonomous agents: LLMs with a broader set of tools to\ninteract with their surrounding environment. These agents perform diverse tasks\nsuch as paper scraping, interfacing with automated laboratories, and synthesis\nplanning. As agents are an emerging topic, we extend the scope of our review of\nagents beyond chemistry and discuss across any scientific domains. This review\ncovers the recent history, current capabilities, and design of LLMs and\nautonomous agents, addressing specific challenges, opportunities, and future\ndirections in chemistry. Key challenges include data quality and integration,\nmodel interpretability, and the need for standard benchmarks, while future\ndirections point towards more sophisticated multi-modal agents and enhanced\ncollaboration between agents and experimental methods. Due to the quick pace of\nthis field, a repository has been built to keep track of the latest studies:\nhttps://github.com/ur-whitelab/LLMs-in-science.",
      "citation_count": 16,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cac8c4f79077c74aa059d1c58c021be1c89f1178",
      "published_date": "2024-06-26",
      "downloaded_date": "2025-02-02",
      "filename": "Ramos-A Review of Large Language Models and Autonomous Agents in Chemistry.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.01603v3",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "physics.chem-ph"
      ]
    },
    "1009.5346v1": {
      "title": "A Novel Approach for Cardiac Disease Prediction and Classification Using Intelligent Agents",
      "authors": [
        "Murugesan Kuttikrishnan"
      ],
      "abstract": "The goal is to develop a novel approach for cardiac disease prediction and\ndiagnosis using intelligent agents. Initially the symptoms are preprocessed\nusing filter and wrapper based agents. The filter removes the missing or\nirrelevant symptoms. Wrapper is used to extract the data in the data set\naccording to the threshold limits. Dependency of each symptom is identified\nusing dependency checker agent. The classification is based on the prior and\nposterior probability of the symptoms with the evidence value. Finally the\nsymptoms are classified in to five classes namely absence, starting, mild,\nmoderate and serious. Using the cooperative approach the cardiac problem is\nsolved and verified.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2010-09-27",
      "downloaded_date": "2025-02-02",
      "filename": "Kuttikrishnan-A Novel Approach for Cardiac Disease Prediction and Classification Using Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1009.5346v1",
      "categories": [
        "cs.MA",
        "cs.AI"
      ]
    },
    "1908.04929v1": {
      "title": "3-D Scene Graph: A Sparse and Semantic Representation of Physical Environments for Intelligent Agents",
      "authors": [
        "Ue-Hwan Kim",
        "Jin-Man Park",
        "Taek-Jin Song",
        "Jong-Hwan Kim"
      ],
      "abstract": "Intelligent agents gather information and perceive semantics within the\nenvironments before taking on given tasks. The agents store the collected\ninformation in the form of environment models that compactly represent the\nsurrounding environments. The agents, however, can only conduct limited tasks\nwithout an efficient and effective environment model. Thus, such an environment\nmodel takes a crucial role for the autonomy systems of intelligent agents. We\nclaim the following characteristics for a versatile environment model:\naccuracy, applicability, usability, and scalability. Although a number of\nresearchers have attempted to develop such models that represent environments\nprecisely to a certain degree, they lack broad applicability, intuitive\nusability, and satisfactory scalability. To tackle these limitations, we\npropose 3-D scene graph as an environment model and the 3-D scene graph\nconstruction framework. The concise and widely used graph structure readily\nguarantees usability as well as scalability for 3-D scene graph. We demonstrate\nthe accuracy and applicability of the 3-D scene graph by exhibiting the\ndeployment of the 3-D scene graph in practical applications. Moreover, we\nverify the performance of the proposed 3-D scene graph and the framework by\nconducting a series of comprehensive experiments under various conditions.",
      "citation_count": 92,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c9afd65297e4a4d1850bb665d73ee1a102f461e1",
      "published_date": "2019-08-14",
      "downloaded_date": "2025-02-02",
      "filename": "Kim-3-D Scene Graph A Sparse and Semantic Representation of Physical Environments for Intelligent Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1908.04929v1",
      "categories": [
        "cs.CV",
        "cs.RO"
      ]
    },
    "2406.18178v2": {
      "title": "Games of Knightian Uncertainty as AGI testbeds",
      "authors": [
        "Spyridon Samothrakis",
        "Dennis J. N. J. Soemers",
        "Damian Machlanski"
      ],
      "abstract": "Arguably, for the latter part of the late 20th and early 21st centuries,\ngames have been seen as the drosophila of AI. Games are a set of exciting\ntestbeds, whose solutions (in terms of identifying optimal players) would lead\nto machines that would possess some form of general intelligence, or at the\nvery least help us gain insights toward building intelligent machines.\nFollowing impressive successes in traditional board games like Go, Chess, and\nPoker, but also video games like the Atari 2600 collection, it is clear that\nthis is not the case. Games have been attacked successfully, but we are nowhere\nnear AGI developments (or, as harsher critics might say, useful AI\ndevelopments!). In this short vision paper, we argue that for game research to\nbecome again relevant to the AGI pathway, we need to be able to address\n\\textit{Knightian uncertainty} in the context of games, i.e. agents need to be\nable to adapt to rapid changes in game rules on the fly with no warning, no\nprevious data, and no model access.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0b2c454166b2c19d4f86dc1482304952c1009b46",
      "published_date": "2024-06-26",
      "downloaded_date": "2025-02-02",
      "filename": "Samothrakis-Games of Knightian Uncertainty as AGI testbeds.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2406.18178v2",
      "categories": [
        "cs.AI"
      ]
    },
    "1709.08071v2": {
      "title": "Autonomous Agents Modelling Other Agents: A Comprehensive Survey and Open Problems",
      "authors": [
        "Stefano V. Albrecht",
        "Peter Stone"
      ],
      "abstract": "Much research in artificial intelligence is concerned with the development of\nautonomous agents that can interact effectively with other agents. An important\naspect of such agents is the ability to reason about the behaviours of other\nagents, by constructing models which make predictions about various properties\nof interest (such as actions, goals, beliefs) of the modelled agents. A variety\nof modelling approaches now exist which vary widely in their methodology and\nunderlying assumptions, catering to the needs of the different sub-communities\nwithin which they were developed and reflecting the different practical uses\nfor which they are intended. The purpose of the present article is to provide a\ncomprehensive survey of the salient modelling methods which can be found in the\nliterature. The article concludes with a discussion of open problems which may\nform the basis for fruitful future research.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2017-09-23",
      "downloaded_date": "2025-02-02",
      "filename": "Albrecht-Autonomous Agents Modelling Other Agents A Comprehensive Survey and Open Problems.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1709.08071v2",
      "categories": [
        "cs.AI",
        "cs.MA",
        "I.2.11"
      ]
    },
    "2301.11977v1": {
      "title": "A Memory Efficient Deep Reinforcement Learning Approach For Snake Game Autonomous Agents",
      "authors": [
        "Md. Rafat Rahman Tushar",
        "Shahnewaz Siddique"
      ],
      "abstract": "To perform well, Deep Reinforcement Learning (DRL) methods require\nsignificant memory resources and computational time. Also, sometimes these\nsystems need additional environment information to achieve a good reward.\nHowever, it is more important for many applications and devices to reduce\nmemory usage and computational times than to achieve the maximum reward. This\npaper presents a modified DRL method that performs reasonably well with\ncompressed imagery data without requiring additional environment information\nand also uses less memory and time. We have designed a lightweight\nConvolutional Neural Network (CNN) with a variant of the Q-network that\nefficiently takes preprocessed image data as input and uses less memory.\nFurthermore, we use a simple reward mechanism and small experience replay\nmemory so as to provide only the minimum necessary information. Our modified\nDRL method enables our autonomous agent to play Snake, a classical control\ngame. The results show our model can achieve similar performance as other DRL\nmethods.",
      "citation_count": 2,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/fbaaedb9d9e219a3599d8f8a6db2b6e4ac45264b",
      "published_date": "2023-01-27",
      "downloaded_date": "2025-02-02",
      "filename": "Tushar-A Memory Efficient Deep Reinforcement Learning Approach For Snake Game Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2301.11977v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    "2403.12273v2": {
      "title": "Multimodal Human-Autonomous Agents Interaction Using Pre-Trained Language and Visual Foundation Models",
      "authors": [
        "Linus Nwankwo",
        "Elmar Rueckert"
      ],
      "abstract": "In this paper, we extended the method proposed in [21] to enable humans to\ninteract naturally with autonomous agents through vocal and textual\nconversations. Our extended method exploits the inherent capabilities of\npre-trained large language models (LLMs), multimodal visual language models\n(VLMs), and speech recognition (SR) models to decode the high-level natural\nlanguage conversations and semantic understanding of the robot's task\nenvironment, and abstract them to the robot's actionable commands or queries.\nWe performed a quantitative evaluation of our framework's natural vocal\nconversation understanding with participants from different racial backgrounds\nand English language accents. The participants interacted with the robot using\nboth spoken and textual instructional commands. Based on the logged interaction\ndata, our framework achieved 87.55% vocal commands decoding accuracy, 86.27%\ncommands execution success, and an average latency of 0.89 seconds from\nreceiving the participants' vocal chat commands to initiating the robot's\nactual physical action. The video demonstrations of this paper can be found at\nhttps://linusnep.github.io/MTCC-IRoNL/.",
      "citation_count": 1,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0e511a63fce114cb1568d228587caac175510200",
      "published_date": "2024-03-18",
      "downloaded_date": "2025-02-02",
      "filename": "Nwankwo-Multimodal Human-Autonomous Agents Interaction Using Pre-Trained Language and Visual Foundation Mode....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2403.12273v2",
      "categories": [
        "cs.RO"
      ]
    },
    "2407.04343v1": {
      "title": "Enhancing Safety for Autonomous Agents in Partly Concealed Urban Traffic Environments Through Representation-Based Shielding",
      "authors": [
        "Pierre Haritz",
        "David Wanke",
        "Thomas Liebig"
      ],
      "abstract": "Navigating unsignalized intersections in urban environments poses a complex\nchallenge for self-driving vehicles, where issues such as view obstructions,\nunpredictable pedestrian crossings, and diverse traffic participants demand a\ngreat focus on crash prevention. In this paper, we propose a novel state\nrepresentation for Reinforcement Learning (RL) agents centered around the\ninformation perceivable by an autonomous agent, enabling the safe navigation of\npreviously uncharted road maps. Our approach surpasses several baseline models\nby a sig nificant margin in terms of safety and energy consumption metrics.\nThese improvements are achieved while maintaining a competitive average travel\nspeed. Our findings pave the way for more robust and reliable autonomous\nnavigation strategies, promising safer and more efficient urban traffic\nenvironments.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-07-05",
      "downloaded_date": "2025-02-02",
      "filename": "Haritz-Enhancing Safety for Autonomous Agents in Partly Concealed Urban Traffic Environments Through Repres....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2407.04343v1",
      "categories": [
        "cs.RO",
        "cs.LG"
      ]
    },
    "2408.06458v2": {
      "title": "Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models",
      "authors": [
        "Abhishek Dutta",
        "Yen-Che Hsiao"
      ],
      "abstract": "We propose a novel in-context learning algorithm for building autonomous\ndecision-making language agents. The language agent continuously attempts to\nsolve the same task by self-correcting each time the task fails. Our selected\nlanguage agent demonstrates the ability to solve tasks in a text-based game\nenvironment. Our results show that the gemma-2-9b-it language model, using our\nproposed method, can successfully complete two of six tasks that failed in the\nfirst attempt. This highlights the effectiveness of our approach in enhancing\nthe problem-solving capabilities of a single language model through\nself-correction, paving the way for more advanced autonomous agents. The code\nis publicly available at\nhttps://github.com/YenCheHsiao/AutonomousLLMAgentwithAdaptingPlanning.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/48315d1ecda75ab5724c6378445276c1f3cfa52d",
      "published_date": "2024-08-12",
      "downloaded_date": "2025-02-02",
      "filename": "Dutta-Towards Autonomous Agents Adaptive-planning Reasoning and Acting in Language Models.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.06458v2",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    "2205.12295v1": {
      "title": "lpSpikeCon: Enabling Low-Precision Spiking Neural Network Processing for Efficient Unsupervised Continual Learning on Autonomous Agents",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Muhammad Shafique"
      ],
      "abstract": "Recent advances have shown that SNN-based systems can efficiently perform\nunsupervised continual learning due to their bio-plausible learning rule, e.g.,\nSpike-Timing-Dependent Plasticity (STDP). Such learning capabilities are\nespecially beneficial for use cases like autonomous agents (e.g., robots and\nUAVs) that need to continuously adapt to dynamically changing\nscenarios/environments, where new data gathered directly from the environment\nmay have novel features that should be learned online. Current state-of-the-art\nworks employ high-precision weights (i.e., 32 bit) for both training and\ninference phases, which pose high memory and energy costs thereby hindering\nefficient embedded implementations of such systems for battery-driven mobile\nautonomous systems. On the other hand, precision reduction may jeopardize the\nquality of unsupervised continual learning due to information loss. Towards\nthis, we propose lpSpikeCon, a novel methodology to enable low-precision SNN\nprocessing for efficient unsupervised continual learning on\nresource-constrained autonomous agents/systems. Our lpSpikeCon methodology\nemploys the following key steps: (1) analyzing the impacts of training the SNN\nmodel under unsupervised continual learning settings with reduced weight\nprecision on the inference accuracy; (2) leveraging this study to identify SNN\nparameters that have a significant impact on the inference accuracy; and (3)\ndeveloping an algorithm for searching the respective SNN parameter values that\nimprove the quality of unsupervised continual learning. The experimental\nresults show that our lpSpikeCon can reduce weight memory of the SNN model by\n8x (i.e., by judiciously employing 4-bit weights) for performing online\ntraining with unsupervised continual learning and achieve no accuracy loss in\nthe inference phase, as compared to the baseline model with 32-bit weights\nacross different network sizes.",
      "citation_count": 14,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/31488b19c621393155f6d59ca45696d0b686ef33",
      "published_date": "2022-05-24",
      "downloaded_date": "2025-02-02",
      "filename": "Putra-lpSpikeCon Enabling Low-Precision Spiking Neural Network Processing for Efficient Unsupervised Conti....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2205.12295v1",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ]
    },
    "2408.10654v1": {
      "title": "Incorporating a 'ladder of trust' into dynamic Allocation of Function in Human-Autonomous Agent Collectives",
      "authors": [
        "Chris Baber",
        "Patrick Waterson",
        "Sanja Milivojevic",
        "Sally Maynard",
        "Edmund R. Hunt",
        "Sagir Yusuf"
      ],
      "abstract": "A major, ongoing social transition is the inclusion of autonomous agents into\nhuman organizations. For example, in defence and security applications, robots\nmay be used alongside human operatives to reduce risk or add capability. But a\nkey barrier to the transition to successful human-autonomous agent collectives\nis the need for sufficient trust between team members. A critical enabling\nfactor for this trust will be a suitably designed dynamic allocation of\nfunction (AoF). We consider AoF in terms of a 'ladder of trust' (from low to\nhigh) with individual team members adjusting trust in their teammates based on\nvariation in 'score' over time. The score is derived by the ability of team\nmember to perceive and understand its situation based on the gathered\ninformation and act to acheive team or self goals. Combining these trust scores\ngives a system-level perspective on how AoF might be adjusted during a mission.\nThat is, the most suitable teammate for a function might have a low trust\nrating from its fellow teammates, so it might be preferable to choose the next\nmost suitable teammate for the function at that point in time. Of course, this\nis only in the situation where the next most suitable teammate is also likely\nto perform within the set framework of moral, ethical, and legal constraints.\nThe trade-offs between trust in the individual agent's capability and\npredictability need to be considered within the broader context of the agent's\nintegrity and accountability. From this perspective, the Allocation Space is\ndefined by more than ability of each agent to perform a function.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2024-08-20",
      "downloaded_date": "2025-02-02",
      "filename": "Baber-Incorporating a ladder of trust into dynamic Allocation of Function in Human-Autonomous Agent Collec....pdf",
      "arxiv_url": "http://arxiv.org/pdf/2408.10654v1",
      "categories": [
        "cs.HC"
      ]
    },
    "0803.0823v1": {
      "title": "Molecular Dynamics Study of Polarization Effects on AgI",
      "authors": [
        "Vicente BitriÃ¡n",
        "Joaquim TrullÃ s"
      ],
      "abstract": "Three different models of AgI are studied by molecular dynamics simulations.\nThe first one is the rigid ion model (RIM) with the effective pair potential of\nthe Vashishta and Rahman form and the parameterization proposed by Shimojo and\nKobayashi. The other two are polarizable ion models in which the induced\npolarization effects have been added to the RIM effective pair potential. In\none of them (PIM1) only the anions are assumed to be polarizable by the local\nelectric field. In the other one (PIM2s) the silver polarization is also\nincluded, and a short-range overlap induced polarization opposes the\nelectrically induced dipole moments. This short-range polarization is proved to\nbe necessary to avoid overpolarization when both species are assumed to be\npolarizable. The three models reproduce the superionic character of alpha-AgI\nat 573 K and the liquid behavior of molten AgI at 923 K. The averaged spatial\ndistribution of the cations in the alpha-phase obtained for PIM1 appears to be\nin better agreement with experimental data analysis. The PIM1 also reproduces\nthe structure factor prepeak at about 1 reciprocal angstrom observed from\nneutron diffraction data of molten AgI. The three models retain in the liquid\nphase the superionic character of alpha-AgI as the mobility of the cations is\nsignificantly larger than that for the anions. The ionic conductivity for the\npolarizable ion models is in better agreement with experimental data for\nalpha-AgI and molten AgI.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2008-03-06",
      "downloaded_date": "2025-02-02",
      "filename": "BitriÃ¡n-Molecular Dynamics Study of Polarization Effects on AgI.pdf",
      "arxiv_url": "http://arxiv.org/pdf/0803.0823v1",
      "categories": [
        "cond-mat.soft",
        "physics.chem-ph"
      ]
    },
    "0907.5118v1": {
      "title": "The Advanced Gamma-ray Imaging System (AGIS): Simulation Studies",
      "authors": [
        "G. Maier"
      ],
      "abstract": "The Advanced Gamma-ray Imaging System (AGIS) is a next-generation\nground-based gamma-ray observatory being planned in the U.S. The anticipated\nsensitivity of AGIS is about one order of magnitude better than the sensitivity\nof current observatories, allowing it to measure gammaray emmission from a\nlarge number of Galactic and extra-galactic sources. We present here results of\nsimulation studies of various possible designs for AGIS. The primary\ncharacteristics of the array performance - collecting area, angular resolution,\nbackground rejection, and sensitivity - are discussed.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2009-07-29",
      "downloaded_date": "2025-02-02",
      "filename": "Maier-The Advanced Gamma-ray Imaging System AGIS Simulation Studies.pdf",
      "arxiv_url": "http://arxiv.org/pdf/0907.5118v1",
      "categories": [
        "astro-ph.IM"
      ]
    },
    "1906.08663v1": {
      "title": "Modeling AGI Safety Frameworks with Causal Influence Diagrams",
      "authors": [
        "Tom Everitt",
        "Ramana Kumar",
        "Victoria Krakovna",
        "Shane Legg"
      ],
      "abstract": "Proposals for safe AGI systems are typically made at the level of frameworks,\nspecifying how the components of the proposed system should be trained and\ninteract with each other. In this paper, we model and compare the most\npromising AGI safety frameworks using causal influence diagrams. The diagrams\nshow the optimization objective and causal assumptions of the framework. The\nunified representation permits easy comparison of frameworks and their\nassumptions. We hope that the diagrams will serve as an accessible and visual\nintroduction to the main AGI safety frameworks.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-06-20",
      "downloaded_date": "2025-02-02",
      "filename": "Everitt-Modeling AGI Safety Frameworks with Causal Influence Diagrams.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1906.08663v1",
      "categories": [
        "cs.AI"
      ]
    },
    "1701.01487v1": {
      "title": "Designing a Safe Autonomous Artificial Intelligence Agent based on Human Self-Regulation",
      "authors": [
        "Mark Muraven"
      ],
      "abstract": "There is a growing focus on how to design safe artificial intelligent (AI)\nagents. As systems become more complex, poorly specified goals or control\nmechanisms may cause AI agents to engage in unwanted and harmful outcomes. Thus\nit is necessary to design AI agents that follow initial programming intentions\nas the program grows in complexity. How to specify these initial intentions has\nalso been an obstacle to designing safe AI agents. Finally, there is a need for\nthe AI agent to have redundant safety mechanisms to ensure that any programming\nerrors do not cascade into major problems. Humans are autonomous intelligent\nagents that have avoided these problems and the present manuscript argues that\nby understanding human self-regulation and goal setting, we may be better able\nto design safe AI agents. Some general principles of human self-regulation are\noutlined and specific guidance for AI design is given.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cbe8428141197ce9e9daf4e0952ab58b67cfcee6",
      "published_date": "2017-01-05",
      "downloaded_date": "2025-02-02",
      "filename": "Muraven-Designing a Safe Autonomous Artificial Intelligence Agent based on Human Self-Regulation.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1701.01487v1",
      "categories": [
        "cs.AI",
        "cs.SY"
      ]
    },
    "2409.07129v1": {
      "title": "MVLLaVA: An Intelligent Agent for Unified and Flexible Novel View Synthesis",
      "authors": [
        "Hanyu Jiang",
        "Jian Xue",
        "Xing Lan",
        "Guohong Hu",
        "Ke Lu"
      ],
      "abstract": "This paper introduces MVLLaVA, an intelligent agent designed for novel view\nsynthesis tasks. MVLLaVA integrates multiple multi-view diffusion models with a\nlarge multimodal model, LLaVA, enabling it to handle a wide range of tasks\nefficiently. MVLLaVA represents a versatile and unified platform that adapts to\ndiverse input types, including a single image, a descriptive caption, or a\nspecific change in viewing azimuth, guided by language instructions for\nviewpoint generation. We carefully craft task-specific instruction templates,\nwhich are subsequently used to fine-tune LLaVA. As a result, MVLLaVA acquires\nthe capability to generate novel view images based on user instructions,\ndemonstrating its flexibility across diverse tasks. Experiments are conducted\nto validate the effectiveness of MVLLaVA, demonstrating its robust performance\nand versatility in tackling diverse novel view synthesis challenges.",
      "citation_count": 0,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5ef017f3d5a2855693ee2e6cbd5d908530966625",
      "published_date": "2024-09-11",
      "downloaded_date": "2025-02-02",
      "filename": "Jiang-MVLLaVA An Intelligent Agent for Unified and Flexible Novel View Synthesis.pdf",
      "arxiv_url": "http://arxiv.org/pdf/2409.07129v1",
      "categories": [
        "cs.CV"
      ]
    },
    "math/0502342v1": {
      "title": "Flocking Control of Groups of Mobile Autonomous Agents via Local Feedback",
      "authors": [
        "Long Wang"
      ],
      "abstract": "This paper considers a group of mobile autonomous agents moving in Euclidean\nspace with point mass dynamics. We introduce a set of coordination control laws\nthat enable the group to generate the desired stable flocking motion. The\ncontrol laws are a combination of attractive/repulsive and alignment forces. By\nusing the control laws, all agent velocities asymptotically approach the\ndesired velocity, collisions can be avoided between agents, and the final tight\nformation minimizes all agent potentials. Moreover, we prove that the velocity\nof the center of mass is always equal to the desired velocity or exponentially\nconverges to the desired value. Furthermore, we study the motion of the group\nwhen the velocity damping is taken into account. In this case, we can properly\nmodify the control laws to generate the same stable flocking motion. Finally,\nfor the case that not all agents know the desired final velocity, we show that\nthe desired flocking motion can still be obtained. Numerical simulations are\nworked out to illustrate our theoretical results.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2005-02-16",
      "downloaded_date": "2025-02-02",
      "filename": "Wang-Flocking Control of Groups of Mobile Autonomous Agents via Local Feedback.pdf",
      "arxiv_url": "http://arxiv.org/pdf/math/0502342v1",
      "categories": [
        "math.ST",
        "math.DS",
        "stat.TH",
        "93"
      ]
    },
    "1403.4134v3": {
      "title": "Probabilistic and Distributed Control of a Large-Scale Swarm of Autonomous Agents",
      "authors": [
        "Saptarshi Bandyopadhyay",
        "Soon-Jo Chung",
        "Fred Y. Hadaegh"
      ],
      "abstract": "We present a novel method for guiding a large-scale swarm of autonomous\nagents into a desired formation shape in a distributed and scalable manner. Our\nProbabilistic Swarm Guidance using Inhomogeneous Markov Chains (PSG-IMC)\nalgorithm adopts an Eulerian framework, where the physical space is partitioned\ninto bins and the swarm's density distribution over each bin is controlled.\nEach agent determines its bin transition probabilities using a\ntime-inhomogeneous Markov chain. These time-varying Markov matrices are\nconstructed by each agent in real-time using the feedback from the current\nswarm distribution, which is estimated in a distributed manner. The PSG-IMC\nalgorithm minimizes the expected cost of the transitions per time instant,\nrequired to achieve and maintain the desired formation shape, even when agents\nare added to or removed from the swarm. The algorithm scales well with a large\nnumber of agents and complex formation shapes, and can also be adapted for area\nexploration applications. We demonstrate the effectiveness of this proposed\nswarm guidance algorithm by using results of numerical simulations and hardware\nexperiments with multiple quadrotors.",
      "citation_count": 96,
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/302e1d9578550209d70ac960293c3fba73288ad8",
      "published_date": "2014-03-17",
      "downloaded_date": "2025-02-02",
      "filename": "Bandyopadhyay-Probabilistic and Distributed Control of a Large-Scale Swarm of Autonomous Agents.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1403.4134v3",
      "categories": [
        "math.OC",
        "math.PR",
        "math.ST",
        "stat.TH"
      ]
    },
    "1405.7178v3": {
      "title": "Artificial Wrestling: A Dynamical Formulation of Autonomous Agents Fighting in a Coupled Inverted Pendula Framework",
      "authors": [
        "Katsutoshi Yoshida",
        "Shigeki Matsumoto",
        "Yoichi Matsue"
      ],
      "abstract": "We develop autonomous agents fighting with each other, inspired by human\nwrestling. For this purpose, we propose a coupled inverted pendula (CIP)\nframework in which: 1) tips of two inverted pendulums are linked by a\nconnection rod, 2) each pendulum is primarily stabilized by a PD-controller, 3)\nand is additionally equipped with an intelligent controller. Based on this\nframework, we dynamically formulate an intelligent controller designed to store\ndynamical correspondence from initial states to final states of the CIP model,\nto receive state vectors of the model, and to output impulsive control forces\nto produce desired final states of the model. Developing a quantized and\nreduced order design of this controller, we have a practical control procedure\nbased on an off-line learning method. We then conduct numerical simulations to\ninvestigate individual performance of the intelligent controller, showing that\nthe performance can be improved by adding a delay element into the intelligent\ncontroller. The result shows that the performance depends not only on\nquantization resolutions of learning data but also on delay time of the delay\nelement. Finally, we install the intelligent controllers into both pendulums in\nthe proposed framework to demonstrate autonomous competitive behavior between\ninverted pendulums.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2014-05-28",
      "downloaded_date": "2025-02-02",
      "filename": "Yoshida-Artificial Wrestling A Dynamical Formulation of Autonomous Agents Fighting in a Coupled Inverted Pen....pdf",
      "arxiv_url": "http://arxiv.org/pdf/1405.7178v3",
      "categories": [
        "cs.RO",
        "cs.SY"
      ]
    },
    "1906.12248v1": {
      "title": "Real-Time Digital Video Streaming at Low-VHF for Compact Autonomous Agents in Complex Scenes",
      "authors": [
        "Jihun Choi",
        "Chirag Rao",
        "Fikadu T. Dagefu"
      ],
      "abstract": "This paper presents an experimental investigation of real-time digital video\nstreaming in physically complex Non-Line-Of-Sight (NLoS) channels using a\nlow-power, low-VHF system integrated on a compact robotic platform. Reliable\nvideo streaming in NLoS channels over infrastructure-poor ad-hoc radio networks\nis challenging due to multipath and shadow fading. In this effort, we focus on\nexploiting the near-ground low-VHF channel which has been shown to have\nimproved penetration, reduced fading, and lower power requirements (which is\ncritical for autonomous agents with limited power) compared to higher\nfrequencies. Specifically, we develop a compact, low-power, low-VHF radio\ntest-bed enabled by recent advances in efficient miniature antennas and\noff-the-shelf software-defined radios. Our main goal is to carry out an\nempirical study in realistic environments of how the improved propagation\nconditions at low-VHF affect the reliability of video-streaming with\nconstraints stemming from the limited available bandwidth with electrically\nsmall low-VHF antennas. We show quantitative performance analysis of video\nstreaming from a robotic platform navigating inside a large occupied building\nreceived by a node located outdoors: bit error rate (BER) and channel-induced\nPeak Signal-to-Noise Ratio (PSNR) degradation. The results show\nchannel-effect-free-like video streaming with the low-VHF system in complex\nNLoS channels.",
      "citation_count": 0,
      "semantic_scholar_url": null,
      "published_date": "2019-06-28",
      "downloaded_date": "2025-02-02",
      "filename": "Choi-Real-Time Digital Video Streaming at Low-VHF for Compact Autonomous Agents in Complex Scenes.pdf",
      "arxiv_url": "http://arxiv.org/pdf/1906.12248v1",
      "categories": [
        "eess.IV",
        "eess.SP"
      ]
    }
  }
}